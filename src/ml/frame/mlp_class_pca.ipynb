{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f78aa7-15d8-4c44-8e24-810219393815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994720bf-b54a-4fb0-ae3c-eea3a5b39e24",
   "metadata": {},
   "source": [
    "<h1>Linear Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d4a403-460f-41ed-85f5-1942215d93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/results_complete_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0935dd9-210a-474b-9a82-aa077ca287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['elem_damaged', 'damage'], axis=1), df['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af628b4-0f5f-4722-bd9a-86c4e372bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "pca = PCA(.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab4ae95-f2fc-436c-acac-8ff44a1e1bc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                1160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 225)               4725      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,725\n",
      "Trainable params: 6,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 5.5383 - accuracy: 0.0229 - val_loss: 5.0489 - val_accuracy: 0.0633\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 4.7056 - accuracy: 0.1087 - val_loss: 4.3526 - val_accuracy: 0.1722\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 3.9930 - accuracy: 0.2460 - val_loss: 3.6090 - val_accuracy: 0.3387\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.2697 - accuracy: 0.4262 - val_loss: 2.9191 - val_accuracy: 0.5102\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.6383 - accuracy: 0.5710 - val_loss: 2.3527 - val_accuracy: 0.6444\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.1374 - accuracy: 0.6853 - val_loss: 1.9151 - val_accuracy: 0.7238\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7511 - accuracy: 0.7563 - val_loss: 1.5806 - val_accuracy: 0.7833\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4627 - accuracy: 0.7976 - val_loss: 1.3361 - val_accuracy: 0.8198\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2443 - accuracy: 0.8275 - val_loss: 1.1465 - val_accuracy: 0.8433\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0758 - accuracy: 0.8492 - val_loss: 0.9996 - val_accuracy: 0.8682\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9438 - accuracy: 0.8714 - val_loss: 0.8838 - val_accuracy: 0.8816\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.8375 - accuracy: 0.8875 - val_loss: 0.7913 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7494 - accuracy: 0.9011 - val_loss: 0.7166 - val_accuracy: 0.9067\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6794 - accuracy: 0.9106 - val_loss: 0.6569 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6222 - accuracy: 0.9195 - val_loss: 0.6069 - val_accuracy: 0.9247\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.9249 - val_loss: 0.5659 - val_accuracy: 0.9284\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.9320 - val_loss: 0.5350 - val_accuracy: 0.9327\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.4965 - accuracy: 0.9348 - val_loss: 0.4990 - val_accuracy: 0.9367\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4651 - accuracy: 0.9413 - val_loss: 0.4718 - val_accuracy: 0.9400\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4356 - accuracy: 0.9442 - val_loss: 0.4490 - val_accuracy: 0.9424\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4109 - accuracy: 0.9461 - val_loss: 0.4279 - val_accuracy: 0.9462\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3894 - accuracy: 0.9500 - val_loss: 0.4077 - val_accuracy: 0.9478\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3694 - accuracy: 0.9532 - val_loss: 0.3915 - val_accuracy: 0.9513\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.3512 - accuracy: 0.9545 - val_loss: 0.3807 - val_accuracy: 0.9531\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.9574 - val_loss: 0.3643 - val_accuracy: 0.9567\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.3190 - accuracy: 0.9601 - val_loss: 0.3517 - val_accuracy: 0.9582\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.9615 - val_loss: 0.3377 - val_accuracy: 0.9598\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.9635 - val_loss: 0.3363 - val_accuracy: 0.9578\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.9648 - val_loss: 0.3240 - val_accuracy: 0.9629\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2683 - accuracy: 0.9669 - val_loss: 0.3063 - val_accuracy: 0.9651\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2565 - accuracy: 0.9691 - val_loss: 0.3042 - val_accuracy: 0.9647\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2478 - accuracy: 0.9696 - val_loss: 0.2982 - val_accuracy: 0.9669\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2390 - accuracy: 0.9707 - val_loss: 0.2954 - val_accuracy: 0.9693\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9727 - val_loss: 0.2825 - val_accuracy: 0.9689\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2225 - accuracy: 0.9735 - val_loss: 0.2783 - val_accuracy: 0.9696\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2164 - accuracy: 0.9739 - val_loss: 0.2746 - val_accuracy: 0.9689\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2086 - accuracy: 0.9748 - val_loss: 0.2718 - val_accuracy: 0.9716\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2024 - accuracy: 0.9763 - val_loss: 0.2621 - val_accuracy: 0.9716\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1970 - accuracy: 0.9765 - val_loss: 0.2538 - val_accuracy: 0.9727\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1913 - accuracy: 0.9775 - val_loss: 0.2508 - val_accuracy: 0.9740\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1860 - accuracy: 0.9779 - val_loss: 0.2471 - val_accuracy: 0.9762\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1811 - accuracy: 0.9790 - val_loss: 0.2415 - val_accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9803 - val_loss: 0.2445 - val_accuracy: 0.9747\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1716 - accuracy: 0.9802 - val_loss: 0.2467 - val_accuracy: 0.9720\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1681 - accuracy: 0.9794 - val_loss: 0.2337 - val_accuracy: 0.9764\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1632 - accuracy: 0.9812 - val_loss: 0.2274 - val_accuracy: 0.9760\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1600 - accuracy: 0.9818 - val_loss: 0.2165 - val_accuracy: 0.9784\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1557 - accuracy: 0.9823 - val_loss: 0.2209 - val_accuracy: 0.9762\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9828 - val_loss: 0.2175 - val_accuracy: 0.9780\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.9831 - val_loss: 0.2165 - val_accuracy: 0.9784\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1456 - accuracy: 0.9828 - val_loss: 0.2163 - val_accuracy: 0.9787\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9837 - val_loss: 0.2146 - val_accuracy: 0.9800\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9839 - val_loss: 0.2105 - val_accuracy: 0.9796\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1357 - accuracy: 0.9848 - val_loss: 0.2155 - val_accuracy: 0.9793\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1340 - accuracy: 0.9848 - val_loss: 0.2039 - val_accuracy: 0.9787\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1304 - accuracy: 0.9855 - val_loss: 0.2103 - val_accuracy: 0.9802\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1279 - accuracy: 0.9858 - val_loss: 0.2061 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1250 - accuracy: 0.9852 - val_loss: 0.2042 - val_accuracy: 0.9820\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1232 - accuracy: 0.9861 - val_loss: 0.2091 - val_accuracy: 0.9809\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1207 - accuracy: 0.9867 - val_loss: 0.2038 - val_accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1181 - accuracy: 0.9865 - val_loss: 0.2028 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1161 - accuracy: 0.9873 - val_loss: 0.2000 - val_accuracy: 0.9802\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1138 - accuracy: 0.9872 - val_loss: 0.1995 - val_accuracy: 0.9818\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1124 - accuracy: 0.9878 - val_loss: 0.1918 - val_accuracy: 0.9820\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1100 - accuracy: 0.9874 - val_loss: 0.1985 - val_accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1089 - accuracy: 0.9881 - val_loss: 0.1990 - val_accuracy: 0.9827\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9880 - val_loss: 0.1973 - val_accuracy: 0.9818\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9881 - val_loss: 0.1910 - val_accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9887 - val_loss: 0.1794 - val_accuracy: 0.9829\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9890 - val_loss: 0.1871 - val_accuracy: 0.9844\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0992 - accuracy: 0.9884 - val_loss: 0.1868 - val_accuracy: 0.9844\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0975 - accuracy: 0.9896 - val_loss: 0.1868 - val_accuracy: 0.9838\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0956 - accuracy: 0.9895 - val_loss: 0.1911 - val_accuracy: 0.9831\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0950 - accuracy: 0.9897 - val_loss: 0.1996 - val_accuracy: 0.9836\n",
      "Epoch 75/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0934 - accuracy: 0.9901 - val_loss: 0.1806 - val_accuracy: 0.9851\n",
      "Epoch 76/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0914 - accuracy: 0.9905 - val_loss: 0.1837 - val_accuracy: 0.9838\n",
      "Epoch 77/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0902 - accuracy: 0.9909 - val_loss: 0.1819 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9902 - val_loss: 0.1726 - val_accuracy: 0.9851\n",
      "Epoch 79/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0874 - accuracy: 0.9903 - val_loss: 0.1831 - val_accuracy: 0.9831\n",
      "Epoch 80/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0862 - accuracy: 0.9908 - val_loss: 0.1839 - val_accuracy: 0.9844\n",
      "Epoch 81/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0850 - accuracy: 0.9907 - val_loss: 0.1838 - val_accuracy: 0.9844\n",
      "Epoch 82/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9907 - val_loss: 0.1867 - val_accuracy: 0.9849\n",
      "Epoch 83/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0821 - accuracy: 0.9909 - val_loss: 0.1970 - val_accuracy: 0.9856\n",
      "Epoch 84/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0818 - accuracy: 0.9917 - val_loss: 0.1920 - val_accuracy: 0.9844\n",
      "Epoch 85/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0801 - accuracy: 0.9917 - val_loss: 0.1865 - val_accuracy: 0.9844\n",
      "Epoch 86/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0789 - accuracy: 0.9916 - val_loss: 0.1885 - val_accuracy: 0.9864\n",
      "Epoch 87/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0777 - accuracy: 0.9915 - val_loss: 0.1721 - val_accuracy: 0.9858\n",
      "Epoch 88/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0766 - accuracy: 0.9918 - val_loss: 0.1733 - val_accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0759 - accuracy: 0.9922 - val_loss: 0.1776 - val_accuracy: 0.9849\n",
      "Epoch 90/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0750 - accuracy: 0.9920 - val_loss: 0.1751 - val_accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0737 - accuracy: 0.9922 - val_loss: 0.1890 - val_accuracy: 0.9856\n",
      "Epoch 92/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0728 - accuracy: 0.9929 - val_loss: 0.1720 - val_accuracy: 0.9864\n",
      "Epoch 93/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0727 - accuracy: 0.9927 - val_loss: 0.1682 - val_accuracy: 0.9856\n",
      "Epoch 94/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0707 - accuracy: 0.9929 - val_loss: 0.1662 - val_accuracy: 0.9873\n",
      "Epoch 95/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9926 - val_loss: 0.1670 - val_accuracy: 0.9869\n",
      "Epoch 96/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0693 - accuracy: 0.9931 - val_loss: 0.1622 - val_accuracy: 0.9869\n",
      "Epoch 97/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0689 - accuracy: 0.9930 - val_loss: 0.1620 - val_accuracy: 0.9858\n",
      "Epoch 98/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0678 - accuracy: 0.9929 - val_loss: 0.1682 - val_accuracy: 0.9873\n",
      "Epoch 99/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.0668 - accuracy: 0.9932 - val_loss: 0.1749 - val_accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0664 - accuracy: 0.9927 - val_loss: 0.1745 - val_accuracy: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class_pca\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class_pca\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 45.7 s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/linear_class_pca'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(int(pca.n_components_))))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9be2663-ca79-46a7-bbbb-460f09cce5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091fb9e5-5ea4-48ad-8868-5b2420ad7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 749us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b88275-d601-4d53-acb0-b20eab968fcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Components from PCA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04dbcc71-021e-4385-8366-06d2229a9938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037eccb-a72f-4f5b-ae4c-05c283ae69dd",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1c79d0-88fb-41e0-bdb7-0ec576ce2dbb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        19\n",
      "           1    1.00000   1.00000   1.00000        20\n",
      "           2    1.00000   1.00000   1.00000        19\n",
      "           3    1.00000   1.00000   1.00000        23\n",
      "           4    1.00000   1.00000   1.00000        26\n",
      "           5    1.00000   1.00000   1.00000        18\n",
      "           6    1.00000   1.00000   1.00000        24\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        17\n",
      "           9    1.00000   0.92308   0.96000        26\n",
      "          10    0.83333   1.00000   0.90909        25\n",
      "          11    1.00000   1.00000   1.00000        21\n",
      "          12    1.00000   1.00000   1.00000        23\n",
      "          13    1.00000   1.00000   1.00000        22\n",
      "          14    1.00000   1.00000   1.00000        23\n",
      "          15    1.00000   0.94444   0.97143        18\n",
      "          16    1.00000   1.00000   1.00000        16\n",
      "          17    0.88235   1.00000   0.93750        15\n",
      "          18    0.94737   1.00000   0.97297        18\n",
      "          19    1.00000   0.95652   0.97778        23\n",
      "          20    1.00000   1.00000   1.00000        19\n",
      "          21    1.00000   0.90476   0.95000        21\n",
      "          22    0.91304   1.00000   0.95455        21\n",
      "          23    1.00000   0.95833   0.97872        24\n",
      "          24    1.00000   0.95238   0.97561        21\n",
      "          25    1.00000   1.00000   1.00000        15\n",
      "          26    1.00000   1.00000   1.00000        25\n",
      "          27    1.00000   1.00000   1.00000        18\n",
      "          28    1.00000   1.00000   1.00000        18\n",
      "          29    1.00000   1.00000   1.00000        19\n",
      "          30    1.00000   0.95455   0.97674        22\n",
      "          31    1.00000   1.00000   1.00000        18\n",
      "          32    0.84211   1.00000   0.91429        16\n",
      "          33    1.00000   1.00000   1.00000        20\n",
      "          34    1.00000   1.00000   1.00000        17\n",
      "          35    1.00000   1.00000   1.00000        25\n",
      "          36    1.00000   0.92308   0.96000        13\n",
      "          37    0.91304   1.00000   0.95455        21\n",
      "          38    0.87500   1.00000   0.93333        21\n",
      "          39    1.00000   0.94737   0.97297        19\n",
      "          40    1.00000   1.00000   1.00000        18\n",
      "          41    1.00000   1.00000   1.00000        27\n",
      "          42    1.00000   0.95238   0.97561        21\n",
      "          43    0.93333   1.00000   0.96552        14\n",
      "          44    1.00000   1.00000   1.00000        18\n",
      "          45    0.80769   1.00000   0.89362        21\n",
      "          46    1.00000   0.88889   0.94118         9\n",
      "          47    1.00000   0.92857   0.96296        14\n",
      "          48    1.00000   1.00000   1.00000        19\n",
      "          49    1.00000   0.92308   0.96000        13\n",
      "          50    1.00000   1.00000   1.00000        27\n",
      "          51    1.00000   0.91667   0.95652        24\n",
      "          52    1.00000   0.83333   0.90909        18\n",
      "          53    0.95652   1.00000   0.97778        22\n",
      "          54    1.00000   0.91304   0.95455        23\n",
      "          55    1.00000   1.00000   1.00000        19\n",
      "          56    1.00000   0.94737   0.97297        19\n",
      "          57    0.95455   1.00000   0.97674        21\n",
      "          58    1.00000   0.95238   0.97561        21\n",
      "          59    1.00000   0.96154   0.98039        26\n",
      "          60    1.00000   1.00000   1.00000        21\n",
      "          61    1.00000   1.00000   1.00000        25\n",
      "          62    1.00000   1.00000   1.00000        19\n",
      "          63    1.00000   1.00000   1.00000        23\n",
      "          64    1.00000   0.94737   0.97297        19\n",
      "          65    0.95652   1.00000   0.97778        22\n",
      "          66    1.00000   1.00000   1.00000        18\n",
      "          67    1.00000   1.00000   1.00000        19\n",
      "          68    1.00000   1.00000   1.00000        23\n",
      "          69    1.00000   1.00000   1.00000        21\n",
      "          70    1.00000   1.00000   1.00000        12\n",
      "          71    1.00000   0.95652   0.97778        23\n",
      "          72    0.85714   1.00000   0.92308        18\n",
      "          73    0.88889   1.00000   0.94118        16\n",
      "          74    1.00000   0.95000   0.97436        20\n",
      "          75    1.00000   0.95000   0.97436        20\n",
      "          76    0.95833   1.00000   0.97872        23\n",
      "          77    1.00000   1.00000   1.00000        21\n",
      "          78    1.00000   1.00000   1.00000        19\n",
      "          79    1.00000   1.00000   1.00000        31\n",
      "          80    0.88235   1.00000   0.93750        30\n",
      "          81    1.00000   1.00000   1.00000        13\n",
      "          82    1.00000   0.92308   0.96000        13\n",
      "          83    1.00000   1.00000   1.00000        25\n",
      "          84    1.00000   1.00000   1.00000        22\n",
      "          85    1.00000   1.00000   1.00000        19\n",
      "          86    1.00000   1.00000   1.00000        16\n",
      "          87    0.70833   1.00000   0.82927        17\n",
      "          88    1.00000   1.00000   1.00000        18\n",
      "          89    1.00000   1.00000   1.00000        26\n",
      "          90    1.00000   1.00000   1.00000        16\n",
      "          91    1.00000   1.00000   1.00000        20\n",
      "          92    1.00000   1.00000   1.00000        21\n",
      "          93    1.00000   1.00000   1.00000        12\n",
      "          94    0.95000   0.90476   0.92683        21\n",
      "          95    1.00000   1.00000   1.00000        16\n",
      "          96    1.00000   1.00000   1.00000        21\n",
      "          97    1.00000   0.96154   0.98039        26\n",
      "          98    1.00000   1.00000   1.00000        25\n",
      "          99    0.94118   1.00000   0.96970        16\n",
      "         100    0.95238   0.95238   0.95238        21\n",
      "         101    1.00000   1.00000   1.00000        24\n",
      "         102    1.00000   1.00000   1.00000        20\n",
      "         103    1.00000   1.00000   1.00000        15\n",
      "         104    1.00000   1.00000   1.00000        15\n",
      "         105    1.00000   0.93333   0.96552        15\n",
      "         106    1.00000   0.91304   0.95455        23\n",
      "         107    0.95238   1.00000   0.97561        20\n",
      "         108    1.00000   1.00000   1.00000        25\n",
      "         109    1.00000   1.00000   1.00000        26\n",
      "         110    1.00000   0.95652   0.97778        23\n",
      "         111    0.95652   1.00000   0.97778        22\n",
      "         112    1.00000   1.00000   1.00000        18\n",
      "         113    1.00000   0.96296   0.98113        27\n",
      "         114    0.83333   1.00000   0.90909        15\n",
      "         115    1.00000   0.94118   0.96970        17\n",
      "         116    1.00000   1.00000   1.00000        23\n",
      "         117    1.00000   1.00000   1.00000        19\n",
      "         118    1.00000   1.00000   1.00000        19\n",
      "         119    1.00000   1.00000   1.00000        18\n",
      "         120    1.00000   1.00000   1.00000        23\n",
      "         121    1.00000   1.00000   1.00000        17\n",
      "         122    1.00000   1.00000   1.00000        19\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    1.00000   0.95000   0.97436        20\n",
      "         126    1.00000   1.00000   1.00000        16\n",
      "         127    1.00000   1.00000   1.00000        23\n",
      "         128    1.00000   1.00000   1.00000        16\n",
      "         129    1.00000   1.00000   1.00000        12\n",
      "         130    1.00000   1.00000   1.00000        20\n",
      "         131    0.96000   1.00000   0.97959        24\n",
      "         132    1.00000   1.00000   1.00000        21\n",
      "         133    1.00000   0.78571   0.88000        14\n",
      "         134    0.93750   1.00000   0.96774        15\n",
      "         135    1.00000   1.00000   1.00000        20\n",
      "         136    1.00000   1.00000   1.00000        26\n",
      "         137    1.00000   1.00000   1.00000        14\n",
      "         138    1.00000   0.95238   0.97561        21\n",
      "         139    1.00000   1.00000   1.00000        20\n",
      "         140    1.00000   1.00000   1.00000        23\n",
      "         141    1.00000   1.00000   1.00000        21\n",
      "         142    1.00000   1.00000   1.00000        17\n",
      "         143    1.00000   1.00000   1.00000        14\n",
      "         144    1.00000   1.00000   1.00000        23\n",
      "         145    1.00000   1.00000   1.00000        13\n",
      "         146    1.00000   0.96296   0.98113        27\n",
      "         147    1.00000   0.92857   0.96296        28\n",
      "         148    0.88462   1.00000   0.93878        23\n",
      "         149    0.92000   1.00000   0.95833        23\n",
      "         150    1.00000   0.88462   0.93878        26\n",
      "         151    1.00000   0.95238   0.97561        21\n",
      "         152    1.00000   1.00000   1.00000        25\n",
      "         153    1.00000   1.00000   1.00000        19\n",
      "         154    1.00000   1.00000   1.00000        22\n",
      "         155    1.00000   1.00000   1.00000        16\n",
      "         156    1.00000   1.00000   1.00000        23\n",
      "         157    1.00000   0.94118   0.96970        17\n",
      "         158    1.00000   0.95455   0.97674        22\n",
      "         159    1.00000   0.95000   0.97436        20\n",
      "         160    0.95652   1.00000   0.97778        22\n",
      "         161    1.00000   1.00000   1.00000        23\n",
      "         162    1.00000   1.00000   1.00000        14\n",
      "         163    1.00000   1.00000   1.00000        23\n",
      "         164    1.00000   1.00000   1.00000        18\n",
      "         165    1.00000   1.00000   1.00000        30\n",
      "         166    1.00000   1.00000   1.00000        19\n",
      "         167    1.00000   1.00000   1.00000        24\n",
      "         168    0.92857   1.00000   0.96296        13\n",
      "         169    1.00000   1.00000   1.00000        15\n",
      "         170    1.00000   0.96154   0.98039        26\n",
      "         171    0.95238   1.00000   0.97561        20\n",
      "         172    1.00000   1.00000   1.00000        22\n",
      "         173    1.00000   0.84615   0.91667        13\n",
      "         174    1.00000   1.00000   1.00000        20\n",
      "         175    1.00000   0.95652   0.97778        23\n",
      "         176    0.94737   0.94737   0.94737        19\n",
      "         177    1.00000   1.00000   1.00000        18\n",
      "         178    1.00000   1.00000   1.00000        16\n",
      "         179    1.00000   1.00000   1.00000        24\n",
      "         180    1.00000   1.00000   1.00000        22\n",
      "         181    1.00000   0.90909   0.95238        11\n",
      "         182    1.00000   1.00000   1.00000        15\n",
      "         183    1.00000   1.00000   1.00000        25\n",
      "         184    1.00000   1.00000   1.00000        17\n",
      "         185    1.00000   1.00000   1.00000        19\n",
      "         186    1.00000   1.00000   1.00000        27\n",
      "         187    1.00000   1.00000   1.00000        20\n",
      "         188    1.00000   1.00000   1.00000        26\n",
      "         189    1.00000   0.96667   0.98305        30\n",
      "         190    0.94737   1.00000   0.97297        18\n",
      "         191    1.00000   1.00000   1.00000        19\n",
      "         192    1.00000   1.00000   1.00000        14\n",
      "         193    1.00000   1.00000   1.00000        20\n",
      "         194    1.00000   1.00000   1.00000        23\n",
      "         195    1.00000   1.00000   1.00000        23\n",
      "         196    1.00000   1.00000   1.00000        22\n",
      "         197    1.00000   0.93333   0.96552        15\n",
      "         198    1.00000   1.00000   1.00000        20\n",
      "         199    1.00000   1.00000   1.00000        20\n",
      "         200    1.00000   1.00000   1.00000        19\n",
      "         201    1.00000   1.00000   1.00000        23\n",
      "         202    1.00000   0.88235   0.93750        17\n",
      "         203    0.93103   1.00000   0.96429        27\n",
      "         204    1.00000   1.00000   1.00000        14\n",
      "         205    1.00000   1.00000   1.00000        17\n",
      "         206    1.00000   0.92308   0.96000        13\n",
      "         207    1.00000   1.00000   1.00000        22\n",
      "         208    1.00000   1.00000   1.00000        21\n",
      "         209    0.93750   1.00000   0.96774        15\n",
      "         210    1.00000   0.95455   0.97674        22\n",
      "         211    1.00000   1.00000   1.00000        25\n",
      "         212    1.00000   1.00000   1.00000        18\n",
      "         213    1.00000   1.00000   1.00000        12\n",
      "         214    1.00000   1.00000   1.00000        19\n",
      "         215    1.00000   1.00000   1.00000        24\n",
      "         216    1.00000   1.00000   1.00000        17\n",
      "         217    1.00000   1.00000   1.00000        22\n",
      "         218    1.00000   1.00000   1.00000        20\n",
      "         219    1.00000   0.94118   0.96970        17\n",
      "         220    0.92857   1.00000   0.96296        13\n",
      "         221    1.00000   1.00000   1.00000        21\n",
      "         222    1.00000   1.00000   1.00000        13\n",
      "         223    1.00000   1.00000   1.00000        21\n",
      "         224    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        0.98489      4500\n",
      "   macro avg    0.98634   0.98408   0.98442      4500\n",
      "weighted avg    0.98675   0.98489   0.98509      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51af58-9ede-46e3-99ed-0164c6834c82",
   "metadata": {},
   "source": [
    "<h1>Exponential Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda86b57-083d-4b8a-879c-09a51d46aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.read_csv('input/results_complete_exponential.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eff74c0-769f-4685-9a72-f69724210c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_exp.drop(['elem_damaged', 'damage'], axis=1), df_exp['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815cc01f-7962-4f05-b49d-1de62fd5eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "pca = PCA(.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c553a7-f94f-43df-9032-385155de8e94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 20)                1220      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 225)               4725      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,785\n",
      "Trainable params: 6,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 5.3980 - accuracy: 0.0393 - val_loss: 4.7556 - val_accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 4.2768 - accuracy: 0.1831 - val_loss: 3.7860 - val_accuracy: 0.2573\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.3628 - accuracy: 0.3716 - val_loss: 2.9444 - val_accuracy: 0.4762\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.6074 - accuracy: 0.5560 - val_loss: 2.2770 - val_accuracy: 0.6218\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.0320 - accuracy: 0.6723 - val_loss: 1.7972 - val_accuracy: 0.7098\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.6237 - accuracy: 0.7500 - val_loss: 1.4547 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3339 - accuracy: 0.8019 - val_loss: 1.2158 - val_accuracy: 0.8198\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1238 - accuracy: 0.8327 - val_loss: 1.0380 - val_accuracy: 0.8451\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9673 - accuracy: 0.8591 - val_loss: 0.9061 - val_accuracy: 0.8689\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8461 - accuracy: 0.8777 - val_loss: 0.8074 - val_accuracy: 0.8804\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7523 - accuracy: 0.8930 - val_loss: 0.7250 - val_accuracy: 0.8978\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6768 - accuracy: 0.9058 - val_loss: 0.6618 - val_accuracy: 0.9116\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6160 - accuracy: 0.9169 - val_loss: 0.6093 - val_accuracy: 0.9193\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5654 - accuracy: 0.9249 - val_loss: 0.5670 - val_accuracy: 0.9256\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5223 - accuracy: 0.9310 - val_loss: 0.5298 - val_accuracy: 0.9309\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4858 - accuracy: 0.9370 - val_loss: 0.4925 - val_accuracy: 0.9409\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4537 - accuracy: 0.9417 - val_loss: 0.4693 - val_accuracy: 0.9440\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4257 - accuracy: 0.9461 - val_loss: 0.4453 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4012 - accuracy: 0.9500 - val_loss: 0.4275 - val_accuracy: 0.9462\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3799 - accuracy: 0.9528 - val_loss: 0.4114 - val_accuracy: 0.9527\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3606 - accuracy: 0.9569 - val_loss: 0.3935 - val_accuracy: 0.9518\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3438 - accuracy: 0.9581 - val_loss: 0.3811 - val_accuracy: 0.9553\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3280 - accuracy: 0.9607 - val_loss: 0.3637 - val_accuracy: 0.9584\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3140 - accuracy: 0.9617 - val_loss: 0.3538 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3011 - accuracy: 0.9641 - val_loss: 0.3486 - val_accuracy: 0.9602\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2909 - accuracy: 0.9650 - val_loss: 0.3376 - val_accuracy: 0.9624\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2804 - accuracy: 0.9676 - val_loss: 0.3274 - val_accuracy: 0.9620\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2706 - accuracy: 0.9681 - val_loss: 0.3207 - val_accuracy: 0.9640\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.2616 - accuracy: 0.9694 - val_loss: 0.3116 - val_accuracy: 0.9653\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2532 - accuracy: 0.9713 - val_loss: 0.3074 - val_accuracy: 0.9660\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2455 - accuracy: 0.9718 - val_loss: 0.2995 - val_accuracy: 0.9656\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2379 - accuracy: 0.9721 - val_loss: 0.2934 - val_accuracy: 0.9682\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2314 - accuracy: 0.9738 - val_loss: 0.2881 - val_accuracy: 0.9664\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2244 - accuracy: 0.9737 - val_loss: 0.2801 - val_accuracy: 0.9682\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2189 - accuracy: 0.9748 - val_loss: 0.2800 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2134 - accuracy: 0.9756 - val_loss: 0.2743 - val_accuracy: 0.9689\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2077 - accuracy: 0.9769 - val_loss: 0.2636 - val_accuracy: 0.9707\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2025 - accuracy: 0.9776 - val_loss: 0.2702 - val_accuracy: 0.9691\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1975 - accuracy: 0.9773 - val_loss: 0.2602 - val_accuracy: 0.9720\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1928 - accuracy: 0.9781 - val_loss: 0.2601 - val_accuracy: 0.9729\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1886 - accuracy: 0.9784 - val_loss: 0.2600 - val_accuracy: 0.9740\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1844 - accuracy: 0.9791 - val_loss: 0.2586 - val_accuracy: 0.9738\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1795 - accuracy: 0.9799 - val_loss: 0.2553 - val_accuracy: 0.9753\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1764 - accuracy: 0.9807 - val_loss: 0.2496 - val_accuracy: 0.9731\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1725 - accuracy: 0.9799 - val_loss: 0.2486 - val_accuracy: 0.9767\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1695 - accuracy: 0.9816 - val_loss: 0.2466 - val_accuracy: 0.9742\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1658 - accuracy: 0.9817 - val_loss: 0.2469 - val_accuracy: 0.9756\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1627 - accuracy: 0.9822 - val_loss: 0.2399 - val_accuracy: 0.9740\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1596 - accuracy: 0.9824 - val_loss: 0.2419 - val_accuracy: 0.9767\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 1s 1ms/step - loss: 0.1560 - accuracy: 0.9824 - val_loss: 0.2431 - val_accuracy: 0.9787\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1536 - accuracy: 0.9826 - val_loss: 0.2378 - val_accuracy: 0.9780\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1519 - accuracy: 0.9833 - val_loss: 0.2392 - val_accuracy: 0.9764\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1484 - accuracy: 0.9832 - val_loss: 0.2336 - val_accuracy: 0.9782\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1455 - accuracy: 0.9838 - val_loss: 0.2341 - val_accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1429 - accuracy: 0.9844 - val_loss: 0.2318 - val_accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1403 - accuracy: 0.9845 - val_loss: 0.2283 - val_accuracy: 0.9784\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1384 - accuracy: 0.9847 - val_loss: 0.2287 - val_accuracy: 0.9793\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1371 - accuracy: 0.9847 - val_loss: 0.2253 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1345 - accuracy: 0.9851 - val_loss: 0.2275 - val_accuracy: 0.9818\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1311 - accuracy: 0.9856 - val_loss: 0.2203 - val_accuracy: 0.9769\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1298 - accuracy: 0.9859 - val_loss: 0.2270 - val_accuracy: 0.9802\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1278 - accuracy: 0.9861 - val_loss: 0.2250 - val_accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1264 - accuracy: 0.9856 - val_loss: 0.2309 - val_accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1232 - accuracy: 0.9862 - val_loss: 0.2254 - val_accuracy: 0.9796\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1211 - accuracy: 0.9863 - val_loss: 0.2315 - val_accuracy: 0.9798\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1192 - accuracy: 0.9868 - val_loss: 0.2317 - val_accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1182 - accuracy: 0.9872 - val_loss: 0.2163 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1165 - accuracy: 0.9878 - val_loss: 0.2147 - val_accuracy: 0.9838\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1154 - accuracy: 0.9874 - val_loss: 0.2154 - val_accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1125 - accuracy: 0.9879 - val_loss: 0.2130 - val_accuracy: 0.9816\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1120 - accuracy: 0.9877 - val_loss: 0.2169 - val_accuracy: 0.9838\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1095 - accuracy: 0.9881 - val_loss: 0.2092 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1091 - accuracy: 0.9884 - val_loss: 0.2179 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1063 - accuracy: 0.9883 - val_loss: 0.2212 - val_accuracy: 0.9818\n",
      "Epoch 75/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1061 - accuracy: 0.9890 - val_loss: 0.2233 - val_accuracy: 0.9827\n",
      "Epoch 76/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1052 - accuracy: 0.9887 - val_loss: 0.2205 - val_accuracy: 0.9831\n",
      "Epoch 77/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1029 - accuracy: 0.9897 - val_loss: 0.2206 - val_accuracy: 0.9829\n",
      "Epoch 78/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1022 - accuracy: 0.9894 - val_loss: 0.2165 - val_accuracy: 0.9798\n",
      "Epoch 79/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1011 - accuracy: 0.9888 - val_loss: 0.2274 - val_accuracy: 0.9824\n",
      "Epoch 80/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0994 - accuracy: 0.9893 - val_loss: 0.2196 - val_accuracy: 0.9818\n",
      "Epoch 81/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0985 - accuracy: 0.9895 - val_loss: 0.2175 - val_accuracy: 0.9856\n",
      "Epoch 82/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0967 - accuracy: 0.9901 - val_loss: 0.2235 - val_accuracy: 0.9844\n",
      "Epoch 83/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0957 - accuracy: 0.9904 - val_loss: 0.2251 - val_accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0948 - accuracy: 0.9902 - val_loss: 0.2230 - val_accuracy: 0.9827\n",
      "Epoch 85/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0939 - accuracy: 0.9902 - val_loss: 0.2177 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0916 - accuracy: 0.9909 - val_loss: 0.2238 - val_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0910 - accuracy: 0.9903 - val_loss: 0.2250 - val_accuracy: 0.9860\n",
      "Epoch 88/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0900 - accuracy: 0.9907 - val_loss: 0.2190 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0887 - accuracy: 0.9908 - val_loss: 0.2182 - val_accuracy: 0.9849\n",
      "Epoch 90/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0880 - accuracy: 0.9909 - val_loss: 0.2272 - val_accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0871 - accuracy: 0.9909 - val_loss: 0.2246 - val_accuracy: 0.9847\n",
      "Epoch 92/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0870 - accuracy: 0.9911 - val_loss: 0.2261 - val_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0861 - accuracy: 0.9911 - val_loss: 0.2316 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9915 - val_loss: 0.2237 - val_accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0838 - accuracy: 0.9911 - val_loss: 0.2202 - val_accuracy: 0.9858\n",
      "Epoch 96/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9913 - val_loss: 0.2297 - val_accuracy: 0.9847\n",
      "Epoch 97/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0817 - accuracy: 0.9917 - val_loss: 0.2192 - val_accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0811 - accuracy: 0.9916 - val_loss: 0.2244 - val_accuracy: 0.9851\n",
      "Epoch 99/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0802 - accuracy: 0.9917 - val_loss: 0.2326 - val_accuracy: 0.9860\n",
      "Epoch 100/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0789 - accuracy: 0.9920 - val_loss: 0.2232 - val_accuracy: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses, leaky_re_lu_4_layer_call_fn, leaky_re_lu_4_layer_call_and_return_conditional_losses, leaky_re_lu_5_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/exp_class_pca\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/exp_class_pca\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 41.7 s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/exp_class_pca'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(int(pca.n_components_))))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d48b8bb-4050-4e4e-9b5d-f544ec904945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 776us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6579e5bf-16c8-43a8-92cd-cc0d9974cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4xElEQVR4nO3de3hc1X3/+8+eq2akGd1sSZYtX8AGY8DEQHAcCOUEJ0B4SKBpT8NxGkpykh+p+RXKr23i5oQ0SYnpoSdPEsITkvyScM4B4kBPIAltoMQECAUbMDbhajDYWMaWZV1H0khz2/v8sfaMJN/QSHOxZt6v59nPlmb2zKzZkj0ffdfaa1mO4zgCAAAoAE+5GwAAACoHwQIAABQMwQIAABQMwQIAABQMwQIAABQMwQIAABQMwQIAABQMwQIAABSMr9QvaNu29u/fr0gkIsuySv3yAABgGhzH0dDQkNrb2+XxHLsuUfJgsX//fnV0dJT6ZQEAQAF0dnZqwYIFx7y/5MEiEolIMg2LRqOlfnkAADANsVhMHR0duc/xYyl5sMh2f0SjUYIFAACzzHsNY2DwJgAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKBiCBQAAKJiKCRbffvQN/eMDL6lnOFHupgAAULUqJlj8/Nm9unfrXh2MjZW7KQAAVK2KCRbRGrMC/OBoqswtAQCgelVMsKgP+SVJsdF0mVsCAED1qphgEc0FCyoWAACUS8UEi1zFYoxgAQBAuVRMsIjWmGDBGAsAAMqnYoJFPV0hAACUXcUEi2iIq0IAACi3ygkWNdkxFlwVAgBAuVRMsKArBACA8quYYJG93JSuEAAAyqdiggWXmwIAUH4VEyy43BQAgPKrmGCRrViMpWwl0pkytwYAgOpUMcGizl2ETGK9EAAAyqVigoXXYynihgvGWQAAUB4VEywkxlkAAFBuFRUsmMsCAIDyqqhgwbTeAACUV0UFi/G5LBi8CQBAOVRUsMitF0LFAgCAssgrWPzTP/2TLMuatC1fvrxYbcsbYywAACgv33sfMtnpp5+u3/3ud+NP4Mv7KYomyrTeAACUVd6pwOfzqa2trRhtmbF6FiIDAKCs8h5j8eabb6q9vV0nnXSS1q1bp7179xajXdOSvSqEmTcBACiPvCoWq1ev1l133aVTTz1VBw4c0Ne//nV96EMf0ssvv6xIJHLUxyQSCSUSidz3sVhsZi0+DibIAgCgvPIKFpdddlnu65UrV2r16tVatGiR7rvvPn3uc5876mM2btyor3/96zNr5RSxdDoAAOU1o8tNGxoadMopp2jXrl3HPGbDhg0aHBzMbZ2dnTN5yeOKMsYCAICymlGwGB4e1ltvvaV58+Yd85hgMKhoNDppK5aJl5s6jlO01wEAAEeXV7D4u7/7Oz3xxBPas2ePnn76aV111VXyer26+uqri9W+vGTHWNiONJxgACcAAKWW1xiLffv26eqrr1Zvb6/mzp2rCy64QFu2bNHcuXOL1b681Pg9Cng9SmZsxcbSirhBAwAAlEZewWLTpk3FakdBWJalaMinnuGkBuMpzW8IlbtJAABUlYpaK0Ri9k0AAMqp8oIFc1kAAFA2FRcsWIgMAIDyqbhgwVwWAACUT8UFi/rseiFjXG4KAECpVVywyI6xoCsEAIDSq7hgwRgLAADKp7KCRSalaI1XEpebAgBQDpUTLL69QvrmHLVn9kti8CYAAOVQOcHCYyoVDRqWJMVGGbwJAECpVU6wCDVJkuo1JImKBQAA5VA5wSJsgkWdHZPEGAsAAMqhcoKFW7EIp02wiCczSmXscrYIAICqUznBwq1Y1KQGcjdxySkAAKVVOcHCrVh4xvpVFzSzbzLOAgCA0qqcYOFWLDTaNz5JFtN6AwBQUpUTLNyKheJ9itRQsQAAoBwqJ1iEG81+tJ9pvQEAKJPKCRYTKhbRXFcIwQIAgFKqnGBxlDEWdIUAAFBalRMsshWL9JiaAhlJTOsNAECpVU6wCEYkjxm02eobkUTFAgCAUqucYGFZuarFHK+7EBljLAAAKKnKCRZSbpxFk2UqFlwVAgBAaVVWsDhshVOCBQAApVVZwcKtWEQdlk4HAKAcKitYhMwkWbWZ7NLpXBUCAEApVVawCGeXTh+UZCoWjuOUs0UAAFSVygoW7hiLoLt0esZ2FE9mytggAACqS2UFi3CzJMmbGJDfa0linAUAAKVUYcHCVCyseJ+iNawXAgBAqVVWsAiNrxeSW4iMab0BACiZygoW4SNXOKUrBACA0qmsYJGtWIwNqj5oxlgwSRYAAKVTYcGi0f3C0bxgQhIVCwAASqmygoXXJwXrJUmtvrgkBm8CAFBKlRUsJClsqhYtLJ0OAEDJVV6wCGVXOHWXTueqEAAASqbygoV7ZUijGyyoWAAAUDqVFywOWzp9cDRZztYAAFBVKi9YHLZ0en+cigUAAKVSecHCrVhkl07vH6FiAQBAqVResHArFiF36fT+eFK2zdLpAACUQuUFC3eSrECyX5JkOwzgBACgVCovWLgVC89ovyI1PklSX5zuEAAASqHygkVofCGyptqAJMZZAABQKpUXLMLjS6c3uiuc9hEsAAAoicoLFtmKRSapeWFbEsECAIBSqbxgEaiVvKYLZEFwVBJjLAAAKJXKCxaWlatatAXMCqeMsQAAoDQqL1hIuXEWLV4TLPpGuNwUAIBSqMxg4VYsmr1mIbJ+ukIAACiJygwWYTNJVqNMsGDwJgAApTGjYHHrrbfKsizdeOONBWpOgRy2winBAgCA0ph2sHjuuef0wx/+UCtXrixkewojzEJkAACUw7SCxfDwsNatW6cf//jHamxsLHSbZi7cLGl8IbKhRFrJtF3OFgEAUBWmFSzWr1+vyy+/XGvXrn3PYxOJhGKx2KSt6NyuEH9iQB7L3DTAAE4AAIou72CxadMmvfDCC9q4ceOUjt+4caPq6+tzW0dHR96NzJvbFWKN9qkxbCbLYpIsAACKL69g0dnZqRtuuEH33HOPampqpvSYDRs2aHBwMLd1dnZOq6F5CU1YL8RdiKxvmGABAECx+fI5eNu2beru7tbZZ5+duy2TyejJJ5/U97//fSUSCXm93kmPCQaDCgaDhWntVGUXIov3q6mJigUAAKWSV7C4+OKL9dJLL0267dprr9Xy5cv1pS996YhQUTbZikViUHNCpk1cGQIAQPHlFSwikYjOOOOMSbfV1taqubn5iNvLKtQgyZLkqL1mTBLTegMAUAqVOfOmxyvV1EuS5vlHJDGtNwAApZBXxeJoHn/88QI0owjCTdLYgFp8cUk1zL4JAEAJVGbFQsqNs5jrNRULggUAAMVXucHCvTKkgfVCAAAomcoNFoctRMYYCwAAiq9yg0VuIbLxioXjOOVsEQAAFa9yg4VbscguRJZI2xpNZcrZIgAAKl7lBouwWXXVl+hX0GfeZi/TegMAUFQVHCzM0ulWvFdN7nohjLMAAKC4KjdY1M41+5Ge8RVOuTIEAICiqvxgEe+hYgEAQIlUfrAY7Vdz2LxN1gsBAKC4KjdY1DRIllnZtCMYl8QKpwAAFFvlBguPJzeAc553WJLUS7AAAKCoKjdYSLnukFZvTBIVCwAAiq3Cg8UcSVKzZYJFH4M3AQAoqgoPFqZi0eCY2TepWAAAUFxVESwimQFJXG4KAECxVXiwMF0htak+SVJ/PCXbZiEyAACKpcKDhalYBJMmWGRsR7Ex5rIAAKBYqiJYeOI9igR9kpjWGwCAYqqKYKGRQ2pkWm8AAIquwoOFGWOhkZ5csGBabwAAiqfCg4VbsUjFNS+UkST1jSTK2CAAACpbZQeLQK3kC0mSOgIjkqhYAABQTJUdLCwrV7Vo95v1QhhjAQBA8VR2sJBy4yxavEOSuCoEAIBiqppgMccywYJpvQEAKJ4qCBamK6RRZr0QFiIDAKB4qiBYmIpF1F0vhK4QAACKpwqChalY1Kb7JREsAAAopqoJFjUJs17I0FhaqYxdzhYBAFCxqiBYmK4Q31iPPJa5iUtOAQAojioIFqZiYY30qDHsrhfCJFkAABRF1QQLxXvUFDYrnPYyrTcAAEVR+cEi7C5EZqe1IGwqFb3DdIUAAFAMlR8sfAGppl6SdFIoLknqHqJiAQBAMVR+sJBy3SELAma9kEMECwAAiqKqgkW7z6xw2j00Vs7WAABQsaokWJhxFnO9MUlULAAAKJbqCBbuAM4mx6wXQrAAAKA4qiNYuF0h9faAJIIFAADFUlXBIpxy1wuJJ5nWGwCAIqiSYGG6QgKJXnk9lhyHuSwAACiGKgkW7rTe8V7NqTPTetMdAgBA4VVVsNDIIbVEaiRxySkAAMVQXcFitF9tdV5JVCwAACiG6ggWoUbJMm91Uc2oJKb1BgCgGKojWHg8ubksFtaY2TepWAAAUHjVESykXHfIPB/rhQAAUCxVFCxMxaLFOySJwZsAABRDFQULU7Fokjut9zAVCwAACq3qgkV9ZkCS1B1LyHGcMjYIAIDKU0XBwnSFhNNmWu9E2tZQIl3OFgEAUHHyChY/+MEPtHLlSkWjUUWjUa1Zs0a//e1vi9W2wnKDhW+0V5GgT5KpWgAAgMLJK1gsWLBAt956q7Zt26bnn39eH/7wh/WJT3xCr7zySrHaVzgTZt+cGw1K4soQAAAKLa9gccUVV+hjH/uYli1bplNOOUW33HKL6urqtGXLlmK1r3AmBos6Eyy4MgQAgMLyTfeBmUxG999/v0ZGRrRmzZpjHpdIJJRIjFcGYrHYdF9yZtyuEI30qKXVrBdCxQIAgMLKe/DmSy+9pLq6OgWDQV133XV64IEHtGLFimMev3HjRtXX1+e2jo6OGTV42rIVi1Rc7SFbEpecAgBQaHkHi1NPPVU7duzQ1q1b9cUvflHXXHONXn311WMev2HDBg0ODua2zs7OGTV42gJ1ks9UKnLTejN4EwCAgsq7KyQQCGjp0qWSpHPOOUfPPfecvvvd7+qHP/zhUY8PBoMKBoMza2UhWJapWgx2jk/rTcUCAICCmvE8FrZtTxpDcULLTuvtMbNvcrkpAACFlVfFYsOGDbrsssu0cOFCDQ0N6d5779Xjjz+uRx55pFjtK6xIu6TtmuP0SopSsQAAoMDyChbd3d36zGc+owMHDqi+vl4rV67UI488oo985CPFal9hRdvNLnlI0hL1jSSVTNsK+KpnAlIAAIopr2Dxk5/8pFjtKI3oPElSaOygfB5LadtR70hC8+pDZW4YAACVobr+VI/OlyRZsf2ak50ki3EWAAAUTJUFC9MVoth+zY0wrTcAAIVWXcEiMh4sWuoCkrjkFACAQqquYOGOsVBqRAtqzZLpdIUAAFA41RUsArVSTYMk6aTAgCTp0DALkQEAUCjVFSyk3DiL+d4BSVQsAAAopKoNFq3qk8QYCwAACqlqg0Wz3SOJigUAAIVUfcHCvTIkmjokyVQsHMcpZ4sAAKgY1Rcs3IpFaPSgJCmZthUbTZezRQAAVIwqDBZm9k3v8AFFasyM5lwZAgBAYVRhsHDnsojtV0uEab0BACikKgwW7uybo31qrzNfcmUIAACFUX3BoqZB8oclSctqhiWxXggAAIVSfcHCsqSI6Q5Z5M6+2U2wAACgIKovWEi57pAFnn5JVCwAACiUKg0W5sqQFnf2ze4hrgoBAKAQqjRYmK6QJmbfBACgoKo0WJiKRb07++b+gVFm3wQAoACqNFiYMRbhMTP75kgyo4F4qpwtAgCgIlRnsHCvCvEMHdBcd5Ksff2j5WwRAAAVoTqDhdsVouGDWtgQkCTt64+XsUEAAFSG6gwWtXMlj09ybK2ImEoFFQsAAGauOoOFx5PrDjklFJNExQIAgEKozmAh5QZwLvIPSKJiAQBAIVR9sGj3DEgiWAAAUAjVGywiJljMcSfJ2tcfZy4LAABmqHqDhVuxiCS7JZm5LPqZywIAgBmp4mBhBm96h7vUkpvLggGcAADMRBUHC3cui9i7WtAYksQ4CwAAZqqKg4XpCtHQAS1oyAYLKhYAAMxE9QaLujazzyS1LGJWN6ViAQDAzFRvsPAFpNoWSdLSYHaSLIIFAAAzUb3BQsp1h3T4+iXRFQIAwEwRLCS1Wn2STMWCuSwAAJg+goWkxrSZJCvOXBYAAMwIwUKSb/gAc1kAAFAA1R0sItlLTveroyksiQGcAADMRHUHi+xcFoP7JkySRcUCAIDpqu5g0XSS2fe/o44GvyQqFgAAzER1B4vofMkXkuyUTg0OSCJYAAAwE9UdLDweqflkSdIS64AkukIAAJiJ6g4WUi5YzEvvk8RcFgAAzATBonmZJKkh/o4kM5dF30iynC0CAGDWIlg0L5Ukeft2qTWancuCcRYAAEwHwWKOqVio9y0taGQuCwAAZoJgkb3kdGi/Tqo3YysYwAkAwPQQLMJNUrhZknRmTa8kKhYAAEwXwULKDeBc6uGSUwAAZoJgIeUGcM6390uiYgEAwHQRLCRpjgkWzWPmklPmsgAAYHoIFlKuYhEe2iPLkkZTzGUBAMB05BUsNm7cqPe///2KRCJqaWnRlVdeqZ07dxarbaXjjrHw9O5Sax1zWQAAMF15BYsnnnhC69ev15YtW/Too48qlUrpox/9qEZGRorVvtJoWiJZHik5pDPqxyRJnQzgBAAgb758Dn744YcnfX/XXXeppaVF27Zt04UXXljQhpWULyg1LJT692hVba9+pzl6+9AsD0sAAJRBXsHicIODg5KkpqamYx6TSCSUSCRy38disZm8ZPE0L5X69+jMmm5Jc7Sza6jcLQIAYNaZ9uBN27Z144036vzzz9cZZ5xxzOM2btyo+vr63NbR0THdlywud5zFEk+XJOn1rhM0AAEAcAKbdrBYv369Xn75ZW3atOm4x23YsEGDg4O5rbOzc7ovWVzu8uktib2SpN09IxpLZcrZIgAAZp1pdYVcf/31euihh/Tkk09qwYIFxz02GAwqGAxOq3El5S5GFhjcrcawX/3xlHZ1D+uM+fVlbhgAALNHXhULx3F0/fXX64EHHtBjjz2mJUuWFKtdpefOZWH179aK1pAk6XXGWQAAkJe8gsX69et19913695771UkElFXV5e6uro0OloBcz5E2iV/WLLTWt1orgjZyTgLAADyklew+MEPfqDBwUFddNFFmjdvXm77xS9+Uaz2lY7HIzWZcRZnhQ5JomIBAEC+8hpjUfHrZ8xZKh18SSd7uyQ1cckpAAB5Yq2QidxxFq1Jc+VK91CCNUMAAMgDwWIiN1j4B97WwqawJOazAAAgHwSLidxJstTzpk5ti0gS3SEAAOSBYDGRO0mWhrt05lxzaggWAABMHcFiolCDVDtXkrQq3CuJK0MAAMgHweJw7jiLZd4DkqQ3Dg7Jtiv8ahgAAAqEYHG4lhVmN7JTAZ9H8WRGnf3xMjcKAIDZgWBxuPnnSJI8+7drWUudJLpDAACYKoLF4dxgof3bdZq7ZggDOAEAmBqCxeHmLJMCESkV1+pIjySCBQAAU0WwOJzHK7W/T5K00npLkvQak2QBADAlBIujmX+2JGnh6OuSpD09IxpLZcrZIgAAZgWCxdG44yxquneoMeyX7Ui7uofL3CgAAE58BIujcYOFdfAVndEakMSVIQAATAXB4mii86W6VsnJ6KJIlyRpJ+MsAAB4TwSLo7GsXNVildcM4KRiAQDAeyNYHIs7gHNxwgzgfO3AkByHqb0BADgegsWxuBWLhv6X5Pda6hlOaG8fU3sDAHA8BItjaV8lSfL079YF881p2vJ2bzlbBADACY9gcSyhRqnpZEnS5U1mAOfWt/vK2SIAAE54BIvjcbtD3h/YLclULBhnAQDAsREsjscNFgvir8nvtbR/cEydfaNlbhQAACcugsXxuMHCe+AFrZxfL0nasptxFgAAHAvB4njazpQ8PmnkkD66ICmJAZwAABwPweJ4/DVS6xmSpAvDeyUxgBMAgOMhWLwXtztkaeoN+TyW3h0YVSfzWQAAcFQEi/fiBgt/13atXOCOs6A7BACAoyJYvBc3WOjdF3T+4jpJ0ha6QwAAOCqCxXuZe6oUmSelR/XR8JuSqFgAAHAsBIv3YlnSKZdKkpYPPiUv4ywAADgmgsVUnHqZJMn/1qNaOT8qSdq6m+4QAAAOR7CYiiUXSr6QFNunj7eZQEF3CAAARyJYTIU/JJ38YUnSRXpOkrSVGTgBADgCwWKqTjXjLBYeelJej6XOvlHt62ecBQAAExEspmrZJZIkb9cOXdiWlsRlpwAAHI5gMVWR1tycFp9qeFWStPm1g+VsEQAAJxyCRT7cq0M+mH5WkvTY690aTqTL2SIAAE4oBIt8nGKCRd3+/9JpzT4l0rZ+9ypVCwAAsggW+Wg9XarvkJUe039b2ClJ+s2L+8vcKAAAThwEi3xMmIXzf9E2SdKTbx7SQDxZzlYBAHDCIFjkyx1nUd+5Wae11iqVcfTIK11lbhQAACcGgkW+Fl8gBeqk4YP67EmDkqTfvHigzI0CAODEQLDIly+Ym4XzEmurJOnpt3p0aChRzlYBAHBCIFhMx8r/VZIU3XmfzllQK9uRfvsyVQsAAAgW03HKpVJdmzRySH/d9rok6SG6QwAAIFhMi9cvnf0ZSdIFg7+WJD27p08HBkfL2SoAAMqOYDFdZ39GsjwKdv6XrlwwIkn69z9StQAAVDeCxXQ1dOQWJvtC7ROSmCwLAACCxUyc+1lJ0vKDDynsSenFfYN6Zf9gmRsFAED5ECxmYunFUv1CecYGtGGhGcT54yffLnOjAAAoH4LFTHi80jlmEOcn7f+UJP3mjwe0rz9ezlYBAFA2BIuZWvWXksencPc2Xb0wpozt6CdP7S53qwAAKIu8g8WTTz6pK664Qu3t7bIsSw8++GARmjWLRNqk5ZdLkv57/R8kSZue7VT/CAuTAQCqT97BYmRkRGeddZbuuOOOYrRndnIHcc5759c6r9XSaCqju7e8U+ZGAQBQenkHi8suu0z//M//rKuuuqoY7ZmdFl8otayQlRzSLXPNWIu7nt6jsVSmzA0DAKC0ij7GIpFIKBaLTdoqjscjrf26JGnp7nt0TnRIvSNJ/du2fWVuGAAApVX0YLFx40bV19fnto6OjmK/ZHks+4i0+EOyMkn9S7OZ5vvHf3hbGdspc8MAACidogeLDRs2aHBwMLd1dnYW+yXLw7Kkj3xDkrT0wL9rdWif3umN6+GXu8rcMAAASqfowSIYDCoajU7aKtb8s6Uz/kyS9H9G/02S9K//uVOJNGMtAADVgXksCu3ir0oevxYNPqvLw69pd88I81oAAKpG3sFieHhYO3bs0I4dOyRJu3fv1o4dO7R3795Ct212alwsnfcFSdItdffJI1u3b97FkuoAgKqQd7B4/vnntWrVKq1atUqSdNNNN2nVqlW6+eabC964WevCv5OC9WqI7dT/aNmm0VRGt/z7a+VuFQAARZd3sLjooovkOM4R21133VWE5s1S4Sbpwv8hSbpu9H9qodWth/54QE+/1VPmhgEAUFyMsSiWD6yXOj4gb2pI9zT+SD6l9bVfvaJUxi53ywAAKBqCRbF4fdInfyzV1Ksj/qq+Evql3uwe1v/99J5ytwwAgKIhWBRTw0Lp49+XJF3rPKgLPC/pO797U519LKsOAKhMBItiW/Hx3CJlt9fcqZpEr9bf+wJzWwAAKhLBohQu+ZbUskKNdr++W3OnXtrXr28+9Gq5WwUAQMERLErBH5L+7KeSL6Tz9aK+4rtXd2/Zqwe3v1vulgEAUFAEi1JpOU36hBlv8b/7/kN/5X1YG375kt44OFTmhgEAUDgEi1I688+ktf8kSbrZ///qQ5ktuu7ubRpOpMvbLgAACoRgUWrn3yid+1l55Oj2wB2K9ryoGzdtZ34LAEBFIFiUmmVJl90mLbtEQSX1k8C/6o3XX9JN972ojO2Uu3UAAMwIwaIcvD4zmHPe+9RsxXRf4Bt6649Pa8Mv/yibcAEAmMUIFuUSrJP+t/ukuaepzerXfYFvqOuFf9c3HnpVjkO4AADMTgSLcoq0Sp99WFpyoeqsMf3Uf5tGtt6l2x7ZSbgAAMxKBItyCzVI6/4/aeWn5LNs3eb/kYJP3aqvPvBHBnQCAGYdgsWJwBeQrrpTuvDvJUk3+B7Q2u3/XX/zPx/RYDxV5sYBADB1BIsThWVJH/4/pE/coYw3qIu8L+ob+/+b/vn2O7SnZ6TcrQMAYEoIFieaVZ+W9wuPa6zxFM21BnXb6Nf02Pe/qGfeOFDulgEA8J4IFiei1hWq+eITGl35GUnSZ/Ur1d99ie7+xc+VTDPuAgBw4iJYnKgCYYX+9HYlP3mX4t6IVnje0adfu05P/8uV2v3WznK3DgCAoyJYnOACZ16l8E07tPekv5AtSxelnlDr//Mhbbv7K7IT8XI3DwCASQgWs0HtHC38zI80sO4/9UZghcJWQufs+r4G/uV07f/P70npRLlbCACAJILFrNK07Dwt+/J/6ckzv6V3nblqsvvU/vRXNfAvZyq+5adShlVSAQDlRbCYZSyPRxd+cr18N2zTfS036qDToIbUQYUf/lvF/q9VSu/4hWRnyt1MAECVspwSzx0di8VUX1+vwcFBRaPRUr50Rdq6813teOBf9Wej96vZGpIkDdYtVe1lX5NvxRVmfgwAAGZoqp/fBIsKkMrY+sVTryr2xPf16cyvFLXMoM6++hWqP/9z8p52hVmXBACAaSJYVKHRZEb3P/WSUn/4nj5lP6RaywzqdGQpM/88+U7/uHTaFVLjojK3FAAw2xAsqlg8mdb9T+zQwDN36cL0M1rl2TX5gPazpdOvlFZcScgAAEwJwQIaS2X06xf361dPPKelfY/rMu+zer/1urzWhB95+ypp6Vpp0flSx3lSoLZ8DQYAnLAIFshxHEdP7erRT57arVfe2KVLPM/qY56tWu19TV5N+PF7fNL8c6RFH5QWnGeCRu2c8jUcAHDCIFjgqPb1x/Vv2/bp/uf3KTHQpQ97X9AHPK/pfN/ranV6jnxA00kmZCxaIy3+kPmeK00AoOoQLHBcGdvRf+3q0b9t26ffvXZQ8WRaC6xDWuN5VX8Selvn+d5Sy9juIx9Y1yYtPl9auEZqPUNqWS6FGkv/BgAAJUWwwJSNJjP6/c5u/ebF/Xrs9W4l3BVUoxrWmsBufby5U+fqNbUMviTLTh75BJF2qeU0af7Z490owboSvwsAQDERLDAtw4m0nnrzkB57vVu/33lIh4bG1yEJKqlLGzp1Rf1urbTeUvPIW/IO7TvySSyv1P4+qeMD0pylUuMSqXGxVN8heX0ley8AgMIhWGDGbNvRK/tjeuz1bj2165C27x1Q2p7867KiydGlLYP6QN0BLU++qsjBZ2UNdh79CT0+qbZFCjeZ7pNQoxkc2rhEmrNMal5mLn/1+kvw7gAA+SBYoOCGE2lteatXT+3q0Za3e7Xz4JAO/+2JBH26uD2pj9a9rTOtt9SS3q9g7B2p/x0pM4VVWD0+U91oOmnyFpkn1bWaUOLxFuX9AQCOjWCBohscTemFvf3atqdfz7/Tpxc7BzWaOnIBtJZIUGfMq9MH5iZ1ev2YTq5LqcUXl2dsQBo+KPW+JfW+afap+PFf1PJItXOlSJvUsFBqWORuC6Vws1QTlYJRs/eHuYIFAAqEYIGSS2ds7Tw4pO17B7R974B2dPbr7Z6RI6oakhTye3VKW0TLWyNaMrdWi5vDWtwc0mL/oGpie6S+tydsu00AifdKyuPX1RuUovOk6Hwp2m62ulYTTGrnSOE5Zh9qkvw1hToNAFCRCBY4IcSTab12YEiv7B/Uy+8O6vWuIe3sGspdeXI0rdGgFjfXasmcWi2eU6vFzbVaPCeshQ0BhVMDJmTE9pvulYG90oC7HxuQxmJSIiY5x37+o/KHTcAIN5rwEW2XogvMPtJ2ZPeLP2wqJOFmqaZB8njyPTUAMKsQLHDCytiO9vSO6PUDQ9p5cEjv9I5oT29ce3pGNDiaOu5j59QFtag5rIVNYS1oDLmb+XpefUgBn0dyHNOlMtIjDR2QYu+aIDL4rjRyyN16pHiP2TtHdt/kxfKYgNG4WGpeKjWdLDWfbLpjRnpMEBruluJ9Um2zGazadJLUtMRcqmu5oSTXbTOh+yZ7G106AMqMYIFZqX8kqT29I9rTO6LdPSZs7Okd0Tu98fcMHZYlza0Lqr0hpPkNIc2rr1FbdovWqNXdAr4J1QXHkcYGpdF+abTPfPgPdZkgEttn9sPdmtyf40jJEXNsYrA4J+JwHp+7+c0lu76QWdclUCsF6sy8IaEmM7g1W0kJ1E54nNfsvQHJF3T3NeY2xzbvKfsew02mu4hBsgAmIFig4gzGU9rbF9c7fSPq7BvVvv649vWP6t0B8/VYamrdH821AbVGTeBojQY1ty6oOZGg5tSZbW4kqJZIULXBKcy5kU6aQDLcbcaD9O4y+543Tfiom2susa1zL7MdPmTu798t9e+RMkeZcOxEYHnMGJRIq+nqySSldMJsmYSUSUv2hE2SQg3j4SbUZAJQJi3ZKSmTkuSY5wo3jwcgf8gEGsd2N0fyuaHHFzR7f8iEp0DdeJiyPOOPk2PmTin2HCmZtPlZjw1KwYh5j77A5GNSY6YSFu8158WRcuOCAnXmsmoCW2XKpE13bPZnH5lnLqmfarUxMeyG/ilebj8WM9XYeK/pvq3vKPpYMYIFqorjOOobSWr/wJjeHRjVfnfrio3pYGzM7AcTSmamPvaiNuB1Q0aNGmv9agwH1FgbUGPYr4ZwQE0Tvm+qDSha45fHk0eXhZ1xx4NM+Cd4tH+Ojj3+4WynzT49aoJLdksMuRWXXlNJGekx3UF2ZnIAyAaE7N5Omw9py5LpgnFM9SbfMSonAm/QhI5gneSvleRI6TE3EI2Zc1vXYsbM1LWZ0JRJSyPdJhgOd5v37vGZwOANmn02LIwO6IjBw4E6E5IsjzTSKyWHjt/GQJ1ZUXj+2dL8c80HgjdbiQqMV5Ac23TROba5zxc0AcsXNN9nf+aJmNn7asz7isybHHaSI9JApzTY6f5OZH9n4lJyePzcZJLuObLN+CF/yOx9NUcGIctrznEwYq7ACkZM92LvLrP17JKGu0ygjs5zxyvNNx+y3gmh0eM153ukZ7xrMjFs2pJJmb2dGn//2ccGwu48OBPmw0mNjD/PyCET/uzU5N9/f3jywO3speuW1/z8su0Z2Du+DR0wr+8PjW+Wd/zfYyZlgvbogAkVh/OFxgeOhxomB2Q55jX695jxYqN95rkbFpou1eaTzeMSQ6Zd8T5zzNBBEygSsSNfL9Ju5gJqWCSt/Zp5fAERLIDDOI6j/nhKXYMTwkZsTD3DCfUMJc1+OKFDQwmNJPMfd+GxlAsfTW7gaAwHVO/uG8N+1YcCqg/51RD25/Yhv1fWiTSGws64Y0O6zH9iiZj7H3vQrSIEx7tksl0tjj35P794n/lg9PjNX2Aet5owNmDui7shKD02HmyyY00yKTcQuKEg+yGYHB6vjpRTIGI+yI4Vvjw+U43xBiRZ7pAZy7zf5HDx21c717z+cLf5WaC0ahpMSIn3luC16k1IGuoyv5MT/f1bBV+deqqf38yvjKphWZaa3A/9Fe3HD7UjibS6hxLqjo3p0HBC/fGU+keS6o8n3X3KfB1Pqn8kpeFEWrYj9Y4k1TuSX/eG32spWmOCRtTdIjU+RWt8itT4FQn6FHG/rqsxX9eH/LmtLugrbDDxeM1f85FWaV7hnrYg0gnzF3dWNpTYGfcv8eHxveWZ3KXiOO5A2oPmL9Ghgyb01LWaSkZdi/nr186Md/mkk6YCMPHSZK9Psu3xkDTaZx5TO9cMzq1pOHr5285Ih3ZK7z4vvbtN2r/dlLOzlaSM+xd2NmRlNzttQlZqVOMVE8utGETMX8DpMfOeMsnxAcpZwagpk9e1jFdzArXmL39faDws+twyeva1UnGzzwUo9z3Zabdakq2YxMx7nrPM/Ut7malUjPSYMUpD+81+LDa5OmJnzONqm8fPbzA63h2QreBk3386aX4m2fFN2XFRo/3mPdU2u6FqjqkOZB+fHWOUGB4fsD1yyPz87IzZHHcfjLh/8S+UGhab92Fn3HMSN9UrO22ee2KlKdQwfoVYtksuNTZh8PgBMx4rOWLakXSDaUOHGfSdnYsnOWzm8+l7y+yHuswg8FwXY6N5j/ULTBUouyaT45gg0/+O6WYd7DTtKRMqFkABJNO2BuImVPSPJNXnBpCBeEr98ZQG3BAyOJqatKUyM//n5/VYitb4FA74FA54FQ54FQp4VRf0qS7oU23QZwJJ0KdQwKeQ3xxT4/eqNuhVbdCn2oBPtUHzmHDAN3mAK04MjuOGj5QJBIdf4pz9cIntNx+gtXNNoAg1lKW5qDxULIASCvg8aonWqCU69cFTjuMonswcETaGxtIaGjtsn0hP+j57bDJtK2M7bgXl+FfN5MPnsRQKeFXrhpVQLrD4FPZ7FXZDSK0bXrJBJejz5PYBn0d+r9kCXo/8PssNMCbEBLyeE6sL6ERnWe74icCx76+dU/DyN5AvggVQJpZluR+yPrU3hKb1HGOpjAbiKcXGUoonM4on0mafMl8Pu4FkOJHW8Fhao6mM4smMxlIZxZPm2OFEWiOJtEYSmdzg1rTtuEGmeGMafB4rF1pCfhNaavwehfwmpNT4ParxeVUT8KrG51Uo4H7v9yronxhYPAp4Lfk8Hnm9lvwej7weS0H38aGAN/e8VGOA4iNYALNYjd+rtnqv2uoLc5lZMm1rNJlRPGVCx2gyo5FEWvGU+drcltaIe3sulCQzSqRsJdIZJdK2EqmMkhlHqYxttrStRNrWSDKduyw4bTuKjaUVK2J4ORq/11I44FNtwKuAzyOf1yOfx5Lf65HPayngNdWWoM+joM8rv9eSz+sxe48JNDV+z3gFxw1GQZ9HQb9HAa/X3bvhxzdesfF63ADkMV/73SCU19VEwAmOYAEgJ+B2YdSreEvXpzN2LpiMuoFlLJWZVE1JpGyNpszXYylbY2lzXMLdJzO2kmlbyYyjZDpjuoQcKWPbSmccpW3HPdaEnNFURmnbjGdJZZxcV9KJYmKw8XkseT0ed28qLxPHxdT4vfJalhnjaZnKl99j5e7LVmo8liXPhGOy3Vs1fm+uKuTNTvrqXr1iSfJ5PPJ45AYgKeA1FZ+gb7xS5LUsc4WmZclrWbnjPe5roboRLACUlM/rUX3Io/pQ8cLL0aQytukmSppun5FEWslMNoiYfSpjj4cWt8piqi6O0hlbKdscM+pWc0wlxwSk7PHZys3E4JNynzsbbg6Xth2l7Yx04mSdafN7s9WY8aqN32flgofXDU5ej3LHZKs6PvexHsvKVXW8E7+ecJ/PY8nj3j9eYfIo6Pea8OMGH8vKPof53rzGeHDzeaxc1Wr8+eUGM/c2z3iA8liWLI0HKEsy9084ptqrUAQLAFXBX6ZAczjbdpRxnFygSWUcJd0Ak8zYsm1Tccm4+2zFZTTp7lMZM+mo48h2JNt9rrFURmNpU+FJpDOy3VnaHccxy+dkxis/5nns3H25tjnmdTMT2pjK2LnurUT62OEoy4QoZ8oz4VYqn8fKVQADXtP9lVsNaEJVx3EcOXInnfVakwZAB31e8zhLuQrUxHCVDTzZSlc2IPk8Ht2wdlnZftcJFgBQQh6PJY8s+b2SNPum987YzqRQk7GdXLjJBqJsdSaV67Kyc4FlYnDKVoOSmYxSaccEq4nhxg04tu0oY5uurowz4Wt3n8w4ufE92WqT7Yam7HM4zoTA5oa6TK4d2e/NB33GGW+reX3lbpuqtO0o7Y5LKofrLjpJKmKX5vFMK1jccccduu2229TV1aWzzjpLt99+u84777xCtw0AcILxerLTv1en7NRP2UqPI+XC1cRKTzbgJDMm8Ni25Gj8sY7kdqmYaoSkXHVozK0OJdK2G+LGw409IWylJwSw9ITAlLYd1U1lraMiyfuVf/GLX+imm27SnXfeqdWrV+s73/mOLrnkEu3cuVMtLS3FaCMAACeE3NiKCdnKW8XjKY4m7wu6v/3tb+vzn/+8rr32Wq1YsUJ33nmnwuGwfvrTnxajfQAAYBbJK1gkk0lt27ZNa9euHX8Cj0dr167VM888c9THJBIJxWKxSRsAAKhMeQWLnp4eZTIZtba2Trq9tbVVXV1dR33Mxo0bVV9fn9s6Ojqm31oAAHBCK/rcths2bNDg4GBu6+zsLPZLAgCAMslr8OacOXPk9Xp18ODBSbcfPHhQbW1tR31MMBhUMBicfgsBAMCskVfFIhAI6JxzztHmzZtzt9m2rc2bN2vNmjUFbxwAAJhd8r7c9KabbtI111yjc889V+edd56+853vaGRkRNdee20x2gcAAGaRvIPFX/zFX+jQoUO6+eab1dXVpfe97316+OGHjxjQCQAAqo/lOM7U5ygtgFgspvr6eg0ODioajZbypQEAwDRN9fO76FeFAACA6kGwAAAABUOwAAAABUOwAAAABVPydVWzY0VZMwQAgNkj+7n9Xtd8lDxYDA0NSRJrhgAAMAsNDQ2pvr7+mPeX/HJT27a1f/9+RSKR3Lr2hRCLxdTR0aHOzk4uYy0yznXpcK5Lh3NdWpzv0inUuXYcR0NDQ2pvb5fHc+yRFCWvWHg8Hi1YsKBozx+NRvklLRHOdelwrkuHc11anO/SKcS5Pl6lIovBmwAAoGAIFgAAoGAqJlgEg0F97WtfY4n2EuBclw7nunQ416XF+S6dUp/rkg/eBAAAlatiKhYAAKD8CBYAAKBgCBYAAKBgCBYAAKBgKiZY3HHHHVq8eLFqamq0evVqPfvss+Vu0qy2ceNGvf/971ckElFLS4uuvPJK7dy5c9IxY2NjWr9+vZqbm1VXV6dPfvKTOnjwYJlaXDluvfVWWZalG2+8MXcb57qw3n33XX36059Wc3OzQqGQzjzzTD3//PO5+x3H0c0336x58+YpFApp7dq1evPNN8vY4tkpk8noq1/9qpYsWaJQKKSTTz5Z3/zmNyetNcG5np4nn3xSV1xxhdrb22VZlh588MFJ90/lvPb19WndunWKRqNqaGjQ5z73OQ0PD8+8cU4F2LRpkxMIBJyf/vSnziuvvOJ8/vOfdxoaGpyDBw+Wu2mz1iWXXOL87Gc/c15++WVnx44dzsc+9jFn4cKFzvDwcO6Y6667zuno6HA2b97sPP/8884HPvAB54Mf/GAZWz37Pfvss87ixYudlStXOjfccEPuds514fT19TmLFi1y/uqv/srZunWr8/bbbzuPPPKIs2vXrtwxt956q1NfX+88+OCDzosvvuh8/OMfd5YsWeKMjo6WseWzzy233OI0Nzc7Dz30kLN7927n/vvvd+rq6pzvfve7uWM419PzH//xH85XvvIV55e//KUjyXnggQcm3T+V83rppZc6Z511lrNlyxbnD3/4g7N06VLn6quvnnHbKiJYnHfeec769etz32cyGae9vd3ZuHFjGVtVWbq7ux1JzhNPPOE4juMMDAw4fr/fuf/++3PHvPbaa44k55lnnilXM2e1oaEhZ9myZc6jjz7q/Mmf/EkuWHCuC+tLX/qSc8EFFxzzftu2nba2Nue2227L3TYwMOAEg0Hn5z//eSmaWDEuv/xy57Of/eyk2/70T//UWbduneM4nOtCOTxYTOW8vvrqq44k57nnnssd89vf/taxLMt59913Z9SeWd8VkkwmtW3bNq1duzZ3m8fj0dq1a/XMM8+UsWWVZXBwUJLU1NQkSdq2bZtSqdSk8758+XItXLiQ8z5N69ev1+WXXz7pnEqc60L79a9/rXPPPVd//ud/rpaWFq1atUo//vGPc/fv3r1bXV1dk853fX29Vq9ezfnO0wc/+EFt3rxZb7zxhiTpxRdf1FNPPaXLLrtMEue6WKZyXp955hk1NDTo3HPPzR2zdu1aeTwebd26dUavX/JFyAqtp6dHmUxGra2tk25vbW3V66+/XqZWVRbbtnXjjTfq/PPP1xlnnCFJ6urqUiAQUENDw6RjW1tb1dXVVYZWzm6bNm3SCy+8oOeee+6I+zjXhfX222/rBz/4gW666Sb94z/+o5577jn9zd/8jQKBgK655prcOT3a/ymc7/x8+ctfViwW0/Lly+X1epXJZHTLLbdo3bp1ksS5LpKpnNeuri61tLRMut/n86mpqWnG537WBwsU3/r16/Xyyy/rqaeeKndTKlJnZ6duuOEGPfroo6qpqSl3cyqebds699xz9a1vfUuStGrVKr388su68847dc0115S5dZXlvvvu0z333KN7771Xp59+unbs2KEbb7xR7e3tnOsKNuu7QubMmSOv13vECPmDBw+qra2tTK2qHNdff70eeugh/f73v5+03H1bW5uSyaQGBgYmHc95z9+2bdvU3d2ts88+Wz6fTz6fT0888YS+973vyefzqbW1lXNdQPPmzdOKFSsm3Xbaaadp7969kpQ7p/yfMnN///d/ry9/+cv61Kc+pTPPPFN/+Zd/qb/927/Vxo0bJXGui2Uq57WtrU3d3d2T7k+n0+rr65vxuZ/1wSIQCOicc87R5s2bc7fZtq3NmzdrzZo1ZWzZ7OY4jq6//no98MADeuyxx7RkyZJJ959zzjny+/2TzvvOnTu1d+9eznueLr74Yr300kvasWNHbjv33HO1bt263Nec68I5//zzj7h0+o033tCiRYskSUuWLFFbW9uk8x2LxbR161bOd57i8bg8nskfM16vV7ZtS+JcF8tUzuuaNWs0MDCgbdu25Y557LHHZNu2Vq9ePbMGzGjo5wli06ZNTjAYdO666y7n1Vdfdb7whS84DQ0NTldXV7mbNmt98YtfdOrr653HH3/cOXDgQG6Lx+O5Y6677jpn4cKFzmOPPeY8//zzzpo1a5w1a9aUsdWVY+JVIY7DuS6kZ5991vH5fM4tt9zivPnmm84999zjhMNh5+67784dc+uttzoNDQ3Or371K+ePf/yj84lPfIJLIKfhmmuucebPn5+73PSXv/ylM2fOHOcf/uEfcsdwrqdnaGjI2b59u7N9+3ZHkvPtb3/b2b59u/POO+84jjO183rppZc6q1atcrZu3eo89dRTzrJly7jcdKLbb7/dWbhwoRMIBJzzzjvP2bJlS7mbNKtJOur2s5/9LHfM6Oio89d//ddOY2OjEw6Hnauuuso5cOBA+RpdQQ4PFpzrwvrNb37jnHHGGU4wGHSWL1/u/OhHP5p0v23bzle/+lWntbXVCQaDzsUXX+zs3LmzTK2dvWKxmHPDDTc4CxcudGpqapyTTjrJ+cpXvuIkEoncMZzr6fn9739/1P+jr7nmGsdxpnZee3t7nauvvtqpq6tzotGoc+211zpDQ0MzbhvLpgMAgIKZ9WMsAADAiYNgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACoZgAQAACub/B85llMzzFrqCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00868c9-584a-4c37-b489-ab5297a2ec9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Components from PCA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08fb7170-d43d-4183-bc46-19b621c18b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb94e0-76ea-48a8-9201-bb3798b826a2",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "380a789e-6c82-431c-bc0d-61f8c449e71a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        19\n",
      "           1    1.00000   1.00000   1.00000        20\n",
      "           2    1.00000   1.00000   1.00000        19\n",
      "           3    1.00000   1.00000   1.00000        23\n",
      "           4    1.00000   1.00000   1.00000        26\n",
      "           5    1.00000   1.00000   1.00000        18\n",
      "           6    1.00000   1.00000   1.00000        24\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        17\n",
      "           9    1.00000   0.96154   0.98039        26\n",
      "          10    0.60976   1.00000   0.75758        25\n",
      "          11    1.00000   1.00000   1.00000        21\n",
      "          12    1.00000   1.00000   1.00000        23\n",
      "          13    1.00000   1.00000   1.00000        22\n",
      "          14    1.00000   1.00000   1.00000        23\n",
      "          15    1.00000   0.94444   0.97143        18\n",
      "          16    1.00000   1.00000   1.00000        16\n",
      "          17    0.88235   1.00000   0.93750        15\n",
      "          18    1.00000   1.00000   1.00000        18\n",
      "          19    1.00000   0.95652   0.97778        23\n",
      "          20    1.00000   1.00000   1.00000        19\n",
      "          21    1.00000   0.90476   0.95000        21\n",
      "          22    0.91304   1.00000   0.95455        21\n",
      "          23    1.00000   0.95833   0.97872        24\n",
      "          24    0.90909   0.95238   0.93023        21\n",
      "          25    0.93750   1.00000   0.96774        15\n",
      "          26    0.96154   1.00000   0.98039        25\n",
      "          27    1.00000   1.00000   1.00000        18\n",
      "          28    1.00000   1.00000   1.00000        18\n",
      "          29    1.00000   1.00000   1.00000        19\n",
      "          30    1.00000   0.95455   0.97674        22\n",
      "          31    1.00000   1.00000   1.00000        18\n",
      "          32    0.94118   1.00000   0.96970        16\n",
      "          33    1.00000   1.00000   1.00000        20\n",
      "          34    1.00000   1.00000   1.00000        17\n",
      "          35    0.96154   1.00000   0.98039        25\n",
      "          36    1.00000   0.92308   0.96000        13\n",
      "          37    0.95455   1.00000   0.97674        21\n",
      "          38    0.95238   0.95238   0.95238        21\n",
      "          39    1.00000   0.94737   0.97297        19\n",
      "          40    1.00000   1.00000   1.00000        18\n",
      "          41    1.00000   1.00000   1.00000        27\n",
      "          42    1.00000   1.00000   1.00000        21\n",
      "          43    1.00000   1.00000   1.00000        14\n",
      "          44    1.00000   1.00000   1.00000        18\n",
      "          45    0.91304   1.00000   0.95455        21\n",
      "          46    1.00000   0.88889   0.94118         9\n",
      "          47    1.00000   0.92857   0.96296        14\n",
      "          48    1.00000   1.00000   1.00000        19\n",
      "          49    1.00000   1.00000   1.00000        13\n",
      "          50    1.00000   1.00000   1.00000        27\n",
      "          51    1.00000   0.91667   0.95652        24\n",
      "          52    1.00000   0.88889   0.94118        18\n",
      "          53    1.00000   1.00000   1.00000        22\n",
      "          54    1.00000   0.91304   0.95455        23\n",
      "          55    1.00000   1.00000   1.00000        19\n",
      "          56    1.00000   0.94737   0.97297        19\n",
      "          57    0.95455   1.00000   0.97674        21\n",
      "          58    1.00000   0.95238   0.97561        21\n",
      "          59    1.00000   0.96154   0.98039        26\n",
      "          60    1.00000   1.00000   1.00000        21\n",
      "          61    1.00000   1.00000   1.00000        25\n",
      "          62    1.00000   1.00000   1.00000        19\n",
      "          63    1.00000   1.00000   1.00000        23\n",
      "          64    1.00000   1.00000   1.00000        19\n",
      "          65    1.00000   1.00000   1.00000        22\n",
      "          66    1.00000   1.00000   1.00000        18\n",
      "          67    1.00000   1.00000   1.00000        19\n",
      "          68    1.00000   1.00000   1.00000        23\n",
      "          69    1.00000   1.00000   1.00000        21\n",
      "          70    1.00000   1.00000   1.00000        12\n",
      "          71    1.00000   1.00000   1.00000        23\n",
      "          72    1.00000   1.00000   1.00000        18\n",
      "          73    0.94118   1.00000   0.96970        16\n",
      "          74    0.95238   1.00000   0.97561        20\n",
      "          75    1.00000   0.95000   0.97436        20\n",
      "          76    1.00000   1.00000   1.00000        23\n",
      "          77    1.00000   1.00000   1.00000        21\n",
      "          78    1.00000   1.00000   1.00000        19\n",
      "          79    1.00000   0.96774   0.98361        31\n",
      "          80    1.00000   1.00000   1.00000        30\n",
      "          81    1.00000   1.00000   1.00000        13\n",
      "          82    1.00000   1.00000   1.00000        13\n",
      "          83    1.00000   1.00000   1.00000        25\n",
      "          84    1.00000   1.00000   1.00000        22\n",
      "          85    1.00000   1.00000   1.00000        19\n",
      "          86    1.00000   1.00000   1.00000        16\n",
      "          87    1.00000   1.00000   1.00000        17\n",
      "          88    0.90000   1.00000   0.94737        18\n",
      "          89    1.00000   1.00000   1.00000        26\n",
      "          90    1.00000   1.00000   1.00000        16\n",
      "          91    1.00000   0.95000   0.97436        20\n",
      "          92    1.00000   1.00000   1.00000        21\n",
      "          93    1.00000   1.00000   1.00000        12\n",
      "          94    0.95238   0.95238   0.95238        21\n",
      "          95    1.00000   1.00000   1.00000        16\n",
      "          96    0.95455   1.00000   0.97674        21\n",
      "          97    1.00000   0.96154   0.98039        26\n",
      "          98    1.00000   1.00000   1.00000        25\n",
      "          99    1.00000   1.00000   1.00000        16\n",
      "         100    1.00000   0.95238   0.97561        21\n",
      "         101    1.00000   1.00000   1.00000        24\n",
      "         102    1.00000   1.00000   1.00000        20\n",
      "         103    1.00000   0.93333   0.96552        15\n",
      "         104    1.00000   1.00000   1.00000        15\n",
      "         105    1.00000   0.93333   0.96552        15\n",
      "         106    1.00000   0.91304   0.95455        23\n",
      "         107    0.86957   1.00000   0.93023        20\n",
      "         108    1.00000   0.96000   0.97959        25\n",
      "         109    1.00000   1.00000   1.00000        26\n",
      "         110    1.00000   0.95652   0.97778        23\n",
      "         111    1.00000   1.00000   1.00000        22\n",
      "         112    0.94737   1.00000   0.97297        18\n",
      "         113    0.96296   0.96296   0.96296        27\n",
      "         114    1.00000   1.00000   1.00000        15\n",
      "         115    1.00000   1.00000   1.00000        17\n",
      "         116    1.00000   1.00000   1.00000        23\n",
      "         117    1.00000   1.00000   1.00000        19\n",
      "         118    1.00000   1.00000   1.00000        19\n",
      "         119    0.94737   1.00000   0.97297        18\n",
      "         120    0.95833   1.00000   0.97872        23\n",
      "         121    1.00000   0.94118   0.96970        17\n",
      "         122    1.00000   1.00000   1.00000        19\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    1.00000   0.95000   0.97436        20\n",
      "         126    0.94118   1.00000   0.96970        16\n",
      "         127    0.95833   1.00000   0.97872        23\n",
      "         128    1.00000   0.93750   0.96774        16\n",
      "         129    1.00000   1.00000   1.00000        12\n",
      "         130    0.95238   1.00000   0.97561        20\n",
      "         131    1.00000   1.00000   1.00000        24\n",
      "         132    0.87500   1.00000   0.93333        21\n",
      "         133    1.00000   0.78571   0.88000        14\n",
      "         134    1.00000   1.00000   1.00000        15\n",
      "         135    1.00000   1.00000   1.00000        20\n",
      "         136    1.00000   1.00000   1.00000        26\n",
      "         137    1.00000   1.00000   1.00000        14\n",
      "         138    1.00000   0.85714   0.92308        21\n",
      "         139    0.90909   1.00000   0.95238        20\n",
      "         140    1.00000   1.00000   1.00000        23\n",
      "         141    1.00000   1.00000   1.00000        21\n",
      "         142    1.00000   1.00000   1.00000        17\n",
      "         143    1.00000   1.00000   1.00000        14\n",
      "         144    1.00000   1.00000   1.00000        23\n",
      "         145    1.00000   1.00000   1.00000        13\n",
      "         146    1.00000   0.96296   0.98113        27\n",
      "         147    1.00000   0.92857   0.96296        28\n",
      "         148    1.00000   0.95652   0.97778        23\n",
      "         149    0.95833   1.00000   0.97872        23\n",
      "         150    1.00000   0.92308   0.96000        26\n",
      "         151    1.00000   1.00000   1.00000        21\n",
      "         152    1.00000   1.00000   1.00000        25\n",
      "         153    1.00000   0.94737   0.97297        19\n",
      "         154    1.00000   1.00000   1.00000        22\n",
      "         155    0.94118   1.00000   0.96970        16\n",
      "         156    1.00000   1.00000   1.00000        23\n",
      "         157    1.00000   0.94118   0.96970        17\n",
      "         158    1.00000   0.95455   0.97674        22\n",
      "         159    1.00000   1.00000   1.00000        20\n",
      "         160    1.00000   1.00000   1.00000        22\n",
      "         161    1.00000   1.00000   1.00000        23\n",
      "         162    1.00000   1.00000   1.00000        14\n",
      "         163    1.00000   1.00000   1.00000        23\n",
      "         164    1.00000   1.00000   1.00000        18\n",
      "         165    1.00000   1.00000   1.00000        30\n",
      "         166    1.00000   1.00000   1.00000        19\n",
      "         167    0.96000   1.00000   0.97959        24\n",
      "         168    0.92857   1.00000   0.96296        13\n",
      "         169    0.88235   1.00000   0.93750        15\n",
      "         170    1.00000   0.92308   0.96000        26\n",
      "         171    1.00000   1.00000   1.00000        20\n",
      "         172    1.00000   1.00000   1.00000        22\n",
      "         173    1.00000   1.00000   1.00000        13\n",
      "         174    1.00000   1.00000   1.00000        20\n",
      "         175    1.00000   0.95652   0.97778        23\n",
      "         176    0.94737   0.94737   0.94737        19\n",
      "         177    1.00000   1.00000   1.00000        18\n",
      "         178    1.00000   1.00000   1.00000        16\n",
      "         179    1.00000   1.00000   1.00000        24\n",
      "         180    1.00000   1.00000   1.00000        22\n",
      "         181    0.91667   1.00000   0.95652        11\n",
      "         182    1.00000   0.93333   0.96552        15\n",
      "         183    1.00000   1.00000   1.00000        25\n",
      "         184    1.00000   1.00000   1.00000        17\n",
      "         185    0.95000   1.00000   0.97436        19\n",
      "         186    1.00000   0.96296   0.98113        27\n",
      "         187    1.00000   1.00000   1.00000        20\n",
      "         188    1.00000   1.00000   1.00000        26\n",
      "         189    1.00000   0.96667   0.98305        30\n",
      "         190    0.94737   1.00000   0.97297        18\n",
      "         191    1.00000   1.00000   1.00000        19\n",
      "         192    1.00000   1.00000   1.00000        14\n",
      "         193    1.00000   1.00000   1.00000        20\n",
      "         194    1.00000   1.00000   1.00000        23\n",
      "         195    1.00000   0.95652   0.97778        23\n",
      "         196    0.95652   1.00000   0.97778        22\n",
      "         197    1.00000   0.86667   0.92857        15\n",
      "         198    1.00000   1.00000   1.00000        20\n",
      "         199    1.00000   1.00000   1.00000        20\n",
      "         200    1.00000   1.00000   1.00000        19\n",
      "         201    1.00000   1.00000   1.00000        23\n",
      "         202    1.00000   0.94118   0.96970        17\n",
      "         203    1.00000   1.00000   1.00000        27\n",
      "         204    1.00000   1.00000   1.00000        14\n",
      "         205    1.00000   1.00000   1.00000        17\n",
      "         206    1.00000   1.00000   1.00000        13\n",
      "         207    1.00000   1.00000   1.00000        22\n",
      "         208    1.00000   1.00000   1.00000        21\n",
      "         209    0.93750   1.00000   0.96774        15\n",
      "         210    1.00000   0.95455   0.97674        22\n",
      "         211    1.00000   1.00000   1.00000        25\n",
      "         212    1.00000   1.00000   1.00000        18\n",
      "         213    1.00000   1.00000   1.00000        12\n",
      "         214    1.00000   0.94737   0.97297        19\n",
      "         215    0.96000   1.00000   0.97959        24\n",
      "         216    1.00000   1.00000   1.00000        17\n",
      "         217    1.00000   1.00000   1.00000        22\n",
      "         218    0.90909   1.00000   0.95238        20\n",
      "         219    1.00000   0.88235   0.93750        17\n",
      "         220    1.00000   1.00000   1.00000        13\n",
      "         221    1.00000   1.00000   1.00000        21\n",
      "         222    1.00000   1.00000   1.00000        13\n",
      "         223    1.00000   0.95238   0.97561        21\n",
      "         224    0.88235   1.00000   0.93750        15\n",
      "\n",
      "    accuracy                        0.98467      4500\n",
      "   macro avg    0.98662   0.98455   0.98484      4500\n",
      "weighted avg    0.98689   0.98467   0.98503      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f47756-08c1-4e9a-a4db-0247f8432987",
   "metadata": {},
   "source": [
    "<h1>Sigmoid-like Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0488ffb-1f97-4d2a-962d-2d5b6c1de260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.read_csv('input/results_complete_sigmoid_like.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a69a9e2-9c1a-460d-8ee0-0b0906b8f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sig.drop(['elem_damaged', 'damage'], axis=1), df_sig['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4725a8a-f537-49c8-b452-b67189a6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "pca = PCA(.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a28008-ffff-418d-862c-e3b1f4a69826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 80)                7120      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 225)               18225     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,305\n",
      "Trainable params: 38,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 5.4724 - accuracy: 0.0436 - val_loss: 4.7495 - val_accuracy: 0.1076\n",
      "Epoch 2/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 4.4364 - accuracy: 0.1745 - val_loss: 4.1734 - val_accuracy: 0.2347\n",
      "Epoch 3/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.9470 - accuracy: 0.2842 - val_loss: 3.7580 - val_accuracy: 0.3287\n",
      "Epoch 4/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.5645 - accuracy: 0.3845 - val_loss: 3.4160 - val_accuracy: 0.4193\n",
      "Epoch 5/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.2439 - accuracy: 0.4548 - val_loss: 3.1157 - val_accuracy: 0.4751\n",
      "Epoch 6/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.9790 - accuracy: 0.5065 - val_loss: 2.8799 - val_accuracy: 0.5316\n",
      "Epoch 7/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.7633 - accuracy: 0.5457 - val_loss: 2.7002 - val_accuracy: 0.5722\n",
      "Epoch 8/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.5924 - accuracy: 0.5812 - val_loss: 2.5427 - val_accuracy: 0.6007\n",
      "Epoch 9/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.4566 - accuracy: 0.6069 - val_loss: 2.4227 - val_accuracy: 0.6322\n",
      "Epoch 10/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.3428 - accuracy: 0.6270 - val_loss: 2.3204 - val_accuracy: 0.6340\n",
      "Epoch 11/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.2530 - accuracy: 0.6411 - val_loss: 2.2341 - val_accuracy: 0.6604\n",
      "Epoch 12/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.1700 - accuracy: 0.6605 - val_loss: 2.1736 - val_accuracy: 0.6689\n",
      "Epoch 13/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.0966 - accuracy: 0.6741 - val_loss: 2.0910 - val_accuracy: 0.6793\n",
      "Epoch 14/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.0281 - accuracy: 0.6840 - val_loss: 2.0341 - val_accuracy: 0.6873\n",
      "Epoch 15/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.9698 - accuracy: 0.6921 - val_loss: 1.9864 - val_accuracy: 0.6873\n",
      "Epoch 16/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.9200 - accuracy: 0.7024 - val_loss: 1.9422 - val_accuracy: 0.7171\n",
      "Epoch 17/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.8681 - accuracy: 0.7129 - val_loss: 1.8843 - val_accuracy: 0.7251\n",
      "Epoch 18/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.8257 - accuracy: 0.7163 - val_loss: 1.8496 - val_accuracy: 0.7200\n",
      "Epoch 19/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7828 - accuracy: 0.7262 - val_loss: 1.8152 - val_accuracy: 0.7280\n",
      "Epoch 20/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7429 - accuracy: 0.7322 - val_loss: 1.7882 - val_accuracy: 0.7313\n",
      "Epoch 21/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7095 - accuracy: 0.7365 - val_loss: 1.7625 - val_accuracy: 0.7482\n",
      "Epoch 22/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.6737 - accuracy: 0.7415 - val_loss: 1.7252 - val_accuracy: 0.7496\n",
      "Epoch 23/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.6418 - accuracy: 0.7492 - val_loss: 1.6981 - val_accuracy: 0.7562\n",
      "Epoch 24/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.6146 - accuracy: 0.7551 - val_loss: 1.6536 - val_accuracy: 0.7649\n",
      "Epoch 25/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5803 - accuracy: 0.7602 - val_loss: 1.6343 - val_accuracy: 0.7644\n",
      "Epoch 26/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5543 - accuracy: 0.7626 - val_loss: 1.6055 - val_accuracy: 0.7707\n",
      "Epoch 27/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5287 - accuracy: 0.7646 - val_loss: 1.5824 - val_accuracy: 0.7733\n",
      "Epoch 28/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5032 - accuracy: 0.7688 - val_loss: 1.5593 - val_accuracy: 0.7760\n",
      "Epoch 29/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4788 - accuracy: 0.7769 - val_loss: 1.5599 - val_accuracy: 0.7811\n",
      "Epoch 30/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4566 - accuracy: 0.7800 - val_loss: 1.5280 - val_accuracy: 0.7827\n",
      "Epoch 31/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4355 - accuracy: 0.7859 - val_loss: 1.5081 - val_accuracy: 0.7889\n",
      "Epoch 32/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4110 - accuracy: 0.7853 - val_loss: 1.4783 - val_accuracy: 0.7849\n",
      "Epoch 33/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3898 - accuracy: 0.7880 - val_loss: 1.4575 - val_accuracy: 0.7858\n",
      "Epoch 34/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3739 - accuracy: 0.7931 - val_loss: 1.4397 - val_accuracy: 0.7993\n",
      "Epoch 35/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3545 - accuracy: 0.7958 - val_loss: 1.4277 - val_accuracy: 0.8082\n",
      "Epoch 36/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3365 - accuracy: 0.7971 - val_loss: 1.4344 - val_accuracy: 0.8027\n",
      "Epoch 37/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3173 - accuracy: 0.7987 - val_loss: 1.4018 - val_accuracy: 0.8020\n",
      "Epoch 38/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3004 - accuracy: 0.8034 - val_loss: 1.3929 - val_accuracy: 0.8142\n",
      "Epoch 39/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2826 - accuracy: 0.8046 - val_loss: 1.3711 - val_accuracy: 0.8173\n",
      "Epoch 40/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2640 - accuracy: 0.8107 - val_loss: 1.3748 - val_accuracy: 0.8118\n",
      "Epoch 41/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2507 - accuracy: 0.8115 - val_loss: 1.3398 - val_accuracy: 0.8098\n",
      "Epoch 42/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2359 - accuracy: 0.8114 - val_loss: 1.3288 - val_accuracy: 0.8156\n",
      "Epoch 43/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2233 - accuracy: 0.8131 - val_loss: 1.3312 - val_accuracy: 0.8216\n",
      "Epoch 44/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2086 - accuracy: 0.8206 - val_loss: 1.3089 - val_accuracy: 0.8213\n",
      "Epoch 45/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1972 - accuracy: 0.8205 - val_loss: 1.3000 - val_accuracy: 0.8276\n",
      "Epoch 46/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1838 - accuracy: 0.8228 - val_loss: 1.3053 - val_accuracy: 0.8273\n",
      "Epoch 47/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1706 - accuracy: 0.8236 - val_loss: 1.2920 - val_accuracy: 0.8264\n",
      "Epoch 48/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1563 - accuracy: 0.8270 - val_loss: 1.2591 - val_accuracy: 0.8311\n",
      "Epoch 49/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1479 - accuracy: 0.8259 - val_loss: 1.2656 - val_accuracy: 0.8309\n",
      "Epoch 50/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1368 - accuracy: 0.8312 - val_loss: 1.2565 - val_accuracy: 0.8358\n",
      "Epoch 51/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1209 - accuracy: 0.8306 - val_loss: 1.2600 - val_accuracy: 0.8284\n",
      "Epoch 52/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1108 - accuracy: 0.8335 - val_loss: 1.2602 - val_accuracy: 0.8298\n",
      "Epoch 53/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1038 - accuracy: 0.8351 - val_loss: 1.2311 - val_accuracy: 0.8391\n",
      "Epoch 54/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0936 - accuracy: 0.8352 - val_loss: 1.2178 - val_accuracy: 0.8389\n",
      "Epoch 55/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0789 - accuracy: 0.8397 - val_loss: 1.2263 - val_accuracy: 0.8362\n",
      "Epoch 56/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0742 - accuracy: 0.8393 - val_loss: 1.2059 - val_accuracy: 0.8500\n",
      "Epoch 57/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0629 - accuracy: 0.8422 - val_loss: 1.2065 - val_accuracy: 0.8384\n",
      "Epoch 58/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0508 - accuracy: 0.8428 - val_loss: 1.1824 - val_accuracy: 0.8378\n",
      "Epoch 59/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0458 - accuracy: 0.8440 - val_loss: 1.2040 - val_accuracy: 0.8364\n",
      "Epoch 60/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0333 - accuracy: 0.8467 - val_loss: 1.1744 - val_accuracy: 0.8433\n",
      "Epoch 61/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0288 - accuracy: 0.8468 - val_loss: 1.1387 - val_accuracy: 0.8462\n",
      "Epoch 62/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0130 - accuracy: 0.8484 - val_loss: 1.1410 - val_accuracy: 0.8520\n",
      "Epoch 63/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0093 - accuracy: 0.8511 - val_loss: 1.1671 - val_accuracy: 0.8467\n",
      "Epoch 64/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0010 - accuracy: 0.8518 - val_loss: 1.1264 - val_accuracy: 0.8404\n",
      "Epoch 65/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9901 - accuracy: 0.8531 - val_loss: 1.1254 - val_accuracy: 0.8542\n",
      "Epoch 66/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9956 - accuracy: 0.8526 - val_loss: 1.1367 - val_accuracy: 0.8576\n",
      "Epoch 67/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9763 - accuracy: 0.8568 - val_loss: 1.1578 - val_accuracy: 0.8582\n",
      "Epoch 68/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9699 - accuracy: 0.8556 - val_loss: 1.1329 - val_accuracy: 0.8558\n",
      "Epoch 69/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9686 - accuracy: 0.8569 - val_loss: 1.1268 - val_accuracy: 0.8596\n",
      "Epoch 70/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9552 - accuracy: 0.8588 - val_loss: 1.1156 - val_accuracy: 0.8462\n",
      "Epoch 71/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9519 - accuracy: 0.8585 - val_loss: 1.1374 - val_accuracy: 0.8538\n",
      "Epoch 72/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9457 - accuracy: 0.8572 - val_loss: 1.1181 - val_accuracy: 0.8618\n",
      "Epoch 73/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9398 - accuracy: 0.8601 - val_loss: 1.0986 - val_accuracy: 0.8667\n",
      "Epoch 74/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9249 - accuracy: 0.8618 - val_loss: 1.1171 - val_accuracy: 0.8618\n",
      "Epoch 75/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9220 - accuracy: 0.8613 - val_loss: 1.1429 - val_accuracy: 0.8609\n",
      "Epoch 76/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9199 - accuracy: 0.8635 - val_loss: 1.0971 - val_accuracy: 0.8553\n",
      "Epoch 77/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9176 - accuracy: 0.8638 - val_loss: 1.0723 - val_accuracy: 0.8616\n",
      "Epoch 78/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9080 - accuracy: 0.8666 - val_loss: 1.0576 - val_accuracy: 0.8653\n",
      "Epoch 79/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9041 - accuracy: 0.8663 - val_loss: 1.0456 - val_accuracy: 0.8578\n",
      "Epoch 80/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8901 - accuracy: 0.8674 - val_loss: 1.0706 - val_accuracy: 0.8689\n",
      "Epoch 81/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8911 - accuracy: 0.8689 - val_loss: 1.0839 - val_accuracy: 0.8564\n",
      "Epoch 82/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8872 - accuracy: 0.8677 - val_loss: 1.0695 - val_accuracy: 0.8651\n",
      "Epoch 83/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8759 - accuracy: 0.8710 - val_loss: 1.0447 - val_accuracy: 0.8647\n",
      "Epoch 84/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8741 - accuracy: 0.8697 - val_loss: 1.0418 - val_accuracy: 0.8738\n",
      "Epoch 85/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8706 - accuracy: 0.8694 - val_loss: 1.0296 - val_accuracy: 0.8767\n",
      "Epoch 86/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8611 - accuracy: 0.8716 - val_loss: 1.0494 - val_accuracy: 0.8669\n",
      "Epoch 87/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8572 - accuracy: 0.8720 - val_loss: 1.0619 - val_accuracy: 0.8742\n",
      "Epoch 88/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8510 - accuracy: 0.8729 - val_loss: 1.0870 - val_accuracy: 0.8713\n",
      "Epoch 89/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8566 - accuracy: 0.8743 - val_loss: 1.0615 - val_accuracy: 0.8793\n",
      "Epoch 90/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8448 - accuracy: 0.8756 - val_loss: 1.0911 - val_accuracy: 0.8573\n",
      "Epoch 91/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8408 - accuracy: 0.8749 - val_loss: 1.0444 - val_accuracy: 0.8749\n",
      "Epoch 92/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8341 - accuracy: 0.8767 - val_loss: 1.0440 - val_accuracy: 0.8662\n",
      "Epoch 93/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8315 - accuracy: 0.8761 - val_loss: 1.0546 - val_accuracy: 0.8698\n",
      "Epoch 94/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8256 - accuracy: 0.8774 - val_loss: 1.0461 - val_accuracy: 0.8756\n",
      "Epoch 95/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8222 - accuracy: 0.8791 - val_loss: 1.0176 - val_accuracy: 0.8738\n",
      "Epoch 96/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8103 - accuracy: 0.8791 - val_loss: 1.1288 - val_accuracy: 0.8680\n",
      "Epoch 97/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8202 - accuracy: 0.8796 - val_loss: 1.0433 - val_accuracy: 0.8851\n",
      "Epoch 98/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8055 - accuracy: 0.8806 - val_loss: 1.0284 - val_accuracy: 0.8804\n",
      "Epoch 99/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8003 - accuracy: 0.8806 - val_loss: 1.0097 - val_accuracy: 0.8784\n",
      "Epoch 100/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8034 - accuracy: 0.8820 - val_loss: 1.0369 - val_accuracy: 0.8776\n",
      "Epoch 101/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7976 - accuracy: 0.8807 - val_loss: 1.0156 - val_accuracy: 0.8733\n",
      "Epoch 102/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7920 - accuracy: 0.8827 - val_loss: 1.0086 - val_accuracy: 0.8876\n",
      "Epoch 103/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7860 - accuracy: 0.8837 - val_loss: 1.0378 - val_accuracy: 0.8836\n",
      "Epoch 104/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7809 - accuracy: 0.8830 - val_loss: 1.0573 - val_accuracy: 0.8776\n",
      "Epoch 105/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7842 - accuracy: 0.8838 - val_loss: 1.0158 - val_accuracy: 0.8820\n",
      "Epoch 106/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7855 - accuracy: 0.8851 - val_loss: 1.0785 - val_accuracy: 0.8880\n",
      "Epoch 107/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7768 - accuracy: 0.8862 - val_loss: 1.0438 - val_accuracy: 0.8862\n",
      "Epoch 108/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7732 - accuracy: 0.8866 - val_loss: 0.9841 - val_accuracy: 0.8911\n",
      "Epoch 109/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7648 - accuracy: 0.8850 - val_loss: 1.0325 - val_accuracy: 0.8833\n",
      "Epoch 110/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7559 - accuracy: 0.8867 - val_loss: 1.0686 - val_accuracy: 0.8740\n",
      "Epoch 111/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7644 - accuracy: 0.8854 - val_loss: 1.0582 - val_accuracy: 0.8784\n",
      "Epoch 112/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7551 - accuracy: 0.8869 - val_loss: 1.0625 - val_accuracy: 0.8847\n",
      "Epoch 113/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7517 - accuracy: 0.8887 - val_loss: 1.0587 - val_accuracy: 0.8884\n",
      "Epoch 114/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7538 - accuracy: 0.8886 - val_loss: 1.0358 - val_accuracy: 0.8873\n",
      "Epoch 115/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7450 - accuracy: 0.8892 - val_loss: 1.0342 - val_accuracy: 0.8889\n",
      "Epoch 116/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7424 - accuracy: 0.8891 - val_loss: 1.0484 - val_accuracy: 0.8924\n",
      "Epoch 117/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7354 - accuracy: 0.8893 - val_loss: 1.0484 - val_accuracy: 0.9013\n",
      "Epoch 118/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7418 - accuracy: 0.8902 - val_loss: 1.0118 - val_accuracy: 0.8884\n",
      "Epoch 119/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7361 - accuracy: 0.8915 - val_loss: 1.0378 - val_accuracy: 0.8878\n",
      "Epoch 120/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7359 - accuracy: 0.8905 - val_loss: 1.0290 - val_accuracy: 0.8876\n",
      "Epoch 121/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7184 - accuracy: 0.8932 - val_loss: 1.0094 - val_accuracy: 0.8889\n",
      "Epoch 122/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7233 - accuracy: 0.8914 - val_loss: 1.0200 - val_accuracy: 0.8847\n",
      "Epoch 123/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7216 - accuracy: 0.8923 - val_loss: 1.0105 - val_accuracy: 0.8933\n",
      "Epoch 124/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7221 - accuracy: 0.8936 - val_loss: 1.0175 - val_accuracy: 0.8927\n",
      "Epoch 125/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7187 - accuracy: 0.8935 - val_loss: 1.0165 - val_accuracy: 0.8958\n",
      "Epoch 126/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7143 - accuracy: 0.8927 - val_loss: 1.0343 - val_accuracy: 0.8936\n",
      "Epoch 127/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7026 - accuracy: 0.8949 - val_loss: 1.0412 - val_accuracy: 0.8929\n",
      "Epoch 128/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7089 - accuracy: 0.8920 - val_loss: 1.0720 - val_accuracy: 0.8876\n",
      "Epoch 129/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7029 - accuracy: 0.8941 - val_loss: 1.0151 - val_accuracy: 0.8956\n",
      "Epoch 130/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7047 - accuracy: 0.8944 - val_loss: 1.0437 - val_accuracy: 0.8971\n",
      "Epoch 131/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7043 - accuracy: 0.8963 - val_loss: 1.0082 - val_accuracy: 0.8878\n",
      "Epoch 132/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6918 - accuracy: 0.8961 - val_loss: 1.0621 - val_accuracy: 0.8936\n",
      "Epoch 133/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6897 - accuracy: 0.8957 - val_loss: 1.0811 - val_accuracy: 0.9038\n",
      "Epoch 134/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6932 - accuracy: 0.8955 - val_loss: 1.0819 - val_accuracy: 0.8947\n",
      "Epoch 135/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6907 - accuracy: 0.8979 - val_loss: 1.0704 - val_accuracy: 0.9007\n",
      "Epoch 136/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6856 - accuracy: 0.8995 - val_loss: 1.0774 - val_accuracy: 0.8944\n",
      "Epoch 137/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6773 - accuracy: 0.8971 - val_loss: 1.0870 - val_accuracy: 0.8940\n",
      "Epoch 138/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6887 - accuracy: 0.8960 - val_loss: 1.0885 - val_accuracy: 0.8993\n",
      "Epoch 139/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6836 - accuracy: 0.8986 - val_loss: 1.0775 - val_accuracy: 0.8944\n",
      "Epoch 140/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.8992 - val_loss: 1.0625 - val_accuracy: 0.9033\n",
      "Epoch 141/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6751 - accuracy: 0.8992 - val_loss: 1.0423 - val_accuracy: 0.8967\n",
      "Epoch 142/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6746 - accuracy: 0.9000 - val_loss: 1.0149 - val_accuracy: 0.8940\n",
      "Epoch 143/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6585 - accuracy: 0.9000 - val_loss: 1.0438 - val_accuracy: 0.8909\n",
      "Epoch 144/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.8982 - val_loss: 1.0589 - val_accuracy: 0.8998\n",
      "Epoch 145/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6706 - accuracy: 0.9011 - val_loss: 0.9856 - val_accuracy: 0.9071\n",
      "Epoch 146/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6678 - accuracy: 0.9014 - val_loss: 1.0124 - val_accuracy: 0.8927\n",
      "Epoch 147/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6584 - accuracy: 0.9021 - val_loss: 0.9971 - val_accuracy: 0.9020\n",
      "Epoch 148/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6655 - accuracy: 0.9015 - val_loss: 1.0035 - val_accuracy: 0.9009\n",
      "Epoch 149/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6542 - accuracy: 0.9011 - val_loss: 1.0079 - val_accuracy: 0.9018\n",
      "Epoch 150/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6445 - accuracy: 0.9011 - val_loss: 1.0474 - val_accuracy: 0.8880\n",
      "Epoch 151/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6562 - accuracy: 0.9023 - val_loss: 1.0155 - val_accuracy: 0.9022\n",
      "Epoch 152/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6569 - accuracy: 0.9033 - val_loss: 1.0860 - val_accuracy: 0.8953\n",
      "Epoch 153/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6512 - accuracy: 0.9026 - val_loss: 1.1051 - val_accuracy: 0.8998\n",
      "Epoch 154/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6524 - accuracy: 0.9039 - val_loss: 1.0479 - val_accuracy: 0.8969\n",
      "Epoch 155/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6358 - accuracy: 0.9040 - val_loss: 1.0715 - val_accuracy: 0.8907\n",
      "Epoch 156/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6360 - accuracy: 0.9048 - val_loss: 1.0744 - val_accuracy: 0.8933\n",
      "Epoch 157/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6362 - accuracy: 0.9058 - val_loss: 1.0636 - val_accuracy: 0.9084\n",
      "Epoch 158/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6479 - accuracy: 0.9019 - val_loss: 1.0825 - val_accuracy: 0.8951\n",
      "Epoch 159/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6430 - accuracy: 0.9046 - val_loss: 1.0689 - val_accuracy: 0.8949\n",
      "Epoch 160/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6344 - accuracy: 0.9066 - val_loss: 1.0665 - val_accuracy: 0.9082\n",
      "Epoch 161/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6355 - accuracy: 0.9053 - val_loss: 1.0546 - val_accuracy: 0.9033\n",
      "Epoch 162/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6354 - accuracy: 0.9060 - val_loss: 1.0702 - val_accuracy: 0.9038\n",
      "Epoch 163/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6315 - accuracy: 0.9054 - val_loss: 1.0662 - val_accuracy: 0.9138\n",
      "Epoch 164/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6307 - accuracy: 0.9051 - val_loss: 1.1070 - val_accuracy: 0.8956\n",
      "Epoch 165/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6237 - accuracy: 0.9055 - val_loss: 1.0721 - val_accuracy: 0.8958\n",
      "Epoch 166/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6201 - accuracy: 0.9066 - val_loss: 1.1153 - val_accuracy: 0.8967\n",
      "Epoch 167/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6254 - accuracy: 0.9055 - val_loss: 1.1120 - val_accuracy: 0.8962\n",
      "Epoch 168/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6253 - accuracy: 0.9066 - val_loss: 1.0817 - val_accuracy: 0.9120\n",
      "Epoch 169/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6121 - accuracy: 0.9087 - val_loss: 1.0726 - val_accuracy: 0.8907\n",
      "Epoch 170/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6130 - accuracy: 0.9085 - val_loss: 1.0444 - val_accuracy: 0.9053\n",
      "Epoch 171/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6031 - accuracy: 0.9085 - val_loss: 1.0702 - val_accuracy: 0.9024\n",
      "Epoch 172/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6099 - accuracy: 0.9077 - val_loss: 1.0525 - val_accuracy: 0.9013\n",
      "Epoch 173/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6198 - accuracy: 0.9074 - val_loss: 1.0664 - val_accuracy: 0.9038\n",
      "Epoch 174/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6097 - accuracy: 0.9092 - val_loss: 1.1207 - val_accuracy: 0.9058\n",
      "Epoch 175/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6068 - accuracy: 0.9086 - val_loss: 1.1542 - val_accuracy: 0.9016\n",
      "Epoch 176/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6080 - accuracy: 0.9098 - val_loss: 1.0582 - val_accuracy: 0.9036\n",
      "Epoch 177/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6009 - accuracy: 0.9089 - val_loss: 1.0879 - val_accuracy: 0.9069\n",
      "Epoch 178/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5957 - accuracy: 0.9088 - val_loss: 1.0943 - val_accuracy: 0.9127\n",
      "Epoch 179/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6011 - accuracy: 0.9095 - val_loss: 1.0613 - val_accuracy: 0.9029\n",
      "Epoch 180/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5971 - accuracy: 0.9098 - val_loss: 1.0427 - val_accuracy: 0.8949\n",
      "Epoch 181/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6015 - accuracy: 0.9100 - val_loss: 0.9855 - val_accuracy: 0.9031\n",
      "Epoch 182/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5999 - accuracy: 0.9083 - val_loss: 1.0715 - val_accuracy: 0.9162\n",
      "Epoch 183/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5929 - accuracy: 0.9115 - val_loss: 1.0747 - val_accuracy: 0.9120\n",
      "Epoch 184/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5919 - accuracy: 0.9096 - val_loss: 1.0920 - val_accuracy: 0.8962\n",
      "Epoch 185/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5868 - accuracy: 0.9104 - val_loss: 1.0954 - val_accuracy: 0.9042\n",
      "Epoch 186/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5913 - accuracy: 0.9105 - val_loss: 1.2118 - val_accuracy: 0.9020\n",
      "Epoch 187/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5996 - accuracy: 0.9090 - val_loss: 1.1595 - val_accuracy: 0.9093\n",
      "Epoch 188/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5808 - accuracy: 0.9112 - val_loss: 1.1344 - val_accuracy: 0.9053\n",
      "Epoch 189/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5782 - accuracy: 0.9122 - val_loss: 1.1374 - val_accuracy: 0.9133\n",
      "Epoch 190/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5854 - accuracy: 0.9107 - val_loss: 1.1445 - val_accuracy: 0.9124\n",
      "Epoch 191/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5839 - accuracy: 0.9123 - val_loss: 1.2561 - val_accuracy: 0.9042\n",
      "Epoch 192/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5860 - accuracy: 0.9123 - val_loss: 1.1712 - val_accuracy: 0.9089\n",
      "Epoch 193/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5810 - accuracy: 0.9125 - val_loss: 1.1330 - val_accuracy: 0.9078\n",
      "Epoch 194/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5669 - accuracy: 0.9118 - val_loss: 1.1813 - val_accuracy: 0.9067\n",
      "Epoch 195/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5784 - accuracy: 0.9117 - val_loss: 1.2090 - val_accuracy: 0.8998\n",
      "Epoch 196/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5862 - accuracy: 0.9119 - val_loss: 1.2128 - val_accuracy: 0.8911\n",
      "Epoch 197/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.9134 - val_loss: 1.1852 - val_accuracy: 0.9133\n",
      "Epoch 198/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5650 - accuracy: 0.9135 - val_loss: 1.1682 - val_accuracy: 0.9098\n",
      "Epoch 199/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5737 - accuracy: 0.9134 - val_loss: 1.1452 - val_accuracy: 0.9089\n",
      "Epoch 200/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5637 - accuracy: 0.9132 - val_loss: 1.2782 - val_accuracy: 0.8996\n",
      "Epoch 201/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5814 - accuracy: 0.9132 - val_loss: 1.1920 - val_accuracy: 0.9042\n",
      "Epoch 202/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5646 - accuracy: 0.9159 - val_loss: 1.1555 - val_accuracy: 0.9138\n",
      "Epoch 203/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5551 - accuracy: 0.9167 - val_loss: 1.1632 - val_accuracy: 0.9167\n",
      "Epoch 204/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5634 - accuracy: 0.9132 - val_loss: 1.1827 - val_accuracy: 0.9058\n",
      "Epoch 205/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5647 - accuracy: 0.9148 - val_loss: 1.1509 - val_accuracy: 0.9107\n",
      "Epoch 206/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5627 - accuracy: 0.9167 - val_loss: 1.1205 - val_accuracy: 0.9173\n",
      "Epoch 207/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5555 - accuracy: 0.9154 - val_loss: 1.1816 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5507 - accuracy: 0.9163 - val_loss: 1.1851 - val_accuracy: 0.9164\n",
      "Epoch 209/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5491 - accuracy: 0.9140 - val_loss: 1.1992 - val_accuracy: 0.9069\n",
      "Epoch 210/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5606 - accuracy: 0.9155 - val_loss: 1.2053 - val_accuracy: 0.9209\n",
      "Epoch 211/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5539 - accuracy: 0.9174 - val_loss: 1.1635 - val_accuracy: 0.9167\n",
      "Epoch 212/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5568 - accuracy: 0.9162 - val_loss: 1.1713 - val_accuracy: 0.9056\n",
      "Epoch 213/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5491 - accuracy: 0.9166 - val_loss: 1.1548 - val_accuracy: 0.9113\n",
      "Epoch 214/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5577 - accuracy: 0.9168 - val_loss: 1.1540 - val_accuracy: 0.9149\n",
      "Epoch 215/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5580 - accuracy: 0.9171 - val_loss: 1.1152 - val_accuracy: 0.9111\n",
      "Epoch 216/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5444 - accuracy: 0.9194 - val_loss: 1.1661 - val_accuracy: 0.9087\n",
      "Epoch 217/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5482 - accuracy: 0.9155 - val_loss: 1.1241 - val_accuracy: 0.9124\n",
      "Epoch 218/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5416 - accuracy: 0.9170 - val_loss: 1.1644 - val_accuracy: 0.9178\n",
      "Epoch 219/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5430 - accuracy: 0.9172 - val_loss: 1.1970 - val_accuracy: 0.9038\n",
      "Epoch 220/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5485 - accuracy: 0.9169 - val_loss: 1.0733 - val_accuracy: 0.9136\n",
      "Epoch 221/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.9187 - val_loss: 1.1056 - val_accuracy: 0.9111\n",
      "Epoch 222/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5471 - accuracy: 0.9189 - val_loss: 1.1556 - val_accuracy: 0.9127\n",
      "Epoch 223/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5459 - accuracy: 0.9178 - val_loss: 1.1182 - val_accuracy: 0.9191\n",
      "Epoch 224/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5245 - accuracy: 0.9187 - val_loss: 1.1340 - val_accuracy: 0.9131\n",
      "Epoch 225/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5371 - accuracy: 0.9174 - val_loss: 1.0983 - val_accuracy: 0.9193\n",
      "Epoch 226/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5360 - accuracy: 0.9180 - val_loss: 1.0904 - val_accuracy: 0.9171\n",
      "Epoch 227/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5323 - accuracy: 0.9183 - val_loss: 1.0843 - val_accuracy: 0.9233\n",
      "Epoch 228/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5300 - accuracy: 0.9197 - val_loss: 1.0958 - val_accuracy: 0.9140\n",
      "Epoch 229/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5261 - accuracy: 0.9190 - val_loss: 1.0917 - val_accuracy: 0.9207\n",
      "Epoch 230/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5351 - accuracy: 0.9178 - val_loss: 1.1668 - val_accuracy: 0.9111\n",
      "Epoch 231/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5435 - accuracy: 0.9200 - val_loss: 1.1099 - val_accuracy: 0.9169\n",
      "Epoch 232/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5302 - accuracy: 0.9210 - val_loss: 1.1499 - val_accuracy: 0.9236\n",
      "Epoch 233/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5244 - accuracy: 0.9209 - val_loss: 1.1091 - val_accuracy: 0.9162\n",
      "Epoch 234/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5297 - accuracy: 0.9197 - val_loss: 1.1394 - val_accuracy: 0.9151\n",
      "Epoch 235/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5277 - accuracy: 0.9191 - val_loss: 1.1630 - val_accuracy: 0.8967\n",
      "Epoch 236/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.9192 - val_loss: 1.0901 - val_accuracy: 0.9109\n",
      "Epoch 237/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5212 - accuracy: 0.9209 - val_loss: 1.1544 - val_accuracy: 0.9176\n",
      "Epoch 238/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5137 - accuracy: 0.9204 - val_loss: 1.2404 - val_accuracy: 0.9131\n",
      "Epoch 239/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5269 - accuracy: 0.9201 - val_loss: 1.2149 - val_accuracy: 0.9116\n",
      "Epoch 240/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5444 - accuracy: 0.9184 - val_loss: 1.1346 - val_accuracy: 0.9180\n",
      "Epoch 241/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5133 - accuracy: 0.9223 - val_loss: 1.1570 - val_accuracy: 0.9176\n",
      "Epoch 242/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5156 - accuracy: 0.9208 - val_loss: 1.1359 - val_accuracy: 0.9113\n",
      "Epoch 243/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5169 - accuracy: 0.9192 - val_loss: 1.1368 - val_accuracy: 0.9187\n",
      "Epoch 244/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5124 - accuracy: 0.9217 - val_loss: 1.1649 - val_accuracy: 0.9167\n",
      "Epoch 245/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5144 - accuracy: 0.9204 - val_loss: 1.1053 - val_accuracy: 0.9147\n",
      "Epoch 246/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5153 - accuracy: 0.9203 - val_loss: 1.1763 - val_accuracy: 0.9113\n",
      "Epoch 247/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5155 - accuracy: 0.9222 - val_loss: 1.1889 - val_accuracy: 0.9144\n",
      "Epoch 248/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5248 - accuracy: 0.9223 - val_loss: 1.1776 - val_accuracy: 0.9193\n",
      "Epoch 249/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5056 - accuracy: 0.9224 - val_loss: 1.2296 - val_accuracy: 0.9022\n",
      "Epoch 250/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5073 - accuracy: 0.9215 - val_loss: 1.1898 - val_accuracy: 0.9156\n",
      "Epoch 251/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5115 - accuracy: 0.9203 - val_loss: 1.2436 - val_accuracy: 0.9136\n",
      "Epoch 252/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5075 - accuracy: 0.9225 - val_loss: 1.2819 - val_accuracy: 0.9196\n",
      "Epoch 253/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5147 - accuracy: 0.9216 - val_loss: 1.2344 - val_accuracy: 0.9231\n",
      "Epoch 254/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5166 - accuracy: 0.9238 - val_loss: 1.2532 - val_accuracy: 0.9167\n",
      "Epoch 255/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5080 - accuracy: 0.9223 - val_loss: 1.1894 - val_accuracy: 0.9189\n",
      "Epoch 256/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4990 - accuracy: 0.9227 - val_loss: 1.1660 - val_accuracy: 0.9209\n",
      "Epoch 257/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5082 - accuracy: 0.9206 - val_loss: 1.1804 - val_accuracy: 0.9220\n",
      "Epoch 258/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5188 - accuracy: 0.9232 - val_loss: 1.1543 - val_accuracy: 0.9229\n",
      "Epoch 259/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5006 - accuracy: 0.9234 - val_loss: 1.1182 - val_accuracy: 0.9153\n",
      "Epoch 260/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5003 - accuracy: 0.9230 - val_loss: 1.1105 - val_accuracy: 0.9120\n",
      "Epoch 261/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4929 - accuracy: 0.9249 - val_loss: 1.1626 - val_accuracy: 0.9202\n",
      "Epoch 262/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5034 - accuracy: 0.9232 - val_loss: 1.1790 - val_accuracy: 0.9193\n",
      "Epoch 263/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5094 - accuracy: 0.9227 - val_loss: 1.1634 - val_accuracy: 0.9144\n",
      "Epoch 264/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4950 - accuracy: 0.9227 - val_loss: 1.1400 - val_accuracy: 0.9231\n",
      "Epoch 265/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4934 - accuracy: 0.9254 - val_loss: 1.1712 - val_accuracy: 0.9240\n",
      "Epoch 266/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4996 - accuracy: 0.9251 - val_loss: 1.2326 - val_accuracy: 0.9133\n",
      "Epoch 267/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4959 - accuracy: 0.9240 - val_loss: 1.2973 - val_accuracy: 0.9140\n",
      "Epoch 268/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4890 - accuracy: 0.9240 - val_loss: 1.2540 - val_accuracy: 0.9242\n",
      "Epoch 269/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5094 - accuracy: 0.9240 - val_loss: 1.2091 - val_accuracy: 0.9231\n",
      "Epoch 270/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4938 - accuracy: 0.9252 - val_loss: 1.3372 - val_accuracy: 0.9064\n",
      "Epoch 271/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4910 - accuracy: 0.9233 - val_loss: 1.2581 - val_accuracy: 0.9204\n",
      "Epoch 272/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4926 - accuracy: 0.9251 - val_loss: 1.2205 - val_accuracy: 0.9191\n",
      "Epoch 273/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4926 - accuracy: 0.9253 - val_loss: 1.2420 - val_accuracy: 0.9227\n",
      "Epoch 274/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4856 - accuracy: 0.9252 - val_loss: 1.1940 - val_accuracy: 0.9207\n",
      "Epoch 275/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5012 - accuracy: 0.9247 - val_loss: 1.1565 - val_accuracy: 0.9267\n",
      "Epoch 276/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4837 - accuracy: 0.9249 - val_loss: 1.1388 - val_accuracy: 0.9111\n",
      "Epoch 277/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4842 - accuracy: 0.9240 - val_loss: 1.1335 - val_accuracy: 0.9133\n",
      "Epoch 278/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4892 - accuracy: 0.9258 - val_loss: 1.0942 - val_accuracy: 0.9220\n",
      "Epoch 279/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4872 - accuracy: 0.9244 - val_loss: 1.1658 - val_accuracy: 0.9233\n",
      "Epoch 280/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4887 - accuracy: 0.9244 - val_loss: 1.2508 - val_accuracy: 0.9184\n",
      "Epoch 281/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4933 - accuracy: 0.9260 - val_loss: 1.2768 - val_accuracy: 0.9253\n",
      "Epoch 282/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4776 - accuracy: 0.9254 - val_loss: 1.2582 - val_accuracy: 0.9173\n",
      "Epoch 283/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4758 - accuracy: 0.9251 - val_loss: 1.2489 - val_accuracy: 0.9164\n",
      "Epoch 284/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4793 - accuracy: 0.9247 - val_loss: 1.2637 - val_accuracy: 0.9198\n",
      "Epoch 285/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4705 - accuracy: 0.9251 - val_loss: 1.3102 - val_accuracy: 0.9247\n",
      "Epoch 286/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4859 - accuracy: 0.9264 - val_loss: 1.2877 - val_accuracy: 0.9200\n",
      "Epoch 287/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4843 - accuracy: 0.9252 - val_loss: 1.2546 - val_accuracy: 0.9276\n",
      "Epoch 288/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4857 - accuracy: 0.9249 - val_loss: 1.2716 - val_accuracy: 0.9131\n",
      "Epoch 289/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4794 - accuracy: 0.9258 - val_loss: 1.2898 - val_accuracy: 0.9120\n",
      "Epoch 290/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4845 - accuracy: 0.9259 - val_loss: 1.2301 - val_accuracy: 0.9153\n",
      "Epoch 291/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4796 - accuracy: 0.9275 - val_loss: 1.2953 - val_accuracy: 0.9224\n",
      "Epoch 292/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4850 - accuracy: 0.9266 - val_loss: 1.2965 - val_accuracy: 0.9151\n",
      "Epoch 293/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4692 - accuracy: 0.9267 - val_loss: 1.2889 - val_accuracy: 0.9051\n",
      "Epoch 294/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4680 - accuracy: 0.9257 - val_loss: 1.2969 - val_accuracy: 0.9282\n",
      "Epoch 295/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4692 - accuracy: 0.9277 - val_loss: 1.3067 - val_accuracy: 0.9176\n",
      "Epoch 296/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4778 - accuracy: 0.9252 - val_loss: 1.3527 - val_accuracy: 0.9087\n",
      "Epoch 297/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4682 - accuracy: 0.9279 - val_loss: 1.3486 - val_accuracy: 0.9244\n",
      "Epoch 298/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4628 - accuracy: 0.9275 - val_loss: 1.2424 - val_accuracy: 0.9256\n",
      "Epoch 299/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4696 - accuracy: 0.9264 - val_loss: 1.2064 - val_accuracy: 0.9284\n",
      "Epoch 300/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4670 - accuracy: 0.9259 - val_loss: 1.2583 - val_accuracy: 0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_9_layer_call_fn, leaky_re_lu_9_layer_call_and_return_conditional_losses, leaky_re_lu_10_layer_call_fn, leaky_re_lu_10_layer_call_and_return_conditional_losses, leaky_re_lu_11_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class_pca_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class_pca_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 13s\n",
      "Wall time: 8min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/sig_class_pca_test'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(int(pca.n_components_))))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "804d5dca-da51-4c35-b5fd-3f6bf937b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc413ec-1d01-4036-8bab-e4309224cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 801us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550fb42-15a5-416a-a527-05341b076f02",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Components from PCA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68ceb80b-59b5-49a7-9a6a-e0e7dc7273c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3c63e-297b-428d-8528-da0aa58098c8",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "345b8adc-5738-4839-82eb-69a6a1eb0741",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.94737   0.97297        19\n",
      "           1    1.00000   0.90000   0.94737        20\n",
      "           2    1.00000   1.00000   1.00000        19\n",
      "           3    0.30667   1.00000   0.46939        23\n",
      "           4    1.00000   0.80769   0.89362        26\n",
      "           5    0.88889   0.88889   0.88889        18\n",
      "           6    1.00000   0.91667   0.95652        24\n",
      "           7    1.00000   0.96000   0.97959        25\n",
      "           8    1.00000   1.00000   1.00000        17\n",
      "           9    1.00000   0.84615   0.91667        26\n",
      "          10    1.00000   1.00000   1.00000        25\n",
      "          11    1.00000   0.95238   0.97561        21\n",
      "          12    1.00000   0.95652   0.97778        23\n",
      "          13    1.00000   0.90909   0.95238        22\n",
      "          14    1.00000   0.91304   0.95455        23\n",
      "          15    0.94444   0.94444   0.94444        18\n",
      "          16    1.00000   0.93750   0.96774        16\n",
      "          17    0.93750   1.00000   0.96774        15\n",
      "          18    1.00000   0.94444   0.97143        18\n",
      "          19    1.00000   0.95652   0.97778        23\n",
      "          20    1.00000   0.89474   0.94444        19\n",
      "          21    1.00000   0.90476   0.95000        21\n",
      "          22    1.00000   1.00000   1.00000        21\n",
      "          23    1.00000   0.83333   0.90909        24\n",
      "          24    1.00000   0.80952   0.89474        21\n",
      "          25    1.00000   1.00000   1.00000        15\n",
      "          26    1.00000   1.00000   1.00000        25\n",
      "          27    1.00000   0.94444   0.97143        18\n",
      "          28    1.00000   1.00000   1.00000        18\n",
      "          29    1.00000   0.94737   0.97297        19\n",
      "          30    1.00000   0.90909   0.95238        22\n",
      "          31    1.00000   0.94444   0.97143        18\n",
      "          32    1.00000   0.87500   0.93333        16\n",
      "          33    0.95000   0.95000   0.95000        20\n",
      "          34    1.00000   0.94118   0.96970        17\n",
      "          35    1.00000   0.96000   0.97959        25\n",
      "          36    1.00000   0.76923   0.86957        13\n",
      "          37    1.00000   0.85714   0.92308        21\n",
      "          38    0.90909   0.95238   0.93023        21\n",
      "          39    1.00000   0.84211   0.91429        19\n",
      "          40    1.00000   0.94444   0.97143        18\n",
      "          41    1.00000   0.92593   0.96154        27\n",
      "          42    1.00000   0.90476   0.95000        21\n",
      "          43    1.00000   1.00000   1.00000        14\n",
      "          44    1.00000   0.94444   0.97143        18\n",
      "          45    1.00000   0.90476   0.95000        21\n",
      "          46    1.00000   0.88889   0.94118         9\n",
      "          47    1.00000   0.92857   0.96296        14\n",
      "          48    1.00000   1.00000   1.00000        19\n",
      "          49    1.00000   0.92308   0.96000        13\n",
      "          50    0.96296   0.96296   0.96296        27\n",
      "          51    0.95455   0.87500   0.91304        24\n",
      "          52    1.00000   0.77778   0.87500        18\n",
      "          53    1.00000   0.95455   0.97674        22\n",
      "          54    1.00000   0.91304   0.95455        23\n",
      "          55    1.00000   1.00000   1.00000        19\n",
      "          56    1.00000   1.00000   1.00000        19\n",
      "          57    0.95455   1.00000   0.97674        21\n",
      "          58    1.00000   0.85714   0.92308        21\n",
      "          59    1.00000   0.88462   0.93878        26\n",
      "          60    1.00000   1.00000   1.00000        21\n",
      "          61    1.00000   0.96000   0.97959        25\n",
      "          62    1.00000   0.94737   0.97297        19\n",
      "          63    1.00000   1.00000   1.00000        23\n",
      "          64    1.00000   0.89474   0.94444        19\n",
      "          65    0.95000   0.86364   0.90476        22\n",
      "          66    1.00000   0.83333   0.90909        18\n",
      "          67    1.00000   1.00000   1.00000        19\n",
      "          68    1.00000   0.82609   0.90476        23\n",
      "          69    1.00000   1.00000   1.00000        21\n",
      "          70    1.00000   1.00000   1.00000        12\n",
      "          71    1.00000   0.82609   0.90476        23\n",
      "          72    0.88889   0.88889   0.88889        18\n",
      "          73    0.69565   1.00000   0.82051        16\n",
      "          74    1.00000   0.90000   0.94737        20\n",
      "          75    1.00000   0.85000   0.91892        20\n",
      "          76    1.00000   0.86957   0.93023        23\n",
      "          77    1.00000   0.85714   0.92308        21\n",
      "          78    1.00000   0.94737   0.97297        19\n",
      "          79    1.00000   0.93548   0.96667        31\n",
      "          80    0.38158   0.96667   0.54717        30\n",
      "          81    0.09420   1.00000   0.17219        13\n",
      "          82    0.66667   0.92308   0.77419        13\n",
      "          83    1.00000   1.00000   1.00000        25\n",
      "          84    0.91667   1.00000   0.95652        22\n",
      "          85    0.90000   0.94737   0.92308        19\n",
      "          86    1.00000   0.93750   0.96774        16\n",
      "          87    1.00000   0.82353   0.90323        17\n",
      "          88    1.00000   0.94444   0.97143        18\n",
      "          89    0.96000   0.92308   0.94118        26\n",
      "          90    1.00000   0.93750   0.96774        16\n",
      "          91    1.00000   0.95000   0.97436        20\n",
      "          92    1.00000   0.95238   0.97561        21\n",
      "          93    1.00000   0.83333   0.90909        12\n",
      "          94    0.86957   0.95238   0.90909        21\n",
      "          95    1.00000   0.75000   0.85714        16\n",
      "          96    1.00000   1.00000   1.00000        21\n",
      "          97    1.00000   0.92308   0.96000        26\n",
      "          98    1.00000   0.96000   0.97959        25\n",
      "          99    0.93750   0.93750   0.93750        16\n",
      "         100    1.00000   0.76190   0.86486        21\n",
      "         101    1.00000   0.95833   0.97872        24\n",
      "         102    0.83333   1.00000   0.90909        20\n",
      "         103    0.93750   1.00000   0.96774        15\n",
      "         104    1.00000   0.93333   0.96552        15\n",
      "         105    1.00000   0.73333   0.84615        15\n",
      "         106    0.95455   0.91304   0.93333        23\n",
      "         107    0.77273   0.85000   0.80952        20\n",
      "         108    0.95652   0.88000   0.91667        25\n",
      "         109    1.00000   0.92308   0.96000        26\n",
      "         110    1.00000   0.82609   0.90476        23\n",
      "         111    0.78571   1.00000   0.88000        22\n",
      "         112    1.00000   0.88889   0.94118        18\n",
      "         113    1.00000   0.85185   0.92000        27\n",
      "         114    0.87500   0.93333   0.90323        15\n",
      "         115    1.00000   0.94118   0.96970        17\n",
      "         116    1.00000   0.95652   0.97778        23\n",
      "         117    1.00000   1.00000   1.00000        19\n",
      "         118    1.00000   0.78947   0.88235        19\n",
      "         119    0.94444   0.94444   0.94444        18\n",
      "         120    1.00000   0.86957   0.93023        23\n",
      "         121    1.00000   0.88235   0.93750        17\n",
      "         122    0.82609   1.00000   0.90476        19\n",
      "         123    1.00000   0.77778   0.87500        18\n",
      "         124    1.00000   0.87500   0.93333        24\n",
      "         125    1.00000   0.80000   0.88889        20\n",
      "         126    1.00000   1.00000   1.00000        16\n",
      "         127    1.00000   0.86957   0.93023        23\n",
      "         128    1.00000   0.93750   0.96774        16\n",
      "         129    1.00000   1.00000   1.00000        12\n",
      "         130    1.00000   1.00000   1.00000        20\n",
      "         131    1.00000   0.79167   0.88372        24\n",
      "         132    1.00000   0.95238   0.97561        21\n",
      "         133    1.00000   0.71429   0.83333        14\n",
      "         134    0.88235   1.00000   0.93750        15\n",
      "         135    0.90000   0.90000   0.90000        20\n",
      "         136    1.00000   0.88462   0.93878        26\n",
      "         137    0.87500   1.00000   0.93333        14\n",
      "         138    0.89474   0.80952   0.85000        21\n",
      "         139    1.00000   0.90000   0.94737        20\n",
      "         140    1.00000   0.95652   0.97778        23\n",
      "         141    1.00000   1.00000   1.00000        21\n",
      "         142    1.00000   0.94118   0.96970        17\n",
      "         143    0.92308   0.85714   0.88889        14\n",
      "         144    1.00000   0.91304   0.95455        23\n",
      "         145    1.00000   0.92308   0.96000        13\n",
      "         146    1.00000   0.88889   0.94118        27\n",
      "         147    0.96000   0.85714   0.90566        28\n",
      "         148    0.95238   0.86957   0.90909        23\n",
      "         149    1.00000   0.95652   0.97778        23\n",
      "         150    0.88000   0.84615   0.86275        26\n",
      "         151    0.95000   0.90476   0.92683        21\n",
      "         152    1.00000   0.96000   0.97959        25\n",
      "         153    1.00000   0.89474   0.94444        19\n",
      "         154    0.66667   1.00000   0.80000        22\n",
      "         155    0.84211   1.00000   0.91429        16\n",
      "         156    1.00000   0.91304   0.95455        23\n",
      "         157    1.00000   0.94118   0.96970        17\n",
      "         158    1.00000   0.90909   0.95238        22\n",
      "         159    0.95000   0.95000   0.95000        20\n",
      "         160    1.00000   1.00000   1.00000        22\n",
      "         161    0.95833   1.00000   0.97872        23\n",
      "         162    1.00000   0.85714   0.92308        14\n",
      "         163    0.95833   1.00000   0.97872        23\n",
      "         164    1.00000   1.00000   1.00000        18\n",
      "         165    1.00000   0.96667   0.98305        30\n",
      "         166    1.00000   0.89474   0.94444        19\n",
      "         167    0.91667   0.91667   0.91667        24\n",
      "         168    0.80000   0.92308   0.85714        13\n",
      "         169    0.88235   1.00000   0.93750        15\n",
      "         170    1.00000   0.84615   0.91667        26\n",
      "         171    0.95000   0.95000   0.95000        20\n",
      "         172    1.00000   0.90909   0.95238        22\n",
      "         173    0.78571   0.84615   0.81481        13\n",
      "         174    1.00000   0.80000   0.88889        20\n",
      "         175    1.00000   0.91304   0.95455        23\n",
      "         176    1.00000   0.94737   0.97297        19\n",
      "         177    1.00000   1.00000   1.00000        18\n",
      "         178    1.00000   1.00000   1.00000        16\n",
      "         179    0.95833   0.95833   0.95833        24\n",
      "         180    1.00000   1.00000   1.00000        22\n",
      "         181    1.00000   0.90909   0.95238        11\n",
      "         182    1.00000   0.93333   0.96552        15\n",
      "         183    1.00000   1.00000   1.00000        25\n",
      "         184    1.00000   0.82353   0.90323        17\n",
      "         185    0.94118   0.84211   0.88889        19\n",
      "         186    0.96154   0.92593   0.94340        27\n",
      "         187    0.94737   0.90000   0.92308        20\n",
      "         188    0.96154   0.96154   0.96154        26\n",
      "         189    1.00000   0.93333   0.96552        30\n",
      "         190    1.00000   1.00000   1.00000        18\n",
      "         191    1.00000   1.00000   1.00000        19\n",
      "         192    1.00000   0.85714   0.92308        14\n",
      "         193    1.00000   0.95000   0.97436        20\n",
      "         194    1.00000   0.86957   0.93023        23\n",
      "         195    0.95652   0.95652   0.95652        23\n",
      "         196    0.95238   0.90909   0.93023        22\n",
      "         197    1.00000   0.80000   0.88889        15\n",
      "         198    1.00000   0.85000   0.91892        20\n",
      "         199    1.00000   0.95000   0.97436        20\n",
      "         200    1.00000   0.94737   0.97297        19\n",
      "         201    0.95833   1.00000   0.97872        23\n",
      "         202    1.00000   0.88235   0.93750        17\n",
      "         203    1.00000   0.77778   0.87500        27\n",
      "         204    1.00000   0.78571   0.88000        14\n",
      "         205    0.94118   0.94118   0.94118        17\n",
      "         206    1.00000   0.84615   0.91667        13\n",
      "         207    0.91667   1.00000   0.95652        22\n",
      "         208    1.00000   0.90476   0.95000        21\n",
      "         209    1.00000   0.93333   0.96552        15\n",
      "         210    1.00000   0.86364   0.92683        22\n",
      "         211    1.00000   1.00000   1.00000        25\n",
      "         212    1.00000   1.00000   1.00000        18\n",
      "         213    1.00000   0.83333   0.90909        12\n",
      "         214    1.00000   0.78947   0.88235        19\n",
      "         215    0.87500   0.87500   0.87500        24\n",
      "         216    0.89474   1.00000   0.94444        17\n",
      "         217    1.00000   1.00000   1.00000        22\n",
      "         218    1.00000   0.95000   0.97436        20\n",
      "         219    1.00000   0.88235   0.93750        17\n",
      "         220    1.00000   1.00000   1.00000        13\n",
      "         221    1.00000   1.00000   1.00000        21\n",
      "         222    0.66667   0.92308   0.77419        13\n",
      "         223    1.00000   0.95238   0.97561        21\n",
      "         224    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        0.92244      4500\n",
      "   macro avg    0.96362   0.92216   0.93662      4500\n",
      "weighted avg    0.96509   0.92244   0.93785      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8eb28-65ac-420d-8955-bf7f3e5e7a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
