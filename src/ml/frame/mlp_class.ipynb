{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f78aa7-15d8-4c44-8e24-810219393815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994720bf-b54a-4fb0-ae3c-eea3a5b39e24",
   "metadata": {},
   "source": [
    "<h1>Linear Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d4a403-460f-41ed-85f5-1942215d93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/results_complete_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0935dd9-210a-474b-9a82-aa077ca287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['elem_damaged', 'damage'], axis=1), df['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af628b4-0f5f-4722-bd9a-86c4e372bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab4ae95-f2fc-436c-acac-8ff44a1e1bc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                10160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 129)               10449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,569\n",
      "Trainable params: 33,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.5802 - accuracy: 0.0856 - val_loss: 4.2733 - val_accuracy: 0.1411\n",
      "Epoch 2/1000\n",
      "726/726 [==============================] - 1s 807us/step - loss: 3.8853 - accuracy: 0.2205 - val_loss: 3.6582 - val_accuracy: 0.2372\n",
      "Epoch 3/1000\n",
      "726/726 [==============================] - 1s 817us/step - loss: 3.2996 - accuracy: 0.3168 - val_loss: 3.1240 - val_accuracy: 0.3411\n",
      "Epoch 4/1000\n",
      "726/726 [==============================] - 1s 789us/step - loss: 2.8374 - accuracy: 0.3994 - val_loss: 2.7266 - val_accuracy: 0.4132\n",
      "Epoch 5/1000\n",
      "726/726 [==============================] - 1s 798us/step - loss: 2.5102 - accuracy: 0.4618 - val_loss: 2.4544 - val_accuracy: 0.4717\n",
      "Epoch 6/1000\n",
      "726/726 [==============================] - 1s 926us/step - loss: 2.2826 - accuracy: 0.5050 - val_loss: 2.2674 - val_accuracy: 0.5124\n",
      "Epoch 7/1000\n",
      "726/726 [==============================] - 1s 792us/step - loss: 2.1173 - accuracy: 0.5462 - val_loss: 2.1276 - val_accuracy: 0.5376\n",
      "Epoch 8/1000\n",
      "726/726 [==============================] - 1s 787us/step - loss: 1.9901 - accuracy: 0.5747 - val_loss: 2.0027 - val_accuracy: 0.5655\n",
      "Epoch 9/1000\n",
      "726/726 [==============================] - 1s 789us/step - loss: 1.8829 - accuracy: 0.6017 - val_loss: 1.9048 - val_accuracy: 0.5961\n",
      "Epoch 10/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7917 - accuracy: 0.6266 - val_loss: 1.8300 - val_accuracy: 0.5922\n",
      "Epoch 11/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7114 - accuracy: 0.6429 - val_loss: 1.7444 - val_accuracy: 0.6194\n",
      "Epoch 12/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6405 - accuracy: 0.6549 - val_loss: 1.6811 - val_accuracy: 0.6384\n",
      "Epoch 13/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5776 - accuracy: 0.6690 - val_loss: 1.6402 - val_accuracy: 0.6636\n",
      "Epoch 14/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 1.5231 - accuracy: 0.6821 - val_loss: 1.5717 - val_accuracy: 0.6694\n",
      "Epoch 15/1000\n",
      "726/726 [==============================] - 1s 991us/step - loss: 1.4703 - accuracy: 0.6912 - val_loss: 1.5207 - val_accuracy: 0.6752\n",
      "Epoch 16/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4209 - accuracy: 0.7031 - val_loss: 1.4786 - val_accuracy: 0.6860\n",
      "Epoch 17/1000\n",
      "726/726 [==============================] - 1s 993us/step - loss: 1.3744 - accuracy: 0.7090 - val_loss: 1.4299 - val_accuracy: 0.7027\n",
      "Epoch 18/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3328 - accuracy: 0.7230 - val_loss: 1.3894 - val_accuracy: 0.6946\n",
      "Epoch 19/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 1.2934 - accuracy: 0.7311 - val_loss: 1.3491 - val_accuracy: 0.7159\n",
      "Epoch 20/1000\n",
      "726/726 [==============================] - 1s 994us/step - loss: 1.2554 - accuracy: 0.7376 - val_loss: 1.3160 - val_accuracy: 0.7279\n",
      "Epoch 21/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 1.2213 - accuracy: 0.7456 - val_loss: 1.2872 - val_accuracy: 0.7171\n",
      "Epoch 22/1000\n",
      "726/726 [==============================] - 1s 985us/step - loss: 1.1883 - accuracy: 0.7492 - val_loss: 1.2594 - val_accuracy: 0.7341\n",
      "Epoch 23/1000\n",
      "726/726 [==============================] - 1s 982us/step - loss: 1.1577 - accuracy: 0.7570 - val_loss: 1.2157 - val_accuracy: 0.7508\n",
      "Epoch 24/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 1.1275 - accuracy: 0.7634 - val_loss: 1.1918 - val_accuracy: 0.7484\n",
      "Epoch 25/1000\n",
      "726/726 [==============================] - 1s 982us/step - loss: 1.1006 - accuracy: 0.7711 - val_loss: 1.1737 - val_accuracy: 0.7469\n",
      "Epoch 26/1000\n",
      "726/726 [==============================] - 1s 995us/step - loss: 1.0752 - accuracy: 0.7765 - val_loss: 1.1474 - val_accuracy: 0.7543\n",
      "Epoch 27/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0504 - accuracy: 0.7815 - val_loss: 1.1273 - val_accuracy: 0.7620\n",
      "Epoch 28/1000\n",
      "726/726 [==============================] - 1s 1000us/step - loss: 1.0287 - accuracy: 0.7860 - val_loss: 1.1085 - val_accuracy: 0.7779\n",
      "Epoch 29/1000\n",
      "726/726 [==============================] - 1s 996us/step - loss: 1.0050 - accuracy: 0.7931 - val_loss: 1.0830 - val_accuracy: 0.7779\n",
      "Epoch 30/1000\n",
      "726/726 [==============================] - 1s 989us/step - loss: 0.9857 - accuracy: 0.7950 - val_loss: 1.0747 - val_accuracy: 0.7814\n",
      "Epoch 31/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.9643 - accuracy: 0.7988 - val_loss: 1.0483 - val_accuracy: 0.7814\n",
      "Epoch 32/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9447 - accuracy: 0.8003 - val_loss: 1.0168 - val_accuracy: 0.7868\n",
      "Epoch 33/1000\n",
      "726/726 [==============================] - 1s 984us/step - loss: 0.9250 - accuracy: 0.8069 - val_loss: 1.0140 - val_accuracy: 0.7690\n",
      "Epoch 34/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9097 - accuracy: 0.8092 - val_loss: 1.0144 - val_accuracy: 0.7946\n",
      "Epoch 35/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8900 - accuracy: 0.8187 - val_loss: 0.9590 - val_accuracy: 0.8105\n",
      "Epoch 36/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 0.8772 - accuracy: 0.8170 - val_loss: 0.9386 - val_accuracy: 0.8089\n",
      "Epoch 37/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8625 - accuracy: 0.8218 - val_loss: 0.9317 - val_accuracy: 0.8167\n",
      "Epoch 38/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8494 - accuracy: 0.8242 - val_loss: 0.9178 - val_accuracy: 0.8105\n",
      "Epoch 39/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8359 - accuracy: 0.8267 - val_loss: 0.9154 - val_accuracy: 0.8004\n",
      "Epoch 40/1000\n",
      "726/726 [==============================] - 1s 988us/step - loss: 0.8274 - accuracy: 0.8317 - val_loss: 0.8860 - val_accuracy: 0.8178\n",
      "Epoch 41/1000\n",
      "726/726 [==============================] - 1s 995us/step - loss: 0.8090 - accuracy: 0.8322 - val_loss: 0.8843 - val_accuracy: 0.8198\n",
      "Epoch 42/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7989 - accuracy: 0.8339 - val_loss: 0.8867 - val_accuracy: 0.8244\n",
      "Epoch 43/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7857 - accuracy: 0.8374 - val_loss: 0.8716 - val_accuracy: 0.8248\n",
      "Epoch 44/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.7747 - accuracy: 0.8382 - val_loss: 0.8413 - val_accuracy: 0.8260\n",
      "Epoch 45/1000\n",
      "726/726 [==============================] - 1s 984us/step - loss: 0.7621 - accuracy: 0.8436 - val_loss: 0.8592 - val_accuracy: 0.8202\n",
      "Epoch 46/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7501 - accuracy: 0.8434 - val_loss: 0.8410 - val_accuracy: 0.8291\n",
      "Epoch 47/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7379 - accuracy: 0.8472 - val_loss: 0.8174 - val_accuracy: 0.8434\n",
      "Epoch 48/1000\n",
      "726/726 [==============================] - 1s 997us/step - loss: 0.7273 - accuracy: 0.8502 - val_loss: 0.8113 - val_accuracy: 0.8388\n",
      "Epoch 49/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 0.7163 - accuracy: 0.8528 - val_loss: 0.7964 - val_accuracy: 0.8399\n",
      "Epoch 50/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7051 - accuracy: 0.8556 - val_loss: 0.7956 - val_accuracy: 0.8380\n",
      "Epoch 51/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.6977 - accuracy: 0.8558 - val_loss: 0.7599 - val_accuracy: 0.8477\n",
      "Epoch 52/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 0.6864 - accuracy: 0.8590 - val_loss: 0.7480 - val_accuracy: 0.8442\n",
      "Epoch 53/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6769 - accuracy: 0.8616 - val_loss: 0.7350 - val_accuracy: 0.8523\n",
      "Epoch 54/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6674 - accuracy: 0.8618 - val_loss: 0.7326 - val_accuracy: 0.8434\n",
      "Epoch 55/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6597 - accuracy: 0.8674 - val_loss: 0.7340 - val_accuracy: 0.8457\n",
      "Epoch 56/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6505 - accuracy: 0.8694 - val_loss: 0.7096 - val_accuracy: 0.8605\n",
      "Epoch 57/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6428 - accuracy: 0.8702 - val_loss: 0.7081 - val_accuracy: 0.8570\n",
      "Epoch 58/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6334 - accuracy: 0.8721 - val_loss: 0.7128 - val_accuracy: 0.8461\n",
      "Epoch 59/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.8714 - val_loss: 0.7082 - val_accuracy: 0.8453\n",
      "Epoch 60/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6182 - accuracy: 0.8736 - val_loss: 0.6810 - val_accuracy: 0.8729\n",
      "Epoch 61/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6108 - accuracy: 0.8786 - val_loss: 0.6693 - val_accuracy: 0.8826\n",
      "Epoch 62/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6048 - accuracy: 0.8780 - val_loss: 0.6729 - val_accuracy: 0.8581\n",
      "Epoch 63/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5961 - accuracy: 0.8819 - val_loss: 0.6727 - val_accuracy: 0.8671\n",
      "Epoch 64/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5889 - accuracy: 0.8798 - val_loss: 0.6646 - val_accuracy: 0.8775\n",
      "Epoch 65/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.8840 - val_loss: 0.6540 - val_accuracy: 0.8671\n",
      "Epoch 66/1000\n",
      "726/726 [==============================] - 1s 996us/step - loss: 0.5728 - accuracy: 0.8852 - val_loss: 0.6581 - val_accuracy: 0.8717\n",
      "Epoch 67/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.8854 - val_loss: 0.6513 - val_accuracy: 0.8748\n",
      "Epoch 68/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5598 - accuracy: 0.8867 - val_loss: 0.6588 - val_accuracy: 0.8748\n",
      "Epoch 69/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.8882 - val_loss: 0.6597 - val_accuracy: 0.8775\n",
      "Epoch 70/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.8893 - val_loss: 0.6421 - val_accuracy: 0.8822\n",
      "Epoch 71/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.8886 - val_loss: 0.6308 - val_accuracy: 0.8694\n",
      "Epoch 72/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.8917 - val_loss: 0.6273 - val_accuracy: 0.8826\n",
      "Epoch 73/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5313 - accuracy: 0.8925 - val_loss: 0.6588 - val_accuracy: 0.8833\n",
      "Epoch 74/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5256 - accuracy: 0.8954 - val_loss: 0.6055 - val_accuracy: 0.8880\n",
      "Epoch 75/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.8953 - val_loss: 0.6198 - val_accuracy: 0.8686\n",
      "Epoch 76/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5163 - accuracy: 0.8976 - val_loss: 0.6155 - val_accuracy: 0.8818\n",
      "Epoch 77/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.5100 - accuracy: 0.8961 - val_loss: 0.6253 - val_accuracy: 0.8802\n",
      "Epoch 78/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5029 - accuracy: 0.8972 - val_loss: 0.6148 - val_accuracy: 0.8884\n",
      "Epoch 79/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.8972 - val_loss: 0.6216 - val_accuracy: 0.8973\n",
      "Epoch 80/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4953 - accuracy: 0.8982 - val_loss: 0.6041 - val_accuracy: 0.8884\n",
      "Epoch 81/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4870 - accuracy: 0.9003 - val_loss: 0.6254 - val_accuracy: 0.8884\n",
      "Epoch 82/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.9013 - val_loss: 0.6376 - val_accuracy: 0.8779\n",
      "Epoch 83/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4785 - accuracy: 0.9022 - val_loss: 0.6238 - val_accuracy: 0.8868\n",
      "Epoch 84/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4744 - accuracy: 0.9042 - val_loss: 0.6164 - val_accuracy: 0.8795\n",
      "Epoch 85/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4694 - accuracy: 0.9040 - val_loss: 0.6173 - val_accuracy: 0.8891\n",
      "Epoch 86/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4688 - accuracy: 0.9042 - val_loss: 0.5443 - val_accuracy: 0.8899\n",
      "Epoch 87/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.9069 - val_loss: 0.5068 - val_accuracy: 0.9043\n",
      "Epoch 88/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.4582 - accuracy: 0.9077 - val_loss: 0.5312 - val_accuracy: 0.8860\n",
      "Epoch 89/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4515 - accuracy: 0.9066 - val_loss: 0.5286 - val_accuracy: 0.8880\n",
      "Epoch 90/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.9096 - val_loss: 0.5212 - val_accuracy: 0.8853\n",
      "Epoch 91/1000\n",
      "726/726 [==============================] - 1s 996us/step - loss: 0.4413 - accuracy: 0.9118 - val_loss: 0.5168 - val_accuracy: 0.8880\n",
      "Epoch 92/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4435 - accuracy: 0.9078 - val_loss: 0.5136 - val_accuracy: 0.9039\n",
      "Epoch 93/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.4338 - accuracy: 0.9116 - val_loss: 0.5001 - val_accuracy: 0.9023\n",
      "Epoch 94/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.9118 - val_loss: 0.5118 - val_accuracy: 0.8996\n",
      "Epoch 95/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4291 - accuracy: 0.9126 - val_loss: 0.5120 - val_accuracy: 0.9070\n",
      "Epoch 96/1000\n",
      "726/726 [==============================] - 1s 1000us/step - loss: 0.4249 - accuracy: 0.9135 - val_loss: 0.5125 - val_accuracy: 0.9023\n",
      "Epoch 97/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4212 - accuracy: 0.9120 - val_loss: 0.4994 - val_accuracy: 0.9147\n",
      "Epoch 98/1000\n",
      "726/726 [==============================] - 1s 984us/step - loss: 0.4173 - accuracy: 0.9165 - val_loss: 0.4816 - val_accuracy: 0.9151\n",
      "Epoch 99/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.9155 - val_loss: 0.4835 - val_accuracy: 0.9047\n",
      "Epoch 100/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4091 - accuracy: 0.9154 - val_loss: 0.4910 - val_accuracy: 0.9132\n",
      "Epoch 101/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4103 - accuracy: 0.9157 - val_loss: 0.5018 - val_accuracy: 0.9043\n",
      "Epoch 102/1000\n",
      "726/726 [==============================] - 1s 993us/step - loss: 0.4020 - accuracy: 0.9210 - val_loss: 0.4921 - val_accuracy: 0.9078\n",
      "Epoch 103/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.9194 - val_loss: 0.4472 - val_accuracy: 0.9058\n",
      "Epoch 104/1000\n",
      "726/726 [==============================] - 1s 993us/step - loss: 0.3982 - accuracy: 0.9193 - val_loss: 0.4445 - val_accuracy: 0.9112\n",
      "Epoch 105/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.9212 - val_loss: 0.4569 - val_accuracy: 0.9128\n",
      "Epoch 106/1000\n",
      "726/726 [==============================] - 1s 994us/step - loss: 0.3912 - accuracy: 0.9192 - val_loss: 0.4681 - val_accuracy: 0.9058\n",
      "Epoch 107/1000\n",
      "726/726 [==============================] - 1s 996us/step - loss: 0.3902 - accuracy: 0.9191 - val_loss: 0.4351 - val_accuracy: 0.9124\n",
      "Epoch 108/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.9203 - val_loss: 0.4512 - val_accuracy: 0.9031\n",
      "Epoch 109/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.9201 - val_loss: 0.4352 - val_accuracy: 0.9275\n",
      "Epoch 110/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.3840 - accuracy: 0.9209 - val_loss: 0.4462 - val_accuracy: 0.9062\n",
      "Epoch 111/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3765 - accuracy: 0.9217 - val_loss: 0.4250 - val_accuracy: 0.9132\n",
      "Epoch 112/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3749 - accuracy: 0.9208 - val_loss: 0.4110 - val_accuracy: 0.9233\n",
      "Epoch 113/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3710 - accuracy: 0.9240 - val_loss: 0.4495 - val_accuracy: 0.8973\n",
      "Epoch 114/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3689 - accuracy: 0.9231 - val_loss: 0.4297 - val_accuracy: 0.9190\n",
      "Epoch 115/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3703 - accuracy: 0.9220 - val_loss: 0.4351 - val_accuracy: 0.9252\n",
      "Epoch 116/1000\n",
      "726/726 [==============================] - 1s 992us/step - loss: 0.3625 - accuracy: 0.9259 - val_loss: 0.4455 - val_accuracy: 0.9178\n",
      "Epoch 117/1000\n",
      "726/726 [==============================] - 1s 995us/step - loss: 0.3593 - accuracy: 0.9260 - val_loss: 0.4535 - val_accuracy: 0.9089\n",
      "Epoch 118/1000\n",
      "726/726 [==============================] - 1s 990us/step - loss: 0.3581 - accuracy: 0.9258 - val_loss: 0.4475 - val_accuracy: 0.9182\n",
      "Epoch 119/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3549 - accuracy: 0.9264 - val_loss: 0.4611 - val_accuracy: 0.9089\n",
      "Epoch 120/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3529 - accuracy: 0.9262 - val_loss: 0.4393 - val_accuracy: 0.9178\n",
      "Epoch 121/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.9245 - val_loss: 0.4774 - val_accuracy: 0.9283\n",
      "Epoch 122/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3492 - accuracy: 0.9286 - val_loss: 0.4230 - val_accuracy: 0.9310\n",
      "Epoch 123/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.9322 - val_loss: 0.4264 - val_accuracy: 0.9287\n",
      "Epoch 124/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.9307 - val_loss: 0.4580 - val_accuracy: 0.9279\n",
      "Epoch 125/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.9287 - val_loss: 0.4155 - val_accuracy: 0.9260\n",
      "Epoch 126/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.9298 - val_loss: 0.4176 - val_accuracy: 0.9264\n",
      "Epoch 127/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.9296 - val_loss: 0.4246 - val_accuracy: 0.9345\n",
      "Epoch 128/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.9299 - val_loss: 0.4505 - val_accuracy: 0.9035\n",
      "Epoch 129/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3355 - accuracy: 0.9297 - val_loss: 0.4385 - val_accuracy: 0.9314\n",
      "Epoch 130/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9308 - val_loss: 0.4402 - val_accuracy: 0.9388\n",
      "Epoch 131/1000\n",
      "726/726 [==============================] - 1s 987us/step - loss: 0.3343 - accuracy: 0.9267 - val_loss: 0.4449 - val_accuracy: 0.9271\n",
      "Epoch 132/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.9322 - val_loss: 0.4255 - val_accuracy: 0.9298\n",
      "Epoch 133/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.3241 - accuracy: 0.9323 - val_loss: 0.4435 - val_accuracy: 0.9298\n",
      "Epoch 134/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3222 - accuracy: 0.9343 - val_loss: 0.4516 - val_accuracy: 0.9256\n",
      "Epoch 135/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.9326 - val_loss: 0.4597 - val_accuracy: 0.9248\n",
      "Epoch 136/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.3213 - accuracy: 0.9333 - val_loss: 0.4549 - val_accuracy: 0.9349\n",
      "Epoch 137/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3169 - accuracy: 0.9326 - val_loss: 0.4740 - val_accuracy: 0.9174\n",
      "Epoch 138/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3206 - accuracy: 0.9318 - val_loss: 0.4513 - val_accuracy: 0.9171\n",
      "Epoch 139/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3162 - accuracy: 0.9320 - val_loss: 0.4189 - val_accuracy: 0.9019\n",
      "Epoch 140/1000\n",
      "726/726 [==============================] - 1s 992us/step - loss: 0.3125 - accuracy: 0.9345 - val_loss: 0.3843 - val_accuracy: 0.9244\n",
      "Epoch 141/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3123 - accuracy: 0.9337 - val_loss: 0.3695 - val_accuracy: 0.9353\n",
      "Epoch 142/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.9328 - val_loss: 0.3717 - val_accuracy: 0.9349\n",
      "Epoch 143/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3083 - accuracy: 0.9332 - val_loss: 0.3664 - val_accuracy: 0.9422\n",
      "Epoch 144/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3039 - accuracy: 0.9363 - val_loss: 0.3553 - val_accuracy: 0.9531\n",
      "Epoch 145/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3049 - accuracy: 0.9348 - val_loss: 0.3633 - val_accuracy: 0.9345\n",
      "Epoch 146/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3078 - accuracy: 0.9345 - val_loss: 0.3620 - val_accuracy: 0.9426\n",
      "Epoch 147/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3007 - accuracy: 0.9355 - val_loss: 0.3884 - val_accuracy: 0.9202\n",
      "Epoch 148/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2992 - accuracy: 0.9351 - val_loss: 0.3585 - val_accuracy: 0.9329\n",
      "Epoch 149/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2959 - accuracy: 0.9366 - val_loss: 0.3691 - val_accuracy: 0.9364\n",
      "Epoch 150/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2949 - accuracy: 0.9360 - val_loss: 0.3894 - val_accuracy: 0.9233\n",
      "Epoch 151/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.9381 - val_loss: 0.3754 - val_accuracy: 0.9364\n",
      "Epoch 152/1000\n",
      "726/726 [==============================] - 1s 994us/step - loss: 0.2943 - accuracy: 0.9351 - val_loss: 0.3637 - val_accuracy: 0.9310\n",
      "Epoch 153/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.9378 - val_loss: 0.3779 - val_accuracy: 0.9399\n",
      "Epoch 154/1000\n",
      "726/726 [==============================] - 1s 1000us/step - loss: 0.2865 - accuracy: 0.9389 - val_loss: 0.3974 - val_accuracy: 0.9221\n",
      "Epoch 155/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.9382 - val_loss: 0.4210 - val_accuracy: 0.9225\n",
      "Epoch 156/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2831 - accuracy: 0.9374 - val_loss: 0.4054 - val_accuracy: 0.9388\n",
      "Epoch 157/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.9387 - val_loss: 0.4189 - val_accuracy: 0.9341\n",
      "Epoch 158/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2822 - accuracy: 0.9366 - val_loss: 0.4225 - val_accuracy: 0.9345\n",
      "Epoch 159/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2810 - accuracy: 0.9369 - val_loss: 0.4277 - val_accuracy: 0.9380\n",
      "Epoch 160/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2785 - accuracy: 0.9393 - val_loss: 0.4145 - val_accuracy: 0.9295\n",
      "Epoch 161/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.9408 - val_loss: 0.4087 - val_accuracy: 0.9287\n",
      "Epoch 162/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.9408 - val_loss: 0.4183 - val_accuracy: 0.9360\n",
      "Epoch 163/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2714 - accuracy: 0.9419 - val_loss: 0.4265 - val_accuracy: 0.9283\n",
      "Epoch 164/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2745 - accuracy: 0.9397 - val_loss: 0.4537 - val_accuracy: 0.9380\n",
      "Epoch 165/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.9399 - val_loss: 0.4218 - val_accuracy: 0.9399\n",
      "Epoch 166/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2718 - accuracy: 0.9405 - val_loss: 0.4394 - val_accuracy: 0.9422\n",
      "Epoch 167/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2692 - accuracy: 0.9389 - val_loss: 0.4489 - val_accuracy: 0.9415\n",
      "Epoch 168/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.9417 - val_loss: 0.4530 - val_accuracy: 0.9484\n",
      "Epoch 169/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2631 - accuracy: 0.9411 - val_loss: 0.4716 - val_accuracy: 0.9388\n",
      "Epoch 170/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2636 - accuracy: 0.9409 - val_loss: 0.4706 - val_accuracy: 0.9446\n",
      "Epoch 171/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2612 - accuracy: 0.9428 - val_loss: 0.4664 - val_accuracy: 0.9469\n",
      "Epoch 172/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2620 - accuracy: 0.9420 - val_loss: 0.5043 - val_accuracy: 0.9333\n",
      "Epoch 173/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2578 - accuracy: 0.9434 - val_loss: 0.5028 - val_accuracy: 0.9341\n",
      "Epoch 174/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2544 - accuracy: 0.9446 - val_loss: 0.4848 - val_accuracy: 0.9589\n",
      "Epoch 175/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.9425 - val_loss: 0.4828 - val_accuracy: 0.9457\n",
      "Epoch 176/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2554 - accuracy: 0.9455 - val_loss: 0.4840 - val_accuracy: 0.9341\n",
      "Epoch 177/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.9452 - val_loss: 0.4716 - val_accuracy: 0.9473\n",
      "Epoch 178/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9461 - val_loss: 0.4779 - val_accuracy: 0.9438\n",
      "Epoch 179/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2523 - accuracy: 0.9431 - val_loss: 0.4826 - val_accuracy: 0.9481\n",
      "Epoch 180/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2544 - accuracy: 0.9437 - val_loss: 0.4502 - val_accuracy: 0.9376\n",
      "Epoch 181/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.9454 - val_loss: 0.4822 - val_accuracy: 0.9302\n",
      "Epoch 182/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.9453 - val_loss: 0.4542 - val_accuracy: 0.9519\n",
      "Epoch 183/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.9452 - val_loss: 0.4586 - val_accuracy: 0.9469\n",
      "Epoch 184/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.9473 - val_loss: 0.5401 - val_accuracy: 0.9264\n",
      "Epoch 185/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2484 - accuracy: 0.9441 - val_loss: 0.4801 - val_accuracy: 0.9391\n",
      "Epoch 186/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9467 - val_loss: 0.4581 - val_accuracy: 0.9531\n",
      "Epoch 187/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.9465 - val_loss: 0.4755 - val_accuracy: 0.9461\n",
      "Epoch 188/1000\n",
      "726/726 [==============================] - 1s 997us/step - loss: 0.2439 - accuracy: 0.9468 - val_loss: 0.4804 - val_accuracy: 0.9465\n",
      "Epoch 189/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9457 - val_loss: 0.5072 - val_accuracy: 0.9345\n",
      "Epoch 190/1000\n",
      "726/726 [==============================] - 1s 988us/step - loss: 0.2399 - accuracy: 0.9466 - val_loss: 0.4852 - val_accuracy: 0.9516\n",
      "Epoch 191/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2367 - accuracy: 0.9474 - val_loss: 0.5189 - val_accuracy: 0.9422\n",
      "Epoch 192/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2368 - accuracy: 0.9485 - val_loss: 0.4744 - val_accuracy: 0.9496\n",
      "Epoch 193/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2386 - accuracy: 0.9468 - val_loss: 0.4993 - val_accuracy: 0.9426\n",
      "Epoch 194/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2335 - accuracy: 0.9472 - val_loss: 0.4729 - val_accuracy: 0.9539\n",
      "Epoch 195/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2364 - accuracy: 0.9462 - val_loss: 0.5137 - val_accuracy: 0.9357\n",
      "Epoch 196/1000\n",
      "726/726 [==============================] - 1s 997us/step - loss: 0.2353 - accuracy: 0.9473 - val_loss: 0.4160 - val_accuracy: 0.9543\n",
      "Epoch 197/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2326 - accuracy: 0.9479 - val_loss: 0.4318 - val_accuracy: 0.9353\n",
      "Epoch 198/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2303 - accuracy: 0.9499 - val_loss: 0.4108 - val_accuracy: 0.9601\n",
      "Epoch 199/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.2315 - accuracy: 0.9484 - val_loss: 0.4077 - val_accuracy: 0.9407\n",
      "Epoch 200/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2328 - accuracy: 0.9462 - val_loss: 0.4140 - val_accuracy: 0.9484\n",
      "Epoch 201/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2300 - accuracy: 0.9477 - val_loss: 0.4113 - val_accuracy: 0.9535\n",
      "Epoch 202/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.9484 - val_loss: 0.4026 - val_accuracy: 0.9500\n",
      "Epoch 203/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2252 - accuracy: 0.9494 - val_loss: 0.4337 - val_accuracy: 0.9434\n",
      "Epoch 204/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.2252 - accuracy: 0.9492 - val_loss: 0.4253 - val_accuracy: 0.9450\n",
      "Epoch 205/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2249 - accuracy: 0.9492 - val_loss: 0.4379 - val_accuracy: 0.9399\n",
      "Epoch 206/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.9474 - val_loss: 0.4483 - val_accuracy: 0.9388\n",
      "Epoch 207/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2235 - accuracy: 0.9500 - val_loss: 0.4969 - val_accuracy: 0.9178\n",
      "Epoch 208/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2214 - accuracy: 0.9501 - val_loss: 0.4413 - val_accuracy: 0.9469\n",
      "Epoch 209/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.9520 - val_loss: 0.4826 - val_accuracy: 0.9434\n",
      "Epoch 210/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2184 - accuracy: 0.9521 - val_loss: 0.4390 - val_accuracy: 0.9453\n",
      "Epoch 211/1000\n",
      "726/726 [==============================] - 1s 991us/step - loss: 0.2215 - accuracy: 0.9501 - val_loss: 0.4637 - val_accuracy: 0.9512\n",
      "Epoch 212/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2202 - accuracy: 0.9493 - val_loss: 0.4515 - val_accuracy: 0.9593\n",
      "Epoch 213/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2146 - accuracy: 0.9531 - val_loss: 0.4514 - val_accuracy: 0.9442\n",
      "Epoch 214/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2200 - accuracy: 0.9488 - val_loss: 0.4522 - val_accuracy: 0.9504\n",
      "Epoch 215/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2153 - accuracy: 0.9514 - val_loss: 0.4829 - val_accuracy: 0.9376\n",
      "Epoch 216/1000\n",
      "726/726 [==============================] - 1s 992us/step - loss: 0.2164 - accuracy: 0.9523 - val_loss: 0.4530 - val_accuracy: 0.9523\n",
      "Epoch 217/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2114 - accuracy: 0.9531 - val_loss: 0.4732 - val_accuracy: 0.9601\n",
      "Epoch 218/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2136 - accuracy: 0.9520 - val_loss: 0.4380 - val_accuracy: 0.9411\n",
      "Epoch 219/1000\n",
      "726/726 [==============================] - 1s 983us/step - loss: 0.2139 - accuracy: 0.9519 - val_loss: 0.4196 - val_accuracy: 0.9446\n",
      "Epoch 220/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2102 - accuracy: 0.9514 - val_loss: 0.4150 - val_accuracy: 0.9411\n",
      "Epoch 221/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2132 - accuracy: 0.9509 - val_loss: 0.4329 - val_accuracy: 0.9380\n",
      "Epoch 222/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2116 - accuracy: 0.9509 - val_loss: 0.4589 - val_accuracy: 0.9349\n",
      "Epoch 223/1000\n",
      "726/726 [==============================] - 1s 997us/step - loss: 0.2146 - accuracy: 0.9500 - val_loss: 0.4308 - val_accuracy: 0.9477\n",
      "Epoch 224/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2104 - accuracy: 0.9522 - val_loss: 0.3644 - val_accuracy: 0.9589\n",
      "Epoch 225/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2054 - accuracy: 0.9543 - val_loss: 0.3800 - val_accuracy: 0.9484\n",
      "Epoch 226/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2037 - accuracy: 0.9536 - val_loss: 0.3666 - val_accuracy: 0.9519\n",
      "Epoch 227/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9539 - val_loss: 0.3749 - val_accuracy: 0.9612\n",
      "Epoch 228/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2095 - accuracy: 0.9512 - val_loss: 0.4012 - val_accuracy: 0.9461\n",
      "Epoch 229/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.2040 - accuracy: 0.9533 - val_loss: 0.3335 - val_accuracy: 0.9519\n",
      "Epoch 230/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2007 - accuracy: 0.9547 - val_loss: 0.3616 - val_accuracy: 0.9469\n",
      "Epoch 231/1000\n",
      "726/726 [==============================] - 1s 989us/step - loss: 0.2063 - accuracy: 0.9513 - val_loss: 0.3582 - val_accuracy: 0.9512\n",
      "Epoch 232/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2033 - accuracy: 0.9528 - val_loss: 0.3469 - val_accuracy: 0.9550\n",
      "Epoch 233/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2027 - accuracy: 0.9534 - val_loss: 0.3657 - val_accuracy: 0.9523\n",
      "Epoch 234/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2031 - accuracy: 0.9539 - val_loss: 0.3743 - val_accuracy: 0.9492\n",
      "Epoch 235/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2012 - accuracy: 0.9540 - val_loss: 0.3673 - val_accuracy: 0.9450\n",
      "Epoch 236/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1998 - accuracy: 0.9550 - val_loss: 0.3209 - val_accuracy: 0.9539\n",
      "Epoch 237/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1990 - accuracy: 0.9554 - val_loss: 0.3119 - val_accuracy: 0.9609\n",
      "Epoch 238/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.9540 - val_loss: 0.3220 - val_accuracy: 0.9651\n",
      "Epoch 239/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1994 - accuracy: 0.9544 - val_loss: 0.3591 - val_accuracy: 0.9438\n",
      "Epoch 240/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1977 - accuracy: 0.9539 - val_loss: 0.3281 - val_accuracy: 0.9543\n",
      "Epoch 241/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1994 - accuracy: 0.9537 - val_loss: 0.3341 - val_accuracy: 0.9453\n",
      "Epoch 242/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1965 - accuracy: 0.9545 - val_loss: 0.3474 - val_accuracy: 0.9527\n",
      "Epoch 243/1000\n",
      "726/726 [==============================] - 1s 991us/step - loss: 0.1997 - accuracy: 0.9540 - val_loss: 0.3473 - val_accuracy: 0.9500\n",
      "Epoch 244/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.9545 - val_loss: 0.3346 - val_accuracy: 0.9570\n",
      "Epoch 245/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1955 - accuracy: 0.9553 - val_loss: 0.3553 - val_accuracy: 0.9500\n",
      "Epoch 246/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1909 - accuracy: 0.9586 - val_loss: 0.3145 - val_accuracy: 0.9589\n",
      "Epoch 247/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1943 - accuracy: 0.9550 - val_loss: 0.3388 - val_accuracy: 0.9446\n",
      "Epoch 248/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1909 - accuracy: 0.9556 - val_loss: 0.3369 - val_accuracy: 0.9461\n",
      "Epoch 249/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1917 - accuracy: 0.9565 - val_loss: 0.3571 - val_accuracy: 0.9450\n",
      "Epoch 250/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1867 - accuracy: 0.9576 - val_loss: 0.3607 - val_accuracy: 0.9550\n",
      "Epoch 251/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1935 - accuracy: 0.9537 - val_loss: 0.3607 - val_accuracy: 0.9306\n",
      "Epoch 252/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1901 - accuracy: 0.9563 - val_loss: 0.3485 - val_accuracy: 0.9574\n",
      "Epoch 253/1000\n",
      "726/726 [==============================] - 1s 995us/step - loss: 0.1872 - accuracy: 0.9575 - val_loss: 0.3722 - val_accuracy: 0.9562\n",
      "Epoch 254/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1935 - accuracy: 0.9546 - val_loss: 0.3729 - val_accuracy: 0.9616\n",
      "Epoch 255/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1883 - accuracy: 0.9557 - val_loss: 0.3876 - val_accuracy: 0.9438\n",
      "Epoch 256/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1897 - accuracy: 0.9558 - val_loss: 0.4071 - val_accuracy: 0.9446\n",
      "Epoch 257/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9591 - val_loss: 0.4065 - val_accuracy: 0.9605\n",
      "Epoch 258/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1839 - accuracy: 0.9580 - val_loss: 0.4181 - val_accuracy: 0.9566\n",
      "Epoch 259/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1871 - accuracy: 0.9564 - val_loss: 0.5048 - val_accuracy: 0.9279\n",
      "Epoch 260/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1901 - accuracy: 0.9550 - val_loss: 0.4591 - val_accuracy: 0.9477\n",
      "Epoch 261/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1831 - accuracy: 0.9575 - val_loss: 0.2853 - val_accuracy: 0.9562\n",
      "Epoch 262/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1858 - accuracy: 0.9572 - val_loss: 0.3309 - val_accuracy: 0.9496\n",
      "Epoch 263/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1859 - accuracy: 0.9571 - val_loss: 0.3201 - val_accuracy: 0.9415\n",
      "Epoch 264/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.1838 - accuracy: 0.9558 - val_loss: 0.3559 - val_accuracy: 0.9531\n",
      "Epoch 265/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1843 - accuracy: 0.9556 - val_loss: 0.3282 - val_accuracy: 0.9589\n",
      "Epoch 266/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1810 - accuracy: 0.9584 - val_loss: 0.3122 - val_accuracy: 0.9612\n",
      "Epoch 267/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1961 - accuracy: 0.9568 - val_loss: 0.3219 - val_accuracy: 0.9589\n",
      "Epoch 268/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1781 - accuracy: 0.9593 - val_loss: 0.3059 - val_accuracy: 0.9539\n",
      "Epoch 269/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1786 - accuracy: 0.9583 - val_loss: 0.2840 - val_accuracy: 0.9655\n",
      "Epoch 270/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.9597 - val_loss: 0.2721 - val_accuracy: 0.9682\n",
      "Epoch 271/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1778 - accuracy: 0.9586 - val_loss: 0.3168 - val_accuracy: 0.9519\n",
      "Epoch 272/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1803 - accuracy: 0.9580 - val_loss: 0.3111 - val_accuracy: 0.9632\n",
      "Epoch 273/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1789 - accuracy: 0.9596 - val_loss: 0.3295 - val_accuracy: 0.9465\n",
      "Epoch 274/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1812 - accuracy: 0.9579 - val_loss: 0.3661 - val_accuracy: 0.9384\n",
      "Epoch 275/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1817 - accuracy: 0.9582 - val_loss: 0.3308 - val_accuracy: 0.9574\n",
      "Epoch 276/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1793 - accuracy: 0.9575 - val_loss: 0.3269 - val_accuracy: 0.9620\n",
      "Epoch 277/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1807 - accuracy: 0.9568 - val_loss: 0.3296 - val_accuracy: 0.9616\n",
      "Epoch 278/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1764 - accuracy: 0.9586 - val_loss: 0.3478 - val_accuracy: 0.9500\n",
      "Epoch 279/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1760 - accuracy: 0.9590 - val_loss: 0.3448 - val_accuracy: 0.9558\n",
      "Epoch 280/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1740 - accuracy: 0.9594 - val_loss: 0.3686 - val_accuracy: 0.9562\n",
      "Epoch 281/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9567 - val_loss: 0.3928 - val_accuracy: 0.9612\n",
      "Epoch 282/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9606 - val_loss: 0.3940 - val_accuracy: 0.9597\n",
      "Epoch 283/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9585 - val_loss: 0.3488 - val_accuracy: 0.9558\n",
      "Epoch 284/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9597 - val_loss: 0.4250 - val_accuracy: 0.9469\n",
      "Epoch 285/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1727 - accuracy: 0.9585 - val_loss: 0.3805 - val_accuracy: 0.9585\n",
      "Epoch 286/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1719 - accuracy: 0.9574 - val_loss: 0.4005 - val_accuracy: 0.9504\n",
      "Epoch 287/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9578 - val_loss: 0.4253 - val_accuracy: 0.9453\n",
      "Epoch 288/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1773 - accuracy: 0.9578 - val_loss: 0.4983 - val_accuracy: 0.9527\n",
      "Epoch 289/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9587 - val_loss: 0.5074 - val_accuracy: 0.9605\n",
      "Epoch 290/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1660 - accuracy: 0.9610 - val_loss: 0.5122 - val_accuracy: 0.9593\n",
      "Epoch 291/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1736 - accuracy: 0.9590 - val_loss: 0.5279 - val_accuracy: 0.9632\n",
      "Epoch 292/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1704 - accuracy: 0.9592 - val_loss: 0.5424 - val_accuracy: 0.9368\n",
      "Epoch 293/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9577 - val_loss: 0.5149 - val_accuracy: 0.9655\n",
      "Epoch 294/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1702 - accuracy: 0.9590 - val_loss: 0.5438 - val_accuracy: 0.9593\n",
      "Epoch 295/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1691 - accuracy: 0.9596 - val_loss: 0.6049 - val_accuracy: 0.9287\n",
      "Epoch 296/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9598 - val_loss: 0.5289 - val_accuracy: 0.9620\n",
      "Epoch 297/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9596 - val_loss: 0.3671 - val_accuracy: 0.9674\n",
      "Epoch 298/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1667 - accuracy: 0.9604 - val_loss: 0.4242 - val_accuracy: 0.9659\n",
      "Epoch 299/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9618 - val_loss: 0.4175 - val_accuracy: 0.9601\n",
      "Epoch 300/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.9609 - val_loss: 0.4019 - val_accuracy: 0.9585\n",
      "Epoch 301/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1662 - accuracy: 0.9606 - val_loss: 0.4205 - val_accuracy: 0.9651\n",
      "Epoch 302/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1686 - accuracy: 0.9590 - val_loss: 0.4666 - val_accuracy: 0.9519\n",
      "Epoch 303/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1648 - accuracy: 0.9615 - val_loss: 0.4455 - val_accuracy: 0.9535\n",
      "Epoch 304/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9575 - val_loss: 0.4972 - val_accuracy: 0.9399\n",
      "Epoch 305/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1635 - accuracy: 0.9600 - val_loss: 0.4786 - val_accuracy: 0.9523\n",
      "Epoch 306/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1666 - accuracy: 0.9597 - val_loss: 0.5249 - val_accuracy: 0.9403\n",
      "Epoch 307/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1633 - accuracy: 0.9607 - val_loss: 0.4507 - val_accuracy: 0.9616\n",
      "Epoch 308/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.9598 - val_loss: 0.4775 - val_accuracy: 0.9628\n",
      "Epoch 309/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1654 - accuracy: 0.9594 - val_loss: 0.4681 - val_accuracy: 0.9698\n",
      "Epoch 310/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1613 - accuracy: 0.9611 - val_loss: 0.4683 - val_accuracy: 0.9484\n",
      "Epoch 311/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1594 - accuracy: 0.9612 - val_loss: 0.4382 - val_accuracy: 0.9636\n",
      "Epoch 312/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1608 - accuracy: 0.9618 - val_loss: 0.4833 - val_accuracy: 0.9469\n",
      "Epoch 313/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1623 - accuracy: 0.9609 - val_loss: 0.4808 - val_accuracy: 0.9465\n",
      "Epoch 314/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9610 - val_loss: 0.4728 - val_accuracy: 0.9663\n",
      "Epoch 315/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9605 - val_loss: 0.4753 - val_accuracy: 0.9558\n",
      "Epoch 316/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1601 - accuracy: 0.9608 - val_loss: 0.5224 - val_accuracy: 0.9364\n",
      "Epoch 317/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.9604 - val_loss: 0.4827 - val_accuracy: 0.9364\n",
      "Epoch 318/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9591 - val_loss: 0.4200 - val_accuracy: 0.9585\n",
      "Epoch 319/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1574 - accuracy: 0.9618 - val_loss: 0.4931 - val_accuracy: 0.9477\n",
      "Epoch 320/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1802 - accuracy: 0.9622 - val_loss: 0.4088 - val_accuracy: 0.9713\n",
      "Epoch 321/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1539 - accuracy: 0.9636 - val_loss: 0.3805 - val_accuracy: 0.9694\n",
      "Epoch 322/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1546 - accuracy: 0.9633 - val_loss: 0.4283 - val_accuracy: 0.9523\n",
      "Epoch 323/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.9621 - val_loss: 0.4249 - val_accuracy: 0.9574\n",
      "Epoch 324/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9609 - val_loss: 0.4331 - val_accuracy: 0.9620\n",
      "Epoch 325/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1554 - accuracy: 0.9627 - val_loss: 0.4352 - val_accuracy: 0.9694\n",
      "Epoch 326/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1523 - accuracy: 0.9633 - val_loss: 0.4798 - val_accuracy: 0.9465\n",
      "Epoch 327/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1583 - accuracy: 0.9612 - val_loss: 0.4573 - val_accuracy: 0.9562\n",
      "Epoch 328/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1572 - accuracy: 0.9617 - val_loss: 0.4637 - val_accuracy: 0.9585\n",
      "Epoch 329/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1585 - accuracy: 0.9619 - val_loss: 0.4950 - val_accuracy: 0.9461\n",
      "Epoch 330/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1555 - accuracy: 0.9630 - val_loss: 0.4617 - val_accuracy: 0.9729\n",
      "Epoch 331/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1555 - accuracy: 0.9618 - val_loss: 0.5174 - val_accuracy: 0.9407\n",
      "Epoch 332/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1545 - accuracy: 0.9634 - val_loss: 0.4645 - val_accuracy: 0.9663\n",
      "Epoch 333/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1544 - accuracy: 0.9624 - val_loss: 0.5037 - val_accuracy: 0.9512\n",
      "Epoch 334/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9629 - val_loss: 0.5731 - val_accuracy: 0.9380\n",
      "Epoch 335/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9638 - val_loss: 0.5334 - val_accuracy: 0.9403\n",
      "Epoch 336/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9632 - val_loss: 0.5009 - val_accuracy: 0.9612\n",
      "Epoch 337/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1575 - accuracy: 0.9617 - val_loss: 0.4964 - val_accuracy: 0.9589\n",
      "Epoch 338/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9624 - val_loss: 0.5847 - val_accuracy: 0.9457\n",
      "Epoch 339/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1516 - accuracy: 0.9637 - val_loss: 0.4949 - val_accuracy: 0.9721\n",
      "Epoch 340/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1489 - accuracy: 0.9639 - val_loss: 0.4958 - val_accuracy: 0.9705\n",
      "Epoch 341/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1561 - accuracy: 0.9619 - val_loss: 0.4923 - val_accuracy: 0.9659\n",
      "Epoch 342/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9616 - val_loss: 0.4793 - val_accuracy: 0.9702\n",
      "Epoch 343/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9633 - val_loss: 0.5184 - val_accuracy: 0.9609\n",
      "Epoch 344/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1531 - accuracy: 0.9618 - val_loss: 0.5505 - val_accuracy: 0.9461\n",
      "Epoch 345/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1522 - accuracy: 0.9633 - val_loss: 0.6616 - val_accuracy: 0.9527\n",
      "Epoch 346/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1483 - accuracy: 0.9665 - val_loss: 0.2386 - val_accuracy: 0.9632\n",
      "Epoch 347/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9632 - val_loss: 0.2247 - val_accuracy: 0.9632\n",
      "Epoch 348/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1495 - accuracy: 0.9634 - val_loss: 0.2478 - val_accuracy: 0.9558\n",
      "Epoch 349/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1530 - accuracy: 0.9636 - val_loss: 0.2926 - val_accuracy: 0.9566\n",
      "Epoch 350/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1506 - accuracy: 0.9644 - val_loss: 0.2784 - val_accuracy: 0.9516\n",
      "Epoch 351/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9651 - val_loss: 0.2429 - val_accuracy: 0.9640\n",
      "Epoch 352/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1499 - accuracy: 0.9624 - val_loss: 0.2768 - val_accuracy: 0.9547\n",
      "Epoch 353/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9629 - val_loss: 0.3239 - val_accuracy: 0.9516\n",
      "Epoch 354/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1506 - accuracy: 0.9632 - val_loss: 0.2800 - val_accuracy: 0.9678\n",
      "Epoch 355/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1513 - accuracy: 0.9634 - val_loss: 0.2840 - val_accuracy: 0.9550\n",
      "Epoch 356/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1541 - accuracy: 0.9608 - val_loss: 0.2720 - val_accuracy: 0.9640\n",
      "Epoch 357/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1443 - accuracy: 0.9651 - val_loss: 0.2478 - val_accuracy: 0.9717\n",
      "Epoch 358/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9634 - val_loss: 0.2781 - val_accuracy: 0.9616\n",
      "Epoch 359/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1460 - accuracy: 0.9654 - val_loss: 0.3303 - val_accuracy: 0.9446\n",
      "Epoch 360/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1494 - accuracy: 0.9635 - val_loss: 0.2776 - val_accuracy: 0.9643\n",
      "Epoch 361/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.9643 - val_loss: 0.3744 - val_accuracy: 0.9395\n",
      "Epoch 362/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1452 - accuracy: 0.9650 - val_loss: 0.2617 - val_accuracy: 0.9690\n",
      "Epoch 363/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1476 - accuracy: 0.9630 - val_loss: 0.2957 - val_accuracy: 0.9628\n",
      "Epoch 364/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1489 - accuracy: 0.9636 - val_loss: 0.1871 - val_accuracy: 0.9601\n",
      "Epoch 365/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9666 - val_loss: 0.1595 - val_accuracy: 0.9802\n",
      "Epoch 366/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1466 - accuracy: 0.9640 - val_loss: 0.1958 - val_accuracy: 0.9547\n",
      "Epoch 367/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9636 - val_loss: 0.2018 - val_accuracy: 0.9725\n",
      "Epoch 368/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1446 - accuracy: 0.9634 - val_loss: 0.2144 - val_accuracy: 0.9640\n",
      "Epoch 369/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9640 - val_loss: 0.2064 - val_accuracy: 0.9640\n",
      "Epoch 370/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1440 - accuracy: 0.9650 - val_loss: 0.2155 - val_accuracy: 0.9717\n",
      "Epoch 371/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.9646 - val_loss: 0.2247 - val_accuracy: 0.9663\n",
      "Epoch 372/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1407 - accuracy: 0.9657 - val_loss: 0.2473 - val_accuracy: 0.9508\n",
      "Epoch 373/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9652 - val_loss: 0.2729 - val_accuracy: 0.9516\n",
      "Epoch 374/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1392 - accuracy: 0.9668 - val_loss: 0.2280 - val_accuracy: 0.9647\n",
      "Epoch 375/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9652 - val_loss: 0.2359 - val_accuracy: 0.9667\n",
      "Epoch 376/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1452 - accuracy: 0.9632 - val_loss: 0.2388 - val_accuracy: 0.9632\n",
      "Epoch 377/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.9655 - val_loss: 0.1759 - val_accuracy: 0.9605\n",
      "Epoch 378/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1442 - accuracy: 0.9644 - val_loss: 0.1698 - val_accuracy: 0.9620\n",
      "Epoch 379/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9649 - val_loss: 0.1694 - val_accuracy: 0.9733\n",
      "Epoch 380/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1444 - accuracy: 0.9644 - val_loss: 0.1873 - val_accuracy: 0.9624\n",
      "Epoch 381/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1460 - accuracy: 0.9639 - val_loss: 0.1656 - val_accuracy: 0.9605\n",
      "Epoch 382/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9638 - val_loss: 0.1514 - val_accuracy: 0.9705\n",
      "Epoch 383/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9655 - val_loss: 0.1527 - val_accuracy: 0.9570\n",
      "Epoch 384/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1410 - accuracy: 0.9651 - val_loss: 0.1704 - val_accuracy: 0.9543\n",
      "Epoch 385/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1387 - accuracy: 0.9671 - val_loss: 0.2343 - val_accuracy: 0.9322\n",
      "Epoch 386/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9647 - val_loss: 0.1788 - val_accuracy: 0.9616\n",
      "Epoch 387/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.9653 - val_loss: 0.1718 - val_accuracy: 0.9651\n",
      "Epoch 388/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1442 - accuracy: 0.9640 - val_loss: 0.2136 - val_accuracy: 0.9473\n",
      "Epoch 389/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.9650 - val_loss: 0.1584 - val_accuracy: 0.9713\n",
      "Epoch 390/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1419 - accuracy: 0.9646 - val_loss: 0.2367 - val_accuracy: 0.9508\n",
      "Epoch 391/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1440 - accuracy: 0.9631 - val_loss: 0.1536 - val_accuracy: 0.9612\n",
      "Epoch 392/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1400 - accuracy: 0.9654 - val_loss: 0.1815 - val_accuracy: 0.9585\n",
      "Epoch 393/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9649 - val_loss: 0.1701 - val_accuracy: 0.9620\n",
      "Epoch 394/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.9656 - val_loss: 0.2191 - val_accuracy: 0.9539\n",
      "Epoch 395/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9652 - val_loss: 0.1642 - val_accuracy: 0.9717\n",
      "Epoch 396/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1364 - accuracy: 0.9663 - val_loss: 0.2779 - val_accuracy: 0.9484\n",
      "Epoch 397/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9633 - val_loss: 0.1845 - val_accuracy: 0.9612\n",
      "Epoch 398/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9677 - val_loss: 0.2198 - val_accuracy: 0.9469\n",
      "Epoch 399/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.1810 - val_accuracy: 0.9647\n",
      "Epoch 400/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1415 - accuracy: 0.9634 - val_loss: 0.1542 - val_accuracy: 0.9674\n",
      "Epoch 401/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9640 - val_loss: 0.2156 - val_accuracy: 0.9504\n",
      "Epoch 402/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1381 - accuracy: 0.9655 - val_loss: 0.1284 - val_accuracy: 0.9709\n",
      "Epoch 403/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9669 - val_loss: 0.1557 - val_accuracy: 0.9597\n",
      "Epoch 404/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1337 - accuracy: 0.9680 - val_loss: 0.1745 - val_accuracy: 0.9659\n",
      "Epoch 405/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9636 - val_loss: 0.1597 - val_accuracy: 0.9698\n",
      "Epoch 406/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1339 - accuracy: 0.9667 - val_loss: 0.2572 - val_accuracy: 0.9364\n",
      "Epoch 407/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.9645 - val_loss: 0.2320 - val_accuracy: 0.9516\n",
      "Epoch 408/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9644 - val_loss: 0.1874 - val_accuracy: 0.9717\n",
      "Epoch 409/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1363 - accuracy: 0.9654 - val_loss: 0.2412 - val_accuracy: 0.9535\n",
      "Epoch 410/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1308 - accuracy: 0.9676 - val_loss: 0.1896 - val_accuracy: 0.9740\n",
      "Epoch 411/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.9676 - val_loss: 0.1838 - val_accuracy: 0.9667\n",
      "Epoch 412/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.9669 - val_loss: 0.2152 - val_accuracy: 0.9523\n",
      "Epoch 413/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1365 - accuracy: 0.9662 - val_loss: 0.2341 - val_accuracy: 0.9709\n",
      "Epoch 414/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1358 - accuracy: 0.9652 - val_loss: 0.2379 - val_accuracy: 0.9636\n",
      "Epoch 415/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1369 - accuracy: 0.9656 - val_loss: 0.2300 - val_accuracy: 0.9709\n",
      "Epoch 416/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1303 - accuracy: 0.9670 - val_loss: 0.2492 - val_accuracy: 0.9698\n",
      "Epoch 417/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1313 - accuracy: 0.9673 - val_loss: 0.2785 - val_accuracy: 0.9698\n",
      "Epoch 418/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.9637 - val_loss: 0.3778 - val_accuracy: 0.9446\n",
      "Epoch 419/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.9653 - val_loss: 0.2862 - val_accuracy: 0.9702\n",
      "Epoch 420/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1299 - accuracy: 0.9680 - val_loss: 0.3279 - val_accuracy: 0.9655\n",
      "Epoch 421/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1313 - accuracy: 0.9674 - val_loss: 0.3099 - val_accuracy: 0.9566\n",
      "Epoch 422/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1301 - accuracy: 0.9670 - val_loss: 0.3216 - val_accuracy: 0.9663\n",
      "Epoch 423/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1374 - accuracy: 0.9655 - val_loss: 0.3898 - val_accuracy: 0.9504\n",
      "Epoch 424/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9655 - val_loss: 0.3683 - val_accuracy: 0.9612\n",
      "Epoch 425/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1345 - accuracy: 0.9653 - val_loss: 0.3825 - val_accuracy: 0.9663\n",
      "Epoch 426/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1378 - accuracy: 0.9652 - val_loss: 0.3806 - val_accuracy: 0.9616\n",
      "Epoch 427/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9661 - val_loss: 0.3477 - val_accuracy: 0.9694\n",
      "Epoch 428/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.9687 - val_loss: 0.3414 - val_accuracy: 0.9736\n",
      "Epoch 429/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.9652 - val_loss: 0.3430 - val_accuracy: 0.9717\n",
      "Epoch 430/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.9673 - val_loss: 0.3531 - val_accuracy: 0.9740\n",
      "Epoch 431/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9664 - val_loss: 0.3156 - val_accuracy: 0.9651\n",
      "Epoch 432/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.9686 - val_loss: 0.3042 - val_accuracy: 0.9643\n",
      "Epoch 433/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.9657 - val_loss: 0.3117 - val_accuracy: 0.9640\n",
      "Epoch 434/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.9671 - val_loss: 0.3086 - val_accuracy: 0.9760\n",
      "Epoch 435/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.9674 - val_loss: 0.3032 - val_accuracy: 0.9733\n",
      "Epoch 436/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1292 - accuracy: 0.9679 - val_loss: 0.3401 - val_accuracy: 0.9547\n",
      "Epoch 437/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.9693 - val_loss: 0.3471 - val_accuracy: 0.9663\n",
      "Epoch 438/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1457 - accuracy: 0.9647 - val_loss: 0.3375 - val_accuracy: 0.9624\n",
      "Epoch 439/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.9693 - val_loss: 0.3394 - val_accuracy: 0.9616\n",
      "Epoch 440/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.9698 - val_loss: 0.3442 - val_accuracy: 0.9570\n",
      "Epoch 441/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9698 - val_loss: 0.3453 - val_accuracy: 0.9678\n",
      "Epoch 442/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.9658 - val_loss: 0.2790 - val_accuracy: 0.9605\n",
      "Epoch 443/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.9680 - val_loss: 0.2583 - val_accuracy: 0.9632\n",
      "Epoch 444/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1258 - accuracy: 0.9684 - val_loss: 0.2549 - val_accuracy: 0.9767\n",
      "Epoch 445/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1337 - accuracy: 0.9665 - val_loss: 0.2583 - val_accuracy: 0.9698\n",
      "Epoch 446/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1252 - accuracy: 0.9680 - val_loss: 0.2573 - val_accuracy: 0.9694\n",
      "Epoch 447/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1310 - accuracy: 0.9654 - val_loss: 0.2511 - val_accuracy: 0.9636\n",
      "Epoch 448/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1274 - accuracy: 0.9688 - val_loss: 0.2533 - val_accuracy: 0.9682\n",
      "Epoch 449/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1334 - accuracy: 0.9660 - val_loss: 0.3140 - val_accuracy: 0.9547\n",
      "Epoch 450/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9671 - val_loss: 0.3087 - val_accuracy: 0.9496\n",
      "Epoch 451/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.9689 - val_loss: 0.2605 - val_accuracy: 0.9659\n",
      "Epoch 452/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9640 - val_loss: 0.2516 - val_accuracy: 0.9612\n",
      "Epoch 453/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9668 - val_loss: 0.3041 - val_accuracy: 0.9457\n",
      "Epoch 454/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1278 - accuracy: 0.9683 - val_loss: 0.2421 - val_accuracy: 0.9678\n",
      "Epoch 455/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9675 - val_loss: 0.2587 - val_accuracy: 0.9570\n",
      "Epoch 456/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1356 - accuracy: 0.9663 - val_loss: 0.2342 - val_accuracy: 0.9674\n",
      "Epoch 457/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1258 - accuracy: 0.9689 - val_loss: 0.2752 - val_accuracy: 0.9616\n",
      "Epoch 458/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9686 - val_loss: 0.2603 - val_accuracy: 0.9705\n",
      "Epoch 459/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1246 - accuracy: 0.9699 - val_loss: 0.2758 - val_accuracy: 0.9643\n",
      "Epoch 460/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1270 - accuracy: 0.9669 - val_loss: 0.2957 - val_accuracy: 0.9628\n",
      "Epoch 461/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1274 - accuracy: 0.9671 - val_loss: 0.3056 - val_accuracy: 0.9659\n",
      "Epoch 462/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.9671 - val_loss: 0.3138 - val_accuracy: 0.9682\n",
      "Epoch 463/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.9689 - val_loss: 0.3070 - val_accuracy: 0.9667\n",
      "Epoch 464/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.9656 - val_loss: 0.3402 - val_accuracy: 0.9612\n",
      "Epoch 465/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1266 - accuracy: 0.9674 - val_loss: 0.3772 - val_accuracy: 0.9585\n",
      "Epoch 466/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1318 - accuracy: 0.9655 - val_loss: 0.3789 - val_accuracy: 0.9671\n",
      "Epoch 467/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.9685 - val_loss: 0.3908 - val_accuracy: 0.9624\n",
      "Epoch 468/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.9693 - val_loss: 0.3666 - val_accuracy: 0.9729\n",
      "Epoch 469/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9686 - val_loss: 0.3817 - val_accuracy: 0.9640\n",
      "Epoch 470/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1256 - accuracy: 0.9677 - val_loss: 0.4410 - val_accuracy: 0.9496\n",
      "Epoch 471/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9689 - val_loss: 0.3998 - val_accuracy: 0.9694\n",
      "Epoch 472/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.9681 - val_loss: 0.4059 - val_accuracy: 0.9736\n",
      "Epoch 473/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1252 - accuracy: 0.9676 - val_loss: 0.4311 - val_accuracy: 0.9767\n",
      "Epoch 474/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9653 - val_loss: 0.4454 - val_accuracy: 0.9709\n",
      "Epoch 475/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1269 - accuracy: 0.9678 - val_loss: 0.4637 - val_accuracy: 0.9624\n",
      "Epoch 476/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.9687 - val_loss: 0.4898 - val_accuracy: 0.9585\n",
      "Epoch 477/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9691 - val_loss: 0.4881 - val_accuracy: 0.9690\n",
      "Epoch 478/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9672 - val_loss: 0.4665 - val_accuracy: 0.9694\n",
      "Epoch 479/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9693 - val_loss: 0.4925 - val_accuracy: 0.9647\n",
      "Epoch 480/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.9680 - val_loss: 0.4808 - val_accuracy: 0.9667\n",
      "Epoch 481/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1219 - accuracy: 0.9684 - val_loss: 0.4456 - val_accuracy: 0.9740\n",
      "Epoch 482/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1342 - accuracy: 0.9648 - val_loss: 0.4810 - val_accuracy: 0.9632\n",
      "Epoch 483/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.9677 - val_loss: 0.5761 - val_accuracy: 0.9450\n",
      "Epoch 484/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9672 - val_loss: 0.5344 - val_accuracy: 0.9523\n",
      "Epoch 485/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9664 - val_loss: 0.5127 - val_accuracy: 0.9748\n",
      "Epoch 486/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.9702 - val_loss: 0.4335 - val_accuracy: 0.9767\n",
      "Epoch 487/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9689 - val_loss: 0.4888 - val_accuracy: 0.9581\n",
      "Epoch 488/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1321 - accuracy: 0.9662 - val_loss: 0.4670 - val_accuracy: 0.9698\n",
      "Epoch 489/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1209 - accuracy: 0.9687 - val_loss: 0.4297 - val_accuracy: 0.9748\n",
      "Epoch 490/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.9686 - val_loss: 0.4373 - val_accuracy: 0.9764\n",
      "Epoch 491/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1208 - accuracy: 0.9688 - val_loss: 0.4508 - val_accuracy: 0.9674\n",
      "Epoch 492/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.9697 - val_loss: 0.4980 - val_accuracy: 0.9527\n",
      "Epoch 493/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9700 - val_loss: 0.5194 - val_accuracy: 0.9500\n",
      "Epoch 494/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1234 - accuracy: 0.9686 - val_loss: 0.4917 - val_accuracy: 0.9736\n",
      "Epoch 495/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9696 - val_loss: 0.5186 - val_accuracy: 0.9636\n",
      "Epoch 496/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9695 - val_loss: 0.5477 - val_accuracy: 0.9547\n",
      "Epoch 497/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9707 - val_loss: 0.5385 - val_accuracy: 0.9705\n",
      "Epoch 498/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.9702 - val_loss: 0.5401 - val_accuracy: 0.9725\n",
      "Epoch 499/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.9693 - val_loss: 0.5644 - val_accuracy: 0.9690\n",
      "Epoch 500/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.9690 - val_loss: 0.5784 - val_accuracy: 0.9713\n",
      "Epoch 501/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1172 - accuracy: 0.9703 - val_loss: 0.6280 - val_accuracy: 0.9624\n",
      "Epoch 502/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9682 - val_loss: 0.6320 - val_accuracy: 0.9597\n",
      "Epoch 503/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.9688 - val_loss: 0.6009 - val_accuracy: 0.9601\n",
      "Epoch 504/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9700 - val_loss: 0.5797 - val_accuracy: 0.9659\n",
      "Epoch 505/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.9712 - val_loss: 0.6148 - val_accuracy: 0.9632\n",
      "Epoch 506/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9690 - val_loss: 0.5704 - val_accuracy: 0.9686\n",
      "Epoch 507/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.9719 - val_loss: 0.5795 - val_accuracy: 0.9733\n",
      "Epoch 508/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9728 - val_loss: 0.5897 - val_accuracy: 0.9810\n",
      "Epoch 509/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.9690 - val_loss: 0.5880 - val_accuracy: 0.9678\n",
      "Epoch 510/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.9671 - val_loss: 0.5946 - val_accuracy: 0.9678\n",
      "Epoch 511/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9694 - val_loss: 0.6215 - val_accuracy: 0.9709\n",
      "Epoch 512/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9708 - val_loss: 0.5961 - val_accuracy: 0.9740\n",
      "Epoch 513/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9707 - val_loss: 0.6370 - val_accuracy: 0.9674\n",
      "Epoch 514/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9688 - val_loss: 0.6327 - val_accuracy: 0.9709\n",
      "Epoch 515/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9717 - val_loss: 0.6333 - val_accuracy: 0.9729\n",
      "Epoch 516/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9704 - val_loss: 0.6653 - val_accuracy: 0.9698\n",
      "Epoch 517/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1380 - accuracy: 0.9674 - val_loss: 0.6559 - val_accuracy: 0.9740\n",
      "Epoch 518/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.9674 - val_loss: 0.6418 - val_accuracy: 0.9709\n",
      "Epoch 519/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.9698 - val_loss: 0.6761 - val_accuracy: 0.9647\n",
      "Epoch 520/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.9702 - val_loss: 0.1275 - val_accuracy: 0.9705\n",
      "Epoch 521/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9697 - val_loss: 0.1085 - val_accuracy: 0.9729\n",
      "Epoch 522/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1160 - accuracy: 0.9703 - val_loss: 0.1246 - val_accuracy: 0.9674\n",
      "Epoch 523/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9703 - val_loss: 0.1090 - val_accuracy: 0.9756\n",
      "Epoch 524/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1204 - accuracy: 0.9683 - val_loss: 0.1094 - val_accuracy: 0.9740\n",
      "Epoch 525/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9699 - val_loss: 0.1641 - val_accuracy: 0.9527\n",
      "Epoch 526/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1268 - accuracy: 0.9677 - val_loss: 0.1192 - val_accuracy: 0.9671\n",
      "Epoch 527/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9731 - val_loss: 0.1685 - val_accuracy: 0.9640\n",
      "Epoch 528/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9696 - val_loss: 0.1495 - val_accuracy: 0.9593\n",
      "Epoch 529/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9682 - val_loss: 0.0993 - val_accuracy: 0.9767\n",
      "Epoch 530/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9685 - val_loss: 0.1307 - val_accuracy: 0.9655\n",
      "Epoch 531/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9709 - val_loss: 0.1543 - val_accuracy: 0.9616\n",
      "Epoch 532/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.9689 - val_loss: 0.1238 - val_accuracy: 0.9616\n",
      "Epoch 533/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9708 - val_loss: 0.1317 - val_accuracy: 0.9705\n",
      "Epoch 534/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.9687 - val_loss: 0.1347 - val_accuracy: 0.9609\n",
      "Epoch 535/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1107 - accuracy: 0.9719 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 536/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9702 - val_loss: 0.1179 - val_accuracy: 0.9721\n",
      "Epoch 537/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1269 - accuracy: 0.9667 - val_loss: 0.1137 - val_accuracy: 0.9690\n",
      "Epoch 538/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9705 - val_loss: 0.1303 - val_accuracy: 0.9632\n",
      "Epoch 539/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.9678 - val_loss: 0.1350 - val_accuracy: 0.9601\n",
      "Epoch 540/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9692 - val_loss: 0.1501 - val_accuracy: 0.9589\n",
      "Epoch 541/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.9696 - val_loss: 0.1085 - val_accuracy: 0.9736\n",
      "Epoch 542/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9704 - val_loss: 0.1707 - val_accuracy: 0.9581\n",
      "Epoch 543/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9701 - val_loss: 0.1409 - val_accuracy: 0.9624\n",
      "Epoch 544/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.9705 - val_loss: 0.1219 - val_accuracy: 0.9690\n",
      "Epoch 545/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9697 - val_loss: 0.1285 - val_accuracy: 0.9709\n",
      "Epoch 546/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.9692 - val_loss: 0.1309 - val_accuracy: 0.9671\n",
      "Epoch 547/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.9686 - val_loss: 0.1330 - val_accuracy: 0.9671\n",
      "Epoch 548/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.9706 - val_loss: 0.1289 - val_accuracy: 0.9628\n",
      "Epoch 549/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9718 - val_loss: 0.1310 - val_accuracy: 0.9659\n",
      "Epoch 550/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.9682 - val_loss: 0.1504 - val_accuracy: 0.9690\n",
      "Epoch 551/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9699 - val_loss: 0.1550 - val_accuracy: 0.9736\n",
      "Epoch 552/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.9690 - val_loss: 0.2391 - val_accuracy: 0.9512\n",
      "Epoch 553/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9705 - val_loss: 0.1775 - val_accuracy: 0.9616\n",
      "Epoch 554/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9724 - val_loss: 0.1775 - val_accuracy: 0.9705\n",
      "Epoch 555/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.9702 - val_loss: 0.1936 - val_accuracy: 0.9589\n",
      "Epoch 556/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.9723 - val_loss: 0.2263 - val_accuracy: 0.9597\n",
      "Epoch 557/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9678 - val_loss: 0.2129 - val_accuracy: 0.9698\n",
      "Epoch 558/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1194 - accuracy: 0.9692 - val_loss: 0.1790 - val_accuracy: 0.9733\n",
      "Epoch 559/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9689 - val_loss: 0.1925 - val_accuracy: 0.9702\n",
      "Epoch 560/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9696 - val_loss: 0.1825 - val_accuracy: 0.9802\n",
      "Epoch 561/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.9711 - val_loss: 0.2452 - val_accuracy: 0.9647\n",
      "Epoch 562/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9697 - val_loss: 0.2271 - val_accuracy: 0.9640\n",
      "Epoch 563/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1396 - accuracy: 0.9679 - val_loss: 0.1825 - val_accuracy: 0.9725\n",
      "Epoch 564/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.9742 - val_loss: 0.1668 - val_accuracy: 0.9686\n",
      "Epoch 565/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.9720 - val_loss: 0.1838 - val_accuracy: 0.9682\n",
      "Epoch 566/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9718 - val_loss: 0.2045 - val_accuracy: 0.9682\n",
      "Epoch 567/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9691 - val_loss: 0.2014 - val_accuracy: 0.9686\n",
      "Epoch 568/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9720 - val_loss: 0.2138 - val_accuracy: 0.9667\n",
      "Epoch 569/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9698 - val_loss: 0.2182 - val_accuracy: 0.9674\n",
      "Epoch 570/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9705 - val_loss: 0.2594 - val_accuracy: 0.9593\n",
      "Epoch 571/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.9705 - val_loss: 0.3068 - val_accuracy: 0.9504\n",
      "Epoch 572/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9696 - val_loss: 0.3419 - val_accuracy: 0.9349\n",
      "Epoch 573/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1160 - accuracy: 0.9708 - val_loss: 0.2365 - val_accuracy: 0.9694\n",
      "Epoch 574/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9703 - val_loss: 0.2632 - val_accuracy: 0.9446\n",
      "Epoch 575/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9704 - val_loss: 0.2560 - val_accuracy: 0.9678\n",
      "Epoch 576/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9711 - val_loss: 0.3009 - val_accuracy: 0.9620\n",
      "Epoch 577/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9688 - val_loss: 0.2591 - val_accuracy: 0.9659\n",
      "Epoch 578/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9702 - val_loss: 0.2917 - val_accuracy: 0.9663\n",
      "Epoch 579/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1172 - accuracy: 0.9703 - val_loss: 0.2908 - val_accuracy: 0.9682\n",
      "Epoch 580/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9711 - val_loss: 0.2973 - val_accuracy: 0.9752\n",
      "Epoch 581/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9688 - val_loss: 0.2970 - val_accuracy: 0.9709\n",
      "Epoch 582/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9725 - val_loss: 0.2727 - val_accuracy: 0.9767\n",
      "Epoch 583/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9689 - val_loss: 0.3280 - val_accuracy: 0.9527\n",
      "Epoch 584/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9720 - val_loss: 0.2594 - val_accuracy: 0.9698\n",
      "Epoch 585/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9697 - val_loss: 0.2879 - val_accuracy: 0.9783\n",
      "Epoch 586/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9708 - val_loss: 0.1433 - val_accuracy: 0.9562\n",
      "Epoch 587/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9726 - val_loss: 0.1235 - val_accuracy: 0.9690\n",
      "Epoch 588/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9732 - val_loss: 0.1174 - val_accuracy: 0.9632\n",
      "Epoch 589/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9685 - val_loss: 0.0995 - val_accuracy: 0.9764\n",
      "Epoch 590/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9702 - val_loss: 0.1197 - val_accuracy: 0.9702\n",
      "Epoch 591/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1181 - accuracy: 0.9689 - val_loss: 0.0945 - val_accuracy: 0.9783\n",
      "Epoch 592/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9711 - val_loss: 0.3399 - val_accuracy: 0.9105\n",
      "Epoch 593/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9710 - val_loss: 0.2025 - val_accuracy: 0.9446\n",
      "Epoch 594/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9715 - val_loss: 0.1211 - val_accuracy: 0.9779\n",
      "Epoch 595/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9710 - val_loss: 0.1787 - val_accuracy: 0.9609\n",
      "Epoch 596/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.9738 - val_loss: 0.1388 - val_accuracy: 0.9771\n",
      "Epoch 597/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.9717 - val_loss: 0.1451 - val_accuracy: 0.9705\n",
      "Epoch 598/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9709 - val_loss: 0.1401 - val_accuracy: 0.9787\n",
      "Epoch 599/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1091 - accuracy: 0.9707 - val_loss: 0.1770 - val_accuracy: 0.9589\n",
      "Epoch 600/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9710 - val_loss: 0.1451 - val_accuracy: 0.9733\n",
      "Epoch 601/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9716 - val_loss: 0.1584 - val_accuracy: 0.9643\n",
      "Epoch 602/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9703 - val_loss: 0.1469 - val_accuracy: 0.9787\n",
      "Epoch 603/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9713 - val_loss: 0.1822 - val_accuracy: 0.9713\n",
      "Epoch 604/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9724 - val_loss: 0.2008 - val_accuracy: 0.9725\n",
      "Epoch 605/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1158 - accuracy: 0.9690 - val_loss: 0.2373 - val_accuracy: 0.9523\n",
      "Epoch 606/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9709 - val_loss: 0.2151 - val_accuracy: 0.9671\n",
      "Epoch 607/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9705 - val_loss: 0.2098 - val_accuracy: 0.9775\n",
      "Epoch 608/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9717 - val_loss: 0.2673 - val_accuracy: 0.9725\n",
      "Epoch 609/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.9720 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
      "Epoch 610/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9711 - val_loss: 0.2803 - val_accuracy: 0.9748\n",
      "Epoch 611/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.9705 - val_loss: 0.3484 - val_accuracy: 0.9589\n",
      "Epoch 612/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9731 - val_loss: 0.3596 - val_accuracy: 0.9609\n",
      "Epoch 613/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.9715 - val_loss: 0.1573 - val_accuracy: 0.9756\n",
      "Epoch 614/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1096 - accuracy: 0.9720 - val_loss: 0.1989 - val_accuracy: 0.9705\n",
      "Epoch 615/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9715 - val_loss: 0.2489 - val_accuracy: 0.9597\n",
      "Epoch 616/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9727 - val_loss: 0.2354 - val_accuracy: 0.9787\n",
      "Epoch 617/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.9715 - val_loss: 0.1375 - val_accuracy: 0.9744\n",
      "Epoch 618/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9729 - val_loss: 0.1350 - val_accuracy: 0.9736\n",
      "Epoch 619/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9709 - val_loss: 0.1309 - val_accuracy: 0.9713\n",
      "Epoch 620/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9709 - val_loss: 0.1535 - val_accuracy: 0.9643\n",
      "Epoch 621/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9736 - val_loss: 0.1333 - val_accuracy: 0.9721\n",
      "Epoch 622/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9711 - val_loss: 0.1381 - val_accuracy: 0.9740\n",
      "Epoch 623/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9718 - val_loss: 0.1589 - val_accuracy: 0.9647\n",
      "Epoch 624/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9717 - val_loss: 0.0941 - val_accuracy: 0.9791\n",
      "Epoch 625/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9694 - val_loss: 0.1060 - val_accuracy: 0.9705\n",
      "Epoch 626/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9741 - val_loss: 0.1463 - val_accuracy: 0.9663\n",
      "Epoch 627/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.9718 - val_loss: 0.1463 - val_accuracy: 0.9659\n",
      "Epoch 628/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9701 - val_loss: 0.1942 - val_accuracy: 0.9504\n",
      "Epoch 629/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.9696 - val_loss: 0.1113 - val_accuracy: 0.9713\n",
      "Epoch 630/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9723 - val_loss: 0.1419 - val_accuracy: 0.9643\n",
      "Epoch 631/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9720 - val_loss: 0.1338 - val_accuracy: 0.9736\n",
      "Epoch 632/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9712 - val_loss: 0.1769 - val_accuracy: 0.9612\n",
      "Epoch 633/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9702 - val_loss: 0.1208 - val_accuracy: 0.9787\n",
      "Epoch 634/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9727 - val_loss: 0.1561 - val_accuracy: 0.9690\n",
      "Epoch 635/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.9741 - val_loss: 0.1795 - val_accuracy: 0.9609\n",
      "Epoch 636/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9708 - val_loss: 0.1880 - val_accuracy: 0.9690\n",
      "Epoch 637/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9700 - val_loss: 0.1877 - val_accuracy: 0.9674\n",
      "Epoch 638/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9730 - val_loss: 0.1980 - val_accuracy: 0.9787\n",
      "Epoch 639/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9710 - val_loss: 0.2242 - val_accuracy: 0.9663\n",
      "Epoch 640/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9710 - val_loss: 0.2411 - val_accuracy: 0.9558\n",
      "Epoch 641/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9708 - val_loss: 0.1859 - val_accuracy: 0.9764\n",
      "Epoch 642/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9733 - val_loss: 0.1502 - val_accuracy: 0.9802\n",
      "Epoch 643/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9712 - val_loss: 0.2006 - val_accuracy: 0.9682\n",
      "Epoch 644/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9731 - val_loss: 0.2000 - val_accuracy: 0.9702\n",
      "Epoch 645/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9718 - val_loss: 0.2440 - val_accuracy: 0.9659\n",
      "Epoch 646/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.9691 - val_loss: 0.2622 - val_accuracy: 0.9574\n",
      "Epoch 647/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9722 - val_loss: 0.2351 - val_accuracy: 0.9802\n",
      "Epoch 648/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1092 - accuracy: 0.9717 - val_loss: 0.2480 - val_accuracy: 0.9756\n",
      "Epoch 649/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1112 - accuracy: 0.9700 - val_loss: 0.1855 - val_accuracy: 0.9806\n",
      "Epoch 650/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9716 - val_loss: 0.2026 - val_accuracy: 0.9736\n",
      "Epoch 651/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9738 - val_loss: 0.2449 - val_accuracy: 0.9717\n",
      "Epoch 652/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9731 - val_loss: 0.2184 - val_accuracy: 0.9744\n",
      "Epoch 653/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9716 - val_loss: 0.2436 - val_accuracy: 0.9690\n",
      "Epoch 654/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.9713 - val_loss: 0.2371 - val_accuracy: 0.9764\n",
      "Epoch 655/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9722 - val_loss: 0.2624 - val_accuracy: 0.9744\n",
      "Epoch 656/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9702 - val_loss: 0.3349 - val_accuracy: 0.9663\n",
      "Epoch 657/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9706 - val_loss: 0.3505 - val_accuracy: 0.9574\n",
      "Epoch 658/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9738 - val_loss: 0.3794 - val_accuracy: 0.9601\n",
      "Epoch 659/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.9714 - val_loss: 0.3374 - val_accuracy: 0.9736\n",
      "Epoch 660/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9710 - val_loss: 0.3559 - val_accuracy: 0.9682\n",
      "Epoch 661/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9712 - val_loss: 0.3450 - val_accuracy: 0.9802\n",
      "Epoch 662/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9733 - val_loss: 0.3919 - val_accuracy: 0.9709\n",
      "Epoch 663/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1154 - accuracy: 0.9702 - val_loss: 0.4010 - val_accuracy: 0.9671\n",
      "Epoch 664/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1072 - accuracy: 0.9713 - val_loss: 0.4137 - val_accuracy: 0.9640\n",
      "Epoch 665/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9727 - val_loss: 0.3185 - val_accuracy: 0.9760\n",
      "Epoch 666/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1194 - accuracy: 0.9695 - val_loss: 0.3729 - val_accuracy: 0.9694\n",
      "Epoch 667/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9738 - val_loss: 0.4089 - val_accuracy: 0.9516\n",
      "Epoch 668/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9740 - val_loss: 0.3576 - val_accuracy: 0.9690\n",
      "Epoch 669/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9732 - val_loss: 0.3476 - val_accuracy: 0.9833\n",
      "Epoch 670/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9715 - val_loss: 0.4320 - val_accuracy: 0.9570\n",
      "Epoch 671/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9729 - val_loss: 0.3572 - val_accuracy: 0.9705\n",
      "Epoch 672/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9718 - val_loss: 0.3806 - val_accuracy: 0.9721\n",
      "Epoch 673/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9734 - val_loss: 0.4076 - val_accuracy: 0.9655\n",
      "Epoch 674/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9718 - val_loss: 0.4359 - val_accuracy: 0.9636\n",
      "Epoch 675/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.9716 - val_loss: 0.4355 - val_accuracy: 0.9767\n",
      "Epoch 676/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9743 - val_loss: 0.4735 - val_accuracy: 0.9651\n",
      "Epoch 677/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9724 - val_loss: 0.4707 - val_accuracy: 0.9702\n",
      "Epoch 678/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9733 - val_loss: 0.4854 - val_accuracy: 0.9744\n",
      "Epoch 679/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.9737 - val_loss: 0.4830 - val_accuracy: 0.9686\n",
      "Epoch 680/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.9721 - val_loss: 0.4837 - val_accuracy: 0.9736\n",
      "Epoch 681/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9692 - val_loss: 0.4956 - val_accuracy: 0.9624\n",
      "Epoch 682/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.9710 - val_loss: 0.4365 - val_accuracy: 0.9829\n",
      "Epoch 683/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.4819 - val_accuracy: 0.9713\n",
      "Epoch 684/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9741 - val_loss: 0.4928 - val_accuracy: 0.9717\n",
      "Epoch 685/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.9727 - val_loss: 0.4600 - val_accuracy: 0.9775\n",
      "Epoch 686/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.9732 - val_loss: 0.4584 - val_accuracy: 0.9717\n",
      "Epoch 687/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9724 - val_loss: 0.5024 - val_accuracy: 0.9550\n",
      "Epoch 688/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9730 - val_loss: 0.4485 - val_accuracy: 0.9814\n",
      "Epoch 689/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0975 - accuracy: 0.9741 - val_loss: 0.4903 - val_accuracy: 0.9640\n",
      "Epoch 690/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9715 - val_loss: 0.5091 - val_accuracy: 0.9671\n",
      "Epoch 691/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9717 - val_loss: 0.4839 - val_accuracy: 0.9791\n",
      "Epoch 692/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9732 - val_loss: 0.4989 - val_accuracy: 0.9779\n",
      "Epoch 693/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.9705 - val_loss: 0.4727 - val_accuracy: 0.9756\n",
      "Epoch 694/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9724 - val_loss: 0.4564 - val_accuracy: 0.9771\n",
      "Epoch 695/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9740 - val_loss: 0.4312 - val_accuracy: 0.9752\n",
      "Epoch 696/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9714 - val_loss: 0.4613 - val_accuracy: 0.9767\n",
      "Epoch 697/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9722 - val_loss: 0.4830 - val_accuracy: 0.9705\n",
      "Epoch 698/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9701 - val_loss: 0.4835 - val_accuracy: 0.9783\n",
      "Epoch 699/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9730 - val_loss: 0.5282 - val_accuracy: 0.9682\n",
      "Epoch 700/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9744 - val_loss: 0.4795 - val_accuracy: 0.9798\n",
      "Epoch 701/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.9732 - val_loss: 0.5826 - val_accuracy: 0.9539\n",
      "Epoch 702/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9727 - val_loss: 0.5911 - val_accuracy: 0.9597\n",
      "Epoch 703/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9724 - val_loss: 0.5787 - val_accuracy: 0.9663\n",
      "Epoch 704/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.9716 - val_loss: 0.5620 - val_accuracy: 0.9678\n",
      "Epoch 705/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9714 - val_loss: 0.6401 - val_accuracy: 0.9713\n",
      "Epoch 706/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.9714 - val_loss: 0.6030 - val_accuracy: 0.9775\n",
      "Epoch 707/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9722 - val_loss: 0.6382 - val_accuracy: 0.9698\n",
      "Epoch 708/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.9718 - val_loss: 0.6618 - val_accuracy: 0.9802\n",
      "Epoch 709/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9690 - val_loss: 0.7160 - val_accuracy: 0.9659\n",
      "Epoch 710/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9725 - val_loss: 0.7526 - val_accuracy: 0.9527\n",
      "Epoch 711/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9738 - val_loss: 0.7042 - val_accuracy: 0.9709\n",
      "Epoch 712/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9748 - val_loss: 0.7426 - val_accuracy: 0.9713\n",
      "Epoch 713/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9727 - val_loss: 0.7230 - val_accuracy: 0.9764\n",
      "Epoch 714/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9739 - val_loss: 0.7562 - val_accuracy: 0.9690\n",
      "Epoch 715/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9740 - val_loss: 0.7426 - val_accuracy: 0.9702\n",
      "Epoch 716/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9741 - val_loss: 0.7661 - val_accuracy: 0.9717\n",
      "Epoch 717/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9701 - val_loss: 0.7153 - val_accuracy: 0.9767\n",
      "Epoch 718/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.9745 - val_loss: 0.7366 - val_accuracy: 0.9671\n",
      "Epoch 719/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.9722 - val_loss: 0.7241 - val_accuracy: 0.9779\n",
      "Epoch 720/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9717 - val_loss: 0.8178 - val_accuracy: 0.9620\n",
      "Epoch 721/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9746 - val_loss: 0.1589 - val_accuracy: 0.9527\n",
      "Epoch 722/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9729 - val_loss: 0.0945 - val_accuracy: 0.9756\n",
      "Epoch 723/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9721 - val_loss: 0.0777 - val_accuracy: 0.9826\n",
      "Epoch 724/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9742 - val_loss: 0.0985 - val_accuracy: 0.9713\n",
      "Epoch 725/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9738 - val_loss: 0.1348 - val_accuracy: 0.9659\n",
      "Epoch 726/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.9700 - val_loss: 0.1349 - val_accuracy: 0.9612\n",
      "Epoch 727/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9721 - val_loss: 0.1125 - val_accuracy: 0.9733\n",
      "Epoch 728/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9737 - val_loss: 0.1210 - val_accuracy: 0.9643\n",
      "Epoch 729/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1072 - accuracy: 0.9716 - val_loss: 0.0978 - val_accuracy: 0.9721\n",
      "Epoch 730/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9749 - val_loss: 0.1281 - val_accuracy: 0.9678\n",
      "Epoch 731/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9744 - val_loss: 0.1284 - val_accuracy: 0.9671\n",
      "Epoch 732/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9744 - val_loss: 0.0909 - val_accuracy: 0.9795\n",
      "Epoch 733/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9771 - val_loss: 0.1043 - val_accuracy: 0.9748\n",
      "Epoch 734/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.9756 - val_loss: 0.0917 - val_accuracy: 0.9733\n",
      "Epoch 735/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9759 - val_loss: 0.0916 - val_accuracy: 0.9752\n",
      "Epoch 736/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9733 - val_loss: 0.0875 - val_accuracy: 0.9760\n",
      "Epoch 737/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9734 - val_loss: 0.0883 - val_accuracy: 0.9764\n",
      "Epoch 738/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.9744 - val_loss: 0.0829 - val_accuracy: 0.9771\n",
      "Epoch 739/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9720 - val_loss: 0.3103 - val_accuracy: 0.9291\n",
      "Epoch 740/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 0.0928 - val_accuracy: 0.9760\n",
      "Epoch 741/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9752 - val_loss: 0.0758 - val_accuracy: 0.9829\n",
      "Epoch 742/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 0.0889 - val_accuracy: 0.9775\n",
      "Epoch 743/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9718 - val_loss: 0.1264 - val_accuracy: 0.9690\n",
      "Epoch 744/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.2231 - val_accuracy: 0.9419\n",
      "Epoch 745/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9743 - val_loss: 0.0841 - val_accuracy: 0.9810\n",
      "Epoch 746/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9717 - val_loss: 0.1213 - val_accuracy: 0.9694\n",
      "Epoch 747/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9697 - val_loss: 0.0788 - val_accuracy: 0.9810\n",
      "Epoch 748/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9737 - val_loss: 0.1045 - val_accuracy: 0.9647\n",
      "Epoch 749/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9750 - val_loss: 0.0860 - val_accuracy: 0.9791\n",
      "Epoch 750/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9717 - val_loss: 0.0834 - val_accuracy: 0.9756\n",
      "Epoch 751/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9747 - val_loss: 0.1126 - val_accuracy: 0.9678\n",
      "Epoch 752/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9705 - val_loss: 0.1102 - val_accuracy: 0.9659\n",
      "Epoch 753/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.9737 - val_loss: 0.1268 - val_accuracy: 0.9601\n",
      "Epoch 754/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9745 - val_loss: 0.0919 - val_accuracy: 0.9760\n",
      "Epoch 755/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9725 - val_loss: 0.1114 - val_accuracy: 0.9694\n",
      "Epoch 756/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9732 - val_loss: 0.1198 - val_accuracy: 0.9698\n",
      "Epoch 757/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9725 - val_loss: 0.1113 - val_accuracy: 0.9678\n",
      "Epoch 758/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9741 - val_loss: 0.1319 - val_accuracy: 0.9655\n",
      "Epoch 759/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.1563 - val_accuracy: 0.9550\n",
      "Epoch 760/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9732 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 761/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9740 - val_loss: 0.1287 - val_accuracy: 0.9643\n",
      "Epoch 762/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9728 - val_loss: 0.1012 - val_accuracy: 0.9744\n",
      "Epoch 763/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9724 - val_loss: 0.0900 - val_accuracy: 0.9764\n",
      "Epoch 764/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9737 - val_loss: 0.0798 - val_accuracy: 0.9806\n",
      "Epoch 765/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9717 - val_loss: 0.0879 - val_accuracy: 0.9791\n",
      "Epoch 766/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9738 - val_loss: 0.0880 - val_accuracy: 0.9779\n",
      "Epoch 767/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9740 - val_loss: 0.0862 - val_accuracy: 0.9802\n",
      "Epoch 768/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9716 - val_loss: 0.1308 - val_accuracy: 0.9609\n",
      "Epoch 769/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9745 - val_loss: 0.0807 - val_accuracy: 0.9798\n",
      "Epoch 770/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9732 - val_loss: 0.0860 - val_accuracy: 0.9764\n",
      "Epoch 771/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9743 - val_loss: 0.0922 - val_accuracy: 0.9756\n",
      "Epoch 772/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9743 - val_loss: 0.0811 - val_accuracy: 0.9837\n",
      "Epoch 773/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9746 - val_loss: 0.1898 - val_accuracy: 0.9519\n",
      "Epoch 774/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.9707 - val_loss: 0.1254 - val_accuracy: 0.9636\n",
      "Epoch 775/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9715 - val_loss: 0.0945 - val_accuracy: 0.9702\n",
      "Epoch 776/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9724 - val_loss: 0.1025 - val_accuracy: 0.9713\n",
      "Epoch 777/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9725 - val_loss: 0.0876 - val_accuracy: 0.9795\n",
      "Epoch 778/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9732 - val_loss: 0.0918 - val_accuracy: 0.9729\n",
      "Epoch 779/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9744 - val_loss: 0.1625 - val_accuracy: 0.9705\n",
      "Epoch 780/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1022 - accuracy: 0.9721 - val_loss: 0.1732 - val_accuracy: 0.9554\n",
      "Epoch 781/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0958 - accuracy: 0.9751 - val_loss: 0.1411 - val_accuracy: 0.9698\n",
      "Epoch 782/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9755 - val_loss: 0.1575 - val_accuracy: 0.9647\n",
      "Epoch 783/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9722 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
      "Epoch 784/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9731 - val_loss: 0.1595 - val_accuracy: 0.9721\n",
      "Epoch 785/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9719 - val_loss: 0.2767 - val_accuracy: 0.9465\n",
      "Epoch 786/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9745 - val_loss: 0.1199 - val_accuracy: 0.9787\n",
      "Epoch 787/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.9699 - val_loss: 0.1443 - val_accuracy: 0.9771\n",
      "Epoch 788/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9751 - val_loss: 0.1619 - val_accuracy: 0.9775\n",
      "Epoch 789/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9767 - val_loss: 0.2023 - val_accuracy: 0.9643\n",
      "Epoch 790/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9712 - val_loss: 0.1622 - val_accuracy: 0.9798\n",
      "Epoch 791/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.9741 - val_loss: 0.1287 - val_accuracy: 0.9748\n",
      "Epoch 792/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9752 - val_loss: 0.1573 - val_accuracy: 0.9775\n",
      "Epoch 793/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9745 - val_loss: 0.1811 - val_accuracy: 0.9822\n",
      "Epoch 794/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.9730 - val_loss: 0.2412 - val_accuracy: 0.9628\n",
      "Epoch 795/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9724 - val_loss: 0.2780 - val_accuracy: 0.9519\n",
      "Epoch 796/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9731 - val_loss: 0.2768 - val_accuracy: 0.9539\n",
      "Epoch 797/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0958 - accuracy: 0.9748 - val_loss: 0.2092 - val_accuracy: 0.9787\n",
      "Epoch 798/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9743 - val_loss: 0.2621 - val_accuracy: 0.9698\n",
      "Epoch 799/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.9735 - val_loss: 0.0899 - val_accuracy: 0.9752\n",
      "Epoch 800/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.9752 - val_loss: 0.0800 - val_accuracy: 0.9767\n",
      "Epoch 801/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9741 - val_loss: 0.1101 - val_accuracy: 0.9663\n",
      "Epoch 802/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9779 - val_loss: 0.0868 - val_accuracy: 0.9744\n",
      "Epoch 803/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9761 - val_loss: 0.1460 - val_accuracy: 0.9612\n",
      "Epoch 804/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9755 - val_loss: 0.1013 - val_accuracy: 0.9802\n",
      "Epoch 805/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9726 - val_loss: 0.1034 - val_accuracy: 0.9682\n",
      "Epoch 806/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9739 - val_loss: 0.0836 - val_accuracy: 0.9779\n",
      "Epoch 807/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.1392 - val_accuracy: 0.9779\n",
      "Epoch 808/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9744 - val_loss: 0.1242 - val_accuracy: 0.9783\n",
      "Epoch 809/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9752 - val_loss: 0.1616 - val_accuracy: 0.9791\n",
      "Epoch 810/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.1992 - val_accuracy: 0.9682\n",
      "Epoch 811/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9730 - val_loss: 0.2328 - val_accuracy: 0.9593\n",
      "Epoch 812/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9728 - val_loss: 0.2601 - val_accuracy: 0.9601\n",
      "Epoch 813/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9734 - val_loss: 0.2603 - val_accuracy: 0.9671\n",
      "Epoch 814/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9722 - val_loss: 0.2355 - val_accuracy: 0.9764\n",
      "Epoch 815/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9760 - val_loss: 0.2221 - val_accuracy: 0.9725\n",
      "Epoch 816/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9726 - val_loss: 0.2197 - val_accuracy: 0.9787\n",
      "Epoch 817/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9743 - val_loss: 0.2830 - val_accuracy: 0.9655\n",
      "Epoch 818/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.3225 - val_accuracy: 0.9597\n",
      "Epoch 819/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9749 - val_loss: 0.3387 - val_accuracy: 0.9733\n",
      "Epoch 820/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.9748 - val_loss: 0.3884 - val_accuracy: 0.9516\n",
      "Epoch 821/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9729 - val_loss: 0.3578 - val_accuracy: 0.9744\n",
      "Epoch 822/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9746 - val_loss: 0.3821 - val_accuracy: 0.9767\n",
      "Epoch 823/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.9735 - val_loss: 0.4447 - val_accuracy: 0.9674\n",
      "Epoch 824/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9747 - val_loss: 0.4293 - val_accuracy: 0.9671\n",
      "Epoch 825/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9755 - val_loss: 0.4504 - val_accuracy: 0.9744\n",
      "Epoch 826/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9745 - val_loss: 0.4203 - val_accuracy: 0.9640\n",
      "Epoch 827/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9748 - val_loss: 0.4104 - val_accuracy: 0.9624\n",
      "Epoch 828/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9737 - val_loss: 0.4242 - val_accuracy: 0.9690\n",
      "Epoch 829/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9748 - val_loss: 0.4603 - val_accuracy: 0.9729\n",
      "Epoch 830/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9747 - val_loss: 0.4604 - val_accuracy: 0.9818\n",
      "Epoch 831/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9723 - val_loss: 0.4518 - val_accuracy: 0.9798\n",
      "Epoch 832/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9736 - val_loss: 0.5163 - val_accuracy: 0.9671\n",
      "Epoch 833/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9711 - val_loss: 0.5664 - val_accuracy: 0.9733\n",
      "Epoch 834/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9755 - val_loss: 0.5943 - val_accuracy: 0.9752\n",
      "Epoch 835/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9757 - val_loss: 0.5853 - val_accuracy: 0.9857\n",
      "Epoch 836/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9732 - val_loss: 0.6328 - val_accuracy: 0.9822\n",
      "Epoch 837/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9744 - val_loss: 0.6474 - val_accuracy: 0.9717\n",
      "Epoch 838/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9713 - val_loss: 0.6986 - val_accuracy: 0.9636\n",
      "Epoch 839/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9753 - val_loss: 0.7071 - val_accuracy: 0.9601\n",
      "Epoch 840/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9753 - val_loss: 0.6848 - val_accuracy: 0.9733\n",
      "Epoch 841/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9749 - val_loss: 0.6207 - val_accuracy: 0.9632\n",
      "Epoch 842/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9734 - val_loss: 0.5971 - val_accuracy: 0.9764\n",
      "Epoch 843/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9746 - val_loss: 0.5816 - val_accuracy: 0.9740\n",
      "Epoch 844/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.9742 - val_loss: 0.6064 - val_accuracy: 0.9783\n",
      "Epoch 845/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9779 - val_loss: 0.6922 - val_accuracy: 0.9519\n",
      "Epoch 846/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9729 - val_loss: 0.7664 - val_accuracy: 0.9547\n",
      "Epoch 847/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9763 - val_loss: 0.6456 - val_accuracy: 0.9841\n",
      "Epoch 848/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9763 - val_loss: 0.6053 - val_accuracy: 0.9853\n",
      "Epoch 849/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0864 - accuracy: 0.9764 - val_loss: 0.6545 - val_accuracy: 0.9725\n",
      "Epoch 850/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9737 - val_loss: 0.6312 - val_accuracy: 0.9841\n",
      "Epoch 851/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9733 - val_loss: 0.6619 - val_accuracy: 0.9760\n",
      "Epoch 852/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 0.6534 - val_accuracy: 0.9760\n",
      "Epoch 853/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9755 - val_loss: 0.6455 - val_accuracy: 0.9791\n",
      "Epoch 854/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9735 - val_loss: 0.6447 - val_accuracy: 0.9845\n",
      "Epoch 855/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0939 - accuracy: 0.9752 - val_loss: 0.6680 - val_accuracy: 0.9829\n",
      "Epoch 856/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9740 - val_loss: 0.5880 - val_accuracy: 0.9721\n",
      "Epoch 857/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9740 - val_loss: 0.8620 - val_accuracy: 0.9698\n",
      "Epoch 858/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9719 - val_loss: 0.7450 - val_accuracy: 0.9492\n",
      "Epoch 859/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9737 - val_loss: 0.6643 - val_accuracy: 0.9756\n",
      "Epoch 860/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9730 - val_loss: 0.7134 - val_accuracy: 0.9690\n",
      "Epoch 861/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9752 - val_loss: 0.6641 - val_accuracy: 0.9779\n",
      "Epoch 862/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0934 - accuracy: 0.9754 - val_loss: 0.6978 - val_accuracy: 0.9721\n",
      "Epoch 863/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9752 - val_loss: 0.7602 - val_accuracy: 0.9709\n",
      "Epoch 864/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9742 - val_loss: 0.7778 - val_accuracy: 0.9698\n",
      "Epoch 865/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9742 - val_loss: 0.7976 - val_accuracy: 0.9771\n",
      "Epoch 866/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9733 - val_loss: 0.7807 - val_accuracy: 0.9810\n",
      "Epoch 867/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9736 - val_loss: 0.8024 - val_accuracy: 0.9791\n",
      "Epoch 868/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9770 - val_loss: 0.8017 - val_accuracy: 0.9721\n",
      "Epoch 869/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9739 - val_loss: 0.9208 - val_accuracy: 0.9399\n",
      "Epoch 870/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.9748 - val_loss: 0.8548 - val_accuracy: 0.9605\n",
      "Epoch 871/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9743 - val_loss: 0.8612 - val_accuracy: 0.9709\n",
      "Epoch 872/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9760 - val_loss: 0.7636 - val_accuracy: 0.9748\n",
      "Epoch 873/1000\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.0905 - accuracy: 0.9762 - val_loss: 0.7808 - val_accuracy: 0.9682\n",
      "Epoch 874/1000\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0907 - accuracy: 0.9759 - val_loss: 0.7749 - val_accuracy: 0.9806\n",
      "Epoch 875/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9730 - val_loss: 0.7128 - val_accuracy: 0.9802\n",
      "Epoch 876/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9749 - val_loss: 0.7670 - val_accuracy: 0.9663\n",
      "Epoch 877/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9730 - val_loss: 0.7630 - val_accuracy: 0.9740\n",
      "Epoch 878/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0918 - accuracy: 0.9761 - val_loss: 0.7534 - val_accuracy: 0.9845\n",
      "Epoch 879/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9707 - val_loss: 0.7378 - val_accuracy: 0.9822\n",
      "Epoch 880/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9739 - val_loss: 0.7932 - val_accuracy: 0.9721\n",
      "Epoch 881/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9735 - val_loss: 0.8072 - val_accuracy: 0.9764\n",
      "Epoch 882/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9747 - val_loss: 0.8282 - val_accuracy: 0.9783\n",
      "Epoch 883/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9768 - val_loss: 0.8453 - val_accuracy: 0.9616\n",
      "Epoch 884/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9747 - val_loss: 0.8975 - val_accuracy: 0.9663\n",
      "Epoch 885/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0967 - accuracy: 0.9737 - val_loss: 0.9039 - val_accuracy: 0.9655\n",
      "Epoch 886/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9746 - val_loss: 0.8608 - val_accuracy: 0.9783\n",
      "Epoch 887/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9758 - val_loss: 0.7673 - val_accuracy: 0.9826\n",
      "Epoch 888/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0854 - accuracy: 0.9772 - val_loss: 0.7771 - val_accuracy: 0.9740\n",
      "Epoch 889/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9756 - val_loss: 0.7506 - val_accuracy: 0.9818\n",
      "Epoch 890/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9724 - val_loss: 0.6763 - val_accuracy: 0.9760\n",
      "Epoch 891/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9758 - val_loss: 0.6933 - val_accuracy: 0.9791\n",
      "Epoch 892/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9742 - val_loss: 0.7127 - val_accuracy: 0.9760\n",
      "Epoch 893/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9751 - val_loss: 0.7203 - val_accuracy: 0.9853\n",
      "Epoch 894/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0934 - accuracy: 0.9757 - val_loss: 0.7854 - val_accuracy: 0.9589\n",
      "Epoch 895/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9745 - val_loss: 0.6943 - val_accuracy: 0.9632\n",
      "Epoch 896/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9758 - val_loss: 0.7268 - val_accuracy: 0.9787\n",
      "Epoch 897/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9739 - val_loss: 0.7814 - val_accuracy: 0.9702\n",
      "Epoch 898/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9747 - val_loss: 0.7931 - val_accuracy: 0.9733\n",
      "Epoch 899/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9756 - val_loss: 0.8323 - val_accuracy: 0.9698\n",
      "Epoch 900/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.9719 - val_loss: 0.8435 - val_accuracy: 0.9694\n",
      "Epoch 901/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9764 - val_loss: 0.8102 - val_accuracy: 0.9783\n",
      "Epoch 902/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9764 - val_loss: 0.8772 - val_accuracy: 0.9702\n",
      "Epoch 903/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0981 - accuracy: 0.9736 - val_loss: 0.9015 - val_accuracy: 0.9709\n",
      "Epoch 904/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9739 - val_loss: 0.8891 - val_accuracy: 0.9550\n",
      "Epoch 905/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9751 - val_loss: 0.9463 - val_accuracy: 0.9585\n",
      "Epoch 906/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9742 - val_loss: 0.9573 - val_accuracy: 0.9659\n",
      "Epoch 907/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9746 - val_loss: 1.0471 - val_accuracy: 0.9426\n",
      "Epoch 908/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9748 - val_loss: 0.9507 - val_accuracy: 0.9756\n",
      "Epoch 909/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9754 - val_loss: 0.9331 - val_accuracy: 0.9767\n",
      "Epoch 910/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9717 - val_loss: 0.9925 - val_accuracy: 0.9674\n",
      "Epoch 911/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9739 - val_loss: 1.0121 - val_accuracy: 0.9636\n",
      "Epoch 912/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.9771 - val_loss: 1.0149 - val_accuracy: 0.9709\n",
      "Epoch 913/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0934 - accuracy: 0.9748 - val_loss: 1.0066 - val_accuracy: 0.9709\n",
      "Epoch 914/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9780 - val_loss: 0.0814 - val_accuracy: 0.9744\n",
      "Epoch 915/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0967 - accuracy: 0.9736 - val_loss: 0.0872 - val_accuracy: 0.9779\n",
      "Epoch 916/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9753 - val_loss: 0.1127 - val_accuracy: 0.9682\n",
      "Epoch 917/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9758 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 918/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9748 - val_loss: 0.1312 - val_accuracy: 0.9605\n",
      "Epoch 919/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9752 - val_loss: 0.0916 - val_accuracy: 0.9705\n",
      "Epoch 920/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9762 - val_loss: 0.0677 - val_accuracy: 0.9845\n",
      "Epoch 921/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9761 - val_loss: 0.0754 - val_accuracy: 0.9818\n",
      "Epoch 922/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9730 - val_loss: 0.1588 - val_accuracy: 0.9581\n",
      "Epoch 923/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9748 - val_loss: 0.1195 - val_accuracy: 0.9636\n",
      "Epoch 924/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9755 - val_loss: 0.0649 - val_accuracy: 0.9845\n",
      "Epoch 925/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9756 - val_loss: 0.1119 - val_accuracy: 0.9690\n",
      "Epoch 926/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9740 - val_loss: 0.1059 - val_accuracy: 0.9702\n",
      "Epoch 927/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0917 - accuracy: 0.9761 - val_loss: 0.0646 - val_accuracy: 0.9833\n",
      "Epoch 928/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9736 - val_loss: 0.1056 - val_accuracy: 0.9682\n",
      "Epoch 929/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.0721 - val_accuracy: 0.9849\n",
      "Epoch 930/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9759 - val_loss: 0.1182 - val_accuracy: 0.9667\n",
      "Epoch 931/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9743 - val_loss: 0.0633 - val_accuracy: 0.9845\n",
      "Epoch 932/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9743 - val_loss: 0.0882 - val_accuracy: 0.9760\n",
      "Epoch 933/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9747 - val_loss: 0.0768 - val_accuracy: 0.9795\n",
      "Epoch 934/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9760 - val_loss: 0.1061 - val_accuracy: 0.9729\n",
      "Epoch 935/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9754 - val_loss: 0.1406 - val_accuracy: 0.9686\n",
      "Epoch 936/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9739 - val_loss: 0.1048 - val_accuracy: 0.9787\n",
      "Epoch 937/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9767 - val_loss: 0.1264 - val_accuracy: 0.9810\n",
      "Epoch 938/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9752 - val_loss: 0.2101 - val_accuracy: 0.9609\n",
      "Epoch 939/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9745 - val_loss: 0.1767 - val_accuracy: 0.9702\n",
      "Epoch 940/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9751 - val_loss: 0.1788 - val_accuracy: 0.9721\n",
      "Epoch 941/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9742 - val_loss: 0.1618 - val_accuracy: 0.9853\n",
      "Epoch 942/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9759 - val_loss: 0.2032 - val_accuracy: 0.9756\n",
      "Epoch 943/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9754 - val_loss: 0.2058 - val_accuracy: 0.9752\n",
      "Epoch 944/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9742 - val_loss: 0.1454 - val_accuracy: 0.9853\n",
      "Epoch 945/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.1098 - val_accuracy: 0.9775\n",
      "Epoch 946/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9764 - val_loss: 0.1190 - val_accuracy: 0.9818\n",
      "Epoch 947/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9752 - val_loss: 0.1967 - val_accuracy: 0.9659\n",
      "Epoch 948/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9766 - val_loss: 0.1153 - val_accuracy: 0.9779\n",
      "Epoch 949/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9753 - val_loss: 0.1499 - val_accuracy: 0.9767\n",
      "Epoch 950/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9753 - val_loss: 0.1901 - val_accuracy: 0.9756\n",
      "Epoch 951/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9748 - val_loss: 0.1388 - val_accuracy: 0.9845\n",
      "Epoch 952/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9758 - val_loss: 0.2098 - val_accuracy: 0.9636\n",
      "Epoch 953/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9773 - val_loss: 0.1732 - val_accuracy: 0.9636\n",
      "Epoch 954/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.1194 - val_accuracy: 0.9690\n",
      "Epoch 955/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9748 - val_loss: 0.2493 - val_accuracy: 0.9508\n",
      "Epoch 956/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9746 - val_loss: 0.1023 - val_accuracy: 0.9845\n",
      "Epoch 957/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 0.1305 - val_accuracy: 0.9829\n",
      "Epoch 958/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9745 - val_loss: 0.1981 - val_accuracy: 0.9709\n",
      "Epoch 959/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9742 - val_loss: 0.1632 - val_accuracy: 0.9798\n",
      "Epoch 960/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9761 - val_loss: 0.2151 - val_accuracy: 0.9802\n",
      "Epoch 961/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1410 - accuracy: 0.9744 - val_loss: 0.1260 - val_accuracy: 0.9810\n",
      "Epoch 962/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.1139 - val_accuracy: 0.9841\n",
      "Epoch 963/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0799 - accuracy: 0.9790 - val_loss: 0.2011 - val_accuracy: 0.9647\n",
      "Epoch 964/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9776 - val_loss: 0.2015 - val_accuracy: 0.9659\n",
      "Epoch 965/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9754 - val_loss: 0.2449 - val_accuracy: 0.9632\n",
      "Epoch 966/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9749 - val_loss: 0.2072 - val_accuracy: 0.9725\n",
      "Epoch 967/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9752 - val_loss: 0.1103 - val_accuracy: 0.9771\n",
      "Epoch 968/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9745 - val_loss: 0.2297 - val_accuracy: 0.9554\n",
      "Epoch 969/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0906 - accuracy: 0.9752 - val_loss: 0.1534 - val_accuracy: 0.9791\n",
      "Epoch 970/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9741 - val_loss: 0.1657 - val_accuracy: 0.9814\n",
      "Epoch 971/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.2368 - val_accuracy: 0.9655\n",
      "Epoch 972/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9748 - val_loss: 0.2281 - val_accuracy: 0.9709\n",
      "Epoch 973/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.9756 - val_loss: 0.2482 - val_accuracy: 0.9760\n",
      "Epoch 974/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9749 - val_loss: 0.3252 - val_accuracy: 0.9620\n",
      "Epoch 975/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 0.3533 - val_accuracy: 0.9756\n",
      "Epoch 976/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0881 - accuracy: 0.9758 - val_loss: 0.0822 - val_accuracy: 0.9775\n",
      "Epoch 977/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9748 - val_loss: 0.0658 - val_accuracy: 0.9806\n",
      "Epoch 978/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9755 - val_loss: 0.0814 - val_accuracy: 0.9775\n",
      "Epoch 979/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9759 - val_loss: 0.0715 - val_accuracy: 0.9795\n",
      "Epoch 980/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9748 - val_loss: 0.0745 - val_accuracy: 0.9802\n",
      "Epoch 981/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9747 - val_loss: 0.0867 - val_accuracy: 0.9748\n",
      "Epoch 982/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9751 - val_loss: 0.0660 - val_accuracy: 0.9837\n",
      "Epoch 983/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0906 - accuracy: 0.9758 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
      "Epoch 984/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9737 - val_loss: 0.1074 - val_accuracy: 0.9733\n",
      "Epoch 985/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9773 - val_loss: 0.0984 - val_accuracy: 0.9744\n",
      "Epoch 986/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9760 - val_loss: 0.0815 - val_accuracy: 0.9771\n",
      "Epoch 987/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9745 - val_loss: 0.0993 - val_accuracy: 0.9818\n",
      "Epoch 988/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9748 - val_loss: 0.0790 - val_accuracy: 0.9779\n",
      "Epoch 989/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9732 - val_loss: 0.0629 - val_accuracy: 0.9860\n",
      "Epoch 990/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9755 - val_loss: 0.1726 - val_accuracy: 0.9663\n",
      "Epoch 991/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9740 - val_loss: 0.1614 - val_accuracy: 0.9674\n",
      "Epoch 992/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9730 - val_loss: 0.1185 - val_accuracy: 0.9791\n",
      "Epoch 993/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9766 - val_loss: 0.0657 - val_accuracy: 0.9857\n",
      "Epoch 994/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9748 - val_loss: 0.0743 - val_accuracy: 0.9771\n",
      "Epoch 995/1000\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.0992 - accuracy: 0.9739 - val_loss: 0.0907 - val_accuracy: 0.9729\n",
      "Epoch 996/1000\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0893 - accuracy: 0.9768 - val_loss: 0.0817 - val_accuracy: 0.9767\n",
      "Epoch 997/1000\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 0.0916 - accuracy: 0.9751 - val_loss: 0.0782 - val_accuracy: 0.9775\n",
      "Epoch 998/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0958 - accuracy: 0.9742 - val_loss: 0.0735 - val_accuracy: 0.9787\n",
      "Epoch 999/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9751 - val_loss: 0.1297 - val_accuracy: 0.9632\n",
      "Epoch 1000/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9748 - val_loss: 0.0901 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 36s, sys: 3min 27s, total: 28min 4s\n",
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/linear_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9be2663-ca79-46a7-bbbb-460f09cce5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091fb9e5-5ea4-48ad-8868-5b2420ad7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037eccb-a72f-4f5b-ae4c-05c283ae69dd",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1c79d0-88fb-41e0-bdb7-0ec576ce2dbb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        21\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      0.96      0.98        23\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        23\n",
      "           5       0.89      0.80      0.84        20\n",
      "           6       1.00      0.96      0.98        23\n",
      "           7       1.00      1.00      1.00        25\n",
      "           8       1.00      1.00      1.00        25\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      0.74      0.85        23\n",
      "          11       1.00      0.94      0.97        17\n",
      "          12       1.00      0.94      0.97        16\n",
      "          13       1.00      1.00      1.00        31\n",
      "          14       1.00      1.00      1.00        30\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        25\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       0.95      0.90      0.92        20\n",
      "          19       1.00      1.00      1.00        16\n",
      "          20       0.95      1.00      0.97        19\n",
      "          21       1.00      1.00      1.00        21\n",
      "          22       1.00      0.94      0.97        18\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      0.95      0.98        21\n",
      "          25       1.00      0.95      0.98        21\n",
      "          26       0.93      1.00      0.96        13\n",
      "          27       1.00      1.00      1.00        25\n",
      "          28       1.00      1.00      1.00        27\n",
      "          29       1.00      1.00      1.00        24\n",
      "          30       1.00      1.00      1.00        21\n",
      "          31       1.00      0.95      0.98        21\n",
      "          32       1.00      1.00      1.00        18\n",
      "          33       1.00      1.00      1.00        22\n",
      "          34       1.00      0.89      0.94        18\n",
      "          35       1.00      1.00      1.00        10\n",
      "          36       1.00      1.00      1.00        27\n",
      "          37       0.93      0.67      0.78        21\n",
      "          38       1.00      1.00      1.00        20\n",
      "          39       1.00      1.00      1.00        15\n",
      "          40       1.00      0.95      0.97        19\n",
      "          41       0.92      1.00      0.96        12\n",
      "          42       1.00      1.00      1.00        30\n",
      "          43       0.55      0.92      0.69        25\n",
      "          44       1.00      0.95      0.98        22\n",
      "          45       1.00      1.00      1.00        23\n",
      "          46       1.00      1.00      1.00        14\n",
      "          47       1.00      1.00      1.00        17\n",
      "          48       1.00      1.00      1.00        20\n",
      "          49       1.00      0.95      0.98        21\n",
      "          50       1.00      1.00      1.00        25\n",
      "          51       1.00      1.00      1.00        22\n",
      "          52       0.84      0.89      0.86        18\n",
      "          53       0.96      1.00      0.98        25\n",
      "          54       1.00      1.00      1.00        22\n",
      "          55       1.00      1.00      1.00        13\n",
      "          56       1.00      1.00      1.00        21\n",
      "          57       1.00      1.00      1.00        28\n",
      "          58       1.00      1.00      1.00        14\n",
      "          59       1.00      1.00      1.00        26\n",
      "          60       1.00      1.00      1.00        17\n",
      "          61       1.00      1.00      1.00        16\n",
      "          62       1.00      1.00      1.00        17\n",
      "          63       1.00      1.00      1.00        25\n",
      "          64       1.00      1.00      1.00        13\n",
      "          65       1.00      1.00      1.00        17\n",
      "          66       1.00      1.00      1.00        20\n",
      "          67       1.00      1.00      1.00        12\n",
      "          68       1.00      1.00      1.00        21\n",
      "          69       1.00      1.00      1.00        18\n",
      "          70       1.00      1.00      1.00        14\n",
      "          71       1.00      1.00      1.00        19\n",
      "          72       1.00      1.00      1.00        11\n",
      "          73       1.00      1.00      1.00        20\n",
      "          74       1.00      1.00      1.00        23\n",
      "          75       1.00      0.96      0.98        27\n",
      "          76       1.00      1.00      1.00        23\n",
      "          77       0.72      1.00      0.84        21\n",
      "          78       1.00      0.85      0.92        20\n",
      "          79       1.00      1.00      1.00        24\n",
      "          80       1.00      0.95      0.97        19\n",
      "          81       1.00      1.00      1.00        14\n",
      "          82       1.00      1.00      1.00        20\n",
      "          83       0.95      0.90      0.92        20\n",
      "          84       1.00      0.96      0.98        23\n",
      "          85       1.00      1.00      1.00        23\n",
      "          86       1.00      1.00      1.00        19\n",
      "          87       0.95      1.00      0.98        20\n",
      "          88       1.00      1.00      1.00        19\n",
      "          89       1.00      1.00      1.00        20\n",
      "          90       1.00      0.95      0.98        22\n",
      "          91       1.00      1.00      1.00        19\n",
      "          92       1.00      1.00      1.00        12\n",
      "          93       1.00      1.00      1.00        19\n",
      "          94       0.89      1.00      0.94        25\n",
      "          95       1.00      1.00      1.00        17\n",
      "          96       1.00      0.96      0.98        28\n",
      "          97       1.00      0.95      0.97        19\n",
      "          98       1.00      1.00      1.00        21\n",
      "          99       1.00      0.92      0.96        24\n",
      "         100       1.00      1.00      1.00        15\n",
      "         101       1.00      0.94      0.97        17\n",
      "         102       0.96      1.00      0.98        25\n",
      "         103       1.00      1.00      1.00        21\n",
      "         104       0.94      0.94      0.94        16\n",
      "         105       1.00      0.93      0.97        15\n",
      "         106       1.00      1.00      1.00        15\n",
      "         107       1.00      1.00      1.00        18\n",
      "         108       1.00      0.82      0.90        22\n",
      "         109       1.00      1.00      1.00        23\n",
      "         110       1.00      1.00      1.00        28\n",
      "         111       0.96      0.96      0.96        24\n",
      "         112       0.94      0.88      0.91        17\n",
      "         113       1.00      0.89      0.94        19\n",
      "         114       1.00      1.00      1.00        14\n",
      "         115       1.00      0.95      0.97        19\n",
      "         116       1.00      1.00      1.00        17\n",
      "         117       1.00      1.00      1.00        11\n",
      "         118       0.52      1.00      0.68        17\n",
      "         119       1.00      1.00      1.00        25\n",
      "         120       1.00      1.00      1.00        22\n",
      "         121       1.00      0.93      0.96        28\n",
      "         122       1.00      1.00      1.00        14\n",
      "         123       1.00      1.00      1.00        18\n",
      "         124       1.00      1.00      1.00        24\n",
      "         125       1.00      1.00      1.00        16\n",
      "         126       1.00      1.00      1.00        17\n",
      "         127       1.00      0.95      0.98        22\n",
      "         128       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           0.97      2580\n",
      "   macro avg       0.98      0.98      0.98      2580\n",
      "weighted avg       0.98      0.97      0.98      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51af58-9ede-46e3-99ed-0164c6834c82",
   "metadata": {},
   "source": [
    "<h1>Exponential Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda86b57-083d-4b8a-879c-09a51d46aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.read_csv('input/results_complete_exponential.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eff74c0-769f-4685-9a72-f69724210c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_exp.drop(['elem_damaged', 'damage'], axis=1), df_exp['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815cc01f-7962-4f05-b49d-1de62fd5eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c553a7-f94f-43df-9032-385155de8e94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 80)                10160     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 129)               10449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,569\n",
      "Trainable params: 33,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.6154 - accuracy: 0.0724 - val_loss: 4.2442 - val_accuracy: 0.1217\n",
      "Epoch 2/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.8416 - accuracy: 0.1950 - val_loss: 3.5547 - val_accuracy: 0.2438\n",
      "Epoch 3/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.1908 - accuracy: 0.3088 - val_loss: 3.0069 - val_accuracy: 0.3360\n",
      "Epoch 4/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.7301 - accuracy: 0.3857 - val_loss: 2.6376 - val_accuracy: 0.3942\n",
      "Epoch 5/1000\n",
      "726/726 [==============================] - 1s 988us/step - loss: 2.4272 - accuracy: 0.4431 - val_loss: 2.3854 - val_accuracy: 0.4585\n",
      "Epoch 6/1000\n",
      "726/726 [==============================] - 1s 879us/step - loss: 2.2138 - accuracy: 0.4936 - val_loss: 2.2015 - val_accuracy: 0.4880\n",
      "Epoch 7/1000\n",
      "726/726 [==============================] - 1s 888us/step - loss: 2.0516 - accuracy: 0.5280 - val_loss: 2.0619 - val_accuracy: 0.5128\n",
      "Epoch 8/1000\n",
      "726/726 [==============================] - 1s 869us/step - loss: 1.9229 - accuracy: 0.5593 - val_loss: 1.9427 - val_accuracy: 0.5558\n",
      "Epoch 9/1000\n",
      "726/726 [==============================] - 1s 867us/step - loss: 1.8136 - accuracy: 0.5848 - val_loss: 1.8382 - val_accuracy: 0.5992\n",
      "Epoch 10/1000\n",
      "726/726 [==============================] - 1s 905us/step - loss: 1.7195 - accuracy: 0.6072 - val_loss: 1.7692 - val_accuracy: 0.5969\n",
      "Epoch 11/1000\n",
      "726/726 [==============================] - 1s 854us/step - loss: 1.6446 - accuracy: 0.6228 - val_loss: 1.6874 - val_accuracy: 0.6151\n",
      "Epoch 12/1000\n",
      "726/726 [==============================] - 1s 873us/step - loss: 1.5780 - accuracy: 0.6421 - val_loss: 1.6246 - val_accuracy: 0.6326\n",
      "Epoch 13/1000\n",
      "726/726 [==============================] - 1s 848us/step - loss: 1.5238 - accuracy: 0.6535 - val_loss: 1.5777 - val_accuracy: 0.6504\n",
      "Epoch 14/1000\n",
      "726/726 [==============================] - 1s 857us/step - loss: 1.4733 - accuracy: 0.6641 - val_loss: 1.5264 - val_accuracy: 0.6632\n",
      "Epoch 15/1000\n",
      "726/726 [==============================] - 1s 870us/step - loss: 1.4284 - accuracy: 0.6798 - val_loss: 1.4858 - val_accuracy: 0.6527\n",
      "Epoch 16/1000\n",
      "726/726 [==============================] - 1s 837us/step - loss: 1.3854 - accuracy: 0.6880 - val_loss: 1.4533 - val_accuracy: 0.6748\n",
      "Epoch 17/1000\n",
      "726/726 [==============================] - 1s 841us/step - loss: 1.3489 - accuracy: 0.6971 - val_loss: 1.4344 - val_accuracy: 0.6597\n",
      "Epoch 18/1000\n",
      "726/726 [==============================] - 1s 828us/step - loss: 1.3144 - accuracy: 0.7060 - val_loss: 1.3780 - val_accuracy: 0.6826\n",
      "Epoch 19/1000\n",
      "726/726 [==============================] - 1s 834us/step - loss: 1.2817 - accuracy: 0.7089 - val_loss: 1.3413 - val_accuracy: 0.6953\n",
      "Epoch 20/1000\n",
      "726/726 [==============================] - 1s 833us/step - loss: 1.2507 - accuracy: 0.7175 - val_loss: 1.3202 - val_accuracy: 0.7074\n",
      "Epoch 21/1000\n",
      "726/726 [==============================] - 1s 833us/step - loss: 1.2196 - accuracy: 0.7254 - val_loss: 1.2830 - val_accuracy: 0.7182\n",
      "Epoch 22/1000\n",
      "726/726 [==============================] - 1s 819us/step - loss: 1.1929 - accuracy: 0.7288 - val_loss: 1.2661 - val_accuracy: 0.7124\n",
      "Epoch 23/1000\n",
      "726/726 [==============================] - 1s 839us/step - loss: 1.1641 - accuracy: 0.7365 - val_loss: 1.2388 - val_accuracy: 0.7074\n",
      "Epoch 24/1000\n",
      "726/726 [==============================] - 1s 875us/step - loss: 1.1391 - accuracy: 0.7405 - val_loss: 1.1961 - val_accuracy: 0.7407\n",
      "Epoch 25/1000\n",
      "726/726 [==============================] - 1s 874us/step - loss: 1.1144 - accuracy: 0.7465 - val_loss: 1.1892 - val_accuracy: 0.7368\n",
      "Epoch 26/1000\n",
      "726/726 [==============================] - 1s 852us/step - loss: 1.0912 - accuracy: 0.7554 - val_loss: 1.1656 - val_accuracy: 0.7291\n",
      "Epoch 27/1000\n",
      "726/726 [==============================] - 1s 840us/step - loss: 1.0693 - accuracy: 0.7579 - val_loss: 1.1492 - val_accuracy: 0.7500\n",
      "Epoch 28/1000\n",
      "726/726 [==============================] - 1s 840us/step - loss: 1.0486 - accuracy: 0.7625 - val_loss: 1.1256 - val_accuracy: 0.7310\n",
      "Epoch 29/1000\n",
      "726/726 [==============================] - 1s 833us/step - loss: 1.0331 - accuracy: 0.7637 - val_loss: 1.1072 - val_accuracy: 0.7442\n",
      "Epoch 30/1000\n",
      "726/726 [==============================] - 1s 851us/step - loss: 1.0092 - accuracy: 0.7709 - val_loss: 1.0891 - val_accuracy: 0.7399\n",
      "Epoch 31/1000\n",
      "726/726 [==============================] - 1s 847us/step - loss: 0.9924 - accuracy: 0.7743 - val_loss: 1.0622 - val_accuracy: 0.7504\n",
      "Epoch 32/1000\n",
      "726/726 [==============================] - 1s 848us/step - loss: 0.9733 - accuracy: 0.7790 - val_loss: 1.0407 - val_accuracy: 0.7694\n",
      "Epoch 33/1000\n",
      "726/726 [==============================] - 1s 843us/step - loss: 0.9572 - accuracy: 0.7833 - val_loss: 1.0391 - val_accuracy: 0.7678\n",
      "Epoch 34/1000\n",
      "726/726 [==============================] - 1s 850us/step - loss: 0.9389 - accuracy: 0.7856 - val_loss: 1.0249 - val_accuracy: 0.7620\n",
      "Epoch 35/1000\n",
      "726/726 [==============================] - 1s 861us/step - loss: 0.9222 - accuracy: 0.7906 - val_loss: 1.0024 - val_accuracy: 0.7709\n",
      "Epoch 36/1000\n",
      "726/726 [==============================] - 1s 854us/step - loss: 0.9052 - accuracy: 0.7946 - val_loss: 0.9702 - val_accuracy: 0.7853\n",
      "Epoch 37/1000\n",
      "726/726 [==============================] - 1s 872us/step - loss: 0.8885 - accuracy: 0.7940 - val_loss: 0.9582 - val_accuracy: 0.7791\n",
      "Epoch 38/1000\n",
      "726/726 [==============================] - 1s 855us/step - loss: 0.8731 - accuracy: 0.7994 - val_loss: 0.9408 - val_accuracy: 0.7915\n",
      "Epoch 39/1000\n",
      "726/726 [==============================] - 1s 847us/step - loss: 0.8608 - accuracy: 0.8007 - val_loss: 0.9405 - val_accuracy: 0.7915\n",
      "Epoch 40/1000\n",
      "726/726 [==============================] - 1s 852us/step - loss: 0.8450 - accuracy: 0.8071 - val_loss: 0.9250 - val_accuracy: 0.7837\n",
      "Epoch 41/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8329 - accuracy: 0.8111 - val_loss: 0.9149 - val_accuracy: 0.7953\n",
      "Epoch 42/1000\n",
      "726/726 [==============================] - 1s 859us/step - loss: 0.8212 - accuracy: 0.8094 - val_loss: 0.8900 - val_accuracy: 0.8039\n",
      "Epoch 43/1000\n",
      "726/726 [==============================] - 1s 871us/step - loss: 0.8088 - accuracy: 0.8139 - val_loss: 0.8855 - val_accuracy: 0.8054\n",
      "Epoch 44/1000\n",
      "726/726 [==============================] - 1s 855us/step - loss: 0.7945 - accuracy: 0.8168 - val_loss: 0.8645 - val_accuracy: 0.7922\n",
      "Epoch 45/1000\n",
      "726/726 [==============================] - 1s 862us/step - loss: 0.7834 - accuracy: 0.8202 - val_loss: 0.8597 - val_accuracy: 0.7926\n",
      "Epoch 46/1000\n",
      "726/726 [==============================] - 1s 877us/step - loss: 0.7706 - accuracy: 0.8233 - val_loss: 0.8451 - val_accuracy: 0.8205\n",
      "Epoch 47/1000\n",
      "726/726 [==============================] - 1s 884us/step - loss: 0.7607 - accuracy: 0.8268 - val_loss: 0.8487 - val_accuracy: 0.8050\n",
      "Epoch 48/1000\n",
      "726/726 [==============================] - 1s 837us/step - loss: 0.7489 - accuracy: 0.8275 - val_loss: 0.8334 - val_accuracy: 0.8050\n",
      "Epoch 49/1000\n",
      "726/726 [==============================] - 1s 848us/step - loss: 0.7388 - accuracy: 0.8316 - val_loss: 0.8564 - val_accuracy: 0.8023\n",
      "Epoch 50/1000\n",
      "726/726 [==============================] - 1s 846us/step - loss: 0.7314 - accuracy: 0.8325 - val_loss: 0.7986 - val_accuracy: 0.8101\n",
      "Epoch 51/1000\n",
      "726/726 [==============================] - 1s 848us/step - loss: 0.7300 - accuracy: 0.8348 - val_loss: 0.7952 - val_accuracy: 0.8105\n",
      "Epoch 52/1000\n",
      "726/726 [==============================] - 1s 847us/step - loss: 0.7112 - accuracy: 0.8360 - val_loss: 0.7845 - val_accuracy: 0.8248\n",
      "Epoch 53/1000\n",
      "726/726 [==============================] - 1s 843us/step - loss: 0.7042 - accuracy: 0.8381 - val_loss: 0.7806 - val_accuracy: 0.8283\n",
      "Epoch 54/1000\n",
      "726/726 [==============================] - 1s 845us/step - loss: 0.6965 - accuracy: 0.8400 - val_loss: 0.7723 - val_accuracy: 0.8236\n",
      "Epoch 55/1000\n",
      "726/726 [==============================] - 1s 846us/step - loss: 0.6873 - accuracy: 0.8425 - val_loss: 0.7563 - val_accuracy: 0.8209\n",
      "Epoch 56/1000\n",
      "726/726 [==============================] - 1s 883us/step - loss: 0.6802 - accuracy: 0.8436 - val_loss: 0.7630 - val_accuracy: 0.8171\n",
      "Epoch 57/1000\n",
      "726/726 [==============================] - 1s 884us/step - loss: 0.6753 - accuracy: 0.8451 - val_loss: 0.7649 - val_accuracy: 0.8415\n",
      "Epoch 58/1000\n",
      "726/726 [==============================] - 1s 840us/step - loss: 0.6782 - accuracy: 0.8462 - val_loss: 0.7419 - val_accuracy: 0.8326\n",
      "Epoch 59/1000\n",
      "726/726 [==============================] - 1s 845us/step - loss: 0.6587 - accuracy: 0.8518 - val_loss: 0.7338 - val_accuracy: 0.8264\n",
      "Epoch 60/1000\n",
      "726/726 [==============================] - 1s 849us/step - loss: 0.6518 - accuracy: 0.8520 - val_loss: 0.7319 - val_accuracy: 0.8248\n",
      "Epoch 61/1000\n",
      "726/726 [==============================] - 1s 847us/step - loss: 0.6480 - accuracy: 0.8518 - val_loss: 0.7193 - val_accuracy: 0.8372\n",
      "Epoch 62/1000\n",
      "726/726 [==============================] - 1s 864us/step - loss: 0.6409 - accuracy: 0.8533 - val_loss: 0.7152 - val_accuracy: 0.8403\n",
      "Epoch 63/1000\n",
      "726/726 [==============================] - 1s 853us/step - loss: 0.6348 - accuracy: 0.8534 - val_loss: 0.7166 - val_accuracy: 0.8461\n",
      "Epoch 64/1000\n",
      "726/726 [==============================] - 1s 885us/step - loss: 0.6297 - accuracy: 0.8547 - val_loss: 0.7213 - val_accuracy: 0.8326\n",
      "Epoch 65/1000\n",
      "726/726 [==============================] - 1s 852us/step - loss: 0.6213 - accuracy: 0.8588 - val_loss: 0.7012 - val_accuracy: 0.8372\n",
      "Epoch 66/1000\n",
      "726/726 [==============================] - 1s 859us/step - loss: 0.6160 - accuracy: 0.8586 - val_loss: 0.6775 - val_accuracy: 0.8500\n",
      "Epoch 67/1000\n",
      "726/726 [==============================] - 1s 848us/step - loss: 0.6086 - accuracy: 0.8598 - val_loss: 0.6796 - val_accuracy: 0.8461\n",
      "Epoch 68/1000\n",
      "726/726 [==============================] - 1s 857us/step - loss: 0.6020 - accuracy: 0.8610 - val_loss: 0.6725 - val_accuracy: 0.8535\n",
      "Epoch 69/1000\n",
      "726/726 [==============================] - 1s 851us/step - loss: 0.5943 - accuracy: 0.8624 - val_loss: 0.6656 - val_accuracy: 0.8523\n",
      "Epoch 70/1000\n",
      "726/726 [==============================] - 1s 888us/step - loss: 0.5878 - accuracy: 0.8646 - val_loss: 0.6579 - val_accuracy: 0.8612\n",
      "Epoch 71/1000\n",
      "726/726 [==============================] - 1s 841us/step - loss: 0.5818 - accuracy: 0.8639 - val_loss: 0.6542 - val_accuracy: 0.8543\n",
      "Epoch 72/1000\n",
      "726/726 [==============================] - 1s 861us/step - loss: 0.5741 - accuracy: 0.8673 - val_loss: 0.6646 - val_accuracy: 0.8426\n",
      "Epoch 73/1000\n",
      "726/726 [==============================] - 1s 883us/step - loss: 0.5704 - accuracy: 0.8662 - val_loss: 0.6395 - val_accuracy: 0.8640\n",
      "Epoch 74/1000\n",
      "726/726 [==============================] - 1s 847us/step - loss: 0.5636 - accuracy: 0.8698 - val_loss: 0.6324 - val_accuracy: 0.8589\n",
      "Epoch 75/1000\n",
      "726/726 [==============================] - 1s 860us/step - loss: 0.5572 - accuracy: 0.8722 - val_loss: 0.6290 - val_accuracy: 0.8624\n",
      "Epoch 76/1000\n",
      "726/726 [==============================] - 1s 842us/step - loss: 0.5497 - accuracy: 0.8725 - val_loss: 0.6158 - val_accuracy: 0.8609\n",
      "Epoch 77/1000\n",
      "726/726 [==============================] - 1s 886us/step - loss: 0.5465 - accuracy: 0.8760 - val_loss: 0.6194 - val_accuracy: 0.8647\n",
      "Epoch 78/1000\n",
      "726/726 [==============================] - 1s 863us/step - loss: 0.5405 - accuracy: 0.8773 - val_loss: 0.6118 - val_accuracy: 0.8717\n",
      "Epoch 79/1000\n",
      "726/726 [==============================] - 1s 844us/step - loss: 0.5350 - accuracy: 0.8789 - val_loss: 0.6072 - val_accuracy: 0.8682\n",
      "Epoch 80/1000\n",
      "726/726 [==============================] - 1s 857us/step - loss: 0.5313 - accuracy: 0.8785 - val_loss: 0.5973 - val_accuracy: 0.8674\n",
      "Epoch 81/1000\n",
      "726/726 [==============================] - 1s 863us/step - loss: 0.5263 - accuracy: 0.8815 - val_loss: 0.5963 - val_accuracy: 0.8632\n",
      "Epoch 82/1000\n",
      "726/726 [==============================] - 1s 841us/step - loss: 0.5230 - accuracy: 0.8789 - val_loss: 0.5864 - val_accuracy: 0.8721\n",
      "Epoch 83/1000\n",
      "726/726 [==============================] - 1s 858us/step - loss: 0.5160 - accuracy: 0.8798 - val_loss: 0.5937 - val_accuracy: 0.8574\n",
      "Epoch 84/1000\n",
      "726/726 [==============================] - 1s 876us/step - loss: 0.5184 - accuracy: 0.8816 - val_loss: 0.8974 - val_accuracy: 0.7496\n",
      "Epoch 85/1000\n",
      "726/726 [==============================] - 1s 849us/step - loss: 0.5114 - accuracy: 0.8828 - val_loss: 0.5746 - val_accuracy: 0.8748\n",
      "Epoch 86/1000\n",
      "726/726 [==============================] - 1s 864us/step - loss: 0.5010 - accuracy: 0.8875 - val_loss: 0.5726 - val_accuracy: 0.8748\n",
      "Epoch 87/1000\n",
      "726/726 [==============================] - 1s 853us/step - loss: 0.4977 - accuracy: 0.8879 - val_loss: 0.5788 - val_accuracy: 0.8659\n",
      "Epoch 88/1000\n",
      "726/726 [==============================] - 1s 855us/step - loss: 0.4970 - accuracy: 0.8866 - val_loss: 0.5601 - val_accuracy: 0.8841\n",
      "Epoch 89/1000\n",
      "726/726 [==============================] - 1s 885us/step - loss: 0.4916 - accuracy: 0.8871 - val_loss: 0.5628 - val_accuracy: 0.8674\n",
      "Epoch 90/1000\n",
      "726/726 [==============================] - 1s 911us/step - loss: 0.4870 - accuracy: 0.8897 - val_loss: 0.5595 - val_accuracy: 0.8698\n",
      "Epoch 91/1000\n",
      "726/726 [==============================] - 1s 865us/step - loss: 0.4856 - accuracy: 0.8887 - val_loss: 0.5582 - val_accuracy: 0.8671\n",
      "Epoch 92/1000\n",
      "726/726 [==============================] - 1s 853us/step - loss: 0.4822 - accuracy: 0.8871 - val_loss: 0.5606 - val_accuracy: 0.8721\n",
      "Epoch 93/1000\n",
      "726/726 [==============================] - 1s 866us/step - loss: 0.4797 - accuracy: 0.8891 - val_loss: 0.5455 - val_accuracy: 0.8798\n",
      "Epoch 94/1000\n",
      "726/726 [==============================] - 1s 864us/step - loss: 0.4739 - accuracy: 0.8900 - val_loss: 0.5307 - val_accuracy: 0.8841\n",
      "Epoch 95/1000\n",
      "726/726 [==============================] - 1s 860us/step - loss: 0.4852 - accuracy: 0.8899 - val_loss: 0.5315 - val_accuracy: 0.8926\n",
      "Epoch 96/1000\n",
      "726/726 [==============================] - 1s 903us/step - loss: 0.4623 - accuracy: 0.8955 - val_loss: 0.5499 - val_accuracy: 0.8783\n",
      "Epoch 97/1000\n",
      "726/726 [==============================] - 1s 850us/step - loss: 0.4593 - accuracy: 0.8946 - val_loss: 0.5371 - val_accuracy: 0.8667\n",
      "Epoch 98/1000\n",
      "726/726 [==============================] - 1s 907us/step - loss: 0.4572 - accuracy: 0.8955 - val_loss: 0.5232 - val_accuracy: 0.8810\n",
      "Epoch 99/1000\n",
      "726/726 [==============================] - 1s 879us/step - loss: 0.4554 - accuracy: 0.8948 - val_loss: 0.5217 - val_accuracy: 0.8880\n",
      "Epoch 100/1000\n",
      "726/726 [==============================] - 1s 858us/step - loss: 0.4526 - accuracy: 0.8962 - val_loss: 0.5137 - val_accuracy: 0.8992\n",
      "Epoch 101/1000\n",
      "726/726 [==============================] - 1s 859us/step - loss: 0.4510 - accuracy: 0.8968 - val_loss: 0.5263 - val_accuracy: 0.8814\n",
      "Epoch 102/1000\n",
      "726/726 [==============================] - 1s 902us/step - loss: 0.4463 - accuracy: 0.8964 - val_loss: 0.5084 - val_accuracy: 0.8891\n",
      "Epoch 103/1000\n",
      "726/726 [==============================] - 1s 859us/step - loss: 0.4426 - accuracy: 0.8982 - val_loss: 0.5182 - val_accuracy: 0.8791\n",
      "Epoch 104/1000\n",
      "726/726 [==============================] - 1s 869us/step - loss: 0.4396 - accuracy: 0.8986 - val_loss: 0.5007 - val_accuracy: 0.8895\n",
      "Epoch 105/1000\n",
      "726/726 [==============================] - 1s 890us/step - loss: 0.4356 - accuracy: 0.9003 - val_loss: 0.4958 - val_accuracy: 0.8934\n",
      "Epoch 106/1000\n",
      "726/726 [==============================] - 1s 851us/step - loss: 0.4333 - accuracy: 0.9001 - val_loss: 0.4896 - val_accuracy: 0.8911\n",
      "Epoch 107/1000\n",
      "726/726 [==============================] - 1s 887us/step - loss: 0.4296 - accuracy: 0.8998 - val_loss: 0.4914 - val_accuracy: 0.8853\n",
      "Epoch 108/1000\n",
      "726/726 [==============================] - 1s 876us/step - loss: 0.4261 - accuracy: 0.9019 - val_loss: 0.5031 - val_accuracy: 0.8938\n",
      "Epoch 109/1000\n",
      "726/726 [==============================] - 1s 938us/step - loss: 0.4215 - accuracy: 0.9033 - val_loss: 0.5011 - val_accuracy: 0.8833\n",
      "Epoch 110/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4192 - accuracy: 0.9039 - val_loss: 0.4897 - val_accuracy: 0.8981\n",
      "Epoch 111/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4232 - accuracy: 0.9022 - val_loss: 0.4814 - val_accuracy: 0.9019\n",
      "Epoch 112/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4103 - accuracy: 0.9063 - val_loss: 0.4856 - val_accuracy: 0.9004\n",
      "Epoch 113/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.9072 - val_loss: 0.4751 - val_accuracy: 0.8950\n",
      "Epoch 114/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.9088 - val_loss: 0.4959 - val_accuracy: 0.8868\n",
      "Epoch 115/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.9058 - val_loss: 0.4949 - val_accuracy: 0.8884\n",
      "Epoch 116/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.9063 - val_loss: 0.4870 - val_accuracy: 0.8833\n",
      "Epoch 117/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.9082 - val_loss: 0.4874 - val_accuracy: 0.8895\n",
      "Epoch 118/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.9076 - val_loss: 0.5076 - val_accuracy: 0.8756\n",
      "Epoch 119/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.9078 - val_loss: 0.4761 - val_accuracy: 0.9023\n",
      "Epoch 120/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.9096 - val_loss: 0.4793 - val_accuracy: 0.9000\n",
      "Epoch 121/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3897 - accuracy: 0.9103 - val_loss: 0.4717 - val_accuracy: 0.8950\n",
      "Epoch 122/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3891 - accuracy: 0.9076 - val_loss: 0.4847 - val_accuracy: 0.8833\n",
      "Epoch 123/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3814 - accuracy: 0.9125 - val_loss: 0.4676 - val_accuracy: 0.9035\n",
      "Epoch 124/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.9133 - val_loss: 0.4584 - val_accuracy: 0.9031\n",
      "Epoch 125/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.9115 - val_loss: 0.4705 - val_accuracy: 0.9016\n",
      "Epoch 126/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3744 - accuracy: 0.9147 - val_loss: 0.4554 - val_accuracy: 0.9132\n",
      "Epoch 127/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3732 - accuracy: 0.9136 - val_loss: 0.5073 - val_accuracy: 0.9081\n",
      "Epoch 128/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3848 - accuracy: 0.9136 - val_loss: 0.4846 - val_accuracy: 0.8764\n",
      "Epoch 129/1000\n",
      "726/726 [==============================] - 1s 994us/step - loss: 0.3661 - accuracy: 0.9183 - val_loss: 0.4604 - val_accuracy: 0.9058\n",
      "Epoch 130/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.9165 - val_loss: 0.4233 - val_accuracy: 0.9155\n",
      "Epoch 131/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.9182 - val_loss: 0.4268 - val_accuracy: 0.9089\n",
      "Epoch 132/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3607 - accuracy: 0.9171 - val_loss: 0.4213 - val_accuracy: 0.9112\n",
      "Epoch 133/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.9174 - val_loss: 0.4134 - val_accuracy: 0.9205\n",
      "Epoch 134/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.9166 - val_loss: 0.4253 - val_accuracy: 0.9054\n",
      "Epoch 135/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3576 - accuracy: 0.9204 - val_loss: 0.4059 - val_accuracy: 0.9132\n",
      "Epoch 136/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3541 - accuracy: 0.9183 - val_loss: 0.4160 - val_accuracy: 0.9132\n",
      "Epoch 137/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3639 - accuracy: 0.9166 - val_loss: 0.4006 - val_accuracy: 0.9190\n",
      "Epoch 138/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.9235 - val_loss: 0.4007 - val_accuracy: 0.9143\n",
      "Epoch 139/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3473 - accuracy: 0.9198 - val_loss: 0.3995 - val_accuracy: 0.9190\n",
      "Epoch 140/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3460 - accuracy: 0.9214 - val_loss: 0.4084 - val_accuracy: 0.8988\n",
      "Epoch 141/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.9198 - val_loss: 0.4027 - val_accuracy: 0.9023\n",
      "Epoch 142/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.9195 - val_loss: 0.4037 - val_accuracy: 0.9171\n",
      "Epoch 143/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.9217 - val_loss: 0.3968 - val_accuracy: 0.9147\n",
      "Epoch 144/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.9211 - val_loss: 0.3959 - val_accuracy: 0.9248\n",
      "Epoch 145/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3419 - accuracy: 0.9216 - val_loss: 0.4069 - val_accuracy: 0.9120\n",
      "Epoch 146/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3370 - accuracy: 0.9193 - val_loss: 0.4181 - val_accuracy: 0.9093\n",
      "Epoch 147/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3337 - accuracy: 0.9238 - val_loss: 0.4424 - val_accuracy: 0.8895\n",
      "Epoch 148/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9236 - val_loss: 0.3936 - val_accuracy: 0.9167\n",
      "Epoch 149/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3314 - accuracy: 0.9245 - val_loss: 0.4001 - val_accuracy: 0.9143\n",
      "Epoch 150/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3281 - accuracy: 0.9246 - val_loss: 0.4129 - val_accuracy: 0.9023\n",
      "Epoch 151/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.9251 - val_loss: 0.3936 - val_accuracy: 0.9163\n",
      "Epoch 152/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3244 - accuracy: 0.9256 - val_loss: 0.3949 - val_accuracy: 0.9093\n",
      "Epoch 153/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3249 - accuracy: 0.9220 - val_loss: 0.3900 - val_accuracy: 0.9236\n",
      "Epoch 154/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.9272 - val_loss: 0.3608 - val_accuracy: 0.9298\n",
      "Epoch 155/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3161 - accuracy: 0.9283 - val_loss: 0.3999 - val_accuracy: 0.9159\n",
      "Epoch 156/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3164 - accuracy: 0.9285 - val_loss: 0.3790 - val_accuracy: 0.9186\n",
      "Epoch 157/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.9280 - val_loss: 0.3893 - val_accuracy: 0.9225\n",
      "Epoch 158/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3147 - accuracy: 0.9282 - val_loss: 0.3718 - val_accuracy: 0.9337\n",
      "Epoch 159/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.9304 - val_loss: 0.3857 - val_accuracy: 0.9182\n",
      "Epoch 160/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3103 - accuracy: 0.9308 - val_loss: 0.3727 - val_accuracy: 0.9225\n",
      "Epoch 161/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3096 - accuracy: 0.9305 - val_loss: 0.3878 - val_accuracy: 0.9345\n",
      "Epoch 162/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3062 - accuracy: 0.9304 - val_loss: 0.3989 - val_accuracy: 0.9085\n",
      "Epoch 163/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3065 - accuracy: 0.9305 - val_loss: 0.3655 - val_accuracy: 0.9198\n",
      "Epoch 164/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3046 - accuracy: 0.9301 - val_loss: 0.3688 - val_accuracy: 0.9271\n",
      "Epoch 165/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3031 - accuracy: 0.9317 - val_loss: 0.3860 - val_accuracy: 0.9140\n",
      "Epoch 166/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2986 - accuracy: 0.9318 - val_loss: 0.3893 - val_accuracy: 0.9163\n",
      "Epoch 167/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.9306 - val_loss: 0.3796 - val_accuracy: 0.9264\n",
      "Epoch 168/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2966 - accuracy: 0.9332 - val_loss: 0.3759 - val_accuracy: 0.9221\n",
      "Epoch 169/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2931 - accuracy: 0.9305 - val_loss: 0.3734 - val_accuracy: 0.9271\n",
      "Epoch 170/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2936 - accuracy: 0.9317 - val_loss: 0.3683 - val_accuracy: 0.9302\n",
      "Epoch 171/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2908 - accuracy: 0.9332 - val_loss: 0.3974 - val_accuracy: 0.9271\n",
      "Epoch 172/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.9332 - val_loss: 0.3723 - val_accuracy: 0.9120\n",
      "Epoch 173/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2884 - accuracy: 0.9309 - val_loss: 0.3948 - val_accuracy: 0.9140\n",
      "Epoch 174/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2859 - accuracy: 0.9335 - val_loss: 0.3633 - val_accuracy: 0.9202\n",
      "Epoch 175/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2862 - accuracy: 0.9345 - val_loss: 0.3583 - val_accuracy: 0.9314\n",
      "Epoch 176/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2818 - accuracy: 0.9366 - val_loss: 0.3523 - val_accuracy: 0.9233\n",
      "Epoch 177/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2819 - accuracy: 0.9357 - val_loss: 0.3944 - val_accuracy: 0.9105\n",
      "Epoch 178/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2829 - accuracy: 0.9357 - val_loss: 0.3655 - val_accuracy: 0.9306\n",
      "Epoch 179/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2791 - accuracy: 0.9363 - val_loss: 0.3740 - val_accuracy: 0.9182\n",
      "Epoch 180/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.9361 - val_loss: 0.3616 - val_accuracy: 0.9310\n",
      "Epoch 181/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.9359 - val_loss: 0.3678 - val_accuracy: 0.9264\n",
      "Epoch 182/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2749 - accuracy: 0.9369 - val_loss: 0.3590 - val_accuracy: 0.9287\n",
      "Epoch 183/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2730 - accuracy: 0.9374 - val_loss: 0.3643 - val_accuracy: 0.9093\n",
      "Epoch 184/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2748 - accuracy: 0.9377 - val_loss: 0.3404 - val_accuracy: 0.9469\n",
      "Epoch 185/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2707 - accuracy: 0.9395 - val_loss: 0.3373 - val_accuracy: 0.9345\n",
      "Epoch 186/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2697 - accuracy: 0.9385 - val_loss: 0.3347 - val_accuracy: 0.9341\n",
      "Epoch 187/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2701 - accuracy: 0.9363 - val_loss: 0.3828 - val_accuracy: 0.9058\n",
      "Epoch 188/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2703 - accuracy: 0.9368 - val_loss: 0.3438 - val_accuracy: 0.9314\n",
      "Epoch 189/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.9382 - val_loss: 0.3740 - val_accuracy: 0.9213\n",
      "Epoch 190/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2666 - accuracy: 0.9374 - val_loss: 0.3503 - val_accuracy: 0.9349\n",
      "Epoch 191/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.9405 - val_loss: 0.3543 - val_accuracy: 0.9403\n",
      "Epoch 192/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2608 - accuracy: 0.9391 - val_loss: 0.3547 - val_accuracy: 0.9353\n",
      "Epoch 193/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.2611 - accuracy: 0.9387 - val_loss: 0.4010 - val_accuracy: 0.9062\n",
      "Epoch 194/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2584 - accuracy: 0.9418 - val_loss: 0.3708 - val_accuracy: 0.9271\n",
      "Epoch 195/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.9409 - val_loss: 0.3511 - val_accuracy: 0.9380\n",
      "Epoch 196/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.9400 - val_loss: 0.3472 - val_accuracy: 0.9360\n",
      "Epoch 197/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.2561 - accuracy: 0.9390 - val_loss: 0.3586 - val_accuracy: 0.9322\n",
      "Epoch 198/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2538 - accuracy: 0.9413 - val_loss: 0.3358 - val_accuracy: 0.9391\n",
      "Epoch 199/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.9421 - val_loss: 0.3476 - val_accuracy: 0.9337\n",
      "Epoch 200/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2552 - accuracy: 0.9403 - val_loss: 0.3844 - val_accuracy: 0.9163\n",
      "Epoch 201/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2470 - accuracy: 0.9435 - val_loss: 0.3276 - val_accuracy: 0.9426\n",
      "Epoch 202/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.9416 - val_loss: 0.3170 - val_accuracy: 0.9384\n",
      "Epoch 203/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.9477 - val_loss: 0.3038 - val_accuracy: 0.9473\n",
      "Epoch 204/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2397 - accuracy: 0.9473 - val_loss: 0.3022 - val_accuracy: 0.9473\n",
      "Epoch 205/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2416 - accuracy: 0.9457 - val_loss: 0.3105 - val_accuracy: 0.9450\n",
      "Epoch 206/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9443 - val_loss: 0.3213 - val_accuracy: 0.9395\n",
      "Epoch 207/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2414 - accuracy: 0.9447 - val_loss: 0.3056 - val_accuracy: 0.9415\n",
      "Epoch 208/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2414 - accuracy: 0.9457 - val_loss: 0.3218 - val_accuracy: 0.9322\n",
      "Epoch 209/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2394 - accuracy: 0.9456 - val_loss: 0.4442 - val_accuracy: 0.9372\n",
      "Epoch 210/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2581 - accuracy: 0.9438 - val_loss: 0.3279 - val_accuracy: 0.9333\n",
      "Epoch 211/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2352 - accuracy: 0.9475 - val_loss: 0.3232 - val_accuracy: 0.9473\n",
      "Epoch 212/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.9462 - val_loss: 0.3194 - val_accuracy: 0.9562\n",
      "Epoch 213/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2400 - accuracy: 0.9440 - val_loss: 0.3306 - val_accuracy: 0.9388\n",
      "Epoch 214/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2380 - accuracy: 0.9440 - val_loss: 0.3499 - val_accuracy: 0.9357\n",
      "Epoch 215/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.9444 - val_loss: 0.3344 - val_accuracy: 0.9434\n",
      "Epoch 216/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2384 - accuracy: 0.9431 - val_loss: 0.3318 - val_accuracy: 0.9391\n",
      "Epoch 217/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2324 - accuracy: 0.9475 - val_loss: 0.3260 - val_accuracy: 0.9488\n",
      "Epoch 218/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2338 - accuracy: 0.9448 - val_loss: 0.3297 - val_accuracy: 0.9461\n",
      "Epoch 219/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2352 - accuracy: 0.9464 - val_loss: 0.3302 - val_accuracy: 0.9415\n",
      "Epoch 220/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9453 - val_loss: 0.2726 - val_accuracy: 0.9341\n",
      "Epoch 221/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2322 - accuracy: 0.9457 - val_loss: 0.3001 - val_accuracy: 0.9419\n",
      "Epoch 222/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2324 - accuracy: 0.9444 - val_loss: 0.3048 - val_accuracy: 0.9434\n",
      "Epoch 223/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2311 - accuracy: 0.9445 - val_loss: 0.2998 - val_accuracy: 0.9519\n",
      "Epoch 224/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2294 - accuracy: 0.9462 - val_loss: 0.3371 - val_accuracy: 0.9450\n",
      "Epoch 225/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.9453 - val_loss: 0.3380 - val_accuracy: 0.9391\n",
      "Epoch 226/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2304 - accuracy: 0.9453 - val_loss: 0.3565 - val_accuracy: 0.9384\n",
      "Epoch 227/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.9473 - val_loss: 0.3354 - val_accuracy: 0.9419\n",
      "Epoch 228/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2242 - accuracy: 0.9484 - val_loss: 0.3498 - val_accuracy: 0.9322\n",
      "Epoch 229/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9459 - val_loss: 0.3233 - val_accuracy: 0.9481\n",
      "Epoch 230/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2255 - accuracy: 0.9464 - val_loss: 0.3241 - val_accuracy: 0.9453\n",
      "Epoch 231/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2238 - accuracy: 0.9475 - val_loss: 0.3422 - val_accuracy: 0.9310\n",
      "Epoch 232/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9481 - val_loss: 0.3111 - val_accuracy: 0.9500\n",
      "Epoch 233/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2215 - accuracy: 0.9477 - val_loss: 0.3165 - val_accuracy: 0.9554\n",
      "Epoch 234/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2183 - accuracy: 0.9486 - val_loss: 0.3307 - val_accuracy: 0.9453\n",
      "Epoch 235/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2187 - accuracy: 0.9472 - val_loss: 0.3198 - val_accuracy: 0.9477\n",
      "Epoch 236/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2150 - accuracy: 0.9500 - val_loss: 0.3455 - val_accuracy: 0.9291\n",
      "Epoch 237/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2168 - accuracy: 0.9485 - val_loss: 0.3359 - val_accuracy: 0.9326\n",
      "Epoch 238/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2144 - accuracy: 0.9496 - val_loss: 0.3223 - val_accuracy: 0.9442\n",
      "Epoch 239/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2129 - accuracy: 0.9497 - val_loss: 0.2991 - val_accuracy: 0.9442\n",
      "Epoch 240/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2163 - accuracy: 0.9499 - val_loss: 0.3207 - val_accuracy: 0.9395\n",
      "Epoch 241/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2110 - accuracy: 0.9502 - val_loss: 0.3273 - val_accuracy: 0.9341\n",
      "Epoch 242/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2087 - accuracy: 0.9512 - val_loss: 0.3253 - val_accuracy: 0.9380\n",
      "Epoch 243/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2106 - accuracy: 0.9513 - val_loss: 0.3171 - val_accuracy: 0.9457\n",
      "Epoch 244/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2088 - accuracy: 0.9510 - val_loss: 0.3152 - val_accuracy: 0.9306\n",
      "Epoch 245/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2108 - accuracy: 0.9495 - val_loss: 0.2596 - val_accuracy: 0.9488\n",
      "Epoch 246/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2086 - accuracy: 0.9501 - val_loss: 0.2859 - val_accuracy: 0.9574\n",
      "Epoch 247/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2087 - accuracy: 0.9501 - val_loss: 0.3194 - val_accuracy: 0.9403\n",
      "Epoch 248/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2039 - accuracy: 0.9526 - val_loss: 0.3394 - val_accuracy: 0.9217\n",
      "Epoch 249/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2031 - accuracy: 0.9518 - val_loss: 0.3020 - val_accuracy: 0.9496\n",
      "Epoch 250/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2090 - accuracy: 0.9491 - val_loss: 0.3607 - val_accuracy: 0.9295\n",
      "Epoch 251/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2062 - accuracy: 0.9511 - val_loss: 0.2757 - val_accuracy: 0.9403\n",
      "Epoch 252/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2064 - accuracy: 0.9499 - val_loss: 0.2574 - val_accuracy: 0.9407\n",
      "Epoch 253/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2007 - accuracy: 0.9531 - val_loss: 0.2659 - val_accuracy: 0.9384\n",
      "Epoch 254/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9488 - val_loss: 0.2482 - val_accuracy: 0.9438\n",
      "Epoch 255/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1999 - accuracy: 0.9529 - val_loss: 0.2552 - val_accuracy: 0.9488\n",
      "Epoch 256/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2020 - accuracy: 0.9534 - val_loss: 0.2390 - val_accuracy: 0.9585\n",
      "Epoch 257/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2013 - accuracy: 0.9521 - val_loss: 0.2404 - val_accuracy: 0.9473\n",
      "Epoch 258/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2002 - accuracy: 0.9544 - val_loss: 0.2455 - val_accuracy: 0.9566\n",
      "Epoch 259/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2013 - accuracy: 0.9511 - val_loss: 0.2621 - val_accuracy: 0.9461\n",
      "Epoch 260/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1939 - accuracy: 0.9547 - val_loss: 0.2522 - val_accuracy: 0.9547\n",
      "Epoch 261/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1992 - accuracy: 0.9519 - val_loss: 0.2615 - val_accuracy: 0.9488\n",
      "Epoch 262/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9549 - val_loss: 0.2639 - val_accuracy: 0.9430\n",
      "Epoch 263/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1925 - accuracy: 0.9535 - val_loss: 0.2578 - val_accuracy: 0.9516\n",
      "Epoch 264/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9529 - val_loss: 0.2547 - val_accuracy: 0.9457\n",
      "Epoch 265/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9550 - val_loss: 0.2467 - val_accuracy: 0.9624\n",
      "Epoch 266/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1940 - accuracy: 0.9536 - val_loss: 0.2552 - val_accuracy: 0.9473\n",
      "Epoch 267/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1945 - accuracy: 0.9525 - val_loss: 0.2577 - val_accuracy: 0.9492\n",
      "Epoch 268/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1905 - accuracy: 0.9546 - val_loss: 0.2684 - val_accuracy: 0.9419\n",
      "Epoch 269/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9541 - val_loss: 0.2704 - val_accuracy: 0.9481\n",
      "Epoch 270/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1892 - accuracy: 0.9542 - val_loss: 0.2532 - val_accuracy: 0.9562\n",
      "Epoch 271/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1875 - accuracy: 0.9556 - val_loss: 0.2530 - val_accuracy: 0.9523\n",
      "Epoch 272/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2294 - accuracy: 0.9501 - val_loss: 0.2635 - val_accuracy: 0.9550\n",
      "Epoch 273/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1817 - accuracy: 0.9609 - val_loss: 0.2308 - val_accuracy: 0.9527\n",
      "Epoch 274/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9588 - val_loss: 0.2561 - val_accuracy: 0.9407\n",
      "Epoch 275/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1822 - accuracy: 0.9590 - val_loss: 0.2156 - val_accuracy: 0.9643\n",
      "Epoch 276/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1816 - accuracy: 0.9577 - val_loss: 0.2539 - val_accuracy: 0.9419\n",
      "Epoch 277/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9564 - val_loss: 0.2849 - val_accuracy: 0.9360\n",
      "Epoch 278/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1825 - accuracy: 0.9569 - val_loss: 0.2335 - val_accuracy: 0.9523\n",
      "Epoch 279/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1839 - accuracy: 0.9559 - val_loss: 0.2306 - val_accuracy: 0.9581\n",
      "Epoch 280/1000\n",
      "726/726 [==============================] - 1s 997us/step - loss: 0.1901 - accuracy: 0.9529 - val_loss: 0.2446 - val_accuracy: 0.9504\n",
      "Epoch 281/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9535 - val_loss: 0.2342 - val_accuracy: 0.9581\n",
      "Epoch 282/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1837 - accuracy: 0.9563 - val_loss: 0.3101 - val_accuracy: 0.9295\n",
      "Epoch 283/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9558 - val_loss: 0.2472 - val_accuracy: 0.9605\n",
      "Epoch 284/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9554 - val_loss: 0.2461 - val_accuracy: 0.9500\n",
      "Epoch 285/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9553 - val_loss: 0.2378 - val_accuracy: 0.9566\n",
      "Epoch 286/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1788 - accuracy: 0.9567 - val_loss: 0.2352 - val_accuracy: 0.9550\n",
      "Epoch 287/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1826 - accuracy: 0.9564 - val_loss: 0.2485 - val_accuracy: 0.9531\n",
      "Epoch 288/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1816 - accuracy: 0.9568 - val_loss: 0.2726 - val_accuracy: 0.9407\n",
      "Epoch 289/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9560 - val_loss: 0.2648 - val_accuracy: 0.9492\n",
      "Epoch 290/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1813 - accuracy: 0.9564 - val_loss: 0.2482 - val_accuracy: 0.9500\n",
      "Epoch 291/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9563 - val_loss: 0.2657 - val_accuracy: 0.9349\n",
      "Epoch 292/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1786 - accuracy: 0.9567 - val_loss: 0.2324 - val_accuracy: 0.9547\n",
      "Epoch 293/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9581 - val_loss: 0.2826 - val_accuracy: 0.9322\n",
      "Epoch 294/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1798 - accuracy: 0.9557 - val_loss: 0.2283 - val_accuracy: 0.9519\n",
      "Epoch 295/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1802 - accuracy: 0.9553 - val_loss: 0.2238 - val_accuracy: 0.9547\n",
      "Epoch 296/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1742 - accuracy: 0.9578 - val_loss: 0.2472 - val_accuracy: 0.9500\n",
      "Epoch 297/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1774 - accuracy: 0.9575 - val_loss: 0.2302 - val_accuracy: 0.9612\n",
      "Epoch 298/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1753 - accuracy: 0.9573 - val_loss: 0.2251 - val_accuracy: 0.9512\n",
      "Epoch 299/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1758 - accuracy: 0.9565 - val_loss: 0.2668 - val_accuracy: 0.9419\n",
      "Epoch 300/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1733 - accuracy: 0.9581 - val_loss: 0.2335 - val_accuracy: 0.9512\n",
      "Epoch 301/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1734 - accuracy: 0.9575 - val_loss: 0.2216 - val_accuracy: 0.9651\n",
      "Epoch 302/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.1753 - accuracy: 0.9577 - val_loss: 0.2298 - val_accuracy: 0.9581\n",
      "Epoch 303/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1744 - accuracy: 0.9581 - val_loss: 0.2096 - val_accuracy: 0.9597\n",
      "Epoch 304/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1743 - accuracy: 0.9568 - val_loss: 0.2241 - val_accuracy: 0.9531\n",
      "Epoch 305/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9578 - val_loss: 0.2157 - val_accuracy: 0.9558\n",
      "Epoch 306/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9591 - val_loss: 0.2159 - val_accuracy: 0.9585\n",
      "Epoch 307/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1686 - accuracy: 0.9590 - val_loss: 0.2118 - val_accuracy: 0.9605\n",
      "Epoch 308/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1668 - accuracy: 0.9590 - val_loss: 0.2501 - val_accuracy: 0.9508\n",
      "Epoch 309/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1685 - accuracy: 0.9584 - val_loss: 0.2224 - val_accuracy: 0.9585\n",
      "Epoch 310/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1668 - accuracy: 0.9587 - val_loss: 0.2341 - val_accuracy: 0.9554\n",
      "Epoch 311/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1715 - accuracy: 0.9574 - val_loss: 0.2484 - val_accuracy: 0.9442\n",
      "Epoch 312/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1702 - accuracy: 0.9572 - val_loss: 0.2153 - val_accuracy: 0.9632\n",
      "Epoch 313/1000\n",
      "726/726 [==============================] - 1s 995us/step - loss: 0.1818 - accuracy: 0.9566 - val_loss: 0.2179 - val_accuracy: 0.9570\n",
      "Epoch 314/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1591 - accuracy: 0.9640 - val_loss: 0.2184 - val_accuracy: 0.9578\n",
      "Epoch 315/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1625 - accuracy: 0.9610 - val_loss: 0.2079 - val_accuracy: 0.9667\n",
      "Epoch 316/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1621 - accuracy: 0.9606 - val_loss: 0.2195 - val_accuracy: 0.9581\n",
      "Epoch 317/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.9599 - val_loss: 0.2223 - val_accuracy: 0.9477\n",
      "Epoch 318/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9610 - val_loss: 0.2187 - val_accuracy: 0.9612\n",
      "Epoch 319/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1669 - accuracy: 0.9586 - val_loss: 0.2308 - val_accuracy: 0.9558\n",
      "Epoch 320/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1667 - accuracy: 0.9585 - val_loss: 0.2208 - val_accuracy: 0.9620\n",
      "Epoch 321/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1634 - accuracy: 0.9606 - val_loss: 0.2180 - val_accuracy: 0.9647\n",
      "Epoch 322/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1644 - accuracy: 0.9598 - val_loss: 0.2236 - val_accuracy: 0.9643\n",
      "Epoch 323/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9596 - val_loss: 0.2207 - val_accuracy: 0.9663\n",
      "Epoch 324/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1624 - accuracy: 0.9592 - val_loss: 0.3202 - val_accuracy: 0.9252\n",
      "Epoch 325/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1673 - accuracy: 0.9591 - val_loss: 0.2252 - val_accuracy: 0.9643\n",
      "Epoch 326/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1580 - accuracy: 0.9622 - val_loss: 0.2305 - val_accuracy: 0.9655\n",
      "Epoch 327/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9648 - val_loss: 0.2182 - val_accuracy: 0.9702\n",
      "Epoch 328/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1564 - accuracy: 0.9627 - val_loss: 0.2378 - val_accuracy: 0.9609\n",
      "Epoch 329/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.9603 - val_loss: 0.2299 - val_accuracy: 0.9597\n",
      "Epoch 330/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1628 - accuracy: 0.9584 - val_loss: 0.2343 - val_accuracy: 0.9535\n",
      "Epoch 331/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1577 - accuracy: 0.9626 - val_loss: 0.2422 - val_accuracy: 0.9516\n",
      "Epoch 332/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1641 - accuracy: 0.9590 - val_loss: 0.2628 - val_accuracy: 0.9473\n",
      "Epoch 333/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1585 - accuracy: 0.9609 - val_loss: 0.2333 - val_accuracy: 0.9554\n",
      "Epoch 334/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1593 - accuracy: 0.9599 - val_loss: 0.2491 - val_accuracy: 0.9531\n",
      "Epoch 335/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1584 - accuracy: 0.9618 - val_loss: 0.2346 - val_accuracy: 0.9453\n",
      "Epoch 336/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1607 - accuracy: 0.9597 - val_loss: 0.2254 - val_accuracy: 0.9589\n",
      "Epoch 337/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1593 - accuracy: 0.9604 - val_loss: 0.2034 - val_accuracy: 0.9698\n",
      "Epoch 338/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1603 - accuracy: 0.9596 - val_loss: 0.2151 - val_accuracy: 0.9574\n",
      "Epoch 339/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1519 - accuracy: 0.9617 - val_loss: 0.2063 - val_accuracy: 0.9663\n",
      "Epoch 340/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1546 - accuracy: 0.9627 - val_loss: 0.2364 - val_accuracy: 0.9496\n",
      "Epoch 341/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1661 - accuracy: 0.9616 - val_loss: 0.1764 - val_accuracy: 0.9655\n",
      "Epoch 342/1000\n",
      "726/726 [==============================] - 1s 998us/step - loss: 0.1518 - accuracy: 0.9631 - val_loss: 0.1898 - val_accuracy: 0.9655\n",
      "Epoch 343/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1562 - accuracy: 0.9598 - val_loss: 0.2194 - val_accuracy: 0.9539\n",
      "Epoch 344/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.9614 - val_loss: 0.2062 - val_accuracy: 0.9496\n",
      "Epoch 345/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1509 - accuracy: 0.9620 - val_loss: 0.1907 - val_accuracy: 0.9647\n",
      "Epoch 346/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1578 - accuracy: 0.9595 - val_loss: 0.2340 - val_accuracy: 0.9395\n",
      "Epoch 347/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1592 - accuracy: 0.9606 - val_loss: 0.1902 - val_accuracy: 0.9636\n",
      "Epoch 348/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1509 - accuracy: 0.9621 - val_loss: 0.2002 - val_accuracy: 0.9589\n",
      "Epoch 349/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1495 - accuracy: 0.9627 - val_loss: 0.2055 - val_accuracy: 0.9562\n",
      "Epoch 350/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9584 - val_loss: 0.1894 - val_accuracy: 0.9609\n",
      "Epoch 351/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1532 - accuracy: 0.9616 - val_loss: 0.2677 - val_accuracy: 0.9380\n",
      "Epoch 352/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1629 - accuracy: 0.9588 - val_loss: 0.2594 - val_accuracy: 0.9353\n",
      "Epoch 353/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9634 - val_loss: 0.2105 - val_accuracy: 0.9519\n",
      "Epoch 354/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1491 - accuracy: 0.9640 - val_loss: 0.2037 - val_accuracy: 0.9578\n",
      "Epoch 355/1000\n",
      "726/726 [==============================] - 1s 999us/step - loss: 0.1501 - accuracy: 0.9628 - val_loss: 0.1941 - val_accuracy: 0.9663\n",
      "Epoch 356/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9635 - val_loss: 0.2175 - val_accuracy: 0.9516\n",
      "Epoch 357/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1802 - accuracy: 0.9603 - val_loss: 0.2074 - val_accuracy: 0.9647\n",
      "Epoch 358/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1461 - accuracy: 0.9652 - val_loss: 0.2181 - val_accuracy: 0.9543\n",
      "Epoch 359/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1465 - accuracy: 0.9640 - val_loss: 0.2086 - val_accuracy: 0.9593\n",
      "Epoch 360/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1510 - accuracy: 0.9624 - val_loss: 0.2649 - val_accuracy: 0.9422\n",
      "Epoch 361/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1467 - accuracy: 0.9631 - val_loss: 0.2226 - val_accuracy: 0.9609\n",
      "Epoch 362/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1450 - accuracy: 0.9644 - val_loss: 0.2031 - val_accuracy: 0.9632\n",
      "Epoch 363/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1488 - accuracy: 0.9633 - val_loss: 0.2354 - val_accuracy: 0.9609\n",
      "Epoch 364/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1495 - accuracy: 0.9627 - val_loss: 0.2165 - val_accuracy: 0.9628\n",
      "Epoch 365/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1503 - accuracy: 0.9611 - val_loss: 0.2800 - val_accuracy: 0.9558\n",
      "Epoch 366/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1464 - accuracy: 0.9634 - val_loss: 0.2407 - val_accuracy: 0.9612\n",
      "Epoch 367/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1505 - accuracy: 0.9627 - val_loss: 0.2493 - val_accuracy: 0.9539\n",
      "Epoch 368/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1491 - accuracy: 0.9627 - val_loss: 0.2231 - val_accuracy: 0.9581\n",
      "Epoch 369/1000\n",
      "726/726 [==============================] - 1s 993us/step - loss: 0.1456 - accuracy: 0.9638 - val_loss: 0.2402 - val_accuracy: 0.9543\n",
      "Epoch 370/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1503 - accuracy: 0.9630 - val_loss: 0.2250 - val_accuracy: 0.9543\n",
      "Epoch 371/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1423 - accuracy: 0.9646 - val_loss: 0.2223 - val_accuracy: 0.9655\n",
      "Epoch 372/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1506 - accuracy: 0.9618 - val_loss: 0.2582 - val_accuracy: 0.9500\n",
      "Epoch 373/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9630 - val_loss: 0.2378 - val_accuracy: 0.9547\n",
      "Epoch 374/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1462 - accuracy: 0.9624 - val_loss: 0.2894 - val_accuracy: 0.9376\n",
      "Epoch 375/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1469 - accuracy: 0.9632 - val_loss: 0.2349 - val_accuracy: 0.9578\n",
      "Epoch 376/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1444 - accuracy: 0.9629 - val_loss: 0.3120 - val_accuracy: 0.9512\n",
      "Epoch 377/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9626 - val_loss: 0.2546 - val_accuracy: 0.9659\n",
      "Epoch 378/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1478 - accuracy: 0.9620 - val_loss: 0.2663 - val_accuracy: 0.9597\n",
      "Epoch 379/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1455 - accuracy: 0.9623 - val_loss: 0.2571 - val_accuracy: 0.9558\n",
      "Epoch 380/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1441 - accuracy: 0.9635 - val_loss: 0.2268 - val_accuracy: 0.9694\n",
      "Epoch 381/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1424 - accuracy: 0.9635 - val_loss: 0.2488 - val_accuracy: 0.9574\n",
      "Epoch 382/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1430 - accuracy: 0.9627 - val_loss: 0.2144 - val_accuracy: 0.9496\n",
      "Epoch 383/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.9643 - val_loss: 0.2024 - val_accuracy: 0.9655\n",
      "Epoch 384/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1446 - accuracy: 0.9626 - val_loss: 0.2245 - val_accuracy: 0.9543\n",
      "Epoch 385/1000\n",
      "726/726 [==============================] - 1s 993us/step - loss: 0.1401 - accuracy: 0.9653 - val_loss: 0.2007 - val_accuracy: 0.9620\n",
      "Epoch 386/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1455 - accuracy: 0.9620 - val_loss: 0.2177 - val_accuracy: 0.9655\n",
      "Epoch 387/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9634 - val_loss: 0.2818 - val_accuracy: 0.9430\n",
      "Epoch 388/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1487 - accuracy: 0.9613 - val_loss: 0.2573 - val_accuracy: 0.9597\n",
      "Epoch 389/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1417 - accuracy: 0.9640 - val_loss: 0.2504 - val_accuracy: 0.9640\n",
      "Epoch 390/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1388 - accuracy: 0.9642 - val_loss: 0.1914 - val_accuracy: 0.9632\n",
      "Epoch 391/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9642 - val_loss: 0.2626 - val_accuracy: 0.9601\n",
      "Epoch 392/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1428 - accuracy: 0.9654 - val_loss: 0.2516 - val_accuracy: 0.9717\n",
      "Epoch 393/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1388 - accuracy: 0.9649 - val_loss: 0.2533 - val_accuracy: 0.9705\n",
      "Epoch 394/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1380 - accuracy: 0.9649 - val_loss: 0.2492 - val_accuracy: 0.9659\n",
      "Epoch 395/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1390 - accuracy: 0.9650 - val_loss: 0.2475 - val_accuracy: 0.9667\n",
      "Epoch 396/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9651 - val_loss: 0.2595 - val_accuracy: 0.9616\n",
      "Epoch 397/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1441 - accuracy: 0.9624 - val_loss: 0.2570 - val_accuracy: 0.9612\n",
      "Epoch 398/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1400 - accuracy: 0.9635 - val_loss: 0.2662 - val_accuracy: 0.9523\n",
      "Epoch 399/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1419 - accuracy: 0.9637 - val_loss: 0.2538 - val_accuracy: 0.9682\n",
      "Epoch 400/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1391 - accuracy: 0.9650 - val_loss: 0.2576 - val_accuracy: 0.9574\n",
      "Epoch 401/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.9658 - val_loss: 0.2453 - val_accuracy: 0.9663\n",
      "Epoch 402/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9654 - val_loss: 0.2695 - val_accuracy: 0.9566\n",
      "Epoch 403/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1353 - accuracy: 0.9643 - val_loss: 0.2560 - val_accuracy: 0.9581\n",
      "Epoch 404/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1395 - accuracy: 0.9638 - val_loss: 0.2549 - val_accuracy: 0.9659\n",
      "Epoch 405/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1390 - accuracy: 0.9644 - val_loss: 0.2622 - val_accuracy: 0.9612\n",
      "Epoch 406/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1373 - accuracy: 0.9635 - val_loss: 0.2569 - val_accuracy: 0.9550\n",
      "Epoch 407/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1352 - accuracy: 0.9654 - val_loss: 0.2702 - val_accuracy: 0.9589\n",
      "Epoch 408/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1408 - accuracy: 0.9647 - val_loss: 0.2358 - val_accuracy: 0.9756\n",
      "Epoch 409/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.9655 - val_loss: 0.2645 - val_accuracy: 0.9601\n",
      "Epoch 410/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1360 - accuracy: 0.9658 - val_loss: 0.2695 - val_accuracy: 0.9550\n",
      "Epoch 411/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.9664 - val_loss: 0.3483 - val_accuracy: 0.9651\n",
      "Epoch 412/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1400 - accuracy: 0.9635 - val_loss: 0.1811 - val_accuracy: 0.9593\n",
      "Epoch 413/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.9673 - val_loss: 0.1781 - val_accuracy: 0.9659\n",
      "Epoch 414/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1327 - accuracy: 0.9663 - val_loss: 0.1666 - val_accuracy: 0.9721\n",
      "Epoch 415/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9648 - val_loss: 0.1907 - val_accuracy: 0.9601\n",
      "Epoch 416/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1399 - accuracy: 0.9642 - val_loss: 0.2034 - val_accuracy: 0.9578\n",
      "Epoch 417/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.9643 - val_loss: 0.1839 - val_accuracy: 0.9628\n",
      "Epoch 418/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1310 - accuracy: 0.9664 - val_loss: 0.1810 - val_accuracy: 0.9651\n",
      "Epoch 419/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.9659 - val_loss: 0.2062 - val_accuracy: 0.9527\n",
      "Epoch 420/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1336 - accuracy: 0.9655 - val_loss: 0.1959 - val_accuracy: 0.9558\n",
      "Epoch 421/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1304 - accuracy: 0.9674 - val_loss: 0.1927 - val_accuracy: 0.9581\n",
      "Epoch 422/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1337 - accuracy: 0.9650 - val_loss: 0.1695 - val_accuracy: 0.9756\n",
      "Epoch 423/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1340 - accuracy: 0.9647 - val_loss: 0.2050 - val_accuracy: 0.9558\n",
      "Epoch 424/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1343 - accuracy: 0.9644 - val_loss: 0.1647 - val_accuracy: 0.9508\n",
      "Epoch 425/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.9663 - val_loss: 0.1276 - val_accuracy: 0.9686\n",
      "Epoch 426/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1317 - accuracy: 0.9658 - val_loss: 0.1393 - val_accuracy: 0.9624\n",
      "Epoch 427/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9656 - val_loss: 0.1587 - val_accuracy: 0.9519\n",
      "Epoch 428/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1297 - accuracy: 0.9665 - val_loss: 0.1593 - val_accuracy: 0.9574\n",
      "Epoch 429/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1318 - accuracy: 0.9660 - val_loss: 0.1443 - val_accuracy: 0.9612\n",
      "Epoch 430/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1356 - accuracy: 0.9650 - val_loss: 0.1618 - val_accuracy: 0.9593\n",
      "Epoch 431/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1313 - accuracy: 0.9666 - val_loss: 0.1365 - val_accuracy: 0.9620\n",
      "Epoch 432/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1331 - accuracy: 0.9648 - val_loss: 0.1264 - val_accuracy: 0.9702\n",
      "Epoch 433/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1310 - accuracy: 0.9659 - val_loss: 0.1243 - val_accuracy: 0.9705\n",
      "Epoch 434/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1258 - accuracy: 0.9692 - val_loss: 0.1537 - val_accuracy: 0.9570\n",
      "Epoch 435/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1288 - accuracy: 0.9667 - val_loss: 0.1318 - val_accuracy: 0.9736\n",
      "Epoch 436/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1464 - accuracy: 0.9620 - val_loss: 0.1483 - val_accuracy: 0.9585\n",
      "Epoch 437/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.9698 - val_loss: 0.1353 - val_accuracy: 0.9640\n",
      "Epoch 438/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1213 - accuracy: 0.9699 - val_loss: 0.2764 - val_accuracy: 0.9287\n",
      "Epoch 439/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1261 - accuracy: 0.9687 - val_loss: 0.1302 - val_accuracy: 0.9760\n",
      "Epoch 440/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1266 - accuracy: 0.9672 - val_loss: 0.1144 - val_accuracy: 0.9795\n",
      "Epoch 441/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9668 - val_loss: 0.1534 - val_accuracy: 0.9539\n",
      "Epoch 442/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.9677 - val_loss: 0.1678 - val_accuracy: 0.9558\n",
      "Epoch 443/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.9680 - val_loss: 0.1270 - val_accuracy: 0.9690\n",
      "Epoch 444/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1273 - accuracy: 0.9668 - val_loss: 0.1494 - val_accuracy: 0.9535\n",
      "Epoch 445/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1252 - accuracy: 0.9676 - val_loss: 0.1291 - val_accuracy: 0.9709\n",
      "Epoch 446/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.9661 - val_loss: 0.2338 - val_accuracy: 0.9473\n",
      "Epoch 447/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1264 - accuracy: 0.9679 - val_loss: 0.1233 - val_accuracy: 0.9713\n",
      "Epoch 448/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9677 - val_loss: 0.1341 - val_accuracy: 0.9702\n",
      "Epoch 449/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1272 - accuracy: 0.9679 - val_loss: 0.1276 - val_accuracy: 0.9760\n",
      "Epoch 450/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9656 - val_loss: 0.1433 - val_accuracy: 0.9624\n",
      "Epoch 451/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.9681 - val_loss: 0.1506 - val_accuracy: 0.9543\n",
      "Epoch 452/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1402 - accuracy: 0.9664 - val_loss: 0.1178 - val_accuracy: 0.9725\n",
      "Epoch 453/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9705 - val_loss: 0.1525 - val_accuracy: 0.9612\n",
      "Epoch 454/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1250 - accuracy: 0.9691 - val_loss: 0.1283 - val_accuracy: 0.9655\n",
      "Epoch 455/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.9671 - val_loss: 0.1595 - val_accuracy: 0.9589\n",
      "Epoch 456/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9694 - val_loss: 0.3544 - val_accuracy: 0.9209\n",
      "Epoch 457/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1932 - accuracy: 0.9664 - val_loss: 0.1423 - val_accuracy: 0.9663\n",
      "Epoch 458/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9726 - val_loss: 0.1435 - val_accuracy: 0.9574\n",
      "Epoch 459/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.9715 - val_loss: 0.1489 - val_accuracy: 0.9581\n",
      "Epoch 460/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.9700 - val_loss: 0.1169 - val_accuracy: 0.9744\n",
      "Epoch 461/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.9698 - val_loss: 0.1287 - val_accuracy: 0.9678\n",
      "Epoch 462/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.9674 - val_loss: 0.1353 - val_accuracy: 0.9640\n",
      "Epoch 463/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.9683 - val_loss: 0.1230 - val_accuracy: 0.9729\n",
      "Epoch 464/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.9679 - val_loss: 0.1290 - val_accuracy: 0.9698\n",
      "Epoch 465/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9681 - val_loss: 0.1222 - val_accuracy: 0.9740\n",
      "Epoch 466/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1301 - accuracy: 0.9658 - val_loss: 0.1503 - val_accuracy: 0.9554\n",
      "Epoch 467/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1193 - accuracy: 0.9698 - val_loss: 0.1251 - val_accuracy: 0.9729\n",
      "Epoch 468/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1246 - accuracy: 0.9671 - val_loss: 0.1270 - val_accuracy: 0.9678\n",
      "Epoch 469/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1269 - accuracy: 0.9659 - val_loss: 0.1242 - val_accuracy: 0.9671\n",
      "Epoch 470/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.9700 - val_loss: 0.1298 - val_accuracy: 0.9636\n",
      "Epoch 471/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.9667 - val_loss: 0.1261 - val_accuracy: 0.9667\n",
      "Epoch 472/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9673 - val_loss: 0.1372 - val_accuracy: 0.9605\n",
      "Epoch 473/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1204 - accuracy: 0.9692 - val_loss: 0.1268 - val_accuracy: 0.9636\n",
      "Epoch 474/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9650 - val_loss: 0.1247 - val_accuracy: 0.9651\n",
      "Epoch 475/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.9671 - val_loss: 0.1699 - val_accuracy: 0.9473\n",
      "Epoch 476/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1277 - accuracy: 0.9679 - val_loss: 0.1602 - val_accuracy: 0.9585\n",
      "Epoch 477/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9698 - val_loss: 0.1334 - val_accuracy: 0.9682\n",
      "Epoch 478/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1240 - accuracy: 0.9666 - val_loss: 0.1475 - val_accuracy: 0.9593\n",
      "Epoch 479/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1245 - accuracy: 0.9680 - val_loss: 0.1186 - val_accuracy: 0.9713\n",
      "Epoch 480/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.9669 - val_loss: 0.1305 - val_accuracy: 0.9655\n",
      "Epoch 481/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1256 - accuracy: 0.9675 - val_loss: 0.1579 - val_accuracy: 0.9578\n",
      "Epoch 482/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.9662 - val_loss: 0.1653 - val_accuracy: 0.9578\n",
      "Epoch 483/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.9665 - val_loss: 0.1448 - val_accuracy: 0.9647\n",
      "Epoch 484/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.9680 - val_loss: 0.1211 - val_accuracy: 0.9740\n",
      "Epoch 485/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.9677 - val_loss: 0.1314 - val_accuracy: 0.9678\n",
      "Epoch 486/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.9665 - val_loss: 0.2107 - val_accuracy: 0.9399\n",
      "Epoch 487/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9695 - val_loss: 0.1772 - val_accuracy: 0.9581\n",
      "Epoch 488/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1233 - accuracy: 0.9677 - val_loss: 0.1247 - val_accuracy: 0.9725\n",
      "Epoch 489/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9690 - val_loss: 0.1779 - val_accuracy: 0.9543\n",
      "Epoch 490/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9680 - val_loss: 0.1293 - val_accuracy: 0.9694\n",
      "Epoch 491/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.9669 - val_loss: 0.1434 - val_accuracy: 0.9636\n",
      "Epoch 492/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.9693 - val_loss: 0.1278 - val_accuracy: 0.9686\n",
      "Epoch 493/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.9664 - val_loss: 0.1435 - val_accuracy: 0.9574\n",
      "Epoch 494/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9675 - val_loss: 0.1368 - val_accuracy: 0.9640\n",
      "Epoch 495/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.9694 - val_loss: 0.1871 - val_accuracy: 0.9578\n",
      "Epoch 496/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.9667 - val_loss: 0.1846 - val_accuracy: 0.9508\n",
      "Epoch 497/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.9675 - val_loss: 0.1241 - val_accuracy: 0.9729\n",
      "Epoch 498/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9685 - val_loss: 0.1306 - val_accuracy: 0.9674\n",
      "Epoch 499/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9658 - val_loss: 0.1255 - val_accuracy: 0.9659\n",
      "Epoch 500/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9701 - val_loss: 0.1287 - val_accuracy: 0.9643\n",
      "Epoch 501/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9683 - val_loss: 0.1760 - val_accuracy: 0.9395\n",
      "Epoch 502/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.9664 - val_loss: 0.1117 - val_accuracy: 0.9752\n",
      "Epoch 503/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.9691 - val_loss: 0.1590 - val_accuracy: 0.9585\n",
      "Epoch 504/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9659 - val_loss: 0.1175 - val_accuracy: 0.9760\n",
      "Epoch 505/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.9673 - val_loss: 0.1405 - val_accuracy: 0.9636\n",
      "Epoch 506/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9689 - val_loss: 0.1303 - val_accuracy: 0.9651\n",
      "Epoch 507/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1238 - accuracy: 0.9674 - val_loss: 0.1289 - val_accuracy: 0.9659\n",
      "Epoch 508/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9689 - val_loss: 0.1262 - val_accuracy: 0.9667\n",
      "Epoch 509/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9697 - val_loss: 0.1649 - val_accuracy: 0.9531\n",
      "Epoch 510/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1264 - accuracy: 0.9661 - val_loss: 0.1301 - val_accuracy: 0.9655\n",
      "Epoch 511/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.9703 - val_loss: 0.1345 - val_accuracy: 0.9671\n",
      "Epoch 512/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.9684 - val_loss: 0.1559 - val_accuracy: 0.9690\n",
      "Epoch 513/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9674 - val_loss: 0.1957 - val_accuracy: 0.9531\n",
      "Epoch 514/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9724 - val_loss: 0.1530 - val_accuracy: 0.9721\n",
      "Epoch 515/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.9662 - val_loss: 0.1979 - val_accuracy: 0.9659\n",
      "Epoch 516/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9698 - val_loss: 0.1773 - val_accuracy: 0.9640\n",
      "Epoch 517/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9690 - val_loss: 0.1999 - val_accuracy: 0.9519\n",
      "Epoch 518/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9698 - val_loss: 0.1352 - val_accuracy: 0.9733\n",
      "Epoch 519/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9692 - val_loss: 0.1222 - val_accuracy: 0.9729\n",
      "Epoch 520/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9695 - val_loss: 0.1276 - val_accuracy: 0.9709\n",
      "Epoch 521/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.9685 - val_loss: 0.1417 - val_accuracy: 0.9698\n",
      "Epoch 522/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9682 - val_loss: 0.1487 - val_accuracy: 0.9682\n",
      "Epoch 523/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.9683 - val_loss: 0.1678 - val_accuracy: 0.9589\n",
      "Epoch 524/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.9722 - val_loss: 0.1225 - val_accuracy: 0.9702\n",
      "Epoch 525/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9699 - val_loss: 0.1582 - val_accuracy: 0.9651\n",
      "Epoch 526/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.9678 - val_loss: 0.1444 - val_accuracy: 0.9640\n",
      "Epoch 527/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.9697 - val_loss: 0.1438 - val_accuracy: 0.9655\n",
      "Epoch 528/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9708 - val_loss: 0.1737 - val_accuracy: 0.9550\n",
      "Epoch 529/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.9672 - val_loss: 0.1314 - val_accuracy: 0.9678\n",
      "Epoch 530/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9705 - val_loss: 0.1355 - val_accuracy: 0.9616\n",
      "Epoch 531/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9700 - val_loss: 0.1271 - val_accuracy: 0.9771\n",
      "Epoch 532/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.9672 - val_loss: 0.1339 - val_accuracy: 0.9756\n",
      "Epoch 533/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9705 - val_loss: 0.1270 - val_accuracy: 0.9721\n",
      "Epoch 534/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1181 - accuracy: 0.9694 - val_loss: 0.1379 - val_accuracy: 0.9643\n",
      "Epoch 535/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9699 - val_loss: 0.1315 - val_accuracy: 0.9671\n",
      "Epoch 536/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.9724 - val_loss: 0.1491 - val_accuracy: 0.9643\n",
      "Epoch 537/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.9699 - val_loss: 0.1874 - val_accuracy: 0.9554\n",
      "Epoch 538/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9683 - val_loss: 0.1315 - val_accuracy: 0.9694\n",
      "Epoch 539/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9703 - val_loss: 0.1250 - val_accuracy: 0.9717\n",
      "Epoch 540/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9706 - val_loss: 0.1351 - val_accuracy: 0.9748\n",
      "Epoch 541/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.9696 - val_loss: 0.1747 - val_accuracy: 0.9647\n",
      "Epoch 542/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.9715 - val_loss: 0.1538 - val_accuracy: 0.9736\n",
      "Epoch 543/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9708 - val_loss: 0.1320 - val_accuracy: 0.9690\n",
      "Epoch 544/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9695 - val_loss: 0.1399 - val_accuracy: 0.9682\n",
      "Epoch 545/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.9700 - val_loss: 0.1476 - val_accuracy: 0.9667\n",
      "Epoch 546/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9709 - val_loss: 0.1330 - val_accuracy: 0.9764\n",
      "Epoch 547/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9694 - val_loss: 0.1590 - val_accuracy: 0.9636\n",
      "Epoch 548/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9690 - val_loss: 0.1394 - val_accuracy: 0.9690\n",
      "Epoch 549/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.9694 - val_loss: 0.1466 - val_accuracy: 0.9717\n",
      "Epoch 550/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9714 - val_loss: 0.1731 - val_accuracy: 0.9663\n",
      "Epoch 551/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9707 - val_loss: 0.1505 - val_accuracy: 0.9752\n",
      "Epoch 552/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1779 - val_accuracy: 0.9589\n",
      "Epoch 553/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9705 - val_loss: 0.1938 - val_accuracy: 0.9640\n",
      "Epoch 554/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1319 - accuracy: 0.9678 - val_loss: 0.1780 - val_accuracy: 0.9709\n",
      "Epoch 555/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9712 - val_loss: 0.1950 - val_accuracy: 0.9671\n",
      "Epoch 556/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9730 - val_loss: 0.1862 - val_accuracy: 0.9678\n",
      "Epoch 557/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9702 - val_loss: 0.1916 - val_accuracy: 0.9643\n",
      "Epoch 558/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9709 - val_loss: 0.1782 - val_accuracy: 0.9760\n",
      "Epoch 559/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9710 - val_loss: 0.1838 - val_accuracy: 0.9736\n",
      "Epoch 560/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9700 - val_loss: 0.1794 - val_accuracy: 0.9678\n",
      "Epoch 561/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9700 - val_loss: 0.2035 - val_accuracy: 0.9647\n",
      "Epoch 562/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.9724 - val_loss: 0.1957 - val_accuracy: 0.9632\n",
      "Epoch 563/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9711 - val_loss: 0.1741 - val_accuracy: 0.9760\n",
      "Epoch 564/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9705 - val_loss: 0.1696 - val_accuracy: 0.9756\n",
      "Epoch 565/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9705 - val_loss: 0.1668 - val_accuracy: 0.9740\n",
      "Epoch 566/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9710 - val_loss: 0.1533 - val_accuracy: 0.9764\n",
      "Epoch 567/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1119 - accuracy: 0.9706 - val_loss: 0.1437 - val_accuracy: 0.9822\n",
      "Epoch 568/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9714 - val_loss: 0.1561 - val_accuracy: 0.9725\n",
      "Epoch 569/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.9695 - val_loss: 0.1623 - val_accuracy: 0.9709\n",
      "Epoch 570/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.9693 - val_loss: 0.1241 - val_accuracy: 0.9748\n",
      "Epoch 571/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9755 - val_loss: 0.1225 - val_accuracy: 0.9729\n",
      "Epoch 572/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9744 - val_loss: 0.1422 - val_accuracy: 0.9671\n",
      "Epoch 573/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9745 - val_loss: 0.1723 - val_accuracy: 0.9543\n",
      "Epoch 574/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9696 - val_loss: 0.1130 - val_accuracy: 0.9767\n",
      "Epoch 575/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.9737 - val_loss: 0.1256 - val_accuracy: 0.9671\n",
      "Epoch 576/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.9717 - val_loss: 0.1250 - val_accuracy: 0.9733\n",
      "Epoch 577/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1124 - accuracy: 0.9692 - val_loss: 0.1391 - val_accuracy: 0.9643\n",
      "Epoch 578/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9691 - val_loss: 0.1218 - val_accuracy: 0.9775\n",
      "Epoch 579/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9697 - val_loss: 0.1220 - val_accuracy: 0.9725\n",
      "Epoch 580/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9693 - val_loss: 0.1349 - val_accuracy: 0.9674\n",
      "Epoch 581/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9714 - val_loss: 0.1208 - val_accuracy: 0.9752\n",
      "Epoch 582/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.9718 - val_loss: 0.1369 - val_accuracy: 0.9690\n",
      "Epoch 583/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9702 - val_loss: 0.1351 - val_accuracy: 0.9717\n",
      "Epoch 584/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9723 - val_loss: 0.1358 - val_accuracy: 0.9729\n",
      "Epoch 585/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9702 - val_loss: 0.1957 - val_accuracy: 0.9570\n",
      "Epoch 586/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9710 - val_loss: 0.1354 - val_accuracy: 0.9744\n",
      "Epoch 587/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.9712 - val_loss: 0.1393 - val_accuracy: 0.9702\n",
      "Epoch 588/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9727 - val_loss: 0.1398 - val_accuracy: 0.9725\n",
      "Epoch 589/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.9700 - val_loss: 0.2226 - val_accuracy: 0.9531\n",
      "Epoch 590/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.9704 - val_loss: 0.1389 - val_accuracy: 0.9779\n",
      "Epoch 591/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9709 - val_loss: 0.2036 - val_accuracy: 0.9547\n",
      "Epoch 592/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9705 - val_loss: 0.1519 - val_accuracy: 0.9647\n",
      "Epoch 593/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9698 - val_loss: 0.1347 - val_accuracy: 0.9736\n",
      "Epoch 594/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9710 - val_loss: 0.1437 - val_accuracy: 0.9671\n",
      "Epoch 595/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.9710 - val_loss: 0.1753 - val_accuracy: 0.9674\n",
      "Epoch 596/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1110 - accuracy: 0.9708 - val_loss: 0.1638 - val_accuracy: 0.9674\n",
      "Epoch 597/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.9713 - val_loss: 0.1377 - val_accuracy: 0.9756\n",
      "Epoch 598/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9724 - val_loss: 0.2574 - val_accuracy: 0.9411\n",
      "Epoch 599/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9690 - val_loss: 0.1336 - val_accuracy: 0.9771\n",
      "Epoch 600/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.1645 - val_accuracy: 0.9709\n",
      "Epoch 601/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9712 - val_loss: 0.1575 - val_accuracy: 0.9632\n",
      "Epoch 602/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9696 - val_loss: 0.1851 - val_accuracy: 0.9620\n",
      "Epoch 603/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1072 - accuracy: 0.9715 - val_loss: 0.1647 - val_accuracy: 0.9729\n",
      "Epoch 604/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9720 - val_loss: 0.1470 - val_accuracy: 0.9787\n",
      "Epoch 605/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.9706 - val_loss: 0.1492 - val_accuracy: 0.9767\n",
      "Epoch 606/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9701 - val_loss: 0.1671 - val_accuracy: 0.9733\n",
      "Epoch 607/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9720 - val_loss: 0.1671 - val_accuracy: 0.9756\n",
      "Epoch 608/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9699 - val_loss: 0.3168 - val_accuracy: 0.9384\n",
      "Epoch 609/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9705 - val_loss: 0.2704 - val_accuracy: 0.9388\n",
      "Epoch 610/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9701 - val_loss: 0.1865 - val_accuracy: 0.9725\n",
      "Epoch 611/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9695 - val_loss: 0.1799 - val_accuracy: 0.9682\n",
      "Epoch 612/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9730 - val_loss: 0.1604 - val_accuracy: 0.9764\n",
      "Epoch 613/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1062 - accuracy: 0.9708 - val_loss: 0.1812 - val_accuracy: 0.9779\n",
      "Epoch 614/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9730 - val_loss: 0.2415 - val_accuracy: 0.9516\n",
      "Epoch 615/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9707 - val_loss: 0.1696 - val_accuracy: 0.9717\n",
      "Epoch 616/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.9717 - val_loss: 0.2719 - val_accuracy: 0.9632\n",
      "Epoch 617/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9724 - val_loss: 0.2350 - val_accuracy: 0.9667\n",
      "Epoch 618/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9725 - val_loss: 0.2349 - val_accuracy: 0.9671\n",
      "Epoch 619/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9710 - val_loss: 0.3510 - val_accuracy: 0.9395\n",
      "Epoch 620/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9703 - val_loss: 0.2543 - val_accuracy: 0.9597\n",
      "Epoch 621/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9720 - val_loss: 0.2006 - val_accuracy: 0.9791\n",
      "Epoch 622/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9715 - val_loss: 0.2067 - val_accuracy: 0.9736\n",
      "Epoch 623/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9701 - val_loss: 0.2059 - val_accuracy: 0.9729\n",
      "Epoch 624/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9716 - val_loss: 0.2219 - val_accuracy: 0.9733\n",
      "Epoch 625/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9720 - val_loss: 0.2520 - val_accuracy: 0.9574\n",
      "Epoch 626/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1050 - accuracy: 0.9722 - val_loss: 0.2015 - val_accuracy: 0.9760\n",
      "Epoch 627/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9721 - val_loss: 0.2118 - val_accuracy: 0.9694\n",
      "Epoch 628/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9727 - val_loss: 0.1830 - val_accuracy: 0.9810\n",
      "Epoch 629/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9733 - val_loss: 0.2737 - val_accuracy: 0.9527\n",
      "Epoch 630/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9734 - val_loss: 0.1993 - val_accuracy: 0.9717\n",
      "Epoch 631/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9739 - val_loss: 0.2107 - val_accuracy: 0.9702\n",
      "Epoch 632/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9716 - val_loss: 0.1992 - val_accuracy: 0.9713\n",
      "Epoch 633/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9735 - val_loss: 0.2276 - val_accuracy: 0.9798\n",
      "Epoch 634/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9724 - val_loss: 0.2353 - val_accuracy: 0.9721\n",
      "Epoch 635/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.9723 - val_loss: 0.2173 - val_accuracy: 0.9810\n",
      "Epoch 636/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.9713 - val_loss: 0.2561 - val_accuracy: 0.9667\n",
      "Epoch 637/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.9728 - val_loss: 0.2526 - val_accuracy: 0.9659\n",
      "Epoch 638/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9721 - val_loss: 0.2741 - val_accuracy: 0.9795\n",
      "Epoch 639/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.2218 - val_accuracy: 0.9694\n",
      "Epoch 640/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9717 - val_loss: 0.2105 - val_accuracy: 0.9721\n",
      "Epoch 641/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9712 - val_loss: 0.2751 - val_accuracy: 0.9550\n",
      "Epoch 642/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9738 - val_loss: 0.2041 - val_accuracy: 0.9733\n",
      "Epoch 643/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9720 - val_loss: 0.2316 - val_accuracy: 0.9643\n",
      "Epoch 644/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.9737 - val_loss: 0.2056 - val_accuracy: 0.9760\n",
      "Epoch 645/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9724 - val_loss: 0.2069 - val_accuracy: 0.9744\n",
      "Epoch 646/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9733 - val_loss: 0.2165 - val_accuracy: 0.9671\n",
      "Epoch 647/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9727 - val_loss: 0.2153 - val_accuracy: 0.9709\n",
      "Epoch 648/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9718 - val_loss: 0.2204 - val_accuracy: 0.9655\n",
      "Epoch 649/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9737 - val_loss: 0.1911 - val_accuracy: 0.9775\n",
      "Epoch 650/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9703 - val_loss: 0.1970 - val_accuracy: 0.9779\n",
      "Epoch 651/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9726 - val_loss: 0.1948 - val_accuracy: 0.9752\n",
      "Epoch 652/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9699 - val_loss: 0.1778 - val_accuracy: 0.9760\n",
      "Epoch 653/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9734 - val_loss: 0.2141 - val_accuracy: 0.9605\n",
      "Epoch 654/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9728 - val_loss: 0.3056 - val_accuracy: 0.9465\n",
      "Epoch 655/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9751 - val_loss: 0.2219 - val_accuracy: 0.9698\n",
      "Epoch 656/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9733 - val_loss: 0.1907 - val_accuracy: 0.9787\n",
      "Epoch 657/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9734 - val_loss: 0.2072 - val_accuracy: 0.9740\n",
      "Epoch 658/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9726 - val_loss: 0.1878 - val_accuracy: 0.9829\n",
      "Epoch 659/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.9729 - val_loss: 0.2367 - val_accuracy: 0.9585\n",
      "Epoch 660/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9726 - val_loss: 0.1788 - val_accuracy: 0.9810\n",
      "Epoch 661/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9726 - val_loss: 0.2023 - val_accuracy: 0.9740\n",
      "Epoch 662/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1030 - accuracy: 0.9728 - val_loss: 0.2077 - val_accuracy: 0.9674\n",
      "Epoch 663/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9736 - val_loss: 0.2102 - val_accuracy: 0.9736\n",
      "Epoch 664/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9717 - val_loss: 0.1989 - val_accuracy: 0.9748\n",
      "Epoch 665/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.9706 - val_loss: 0.1906 - val_accuracy: 0.9760\n",
      "Epoch 666/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9705 - val_loss: 0.2056 - val_accuracy: 0.9698\n",
      "Epoch 667/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1011 - accuracy: 0.9727 - val_loss: 0.3015 - val_accuracy: 0.9465\n",
      "Epoch 668/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.9715 - val_loss: 0.3606 - val_accuracy: 0.9391\n",
      "Epoch 669/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1022 - accuracy: 0.9712 - val_loss: 0.2066 - val_accuracy: 0.9663\n",
      "Epoch 670/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.2723 - val_accuracy: 0.9531\n",
      "Epoch 671/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1374 - accuracy: 0.9722 - val_loss: 0.1836 - val_accuracy: 0.9752\n",
      "Epoch 672/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9780 - val_loss: 0.2234 - val_accuracy: 0.9585\n",
      "Epoch 673/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0915 - accuracy: 0.9752 - val_loss: 0.1739 - val_accuracy: 0.9748\n",
      "Epoch 674/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9767 - val_loss: 0.1757 - val_accuracy: 0.9729\n",
      "Epoch 675/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9733 - val_loss: 0.2181 - val_accuracy: 0.9609\n",
      "Epoch 676/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9748 - val_loss: 0.1588 - val_accuracy: 0.9760\n",
      "Epoch 677/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9748 - val_loss: 0.1549 - val_accuracy: 0.9779\n",
      "Epoch 678/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0966 - accuracy: 0.9752 - val_loss: 0.1513 - val_accuracy: 0.9725\n",
      "Epoch 679/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9724 - val_loss: 0.1956 - val_accuracy: 0.9601\n",
      "Epoch 680/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9748 - val_loss: 0.1912 - val_accuracy: 0.9628\n",
      "Epoch 681/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.9715 - val_loss: 0.1359 - val_accuracy: 0.9764\n",
      "Epoch 682/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9723 - val_loss: 0.1658 - val_accuracy: 0.9690\n",
      "Epoch 683/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9725 - val_loss: 0.1475 - val_accuracy: 0.9671\n",
      "Epoch 684/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0917 - accuracy: 0.9757 - val_loss: 0.1402 - val_accuracy: 0.9729\n",
      "Epoch 685/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.2532 - val_accuracy: 0.9698\n",
      "Epoch 686/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9727 - val_loss: 0.1941 - val_accuracy: 0.9733\n",
      "Epoch 687/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.2075 - val_accuracy: 0.9674\n",
      "Epoch 688/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9705 - val_loss: 0.1925 - val_accuracy: 0.9702\n",
      "Epoch 689/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9747 - val_loss: 0.1896 - val_accuracy: 0.9748\n",
      "Epoch 690/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9722 - val_loss: 0.1950 - val_accuracy: 0.9682\n",
      "Epoch 691/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9711 - val_loss: 0.1783 - val_accuracy: 0.9733\n",
      "Epoch 692/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9739 - val_loss: 0.1748 - val_accuracy: 0.9771\n",
      "Epoch 693/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1045 - accuracy: 0.9730 - val_loss: 0.1951 - val_accuracy: 0.9721\n",
      "Epoch 694/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9720 - val_loss: 0.1987 - val_accuracy: 0.9620\n",
      "Epoch 695/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.1990 - val_accuracy: 0.9736\n",
      "Epoch 696/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9734 - val_loss: 0.1873 - val_accuracy: 0.9752\n",
      "Epoch 697/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9736 - val_loss: 0.2441 - val_accuracy: 0.9574\n",
      "Epoch 698/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9720 - val_loss: 0.2058 - val_accuracy: 0.9733\n",
      "Epoch 699/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9711 - val_loss: 0.1847 - val_accuracy: 0.9787\n",
      "Epoch 700/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9705 - val_loss: 0.2152 - val_accuracy: 0.9717\n",
      "Epoch 701/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9741 - val_loss: 0.2203 - val_accuracy: 0.9709\n",
      "Epoch 702/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 0.2672 - val_accuracy: 0.9535\n",
      "Epoch 703/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9738 - val_loss: 0.2441 - val_accuracy: 0.9609\n",
      "Epoch 704/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9733 - val_loss: 0.1594 - val_accuracy: 0.9818\n",
      "Epoch 705/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.9736 - val_loss: 0.1737 - val_accuracy: 0.9760\n",
      "Epoch 706/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.2419 - val_accuracy: 0.9488\n",
      "Epoch 707/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9714 - val_loss: 0.1847 - val_accuracy: 0.9663\n",
      "Epoch 708/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.9717 - val_loss: 0.2040 - val_accuracy: 0.9760\n",
      "Epoch 709/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9742 - val_loss: 0.2010 - val_accuracy: 0.9686\n",
      "Epoch 710/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9727 - val_loss: 0.1958 - val_accuracy: 0.9713\n",
      "Epoch 711/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9741 - val_loss: 0.1815 - val_accuracy: 0.9740\n",
      "Epoch 712/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9724 - val_loss: 0.2111 - val_accuracy: 0.9632\n",
      "Epoch 713/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9737 - val_loss: 0.2212 - val_accuracy: 0.9547\n",
      "Epoch 714/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.9693 - val_loss: 0.2231 - val_accuracy: 0.9698\n",
      "Epoch 715/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9745 - val_loss: 0.1925 - val_accuracy: 0.9787\n",
      "Epoch 716/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9726 - val_loss: 0.2002 - val_accuracy: 0.9783\n",
      "Epoch 717/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0966 - accuracy: 0.9731 - val_loss: 0.2222 - val_accuracy: 0.9791\n",
      "Epoch 718/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9735 - val_loss: 0.2439 - val_accuracy: 0.9647\n",
      "Epoch 719/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.9711 - val_loss: 0.2409 - val_accuracy: 0.9709\n",
      "Epoch 720/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9719 - val_loss: 0.2660 - val_accuracy: 0.9578\n",
      "Epoch 721/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9731 - val_loss: 0.2090 - val_accuracy: 0.9647\n",
      "Epoch 722/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9720 - val_loss: 0.2061 - val_accuracy: 0.9736\n",
      "Epoch 723/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9746 - val_loss: 0.1994 - val_accuracy: 0.9698\n",
      "Epoch 724/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9722 - val_loss: 0.1985 - val_accuracy: 0.9767\n",
      "Epoch 725/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9732 - val_loss: 0.1939 - val_accuracy: 0.9744\n",
      "Epoch 726/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9748 - val_loss: 0.1877 - val_accuracy: 0.9775\n",
      "Epoch 727/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.9707 - val_loss: 0.1986 - val_accuracy: 0.9694\n",
      "Epoch 728/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.1994 - val_accuracy: 0.9729\n",
      "Epoch 729/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9746 - val_loss: 0.2026 - val_accuracy: 0.9783\n",
      "Epoch 730/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9692 - val_loss: 0.2159 - val_accuracy: 0.9667\n",
      "Epoch 731/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9729 - val_loss: 0.2721 - val_accuracy: 0.9725\n",
      "Epoch 732/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9725 - val_loss: 0.2792 - val_accuracy: 0.9771\n",
      "Epoch 733/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9741 - val_loss: 0.2873 - val_accuracy: 0.9752\n",
      "Epoch 734/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9737 - val_loss: 0.2955 - val_accuracy: 0.9593\n",
      "Epoch 735/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9752 - val_loss: 0.3011 - val_accuracy: 0.9643\n",
      "Epoch 736/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9743 - val_loss: 0.2463 - val_accuracy: 0.9857\n",
      "Epoch 737/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9742 - val_loss: 0.2518 - val_accuracy: 0.9767\n",
      "Epoch 738/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9747 - val_loss: 0.2714 - val_accuracy: 0.9760\n",
      "Epoch 739/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9734 - val_loss: 0.3152 - val_accuracy: 0.9585\n",
      "Epoch 740/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9741 - val_loss: 0.3336 - val_accuracy: 0.9748\n",
      "Epoch 741/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9758 - val_loss: 0.3640 - val_accuracy: 0.9640\n",
      "Epoch 742/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9746 - val_loss: 0.3558 - val_accuracy: 0.9752\n",
      "Epoch 743/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9746 - val_loss: 0.3980 - val_accuracy: 0.9624\n",
      "Epoch 744/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.9732 - val_loss: 0.3540 - val_accuracy: 0.9616\n",
      "Epoch 745/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9731 - val_loss: 0.3215 - val_accuracy: 0.9775\n",
      "Epoch 746/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9730 - val_loss: 0.3099 - val_accuracy: 0.9760\n",
      "Epoch 747/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9723 - val_loss: 0.3118 - val_accuracy: 0.9787\n",
      "Epoch 748/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9739 - val_loss: 0.3318 - val_accuracy: 0.9756\n",
      "Epoch 749/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0822 - accuracy: 0.9790 - val_loss: 0.3463 - val_accuracy: 0.9663\n",
      "Epoch 750/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0845 - accuracy: 0.9770 - val_loss: 0.3404 - val_accuracy: 0.9702\n",
      "Epoch 751/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9735 - val_loss: 0.3348 - val_accuracy: 0.9690\n",
      "Epoch 752/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0851 - accuracy: 0.9778 - val_loss: 0.3211 - val_accuracy: 0.9663\n",
      "Epoch 753/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9761 - val_loss: 0.3127 - val_accuracy: 0.9806\n",
      "Epoch 754/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9721 - val_loss: 0.3457 - val_accuracy: 0.9760\n",
      "Epoch 755/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0906 - accuracy: 0.9750 - val_loss: 0.3413 - val_accuracy: 0.9744\n",
      "Epoch 756/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9755 - val_loss: 0.4067 - val_accuracy: 0.9574\n",
      "Epoch 757/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9742 - val_loss: 0.3448 - val_accuracy: 0.9702\n",
      "Epoch 758/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9731 - val_loss: 0.3514 - val_accuracy: 0.9702\n",
      "Epoch 759/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9751 - val_loss: 0.3360 - val_accuracy: 0.9752\n",
      "Epoch 760/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9745 - val_loss: 0.2998 - val_accuracy: 0.9756\n",
      "Epoch 761/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9739 - val_loss: 0.3215 - val_accuracy: 0.9667\n",
      "Epoch 762/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0939 - accuracy: 0.9736 - val_loss: 0.3827 - val_accuracy: 0.9764\n",
      "Epoch 763/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9755 - val_loss: 0.3997 - val_accuracy: 0.9566\n",
      "Epoch 764/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9728 - val_loss: 0.3738 - val_accuracy: 0.9771\n",
      "Epoch 765/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9739 - val_loss: 0.3609 - val_accuracy: 0.9818\n",
      "Epoch 766/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9733 - val_loss: 0.3776 - val_accuracy: 0.9702\n",
      "Epoch 767/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9758 - val_loss: 0.3161 - val_accuracy: 0.9729\n",
      "Epoch 768/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.3318 - val_accuracy: 0.9686\n",
      "Epoch 769/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9767 - val_loss: 0.3214 - val_accuracy: 0.9698\n",
      "Epoch 770/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9756 - val_loss: 0.3301 - val_accuracy: 0.9740\n",
      "Epoch 771/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9722 - val_loss: 0.3117 - val_accuracy: 0.9779\n",
      "Epoch 772/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9741 - val_loss: 0.3202 - val_accuracy: 0.9659\n",
      "Epoch 773/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9760 - val_loss: 0.3294 - val_accuracy: 0.9752\n",
      "Epoch 774/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9717 - val_loss: 0.3598 - val_accuracy: 0.9578\n",
      "Epoch 775/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.9724 - val_loss: 0.3063 - val_accuracy: 0.9744\n",
      "Epoch 776/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9733 - val_loss: 0.2984 - val_accuracy: 0.9791\n",
      "Epoch 777/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9731 - val_loss: 0.3698 - val_accuracy: 0.9647\n",
      "Epoch 778/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.3183 - val_accuracy: 0.9787\n",
      "Epoch 779/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9743 - val_loss: 0.4400 - val_accuracy: 0.9709\n",
      "Epoch 780/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9741 - val_loss: 0.4301 - val_accuracy: 0.9686\n",
      "Epoch 781/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9744 - val_loss: 0.4491 - val_accuracy: 0.9581\n",
      "Epoch 782/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9734 - val_loss: 0.4441 - val_accuracy: 0.9643\n",
      "Epoch 783/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9752 - val_loss: 0.4563 - val_accuracy: 0.9616\n",
      "Epoch 784/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0880 - accuracy: 0.9762 - val_loss: 0.4502 - val_accuracy: 0.9733\n",
      "Epoch 785/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.4244 - val_accuracy: 0.9725\n",
      "Epoch 786/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9753 - val_loss: 0.4117 - val_accuracy: 0.9822\n",
      "Epoch 787/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0939 - accuracy: 0.9744 - val_loss: 0.4294 - val_accuracy: 0.9736\n",
      "Epoch 788/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0915 - accuracy: 0.9757 - val_loss: 0.4142 - val_accuracy: 0.9791\n",
      "Epoch 789/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9742 - val_loss: 0.4010 - val_accuracy: 0.9826\n",
      "Epoch 790/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0966 - accuracy: 0.9732 - val_loss: 0.4174 - val_accuracy: 0.9748\n",
      "Epoch 791/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9732 - val_loss: 0.3931 - val_accuracy: 0.9705\n",
      "Epoch 792/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9727 - val_loss: 0.4457 - val_accuracy: 0.9508\n",
      "Epoch 793/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9755 - val_loss: 0.4258 - val_accuracy: 0.9663\n",
      "Epoch 794/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9753 - val_loss: 0.4097 - val_accuracy: 0.9678\n",
      "Epoch 795/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9777 - val_loss: 0.3818 - val_accuracy: 0.9725\n",
      "Epoch 796/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9722 - val_loss: 0.4308 - val_accuracy: 0.9690\n",
      "Epoch 797/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.9761 - val_loss: 0.4173 - val_accuracy: 0.9628\n",
      "Epoch 798/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9740 - val_loss: 0.4158 - val_accuracy: 0.9663\n",
      "Epoch 799/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9748 - val_loss: 0.4269 - val_accuracy: 0.9709\n",
      "Epoch 800/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9723 - val_loss: 0.3997 - val_accuracy: 0.9740\n",
      "Epoch 801/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9756 - val_loss: 0.4026 - val_accuracy: 0.9686\n",
      "Epoch 802/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9759 - val_loss: 0.4303 - val_accuracy: 0.9616\n",
      "Epoch 803/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9757 - val_loss: 0.4155 - val_accuracy: 0.9678\n",
      "Epoch 804/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9746 - val_loss: 0.3996 - val_accuracy: 0.9647\n",
      "Epoch 805/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9724 - val_loss: 0.3674 - val_accuracy: 0.9764\n",
      "Epoch 806/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9730 - val_loss: 0.4284 - val_accuracy: 0.9756\n",
      "Epoch 807/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0873 - accuracy: 0.9758 - val_loss: 0.2870 - val_accuracy: 0.9624\n",
      "Epoch 808/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9744 - val_loss: 0.2623 - val_accuracy: 0.9802\n",
      "Epoch 809/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9753 - val_loss: 0.2796 - val_accuracy: 0.9698\n",
      "Epoch 810/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9728 - val_loss: 0.2663 - val_accuracy: 0.9822\n",
      "Epoch 811/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1022 - accuracy: 0.9724 - val_loss: 0.2608 - val_accuracy: 0.9787\n",
      "Epoch 812/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0868 - accuracy: 0.9748 - val_loss: 0.2845 - val_accuracy: 0.9779\n",
      "Epoch 813/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.9720 - val_loss: 0.2893 - val_accuracy: 0.9752\n",
      "Epoch 814/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9747 - val_loss: 0.3233 - val_accuracy: 0.9647\n",
      "Epoch 815/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9721 - val_loss: 0.2824 - val_accuracy: 0.9764\n",
      "Epoch 816/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9739 - val_loss: 0.3300 - val_accuracy: 0.9767\n",
      "Epoch 817/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0889 - accuracy: 0.9763 - val_loss: 0.3020 - val_accuracy: 0.9787\n",
      "Epoch 818/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0975 - accuracy: 0.9735 - val_loss: 0.3400 - val_accuracy: 0.9767\n",
      "Epoch 819/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0851 - accuracy: 0.9777 - val_loss: 0.3586 - val_accuracy: 0.9760\n",
      "Epoch 820/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9744 - val_loss: 0.3389 - val_accuracy: 0.9795\n",
      "Epoch 821/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9724 - val_loss: 0.3703 - val_accuracy: 0.9721\n",
      "Epoch 822/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9748 - val_loss: 0.3597 - val_accuracy: 0.9767\n",
      "Epoch 823/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9756 - val_loss: 0.3535 - val_accuracy: 0.9767\n",
      "Epoch 824/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9737 - val_loss: 0.3626 - val_accuracy: 0.9798\n",
      "Epoch 825/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9766 - val_loss: 0.3561 - val_accuracy: 0.9783\n",
      "Epoch 826/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9735 - val_loss: 0.3889 - val_accuracy: 0.9686\n",
      "Epoch 827/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9752 - val_loss: 0.4224 - val_accuracy: 0.9659\n",
      "Epoch 828/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9752 - val_loss: 0.3878 - val_accuracy: 0.9651\n",
      "Epoch 829/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9749 - val_loss: 0.4049 - val_accuracy: 0.9713\n",
      "Epoch 830/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9759 - val_loss: 0.4161 - val_accuracy: 0.9647\n",
      "Epoch 831/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9745 - val_loss: 0.4285 - val_accuracy: 0.9651\n",
      "Epoch 832/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9753 - val_loss: 0.4647 - val_accuracy: 0.9585\n",
      "Epoch 833/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.9760 - val_loss: 0.4150 - val_accuracy: 0.9659\n",
      "Epoch 834/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9746 - val_loss: 0.4242 - val_accuracy: 0.9640\n",
      "Epoch 835/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9733 - val_loss: 0.4992 - val_accuracy: 0.9543\n",
      "Epoch 836/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9726 - val_loss: 0.4614 - val_accuracy: 0.9667\n",
      "Epoch 837/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0822 - accuracy: 0.9780 - val_loss: 0.4036 - val_accuracy: 0.9814\n",
      "Epoch 838/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9753 - val_loss: 0.4474 - val_accuracy: 0.9562\n",
      "Epoch 839/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.9720 - val_loss: 0.4013 - val_accuracy: 0.9798\n",
      "Epoch 840/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9756 - val_loss: 0.3940 - val_accuracy: 0.9791\n",
      "Epoch 841/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9752 - val_loss: 0.4374 - val_accuracy: 0.9729\n",
      "Epoch 842/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9758 - val_loss: 0.4600 - val_accuracy: 0.9705\n",
      "Epoch 843/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.9753 - val_loss: 0.4065 - val_accuracy: 0.9791\n",
      "Epoch 844/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.9771 - val_loss: 0.3865 - val_accuracy: 0.9857\n",
      "Epoch 845/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9742 - val_loss: 0.3809 - val_accuracy: 0.9798\n",
      "Epoch 846/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0915 - accuracy: 0.9758 - val_loss: 0.5050 - val_accuracy: 0.9578\n",
      "Epoch 847/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9746 - val_loss: 0.5761 - val_accuracy: 0.9562\n",
      "Epoch 848/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9716 - val_loss: 0.4967 - val_accuracy: 0.9733\n",
      "Epoch 849/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9779 - val_loss: 0.4903 - val_accuracy: 0.9779\n",
      "Epoch 850/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9744 - val_loss: 0.5121 - val_accuracy: 0.9636\n",
      "Epoch 851/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0827 - accuracy: 0.9771 - val_loss: 0.4950 - val_accuracy: 0.9752\n",
      "Epoch 852/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9748 - val_loss: 0.5136 - val_accuracy: 0.9725\n",
      "Epoch 853/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0878 - accuracy: 0.9761 - val_loss: 0.5593 - val_accuracy: 0.9671\n",
      "Epoch 854/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9746 - val_loss: 0.5667 - val_accuracy: 0.9593\n",
      "Epoch 855/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9724 - val_loss: 0.4906 - val_accuracy: 0.9764\n",
      "Epoch 856/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0797 - accuracy: 0.9788 - val_loss: 0.5004 - val_accuracy: 0.9717\n",
      "Epoch 857/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9762 - val_loss: 0.5145 - val_accuracy: 0.9740\n",
      "Epoch 858/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9746 - val_loss: 0.4811 - val_accuracy: 0.9771\n",
      "Epoch 859/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9736 - val_loss: 0.4740 - val_accuracy: 0.9802\n",
      "Epoch 860/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0844 - accuracy: 0.9775 - val_loss: 0.4799 - val_accuracy: 0.9764\n",
      "Epoch 861/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9743 - val_loss: 0.4836 - val_accuracy: 0.9756\n",
      "Epoch 862/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9773 - val_loss: 0.4769 - val_accuracy: 0.9771\n",
      "Epoch 863/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9751 - val_loss: 0.4832 - val_accuracy: 0.9729\n",
      "Epoch 864/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.7797 - val_accuracy: 0.9178\n",
      "Epoch 865/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9740 - val_loss: 0.4755 - val_accuracy: 0.9713\n",
      "Epoch 866/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9755 - val_loss: 0.4536 - val_accuracy: 0.9814\n",
      "Epoch 867/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0921 - accuracy: 0.9747 - val_loss: 0.4635 - val_accuracy: 0.9826\n",
      "Epoch 868/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9760 - val_loss: 0.4874 - val_accuracy: 0.9705\n",
      "Epoch 869/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9748 - val_loss: 0.4423 - val_accuracy: 0.9857\n",
      "Epoch 870/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9751 - val_loss: 0.4845 - val_accuracy: 0.9752\n",
      "Epoch 871/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9751 - val_loss: 0.5469 - val_accuracy: 0.9589\n",
      "Epoch 872/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9757 - val_loss: 0.5213 - val_accuracy: 0.9694\n",
      "Epoch 873/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 0.5080 - val_accuracy: 0.9764\n",
      "Epoch 874/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9754 - val_loss: 0.4903 - val_accuracy: 0.9779\n",
      "Epoch 875/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9743 - val_loss: 0.4624 - val_accuracy: 0.9744\n",
      "Epoch 876/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9762 - val_loss: 0.4467 - val_accuracy: 0.9791\n",
      "Epoch 877/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9754 - val_loss: 0.4742 - val_accuracy: 0.9810\n",
      "Epoch 878/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9764 - val_loss: 0.5198 - val_accuracy: 0.9589\n",
      "Epoch 879/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9727 - val_loss: 0.5278 - val_accuracy: 0.9810\n",
      "Epoch 880/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9752 - val_loss: 0.5124 - val_accuracy: 0.9868\n",
      "Epoch 881/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9724 - val_loss: 0.5373 - val_accuracy: 0.9791\n",
      "Epoch 882/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.5509 - val_accuracy: 0.9744\n",
      "Epoch 883/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0826 - accuracy: 0.9775 - val_loss: 0.5271 - val_accuracy: 0.9764\n",
      "Epoch 884/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9754 - val_loss: 0.5374 - val_accuracy: 0.9810\n",
      "Epoch 885/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9741 - val_loss: 0.5566 - val_accuracy: 0.9736\n",
      "Epoch 886/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0881 - accuracy: 0.9754 - val_loss: 0.5235 - val_accuracy: 0.9798\n",
      "Epoch 887/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9763 - val_loss: 0.5170 - val_accuracy: 0.9752\n",
      "Epoch 888/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9733 - val_loss: 0.4925 - val_accuracy: 0.9787\n",
      "Epoch 889/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9744 - val_loss: 0.4934 - val_accuracy: 0.9779\n",
      "Epoch 890/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.9759 - val_loss: 0.4686 - val_accuracy: 0.9822\n",
      "Epoch 891/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9731 - val_loss: 0.5771 - val_accuracy: 0.9609\n",
      "Epoch 892/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9746 - val_loss: 0.5115 - val_accuracy: 0.9791\n",
      "Epoch 893/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9772 - val_loss: 0.5663 - val_accuracy: 0.9655\n",
      "Epoch 894/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9749 - val_loss: 0.5451 - val_accuracy: 0.9826\n",
      "Epoch 895/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9769 - val_loss: 0.5523 - val_accuracy: 0.9775\n",
      "Epoch 896/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0961 - accuracy: 0.9747 - val_loss: 0.5736 - val_accuracy: 0.9663\n",
      "Epoch 897/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9756 - val_loss: 0.5518 - val_accuracy: 0.9760\n",
      "Epoch 898/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9729 - val_loss: 0.5271 - val_accuracy: 0.9849\n",
      "Epoch 899/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 0.5284 - val_accuracy: 0.9779\n",
      "Epoch 900/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9761 - val_loss: 0.5112 - val_accuracy: 0.9760\n",
      "Epoch 901/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9770 - val_loss: 0.5436 - val_accuracy: 0.9709\n",
      "Epoch 902/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9749 - val_loss: 0.5862 - val_accuracy: 0.9616\n",
      "Epoch 903/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9763 - val_loss: 0.5996 - val_accuracy: 0.9527\n",
      "Epoch 904/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9740 - val_loss: 0.5261 - val_accuracy: 0.9806\n",
      "Epoch 905/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0876 - accuracy: 0.9756 - val_loss: 0.5253 - val_accuracy: 0.9798\n",
      "Epoch 906/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9748 - val_loss: 0.5315 - val_accuracy: 0.9771\n",
      "Epoch 907/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0854 - accuracy: 0.9763 - val_loss: 0.5336 - val_accuracy: 0.9833\n",
      "Epoch 908/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9761 - val_loss: 0.5743 - val_accuracy: 0.9705\n",
      "Epoch 909/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9748 - val_loss: 0.5724 - val_accuracy: 0.9651\n",
      "Epoch 910/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9755 - val_loss: 0.5196 - val_accuracy: 0.9767\n",
      "Epoch 911/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0906 - accuracy: 0.9747 - val_loss: 0.6489 - val_accuracy: 0.9388\n",
      "Epoch 912/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9720 - val_loss: 0.5870 - val_accuracy: 0.9659\n",
      "Epoch 913/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0811 - accuracy: 0.9785 - val_loss: 0.3736 - val_accuracy: 0.9814\n",
      "Epoch 914/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9767 - val_loss: 0.4182 - val_accuracy: 0.9729\n",
      "Epoch 915/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9756 - val_loss: 0.4230 - val_accuracy: 0.9721\n",
      "Epoch 916/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9750 - val_loss: 0.4147 - val_accuracy: 0.9767\n",
      "Epoch 917/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.4144 - val_accuracy: 0.9702\n",
      "Epoch 918/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0820 - accuracy: 0.9767 - val_loss: 0.3905 - val_accuracy: 0.9822\n",
      "Epoch 919/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9742 - val_loss: 0.4656 - val_accuracy: 0.9686\n",
      "Epoch 920/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.9768 - val_loss: 0.4586 - val_accuracy: 0.9686\n",
      "Epoch 921/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0880 - accuracy: 0.9754 - val_loss: 0.4262 - val_accuracy: 0.9760\n",
      "Epoch 922/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9724 - val_loss: 0.4761 - val_accuracy: 0.9713\n",
      "Epoch 923/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.4427 - val_accuracy: 0.9787\n",
      "Epoch 924/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9755 - val_loss: 0.4429 - val_accuracy: 0.9829\n",
      "Epoch 925/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0906 - accuracy: 0.9750 - val_loss: 0.4433 - val_accuracy: 0.9837\n",
      "Epoch 926/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.4015 - val_accuracy: 0.9849\n",
      "Epoch 927/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.4998 - val_accuracy: 0.9531\n",
      "Epoch 928/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9755 - val_loss: 0.3969 - val_accuracy: 0.9795\n",
      "Epoch 929/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0878 - accuracy: 0.9752 - val_loss: 0.3896 - val_accuracy: 0.9764\n",
      "Epoch 930/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9738 - val_loss: 0.3687 - val_accuracy: 0.9841\n",
      "Epoch 931/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9743 - val_loss: 0.4019 - val_accuracy: 0.9686\n",
      "Epoch 932/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9750 - val_loss: 0.4277 - val_accuracy: 0.9713\n",
      "Epoch 933/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0846 - accuracy: 0.9768 - val_loss: 0.4166 - val_accuracy: 0.9713\n",
      "Epoch 934/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9753 - val_loss: 0.3961 - val_accuracy: 0.9833\n",
      "Epoch 935/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 0.4046 - val_accuracy: 0.9752\n",
      "Epoch 936/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9742 - val_loss: 0.4098 - val_accuracy: 0.9744\n",
      "Epoch 937/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0868 - accuracy: 0.9752 - val_loss: 0.5375 - val_accuracy: 0.9453\n",
      "Epoch 938/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9735 - val_loss: 0.4014 - val_accuracy: 0.9787\n",
      "Epoch 939/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9776 - val_loss: 0.4726 - val_accuracy: 0.9562\n",
      "Epoch 940/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9731 - val_loss: 0.4551 - val_accuracy: 0.9605\n",
      "Epoch 941/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0868 - accuracy: 0.9751 - val_loss: 0.3842 - val_accuracy: 0.9744\n",
      "Epoch 942/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9733 - val_loss: 0.3820 - val_accuracy: 0.9826\n",
      "Epoch 943/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9773 - val_loss: 0.4232 - val_accuracy: 0.9698\n",
      "Epoch 944/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9762 - val_loss: 0.3682 - val_accuracy: 0.9876\n",
      "Epoch 945/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0883 - accuracy: 0.9755 - val_loss: 0.4321 - val_accuracy: 0.9729\n",
      "Epoch 946/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9759 - val_loss: 0.4009 - val_accuracy: 0.9853\n",
      "Epoch 947/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0855 - accuracy: 0.9773 - val_loss: 0.4273 - val_accuracy: 0.9721\n",
      "Epoch 948/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0816 - accuracy: 0.9773 - val_loss: 0.4271 - val_accuracy: 0.9756\n",
      "Epoch 949/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9767 - val_loss: 0.3787 - val_accuracy: 0.9818\n",
      "Epoch 950/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9758 - val_loss: 0.4288 - val_accuracy: 0.9779\n",
      "Epoch 951/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9743 - val_loss: 0.4885 - val_accuracy: 0.9632\n",
      "Epoch 952/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9766 - val_loss: 0.4141 - val_accuracy: 0.9682\n",
      "Epoch 953/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9739 - val_loss: 0.3822 - val_accuracy: 0.9620\n",
      "Epoch 954/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9765 - val_loss: 0.3567 - val_accuracy: 0.9717\n",
      "Epoch 955/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9759 - val_loss: 0.4073 - val_accuracy: 0.9841\n",
      "Epoch 956/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0773 - accuracy: 0.9798 - val_loss: 0.4621 - val_accuracy: 0.9678\n",
      "Epoch 957/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 0.4770 - val_accuracy: 0.9628\n",
      "Epoch 958/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0802 - accuracy: 0.9782 - val_loss: 0.4380 - val_accuracy: 0.9806\n",
      "Epoch 959/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9757 - val_loss: 0.4584 - val_accuracy: 0.9744\n",
      "Epoch 960/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9760 - val_loss: 0.4545 - val_accuracy: 0.9682\n",
      "Epoch 961/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9758 - val_loss: 0.4465 - val_accuracy: 0.9868\n",
      "Epoch 962/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.4573 - val_accuracy: 0.9725\n",
      "Epoch 963/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9758 - val_loss: 0.4228 - val_accuracy: 0.9829\n",
      "Epoch 964/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9752 - val_loss: 0.4546 - val_accuracy: 0.9713\n",
      "Epoch 965/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9741 - val_loss: 0.4083 - val_accuracy: 0.9806\n",
      "Epoch 966/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9790 - val_loss: 0.4937 - val_accuracy: 0.9550\n",
      "Epoch 967/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9750 - val_loss: 0.4191 - val_accuracy: 0.9736\n",
      "Epoch 968/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9743 - val_loss: 0.4658 - val_accuracy: 0.9620\n",
      "Epoch 969/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9759 - val_loss: 0.4226 - val_accuracy: 0.9783\n",
      "Epoch 970/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9744 - val_loss: 0.4962 - val_accuracy: 0.9760\n",
      "Epoch 971/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0808 - accuracy: 0.9772 - val_loss: 0.4720 - val_accuracy: 0.9767\n",
      "Epoch 972/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0823 - accuracy: 0.9779 - val_loss: 0.7764 - val_accuracy: 0.9194\n",
      "Epoch 973/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9763 - val_loss: 0.5172 - val_accuracy: 0.9663\n",
      "Epoch 974/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9772 - val_loss: 0.5303 - val_accuracy: 0.9624\n",
      "Epoch 975/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9755 - val_loss: 0.5738 - val_accuracy: 0.9562\n",
      "Epoch 976/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9724 - val_loss: 0.4892 - val_accuracy: 0.9709\n",
      "Epoch 977/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0939 - accuracy: 0.9731 - val_loss: 0.4578 - val_accuracy: 0.9810\n",
      "Epoch 978/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9761 - val_loss: 0.3723 - val_accuracy: 0.9581\n",
      "Epoch 979/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0802 - accuracy: 0.9773 - val_loss: 0.3525 - val_accuracy: 0.9647\n",
      "Epoch 980/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9743 - val_loss: 0.3583 - val_accuracy: 0.9663\n",
      "Epoch 981/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9750 - val_loss: 0.4612 - val_accuracy: 0.9581\n",
      "Epoch 982/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9751 - val_loss: 0.4480 - val_accuracy: 0.9783\n",
      "Epoch 983/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0831 - accuracy: 0.9771 - val_loss: 0.4962 - val_accuracy: 0.9616\n",
      "Epoch 984/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9730 - val_loss: 0.4428 - val_accuracy: 0.9795\n",
      "Epoch 985/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.4500 - val_accuracy: 0.9760\n",
      "Epoch 986/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9777 - val_loss: 0.5333 - val_accuracy: 0.9550\n",
      "Epoch 987/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.5338 - val_accuracy: 0.9539\n",
      "Epoch 988/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9757 - val_loss: 0.5079 - val_accuracy: 0.9597\n",
      "Epoch 989/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0863 - accuracy: 0.9765 - val_loss: 0.4192 - val_accuracy: 0.9837\n",
      "Epoch 990/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9770 - val_loss: 0.4910 - val_accuracy: 0.9612\n",
      "Epoch 991/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9759 - val_loss: 0.4441 - val_accuracy: 0.9682\n",
      "Epoch 992/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9735 - val_loss: 0.4810 - val_accuracy: 0.9616\n",
      "Epoch 993/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9757 - val_loss: 0.4637 - val_accuracy: 0.9667\n",
      "Epoch 994/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9766 - val_loss: 0.4370 - val_accuracy: 0.9709\n",
      "Epoch 995/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0846 - accuracy: 0.9774 - val_loss: 0.4641 - val_accuracy: 0.9806\n",
      "Epoch 996/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0820 - accuracy: 0.9764 - val_loss: 0.4535 - val_accuracy: 0.9756\n",
      "Epoch 997/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0844 - accuracy: 0.9752 - val_loss: 0.5251 - val_accuracy: 0.9628\n",
      "Epoch 998/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.9752 - val_loss: 0.4621 - val_accuracy: 0.9767\n",
      "Epoch 999/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0917 - accuracy: 0.9745 - val_loss: 0.4836 - val_accuracy: 0.9872\n",
      "Epoch 1000/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0855 - accuracy: 0.9757 - val_loss: 0.4938 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses, leaky_re_lu_4_layer_call_fn, leaky_re_lu_4_layer_call_and_return_conditional_losses, leaky_re_lu_5_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\exp_class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\exp_class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 13s, sys: 3min 14s, total: 26min 28s\n",
      "Wall time: 12min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models\\\\exp_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d48b8bb-4050-4e4e-9b5d-f544ec904945",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29de131-b034-4c2b-af37-24c452d2eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb94e0-76ea-48a8-9201-bb3798b826a2",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380a789e-6c82-431c-bc0d-61f8c449e71a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.95      1.00      0.97        18\n",
      "           2       1.00      0.91      0.95        23\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        23\n",
      "           5       1.00      0.65      0.79        20\n",
      "           6       1.00      1.00      1.00        23\n",
      "           7       0.96      1.00      0.98        25\n",
      "           8       1.00      1.00      1.00        25\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       0.79      0.96      0.86        23\n",
      "          11       1.00      0.94      0.97        17\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        31\n",
      "          14       1.00      1.00      1.00        30\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        25\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       0.95      0.90      0.92        20\n",
      "          19       1.00      1.00      1.00        16\n",
      "          20       1.00      1.00      1.00        19\n",
      "          21       1.00      1.00      1.00        21\n",
      "          22       1.00      1.00      1.00        18\n",
      "          23       1.00      1.00      1.00        14\n",
      "          24       1.00      0.90      0.95        21\n",
      "          25       1.00      0.95      0.98        21\n",
      "          26       1.00      1.00      1.00        13\n",
      "          27       1.00      0.96      0.98        25\n",
      "          28       0.96      1.00      0.98        27\n",
      "          29       1.00      1.00      1.00        24\n",
      "          30       1.00      1.00      1.00        21\n",
      "          31       1.00      0.95      0.98        21\n",
      "          32       1.00      0.94      0.97        18\n",
      "          33       1.00      1.00      1.00        22\n",
      "          34       0.55      1.00      0.71        18\n",
      "          35       1.00      1.00      1.00        10\n",
      "          36       1.00      1.00      1.00        27\n",
      "          37       0.95      1.00      0.98        21\n",
      "          38       1.00      0.95      0.97        20\n",
      "          39       1.00      1.00      1.00        15\n",
      "          40       1.00      0.95      0.97        19\n",
      "          41       0.92      1.00      0.96        12\n",
      "          42       1.00      1.00      1.00        30\n",
      "          43       0.95      0.84      0.89        25\n",
      "          44       1.00      1.00      1.00        22\n",
      "          45       1.00      0.96      0.98        23\n",
      "          46       1.00      1.00      1.00        14\n",
      "          47       1.00      1.00      1.00        17\n",
      "          48       1.00      1.00      1.00        20\n",
      "          49       1.00      0.95      0.98        21\n",
      "          50       0.96      1.00      0.98        25\n",
      "          51       1.00      1.00      1.00        22\n",
      "          52       0.94      0.89      0.91        18\n",
      "          53       1.00      1.00      1.00        25\n",
      "          54       0.96      1.00      0.98        22\n",
      "          55       1.00      1.00      1.00        13\n",
      "          56       1.00      1.00      1.00        21\n",
      "          57       1.00      1.00      1.00        28\n",
      "          58       0.93      1.00      0.97        14\n",
      "          59       1.00      1.00      1.00        26\n",
      "          60       1.00      1.00      1.00        17\n",
      "          61       1.00      1.00      1.00        16\n",
      "          62       1.00      1.00      1.00        17\n",
      "          63       1.00      1.00      1.00        25\n",
      "          64       1.00      1.00      1.00        13\n",
      "          65       1.00      1.00      1.00        17\n",
      "          66       1.00      0.95      0.97        20\n",
      "          67       1.00      1.00      1.00        12\n",
      "          68       1.00      1.00      1.00        21\n",
      "          69       1.00      1.00      1.00        18\n",
      "          70       1.00      1.00      1.00        14\n",
      "          71       1.00      1.00      1.00        19\n",
      "          72       1.00      1.00      1.00        11\n",
      "          73       1.00      1.00      1.00        20\n",
      "          74       0.96      1.00      0.98        23\n",
      "          75       1.00      1.00      1.00        27\n",
      "          76       1.00      1.00      1.00        23\n",
      "          77       0.95      0.95      0.95        21\n",
      "          78       0.77      1.00      0.87        20\n",
      "          79       1.00      1.00      1.00        24\n",
      "          80       1.00      1.00      1.00        19\n",
      "          81       1.00      1.00      1.00        14\n",
      "          82       1.00      1.00      1.00        20\n",
      "          83       1.00      1.00      1.00        20\n",
      "          84       0.92      0.96      0.94        23\n",
      "          85       1.00      1.00      1.00        23\n",
      "          86       1.00      1.00      1.00        19\n",
      "          87       0.95      1.00      0.98        20\n",
      "          88       1.00      1.00      1.00        19\n",
      "          89       1.00      1.00      1.00        20\n",
      "          90       1.00      1.00      1.00        22\n",
      "          91       1.00      1.00      1.00        19\n",
      "          92       1.00      1.00      1.00        12\n",
      "          93       1.00      1.00      1.00        19\n",
      "          94       0.89      1.00      0.94        25\n",
      "          95       1.00      1.00      1.00        17\n",
      "          96       1.00      0.93      0.96        28\n",
      "          97       1.00      0.95      0.97        19\n",
      "          98       1.00      1.00      1.00        21\n",
      "          99       1.00      0.96      0.98        24\n",
      "         100       1.00      0.87      0.93        15\n",
      "         101       1.00      0.94      0.97        17\n",
      "         102       1.00      1.00      1.00        25\n",
      "         103       1.00      1.00      1.00        21\n",
      "         104       1.00      0.88      0.93        16\n",
      "         105       1.00      0.93      0.97        15\n",
      "         106       1.00      1.00      1.00        15\n",
      "         107       1.00      1.00      1.00        18\n",
      "         108       1.00      0.95      0.98        22\n",
      "         109       1.00      1.00      1.00        23\n",
      "         110       1.00      1.00      1.00        28\n",
      "         111       1.00      1.00      1.00        24\n",
      "         112       1.00      1.00      1.00        17\n",
      "         113       1.00      0.84      0.91        19\n",
      "         114       1.00      1.00      1.00        14\n",
      "         115       0.69      0.95      0.80        19\n",
      "         116       1.00      1.00      1.00        17\n",
      "         117       1.00      1.00      1.00        11\n",
      "         118       0.84      0.94      0.89        17\n",
      "         119       1.00      0.68      0.81        25\n",
      "         120       1.00      0.95      0.98        22\n",
      "         121       0.96      0.96      0.96        28\n",
      "         122       1.00      1.00      1.00        14\n",
      "         123       1.00      1.00      1.00        18\n",
      "         124       1.00      1.00      1.00        24\n",
      "         125       1.00      1.00      1.00        16\n",
      "         126       0.94      1.00      0.97        17\n",
      "         127       1.00      0.95      0.98        22\n",
      "         128       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           0.98      2580\n",
      "   macro avg       0.98      0.98      0.98      2580\n",
      "weighted avg       0.98      0.98      0.98      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f47756-08c1-4e9a-a4db-0247f8432987",
   "metadata": {},
   "source": [
    "<h1>Sigmoid-like Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0488ffb-1f97-4d2a-962d-2d5b6c1de260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.read_csv('input/results_complete_sigmoid_like.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a69a9e2-9c1a-460d-8ee0-0b0906b8f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sig.drop(['elem_damaged', 'damage'], axis=1), df_sig['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4725a8a-f537-49c8-b452-b67189a6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29a28008-ffff-418d-862c-e3b1f4a69826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 80)                10160     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 129)               10449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,569\n",
      "Trainable params: 33,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.8159 - accuracy: 0.0324 - val_loss: 4.6631 - val_accuracy: 0.0496\n",
      "Epoch 2/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.4376 - accuracy: 0.0758 - val_loss: 4.2798 - val_accuracy: 0.0884\n",
      "Epoch 3/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.0770 - accuracy: 0.1128 - val_loss: 3.9793 - val_accuracy: 0.1174\n",
      "Epoch 4/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.7905 - accuracy: 0.1501 - val_loss: 3.7258 - val_accuracy: 0.1581\n",
      "Epoch 5/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.5599 - accuracy: 0.1802 - val_loss: 3.5268 - val_accuracy: 0.1818\n",
      "Epoch 6/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.3792 - accuracy: 0.2065 - val_loss: 3.3668 - val_accuracy: 0.2109\n",
      "Epoch 7/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.2344 - accuracy: 0.2273 - val_loss: 3.2377 - val_accuracy: 0.2283\n",
      "Epoch 8/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.1191 - accuracy: 0.2390 - val_loss: 3.1401 - val_accuracy: 0.2217\n",
      "Epoch 9/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.0220 - accuracy: 0.2546 - val_loss: 3.0436 - val_accuracy: 0.2372\n",
      "Epoch 10/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.9365 - accuracy: 0.2654 - val_loss: 2.9631 - val_accuracy: 0.2531\n",
      "Epoch 11/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.8656 - accuracy: 0.2748 - val_loss: 2.8949 - val_accuracy: 0.2682\n",
      "Epoch 12/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.8062 - accuracy: 0.2835 - val_loss: 2.8443 - val_accuracy: 0.2841\n",
      "Epoch 13/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.7572 - accuracy: 0.2953 - val_loss: 2.7883 - val_accuracy: 0.2950\n",
      "Epoch 14/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.7109 - accuracy: 0.2997 - val_loss: 2.7466 - val_accuracy: 0.2961\n",
      "Epoch 15/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.6669 - accuracy: 0.3105 - val_loss: 2.7084 - val_accuracy: 0.3031\n",
      "Epoch 16/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.6250 - accuracy: 0.3160 - val_loss: 2.6715 - val_accuracy: 0.3140\n",
      "Epoch 17/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.5846 - accuracy: 0.3281 - val_loss: 2.6342 - val_accuracy: 0.3190\n",
      "Epoch 18/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.5466 - accuracy: 0.3346 - val_loss: 2.6039 - val_accuracy: 0.3070\n",
      "Epoch 19/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.5177 - accuracy: 0.3413 - val_loss: 2.5653 - val_accuracy: 0.3213\n",
      "Epoch 20/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4830 - accuracy: 0.3454 - val_loss: 2.5401 - val_accuracy: 0.3453\n",
      "Epoch 21/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4577 - accuracy: 0.3561 - val_loss: 2.5120 - val_accuracy: 0.3411\n",
      "Epoch 22/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4298 - accuracy: 0.3616 - val_loss: 2.4986 - val_accuracy: 0.3481\n",
      "Epoch 23/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4070 - accuracy: 0.3707 - val_loss: 2.4665 - val_accuracy: 0.3539\n",
      "Epoch 24/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3814 - accuracy: 0.3762 - val_loss: 2.4777 - val_accuracy: 0.3597\n",
      "Epoch 25/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3594 - accuracy: 0.3797 - val_loss: 2.4172 - val_accuracy: 0.3740\n",
      "Epoch 26/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3408 - accuracy: 0.3853 - val_loss: 2.4065 - val_accuracy: 0.3628\n",
      "Epoch 27/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3169 - accuracy: 0.3927 - val_loss: 2.3871 - val_accuracy: 0.3736\n",
      "Epoch 28/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2978 - accuracy: 0.3945 - val_loss: 2.3642 - val_accuracy: 0.3818\n",
      "Epoch 29/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2770 - accuracy: 0.4016 - val_loss: 2.3495 - val_accuracy: 0.4012\n",
      "Epoch 30/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2618 - accuracy: 0.4043 - val_loss: 2.3392 - val_accuracy: 0.3795\n",
      "Epoch 31/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2418 - accuracy: 0.4121 - val_loss: 2.3083 - val_accuracy: 0.4085\n",
      "Epoch 32/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2254 - accuracy: 0.4189 - val_loss: 2.2985 - val_accuracy: 0.4043\n",
      "Epoch 33/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2081 - accuracy: 0.4170 - val_loss: 2.2856 - val_accuracy: 0.4016\n",
      "Epoch 34/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1909 - accuracy: 0.4238 - val_loss: 2.2781 - val_accuracy: 0.4031\n",
      "Epoch 35/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1760 - accuracy: 0.4273 - val_loss: 2.2580 - val_accuracy: 0.4012\n",
      "Epoch 36/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1597 - accuracy: 0.4329 - val_loss: 2.2432 - val_accuracy: 0.4089\n",
      "Epoch 37/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1431 - accuracy: 0.4358 - val_loss: 2.2303 - val_accuracy: 0.4380\n",
      "Epoch 38/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1301 - accuracy: 0.4397 - val_loss: 2.2008 - val_accuracy: 0.4322\n",
      "Epoch 39/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1141 - accuracy: 0.4477 - val_loss: 2.1921 - val_accuracy: 0.4140\n",
      "Epoch 40/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1055 - accuracy: 0.4469 - val_loss: 2.1971 - val_accuracy: 0.4143\n",
      "Epoch 41/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0976 - accuracy: 0.4534 - val_loss: 2.1799 - val_accuracy: 0.4221\n",
      "Epoch 42/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0762 - accuracy: 0.4594 - val_loss: 2.1609 - val_accuracy: 0.4438\n",
      "Epoch 43/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0639 - accuracy: 0.4595 - val_loss: 2.1678 - val_accuracy: 0.4473\n",
      "Epoch 44/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0540 - accuracy: 0.4667 - val_loss: 2.1450 - val_accuracy: 0.4426\n",
      "Epoch 45/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0404 - accuracy: 0.4652 - val_loss: 2.1345 - val_accuracy: 0.4477\n",
      "Epoch 46/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0287 - accuracy: 0.4714 - val_loss: 2.1213 - val_accuracy: 0.4516\n",
      "Epoch 47/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0186 - accuracy: 0.4665 - val_loss: 2.1077 - val_accuracy: 0.4562\n",
      "Epoch 48/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0050 - accuracy: 0.4719 - val_loss: 2.1103 - val_accuracy: 0.4469\n",
      "Epoch 49/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9935 - accuracy: 0.4798 - val_loss: 2.1045 - val_accuracy: 0.4578\n",
      "Epoch 50/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9894 - accuracy: 0.4776 - val_loss: 2.0823 - val_accuracy: 0.4597\n",
      "Epoch 51/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9706 - accuracy: 0.4813 - val_loss: 2.0826 - val_accuracy: 0.4717\n",
      "Epoch 52/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9605 - accuracy: 0.4841 - val_loss: 2.0470 - val_accuracy: 0.4616\n",
      "Epoch 53/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9496 - accuracy: 0.4872 - val_loss: 2.0415 - val_accuracy: 0.4624\n",
      "Epoch 54/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9373 - accuracy: 0.4913 - val_loss: 2.0349 - val_accuracy: 0.4814\n",
      "Epoch 55/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9299 - accuracy: 0.4929 - val_loss: 2.0195 - val_accuracy: 0.4744\n",
      "Epoch 56/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9201 - accuracy: 0.4952 - val_loss: 2.0190 - val_accuracy: 0.4779\n",
      "Epoch 57/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9067 - accuracy: 0.5004 - val_loss: 1.9981 - val_accuracy: 0.4911\n",
      "Epoch 58/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8977 - accuracy: 0.5002 - val_loss: 2.0036 - val_accuracy: 0.4899\n",
      "Epoch 59/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8845 - accuracy: 0.5062 - val_loss: 2.0230 - val_accuracy: 0.4876\n",
      "Epoch 60/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8776 - accuracy: 0.5056 - val_loss: 2.0438 - val_accuracy: 0.4795\n",
      "Epoch 61/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8677 - accuracy: 0.5092 - val_loss: 1.9735 - val_accuracy: 0.4891\n",
      "Epoch 62/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8614 - accuracy: 0.5099 - val_loss: 1.9817 - val_accuracy: 0.4961\n",
      "Epoch 63/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8503 - accuracy: 0.5134 - val_loss: 1.9716 - val_accuracy: 0.4833\n",
      "Epoch 64/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8418 - accuracy: 0.5208 - val_loss: 1.9586 - val_accuracy: 0.4822\n",
      "Epoch 65/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8309 - accuracy: 0.5200 - val_loss: 1.9461 - val_accuracy: 0.5209\n",
      "Epoch 66/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8232 - accuracy: 0.5236 - val_loss: 1.9477 - val_accuracy: 0.4864\n",
      "Epoch 67/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8176 - accuracy: 0.5232 - val_loss: 1.9261 - val_accuracy: 0.5027\n",
      "Epoch 68/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8091 - accuracy: 0.5218 - val_loss: 1.9302 - val_accuracy: 0.5043\n",
      "Epoch 69/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7997 - accuracy: 0.5237 - val_loss: 1.9118 - val_accuracy: 0.5066\n",
      "Epoch 70/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7927 - accuracy: 0.5289 - val_loss: 1.9049 - val_accuracy: 0.5124\n",
      "Epoch 71/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7830 - accuracy: 0.5321 - val_loss: 1.9122 - val_accuracy: 0.5062\n",
      "Epoch 72/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7759 - accuracy: 0.5368 - val_loss: 1.9007 - val_accuracy: 0.5198\n",
      "Epoch 73/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7663 - accuracy: 0.5339 - val_loss: 1.9113 - val_accuracy: 0.4973\n",
      "Epoch 74/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7686 - accuracy: 0.5357 - val_loss: 1.8669 - val_accuracy: 0.5240\n",
      "Epoch 75/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7515 - accuracy: 0.5385 - val_loss: 1.8867 - val_accuracy: 0.5473\n",
      "Epoch 76/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7520 - accuracy: 0.5396 - val_loss: 1.8764 - val_accuracy: 0.5248\n",
      "Epoch 77/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7383 - accuracy: 0.5474 - val_loss: 1.8810 - val_accuracy: 0.5326\n",
      "Epoch 78/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7312 - accuracy: 0.5501 - val_loss: 1.8698 - val_accuracy: 0.5109\n",
      "Epoch 79/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7266 - accuracy: 0.5500 - val_loss: 1.8611 - val_accuracy: 0.5217\n",
      "Epoch 80/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7206 - accuracy: 0.5484 - val_loss: 1.8562 - val_accuracy: 0.5384\n",
      "Epoch 81/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7155 - accuracy: 0.5526 - val_loss: 1.8630 - val_accuracy: 0.5225\n",
      "Epoch 82/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7106 - accuracy: 0.5533 - val_loss: 1.8593 - val_accuracy: 0.5178\n",
      "Epoch 83/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7024 - accuracy: 0.5580 - val_loss: 1.8560 - val_accuracy: 0.5244\n",
      "Epoch 84/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6950 - accuracy: 0.5528 - val_loss: 1.8444 - val_accuracy: 0.5229\n",
      "Epoch 85/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6912 - accuracy: 0.5572 - val_loss: 1.8329 - val_accuracy: 0.5422\n",
      "Epoch 86/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6842 - accuracy: 0.5592 - val_loss: 1.8374 - val_accuracy: 0.5329\n",
      "Epoch 87/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6755 - accuracy: 0.5614 - val_loss: 1.8301 - val_accuracy: 0.5516\n",
      "Epoch 88/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6690 - accuracy: 0.5657 - val_loss: 1.8254 - val_accuracy: 0.5450\n",
      "Epoch 89/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6603 - accuracy: 0.5662 - val_loss: 1.7978 - val_accuracy: 0.5430\n",
      "Epoch 90/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6563 - accuracy: 0.5700 - val_loss: 1.8008 - val_accuracy: 0.5391\n",
      "Epoch 91/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6500 - accuracy: 0.5678 - val_loss: 1.7921 - val_accuracy: 0.5477\n",
      "Epoch 92/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6457 - accuracy: 0.5720 - val_loss: 1.8019 - val_accuracy: 0.5527\n",
      "Epoch 93/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6408 - accuracy: 0.5721 - val_loss: 1.8067 - val_accuracy: 0.5391\n",
      "Epoch 94/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6303 - accuracy: 0.5764 - val_loss: 1.7719 - val_accuracy: 0.5570\n",
      "Epoch 95/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6260 - accuracy: 0.5757 - val_loss: 1.7610 - val_accuracy: 0.5628\n",
      "Epoch 96/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6202 - accuracy: 0.5773 - val_loss: 1.7709 - val_accuracy: 0.5399\n",
      "Epoch 97/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.5810 - val_loss: 1.7874 - val_accuracy: 0.5388\n",
      "Epoch 98/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6124 - accuracy: 0.5810 - val_loss: 1.7680 - val_accuracy: 0.5562\n",
      "Epoch 99/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6030 - accuracy: 0.5813 - val_loss: 1.7717 - val_accuracy: 0.5647\n",
      "Epoch 100/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6007 - accuracy: 0.5826 - val_loss: 1.7581 - val_accuracy: 0.5682\n",
      "Epoch 101/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5924 - accuracy: 0.5857 - val_loss: 1.7443 - val_accuracy: 0.5764\n",
      "Epoch 102/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5898 - accuracy: 0.5856 - val_loss: 1.7401 - val_accuracy: 0.5729\n",
      "Epoch 103/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5846 - accuracy: 0.5873 - val_loss: 1.7637 - val_accuracy: 0.5655\n",
      "Epoch 104/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5806 - accuracy: 0.5885 - val_loss: 1.7126 - val_accuracy: 0.5686\n",
      "Epoch 105/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5737 - accuracy: 0.5907 - val_loss: 1.7308 - val_accuracy: 0.5783\n",
      "Epoch 106/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5665 - accuracy: 0.5917 - val_loss: 1.7130 - val_accuracy: 0.5798\n",
      "Epoch 107/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5621 - accuracy: 0.5935 - val_loss: 1.7058 - val_accuracy: 0.5581\n",
      "Epoch 108/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5591 - accuracy: 0.5942 - val_loss: 1.7116 - val_accuracy: 0.5581\n",
      "Epoch 109/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5510 - accuracy: 0.5961 - val_loss: 1.7018 - val_accuracy: 0.5702\n",
      "Epoch 110/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5454 - accuracy: 0.5988 - val_loss: 1.7020 - val_accuracy: 0.5705\n",
      "Epoch 111/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5406 - accuracy: 0.5988 - val_loss: 1.6867 - val_accuracy: 0.5802\n",
      "Epoch 112/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5379 - accuracy: 0.5982 - val_loss: 1.7225 - val_accuracy: 0.5849\n",
      "Epoch 113/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5312 - accuracy: 0.6024 - val_loss: 1.7077 - val_accuracy: 0.5756\n",
      "Epoch 114/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5271 - accuracy: 0.6038 - val_loss: 1.7922 - val_accuracy: 0.5729\n",
      "Epoch 115/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5214 - accuracy: 0.6056 - val_loss: 1.7097 - val_accuracy: 0.5961\n",
      "Epoch 116/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5190 - accuracy: 0.6081 - val_loss: 1.7463 - val_accuracy: 0.5884\n",
      "Epoch 117/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5136 - accuracy: 0.6097 - val_loss: 1.6879 - val_accuracy: 0.5930\n",
      "Epoch 118/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5128 - accuracy: 0.6071 - val_loss: 1.7640 - val_accuracy: 0.5764\n",
      "Epoch 119/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5030 - accuracy: 0.6087 - val_loss: 1.7019 - val_accuracy: 0.5845\n",
      "Epoch 120/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5016 - accuracy: 0.6117 - val_loss: 1.6958 - val_accuracy: 0.5922\n",
      "Epoch 121/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4960 - accuracy: 0.6118 - val_loss: 1.7232 - val_accuracy: 0.5895\n",
      "Epoch 122/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4919 - accuracy: 0.6127 - val_loss: 1.6971 - val_accuracy: 0.6004\n",
      "Epoch 123/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4900 - accuracy: 0.6170 - val_loss: 1.7188 - val_accuracy: 0.5907\n",
      "Epoch 124/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4842 - accuracy: 0.6148 - val_loss: 1.7876 - val_accuracy: 0.6047\n",
      "Epoch 125/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4873 - accuracy: 0.6199 - val_loss: 1.6494 - val_accuracy: 0.5911\n",
      "Epoch 126/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4766 - accuracy: 0.6189 - val_loss: 1.6599 - val_accuracy: 0.5942\n",
      "Epoch 127/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4701 - accuracy: 0.6198 - val_loss: 1.6560 - val_accuracy: 0.5961\n",
      "Epoch 128/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4680 - accuracy: 0.6232 - val_loss: 1.6602 - val_accuracy: 0.5996\n",
      "Epoch 129/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4615 - accuracy: 0.6264 - val_loss: 1.6491 - val_accuracy: 0.6163\n",
      "Epoch 130/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4616 - accuracy: 0.6249 - val_loss: 1.6466 - val_accuracy: 0.5946\n",
      "Epoch 131/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4546 - accuracy: 0.6256 - val_loss: 1.6503 - val_accuracy: 0.6054\n",
      "Epoch 132/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4528 - accuracy: 0.6235 - val_loss: 1.6718 - val_accuracy: 0.5926\n",
      "Epoch 133/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4513 - accuracy: 0.6258 - val_loss: 1.6587 - val_accuracy: 0.5934\n",
      "Epoch 134/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4463 - accuracy: 0.6260 - val_loss: 1.6498 - val_accuracy: 0.6074\n",
      "Epoch 135/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4434 - accuracy: 0.6263 - val_loss: 1.6415 - val_accuracy: 0.6000\n",
      "Epoch 136/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4369 - accuracy: 0.6308 - val_loss: 1.6494 - val_accuracy: 0.6027\n",
      "Epoch 137/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4366 - accuracy: 0.6310 - val_loss: 1.6589 - val_accuracy: 0.5895\n",
      "Epoch 138/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4303 - accuracy: 0.6336 - val_loss: 1.6373 - val_accuracy: 0.6136\n",
      "Epoch 139/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4277 - accuracy: 0.6364 - val_loss: 1.6481 - val_accuracy: 0.6167\n",
      "Epoch 140/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4221 - accuracy: 0.6373 - val_loss: 1.6608 - val_accuracy: 0.6054\n",
      "Epoch 141/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4194 - accuracy: 0.6381 - val_loss: 1.6484 - val_accuracy: 0.6004\n",
      "Epoch 142/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4158 - accuracy: 0.6366 - val_loss: 1.6456 - val_accuracy: 0.6093\n",
      "Epoch 143/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4115 - accuracy: 0.6406 - val_loss: 1.6351 - val_accuracy: 0.6155\n",
      "Epoch 144/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4071 - accuracy: 0.6405 - val_loss: 1.6027 - val_accuracy: 0.6151\n",
      "Epoch 145/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4022 - accuracy: 0.6404 - val_loss: 1.5839 - val_accuracy: 0.6136\n",
      "Epoch 146/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4230 - accuracy: 0.6390 - val_loss: 1.5721 - val_accuracy: 0.6326\n",
      "Epoch 147/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3914 - accuracy: 0.6483 - val_loss: 1.5461 - val_accuracy: 0.6256\n",
      "Epoch 148/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3877 - accuracy: 0.6477 - val_loss: 1.5622 - val_accuracy: 0.6205\n",
      "Epoch 149/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3921 - accuracy: 0.6469 - val_loss: 1.5817 - val_accuracy: 0.6256\n",
      "Epoch 150/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3851 - accuracy: 0.6467 - val_loss: 1.6012 - val_accuracy: 0.6062\n",
      "Epoch 151/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3851 - accuracy: 0.6482 - val_loss: 1.5601 - val_accuracy: 0.6411\n",
      "Epoch 152/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3824 - accuracy: 0.6471 - val_loss: 1.5666 - val_accuracy: 0.6279\n",
      "Epoch 153/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3813 - accuracy: 0.6460 - val_loss: 1.5723 - val_accuracy: 0.6380\n",
      "Epoch 154/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3804 - accuracy: 0.6518 - val_loss: 1.5643 - val_accuracy: 0.6326\n",
      "Epoch 155/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3694 - accuracy: 0.6534 - val_loss: 1.5671 - val_accuracy: 0.6190\n",
      "Epoch 156/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3729 - accuracy: 0.6530 - val_loss: 1.5813 - val_accuracy: 0.6097\n",
      "Epoch 157/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3654 - accuracy: 0.6541 - val_loss: 1.5685 - val_accuracy: 0.6244\n",
      "Epoch 158/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3676 - accuracy: 0.6503 - val_loss: 1.5592 - val_accuracy: 0.6314\n",
      "Epoch 159/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3727 - accuracy: 0.6543 - val_loss: 1.5587 - val_accuracy: 0.6279\n",
      "Epoch 160/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3564 - accuracy: 0.6557 - val_loss: 1.5645 - val_accuracy: 0.6318\n",
      "Epoch 161/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3533 - accuracy: 0.6596 - val_loss: 1.5676 - val_accuracy: 0.6357\n",
      "Epoch 162/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3537 - accuracy: 0.6553 - val_loss: 1.5483 - val_accuracy: 0.6415\n",
      "Epoch 163/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3493 - accuracy: 0.6598 - val_loss: 1.5668 - val_accuracy: 0.6326\n",
      "Epoch 164/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3485 - accuracy: 0.6574 - val_loss: 1.5408 - val_accuracy: 0.6318\n",
      "Epoch 165/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3470 - accuracy: 0.6596 - val_loss: 1.5455 - val_accuracy: 0.6372\n",
      "Epoch 166/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3404 - accuracy: 0.6611 - val_loss: 1.5536 - val_accuracy: 0.6318\n",
      "Epoch 167/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3393 - accuracy: 0.6581 - val_loss: 1.5721 - val_accuracy: 0.6403\n",
      "Epoch 168/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3374 - accuracy: 0.6632 - val_loss: 1.5498 - val_accuracy: 0.6461\n",
      "Epoch 169/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3341 - accuracy: 0.6636 - val_loss: 1.5766 - val_accuracy: 0.6484\n",
      "Epoch 170/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3349 - accuracy: 0.6624 - val_loss: 1.5612 - val_accuracy: 0.6271\n",
      "Epoch 171/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3288 - accuracy: 0.6652 - val_loss: 1.5557 - val_accuracy: 0.6550\n",
      "Epoch 172/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3230 - accuracy: 0.6655 - val_loss: 1.5530 - val_accuracy: 0.6430\n",
      "Epoch 173/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3231 - accuracy: 0.6634 - val_loss: 1.5534 - val_accuracy: 0.6442\n",
      "Epoch 174/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3160 - accuracy: 0.6680 - val_loss: 1.5990 - val_accuracy: 0.6178\n",
      "Epoch 175/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3332 - accuracy: 0.6677 - val_loss: 1.6160 - val_accuracy: 0.6209\n",
      "Epoch 176/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3109 - accuracy: 0.6709 - val_loss: 1.5825 - val_accuracy: 0.6461\n",
      "Epoch 177/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3076 - accuracy: 0.6734 - val_loss: 1.5999 - val_accuracy: 0.6287\n",
      "Epoch 178/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3050 - accuracy: 0.6734 - val_loss: 1.6099 - val_accuracy: 0.6388\n",
      "Epoch 179/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3045 - accuracy: 0.6709 - val_loss: 1.6001 - val_accuracy: 0.6384\n",
      "Epoch 180/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3010 - accuracy: 0.6734 - val_loss: 1.6044 - val_accuracy: 0.6422\n",
      "Epoch 181/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3033 - accuracy: 0.6734 - val_loss: 1.5259 - val_accuracy: 0.6446\n",
      "Epoch 182/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2959 - accuracy: 0.6765 - val_loss: 1.5059 - val_accuracy: 0.6453\n",
      "Epoch 183/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2982 - accuracy: 0.6754 - val_loss: 1.5397 - val_accuracy: 0.6380\n",
      "Epoch 184/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2910 - accuracy: 0.6745 - val_loss: 1.5231 - val_accuracy: 0.6465\n",
      "Epoch 185/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2899 - accuracy: 0.6765 - val_loss: 1.5257 - val_accuracy: 0.6461\n",
      "Epoch 186/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2874 - accuracy: 0.6752 - val_loss: 1.5551 - val_accuracy: 0.6453\n",
      "Epoch 187/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2845 - accuracy: 0.6766 - val_loss: 1.5486 - val_accuracy: 0.6519\n",
      "Epoch 188/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2830 - accuracy: 0.6795 - val_loss: 1.5667 - val_accuracy: 0.6399\n",
      "Epoch 189/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2807 - accuracy: 0.6798 - val_loss: 1.5187 - val_accuracy: 0.6717\n",
      "Epoch 190/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2773 - accuracy: 0.6798 - val_loss: 1.5428 - val_accuracy: 0.6488\n",
      "Epoch 191/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2703 - accuracy: 0.6809 - val_loss: 1.5309 - val_accuracy: 0.6698\n",
      "Epoch 192/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2717 - accuracy: 0.6806 - val_loss: 1.5568 - val_accuracy: 0.6547\n",
      "Epoch 193/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2642 - accuracy: 0.6839 - val_loss: 1.5479 - val_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2654 - accuracy: 0.6811 - val_loss: 1.5954 - val_accuracy: 0.6581\n",
      "Epoch 195/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2641 - accuracy: 0.6818 - val_loss: 1.5704 - val_accuracy: 0.6682\n",
      "Epoch 196/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2618 - accuracy: 0.6849 - val_loss: 1.6092 - val_accuracy: 0.6403\n",
      "Epoch 197/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2581 - accuracy: 0.6848 - val_loss: 1.5752 - val_accuracy: 0.6554\n",
      "Epoch 198/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2576 - accuracy: 0.6838 - val_loss: 1.5627 - val_accuracy: 0.6578\n",
      "Epoch 199/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2529 - accuracy: 0.6843 - val_loss: 1.5705 - val_accuracy: 0.6756\n",
      "Epoch 200/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2503 - accuracy: 0.6905 - val_loss: 1.5603 - val_accuracy: 0.6725\n",
      "Epoch 201/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2499 - accuracy: 0.6850 - val_loss: 1.5321 - val_accuracy: 0.6725\n",
      "Epoch 202/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2421 - accuracy: 0.6903 - val_loss: 1.5211 - val_accuracy: 0.6581\n",
      "Epoch 203/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2449 - accuracy: 0.6865 - val_loss: 1.5561 - val_accuracy: 0.6446\n",
      "Epoch 204/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2394 - accuracy: 0.6922 - val_loss: 1.5392 - val_accuracy: 0.6690\n",
      "Epoch 205/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2369 - accuracy: 0.6914 - val_loss: 1.5351 - val_accuracy: 0.6636\n",
      "Epoch 206/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2351 - accuracy: 0.6903 - val_loss: 1.5215 - val_accuracy: 0.6694\n",
      "Epoch 207/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2331 - accuracy: 0.6933 - val_loss: 1.5485 - val_accuracy: 0.6469\n",
      "Epoch 208/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2494 - accuracy: 0.6917 - val_loss: 1.4975 - val_accuracy: 0.6682\n",
      "Epoch 209/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2249 - accuracy: 0.6970 - val_loss: 1.5003 - val_accuracy: 0.6725\n",
      "Epoch 210/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2220 - accuracy: 0.6963 - val_loss: 1.5153 - val_accuracy: 0.6802\n",
      "Epoch 211/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2248 - accuracy: 0.6949 - val_loss: 1.5156 - val_accuracy: 0.6744\n",
      "Epoch 212/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2192 - accuracy: 0.6985 - val_loss: 1.5327 - val_accuracy: 0.6601\n",
      "Epoch 213/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2241 - accuracy: 0.6964 - val_loss: 1.5237 - val_accuracy: 0.6756\n",
      "Epoch 214/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2167 - accuracy: 0.6979 - val_loss: 1.5174 - val_accuracy: 0.6779\n",
      "Epoch 215/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2170 - accuracy: 0.6996 - val_loss: 1.5359 - val_accuracy: 0.6729\n",
      "Epoch 216/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2171 - accuracy: 0.6994 - val_loss: 1.5377 - val_accuracy: 0.6713\n",
      "Epoch 217/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2134 - accuracy: 0.6970 - val_loss: 1.5587 - val_accuracy: 0.6791\n",
      "Epoch 218/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2151 - accuracy: 0.6968 - val_loss: 1.5559 - val_accuracy: 0.6822\n",
      "Epoch 219/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2056 - accuracy: 0.6992 - val_loss: 1.5301 - val_accuracy: 0.6736\n",
      "Epoch 220/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2054 - accuracy: 0.7008 - val_loss: 1.5251 - val_accuracy: 0.6771\n",
      "Epoch 221/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2021 - accuracy: 0.6992 - val_loss: 1.5560 - val_accuracy: 0.6698\n",
      "Epoch 222/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2009 - accuracy: 0.7002 - val_loss: 1.5716 - val_accuracy: 0.6581\n",
      "Epoch 223/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2006 - accuracy: 0.7012 - val_loss: 1.5455 - val_accuracy: 0.6764\n",
      "Epoch 224/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1976 - accuracy: 0.7028 - val_loss: 1.5463 - val_accuracy: 0.6686\n",
      "Epoch 225/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1968 - accuracy: 0.7028 - val_loss: 1.5266 - val_accuracy: 0.6864\n",
      "Epoch 226/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1958 - accuracy: 0.7032 - val_loss: 1.5124 - val_accuracy: 0.6957\n",
      "Epoch 227/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2069 - accuracy: 0.7017 - val_loss: 1.5418 - val_accuracy: 0.6818\n",
      "Epoch 228/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1855 - accuracy: 0.7062 - val_loss: 1.5575 - val_accuracy: 0.6798\n",
      "Epoch 229/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1836 - accuracy: 0.7089 - val_loss: 1.5432 - val_accuracy: 0.6942\n",
      "Epoch 230/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1877 - accuracy: 0.7069 - val_loss: 1.5544 - val_accuracy: 0.6849\n",
      "Epoch 231/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1817 - accuracy: 0.7083 - val_loss: 1.5573 - val_accuracy: 0.6822\n",
      "Epoch 232/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1851 - accuracy: 0.7073 - val_loss: 1.4966 - val_accuracy: 0.6620\n",
      "Epoch 233/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1825 - accuracy: 0.7050 - val_loss: 1.4840 - val_accuracy: 0.6934\n",
      "Epoch 234/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1808 - accuracy: 0.7060 - val_loss: 1.4659 - val_accuracy: 0.6868\n",
      "Epoch 235/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1795 - accuracy: 0.7058 - val_loss: 1.4953 - val_accuracy: 0.6868\n",
      "Epoch 236/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1765 - accuracy: 0.7095 - val_loss: 1.4906 - val_accuracy: 0.6779\n",
      "Epoch 237/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1762 - accuracy: 0.7089 - val_loss: 1.4944 - val_accuracy: 0.6833\n",
      "Epoch 238/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1727 - accuracy: 0.7099 - val_loss: 1.4986 - val_accuracy: 0.6984\n",
      "Epoch 239/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1717 - accuracy: 0.7092 - val_loss: 1.5188 - val_accuracy: 0.6729\n",
      "Epoch 240/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1671 - accuracy: 0.7115 - val_loss: 1.4890 - val_accuracy: 0.6926\n",
      "Epoch 241/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1631 - accuracy: 0.7123 - val_loss: 1.5199 - val_accuracy: 0.6853\n",
      "Epoch 242/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1683 - accuracy: 0.7112 - val_loss: 1.5213 - val_accuracy: 0.6864\n",
      "Epoch 243/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1708 - accuracy: 0.7078 - val_loss: 1.5269 - val_accuracy: 0.6845\n",
      "Epoch 244/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1683 - accuracy: 0.7168 - val_loss: 1.5360 - val_accuracy: 0.6791\n",
      "Epoch 245/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1561 - accuracy: 0.7122 - val_loss: 1.5481 - val_accuracy: 0.6787\n",
      "Epoch 246/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1566 - accuracy: 0.7145 - val_loss: 1.5351 - val_accuracy: 0.6868\n",
      "Epoch 247/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1548 - accuracy: 0.7164 - val_loss: 1.5461 - val_accuracy: 0.6922\n",
      "Epoch 248/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1536 - accuracy: 0.7115 - val_loss: 1.5446 - val_accuracy: 0.6880\n",
      "Epoch 249/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1532 - accuracy: 0.7162 - val_loss: 1.6145 - val_accuracy: 0.6620\n",
      "Epoch 250/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1507 - accuracy: 0.7127 - val_loss: 1.5797 - val_accuracy: 0.6942\n",
      "Epoch 251/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1530 - accuracy: 0.7134 - val_loss: 1.5442 - val_accuracy: 0.6938\n",
      "Epoch 252/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1496 - accuracy: 0.7148 - val_loss: 1.6011 - val_accuracy: 0.6636\n",
      "Epoch 253/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1487 - accuracy: 0.7182 - val_loss: 1.4187 - val_accuracy: 0.7155\n",
      "Epoch 254/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1614 - accuracy: 0.7108 - val_loss: 1.4597 - val_accuracy: 0.6690\n",
      "Epoch 255/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1491 - accuracy: 0.7198 - val_loss: 1.4571 - val_accuracy: 0.6663\n",
      "Epoch 256/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1335 - accuracy: 0.7226 - val_loss: 1.4695 - val_accuracy: 0.6674\n",
      "Epoch 257/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1331 - accuracy: 0.7211 - val_loss: 1.4339 - val_accuracy: 0.6981\n",
      "Epoch 258/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1347 - accuracy: 0.7192 - val_loss: 1.4251 - val_accuracy: 0.7023\n",
      "Epoch 259/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1363 - accuracy: 0.7171 - val_loss: 1.4587 - val_accuracy: 0.6981\n",
      "Epoch 260/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1338 - accuracy: 0.7194 - val_loss: 1.4582 - val_accuracy: 0.6996\n",
      "Epoch 261/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1316 - accuracy: 0.7198 - val_loss: 1.4529 - val_accuracy: 0.6888\n",
      "Epoch 262/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1330 - accuracy: 0.7196 - val_loss: 1.4577 - val_accuracy: 0.6884\n",
      "Epoch 263/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1344 - accuracy: 0.7209 - val_loss: 1.4739 - val_accuracy: 0.7000\n",
      "Epoch 264/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1292 - accuracy: 0.7202 - val_loss: 1.4587 - val_accuracy: 0.7016\n",
      "Epoch 265/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1257 - accuracy: 0.7205 - val_loss: 1.5079 - val_accuracy: 0.6655\n",
      "Epoch 266/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1231 - accuracy: 0.7213 - val_loss: 1.5060 - val_accuracy: 0.6911\n",
      "Epoch 267/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1290 - accuracy: 0.7180 - val_loss: 1.4963 - val_accuracy: 0.6771\n",
      "Epoch 268/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1241 - accuracy: 0.7214 - val_loss: 1.4798 - val_accuracy: 0.6915\n",
      "Epoch 269/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1234 - accuracy: 0.7239 - val_loss: 1.5451 - val_accuracy: 0.6911\n",
      "Epoch 270/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1141 - accuracy: 0.7242 - val_loss: 1.5673 - val_accuracy: 0.6903\n",
      "Epoch 271/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1143 - accuracy: 0.7245 - val_loss: 1.5846 - val_accuracy: 0.6822\n",
      "Epoch 272/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1157 - accuracy: 0.7248 - val_loss: 1.5683 - val_accuracy: 0.6907\n",
      "Epoch 273/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1103 - accuracy: 0.7268 - val_loss: 1.5416 - val_accuracy: 0.6907\n",
      "Epoch 274/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1145 - accuracy: 0.7230 - val_loss: 1.5666 - val_accuracy: 0.6969\n",
      "Epoch 275/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1084 - accuracy: 0.7270 - val_loss: 1.5437 - val_accuracy: 0.7147\n",
      "Epoch 276/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1128 - accuracy: 0.7219 - val_loss: 1.5625 - val_accuracy: 0.6996\n",
      "Epoch 277/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1060 - accuracy: 0.7247 - val_loss: 1.5325 - val_accuracy: 0.7109\n",
      "Epoch 278/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1250 - accuracy: 0.7248 - val_loss: 1.5180 - val_accuracy: 0.7174\n",
      "Epoch 279/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0949 - accuracy: 0.7333 - val_loss: 1.5210 - val_accuracy: 0.7112\n",
      "Epoch 280/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1004 - accuracy: 0.7286 - val_loss: 1.5451 - val_accuracy: 0.6876\n",
      "Epoch 281/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0975 - accuracy: 0.7308 - val_loss: 1.5311 - val_accuracy: 0.7004\n",
      "Epoch 282/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0985 - accuracy: 0.7285 - val_loss: 1.5222 - val_accuracy: 0.7252\n",
      "Epoch 283/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1001 - accuracy: 0.7266 - val_loss: 1.4681 - val_accuracy: 0.7019\n",
      "Epoch 284/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0977 - accuracy: 0.7286 - val_loss: 1.4689 - val_accuracy: 0.7027\n",
      "Epoch 285/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0972 - accuracy: 0.7294 - val_loss: 1.5066 - val_accuracy: 0.6930\n",
      "Epoch 286/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0927 - accuracy: 0.7276 - val_loss: 1.4951 - val_accuracy: 0.7109\n",
      "Epoch 287/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1056 - accuracy: 0.7275 - val_loss: 1.4833 - val_accuracy: 0.6919\n",
      "Epoch 288/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0934 - accuracy: 0.7305 - val_loss: 1.4796 - val_accuracy: 0.7155\n",
      "Epoch 289/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0826 - accuracy: 0.7356 - val_loss: 1.4667 - val_accuracy: 0.7089\n",
      "Epoch 290/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0843 - accuracy: 0.7294 - val_loss: 1.4799 - val_accuracy: 0.7027\n",
      "Epoch 291/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0864 - accuracy: 0.7305 - val_loss: 1.4867 - val_accuracy: 0.7078\n",
      "Epoch 292/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0861 - accuracy: 0.7295 - val_loss: 1.4617 - val_accuracy: 0.7124\n",
      "Epoch 293/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0865 - accuracy: 0.7282 - val_loss: 1.4692 - val_accuracy: 0.7054\n",
      "Epoch 294/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0852 - accuracy: 0.7345 - val_loss: 1.5213 - val_accuracy: 0.6988\n",
      "Epoch 295/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0806 - accuracy: 0.7323 - val_loss: 1.4840 - val_accuracy: 0.7151\n",
      "Epoch 296/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0805 - accuracy: 0.7308 - val_loss: 1.4888 - val_accuracy: 0.7167\n",
      "Epoch 297/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0844 - accuracy: 0.7308 - val_loss: 1.4903 - val_accuracy: 0.7132\n",
      "Epoch 298/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0802 - accuracy: 0.7358 - val_loss: 1.5057 - val_accuracy: 0.7101\n",
      "Epoch 299/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0783 - accuracy: 0.7325 - val_loss: 1.4863 - val_accuracy: 0.7186\n",
      "Epoch 300/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0782 - accuracy: 0.7319 - val_loss: 1.5086 - val_accuracy: 0.7012\n",
      "Epoch 301/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0801 - accuracy: 0.7322 - val_loss: 1.4979 - val_accuracy: 0.7097\n",
      "Epoch 302/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0723 - accuracy: 0.7321 - val_loss: 1.5225 - val_accuracy: 0.7105\n",
      "Epoch 303/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0751 - accuracy: 0.7371 - val_loss: 1.5459 - val_accuracy: 0.7023\n",
      "Epoch 304/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0767 - accuracy: 0.7342 - val_loss: 1.5203 - val_accuracy: 0.7205\n",
      "Epoch 305/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0725 - accuracy: 0.7339 - val_loss: 1.5315 - val_accuracy: 0.7078\n",
      "Epoch 306/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0649 - accuracy: 0.7357 - val_loss: 1.5362 - val_accuracy: 0.7050\n",
      "Epoch 307/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0681 - accuracy: 0.7357 - val_loss: 1.5607 - val_accuracy: 0.6946\n",
      "Epoch 308/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0634 - accuracy: 0.7367 - val_loss: 1.5546 - val_accuracy: 0.6934\n",
      "Epoch 309/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0727 - accuracy: 0.7337 - val_loss: 1.5365 - val_accuracy: 0.7143\n",
      "Epoch 310/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0580 - accuracy: 0.7392 - val_loss: 1.5506 - val_accuracy: 0.7097\n",
      "Epoch 311/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0645 - accuracy: 0.7347 - val_loss: 1.5450 - val_accuracy: 0.7155\n",
      "Epoch 312/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0756 - accuracy: 0.7335 - val_loss: 1.4726 - val_accuracy: 0.7136\n",
      "Epoch 313/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0547 - accuracy: 0.7388 - val_loss: 1.4806 - val_accuracy: 0.7151\n",
      "Epoch 314/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0536 - accuracy: 0.7439 - val_loss: 1.4796 - val_accuracy: 0.7078\n",
      "Epoch 315/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0557 - accuracy: 0.7356 - val_loss: 1.4899 - val_accuracy: 0.7318\n",
      "Epoch 316/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0552 - accuracy: 0.7388 - val_loss: 1.5231 - val_accuracy: 0.7081\n",
      "Epoch 317/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0559 - accuracy: 0.7399 - val_loss: 1.5796 - val_accuracy: 0.6884\n",
      "Epoch 318/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0534 - accuracy: 0.7373 - val_loss: 1.5536 - val_accuracy: 0.6973\n",
      "Epoch 319/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0555 - accuracy: 0.7374 - val_loss: 1.5063 - val_accuracy: 0.7120\n",
      "Epoch 320/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0510 - accuracy: 0.7404 - val_loss: 1.5662 - val_accuracy: 0.7047\n",
      "Epoch 321/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0501 - accuracy: 0.7388 - val_loss: 1.5172 - val_accuracy: 0.7070\n",
      "Epoch 322/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0492 - accuracy: 0.7431 - val_loss: 1.5908 - val_accuracy: 0.6899\n",
      "Epoch 323/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0533 - accuracy: 0.7379 - val_loss: 1.5322 - val_accuracy: 0.6977\n",
      "Epoch 324/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0449 - accuracy: 0.7421 - val_loss: 1.5352 - val_accuracy: 0.7240\n",
      "Epoch 325/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0412 - accuracy: 0.7407 - val_loss: 1.5557 - val_accuracy: 0.7353\n",
      "Epoch 326/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0480 - accuracy: 0.7410 - val_loss: 1.5569 - val_accuracy: 0.7271\n",
      "Epoch 327/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0510 - accuracy: 0.7391 - val_loss: 1.5918 - val_accuracy: 0.7047\n",
      "Epoch 328/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0381 - accuracy: 0.7444 - val_loss: 1.5632 - val_accuracy: 0.7221\n",
      "Epoch 329/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0413 - accuracy: 0.7422 - val_loss: 1.6209 - val_accuracy: 0.6868\n",
      "Epoch 330/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0498 - accuracy: 0.7435 - val_loss: 1.6807 - val_accuracy: 0.6907\n",
      "Epoch 331/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0417 - accuracy: 0.7465 - val_loss: 1.5763 - val_accuracy: 0.7151\n",
      "Epoch 332/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0299 - accuracy: 0.7479 - val_loss: 1.5868 - val_accuracy: 0.7256\n",
      "Epoch 333/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0315 - accuracy: 0.7513 - val_loss: 1.5826 - val_accuracy: 0.7093\n",
      "Epoch 334/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0302 - accuracy: 0.7450 - val_loss: 1.5912 - val_accuracy: 0.7143\n",
      "Epoch 335/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0284 - accuracy: 0.7455 - val_loss: 1.5591 - val_accuracy: 0.7353\n",
      "Epoch 336/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0308 - accuracy: 0.7453 - val_loss: 1.6023 - val_accuracy: 0.7155\n",
      "Epoch 337/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0285 - accuracy: 0.7478 - val_loss: 1.5806 - val_accuracy: 0.7306\n",
      "Epoch 338/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0280 - accuracy: 0.7465 - val_loss: 1.5604 - val_accuracy: 0.7318\n",
      "Epoch 339/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0332 - accuracy: 0.7423 - val_loss: 1.5867 - val_accuracy: 0.7097\n",
      "Epoch 340/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0266 - accuracy: 0.7473 - val_loss: 1.6157 - val_accuracy: 0.7229\n",
      "Epoch 341/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0266 - accuracy: 0.7447 - val_loss: 1.6494 - val_accuracy: 0.6996\n",
      "Epoch 342/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0239 - accuracy: 0.7461 - val_loss: 1.6333 - val_accuracy: 0.7236\n",
      "Epoch 343/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0235 - accuracy: 0.7475 - val_loss: 1.7220 - val_accuracy: 0.6950\n",
      "Epoch 344/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0283 - accuracy: 0.7441 - val_loss: 1.5876 - val_accuracy: 0.7128\n",
      "Epoch 345/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0256 - accuracy: 0.7446 - val_loss: 1.5991 - val_accuracy: 0.7271\n",
      "Epoch 346/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0225 - accuracy: 0.7481 - val_loss: 1.6332 - val_accuracy: 0.7217\n",
      "Epoch 347/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0164 - accuracy: 0.7475 - val_loss: 1.6150 - val_accuracy: 0.7322\n",
      "Epoch 348/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0230 - accuracy: 0.7454 - val_loss: 1.6549 - val_accuracy: 0.7027\n",
      "Epoch 349/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0147 - accuracy: 0.7464 - val_loss: 1.6323 - val_accuracy: 0.7287\n",
      "Epoch 350/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0200 - accuracy: 0.7438 - val_loss: 1.4282 - val_accuracy: 0.7202\n",
      "Epoch 351/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0174 - accuracy: 0.7464 - val_loss: 1.4695 - val_accuracy: 0.6969\n",
      "Epoch 352/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0115 - accuracy: 0.7485 - val_loss: 1.4441 - val_accuracy: 0.7306\n",
      "Epoch 353/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0115 - accuracy: 0.7503 - val_loss: 1.4243 - val_accuracy: 0.7457\n",
      "Epoch 354/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0097 - accuracy: 0.7478 - val_loss: 1.4838 - val_accuracy: 0.7566\n",
      "Epoch 355/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0095 - accuracy: 0.7492 - val_loss: 1.4900 - val_accuracy: 0.7124\n",
      "Epoch 356/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0138 - accuracy: 0.7475 - val_loss: 1.5776 - val_accuracy: 0.7306\n",
      "Epoch 357/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0077 - accuracy: 0.7510 - val_loss: 1.5107 - val_accuracy: 0.7186\n",
      "Epoch 358/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0445 - accuracy: 0.7502 - val_loss: 1.5122 - val_accuracy: 0.7329\n",
      "Epoch 359/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0094 - accuracy: 0.7601 - val_loss: 1.5143 - val_accuracy: 0.7368\n",
      "Epoch 360/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9926 - accuracy: 0.7590 - val_loss: 1.5207 - val_accuracy: 0.7419\n",
      "Epoch 361/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9982 - accuracy: 0.7546 - val_loss: 1.5181 - val_accuracy: 0.7446\n",
      "Epoch 362/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9994 - accuracy: 0.7551 - val_loss: 1.5543 - val_accuracy: 0.7155\n",
      "Epoch 363/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9966 - accuracy: 0.7555 - val_loss: 1.5352 - val_accuracy: 0.7205\n",
      "Epoch 364/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9926 - accuracy: 0.7570 - val_loss: 1.5540 - val_accuracy: 0.7554\n",
      "Epoch 365/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0007 - accuracy: 0.7487 - val_loss: 1.6286 - val_accuracy: 0.7194\n",
      "Epoch 366/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9965 - accuracy: 0.7548 - val_loss: 1.6088 - val_accuracy: 0.7442\n",
      "Epoch 367/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9996 - accuracy: 0.7527 - val_loss: 1.6031 - val_accuracy: 0.7326\n",
      "Epoch 368/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0027 - accuracy: 0.7520 - val_loss: 1.6615 - val_accuracy: 0.7395\n",
      "Epoch 369/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9988 - accuracy: 0.7523 - val_loss: 1.6229 - val_accuracy: 0.7337\n",
      "Epoch 370/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9985 - accuracy: 0.7498 - val_loss: 1.6408 - val_accuracy: 0.7271\n",
      "Epoch 371/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9915 - accuracy: 0.7527 - val_loss: 1.6141 - val_accuracy: 0.7391\n",
      "Epoch 372/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9972 - accuracy: 0.7523 - val_loss: 1.6644 - val_accuracy: 0.7159\n",
      "Epoch 373/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9885 - accuracy: 0.7553 - val_loss: 1.6422 - val_accuracy: 0.7364\n",
      "Epoch 374/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9914 - accuracy: 0.7557 - val_loss: 1.6285 - val_accuracy: 0.7457\n",
      "Epoch 375/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9907 - accuracy: 0.7577 - val_loss: 1.6577 - val_accuracy: 0.7384\n",
      "Epoch 376/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9943 - accuracy: 0.7520 - val_loss: 1.6763 - val_accuracy: 0.7267\n",
      "Epoch 377/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9906 - accuracy: 0.7525 - val_loss: 1.6374 - val_accuracy: 0.7453\n",
      "Epoch 378/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9851 - accuracy: 0.7568 - val_loss: 1.6531 - val_accuracy: 0.7426\n",
      "Epoch 379/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9935 - accuracy: 0.7541 - val_loss: 1.7633 - val_accuracy: 0.7419\n",
      "Epoch 380/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9836 - accuracy: 0.7572 - val_loss: 1.7723 - val_accuracy: 0.7422\n",
      "Epoch 381/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9815 - accuracy: 0.7556 - val_loss: 1.8408 - val_accuracy: 0.7159\n",
      "Epoch 382/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9876 - accuracy: 0.7553 - val_loss: 1.7964 - val_accuracy: 0.7345\n",
      "Epoch 383/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9845 - accuracy: 0.7562 - val_loss: 1.7829 - val_accuracy: 0.7391\n",
      "Epoch 384/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9810 - accuracy: 0.7575 - val_loss: 1.7442 - val_accuracy: 0.7376\n",
      "Epoch 385/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9918 - accuracy: 0.7553 - val_loss: 1.7076 - val_accuracy: 0.7391\n",
      "Epoch 386/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9800 - accuracy: 0.7566 - val_loss: 1.6937 - val_accuracy: 0.7399\n",
      "Epoch 387/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9787 - accuracy: 0.7565 - val_loss: 1.7415 - val_accuracy: 0.7411\n",
      "Epoch 388/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9825 - accuracy: 0.7599 - val_loss: 1.5676 - val_accuracy: 0.7310\n",
      "Epoch 389/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9718 - accuracy: 0.7619 - val_loss: 1.5395 - val_accuracy: 0.7566\n",
      "Epoch 390/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9748 - accuracy: 0.7602 - val_loss: 1.5729 - val_accuracy: 0.7450\n",
      "Epoch 391/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9761 - accuracy: 0.7588 - val_loss: 1.6015 - val_accuracy: 0.7298\n",
      "Epoch 392/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9769 - accuracy: 0.7587 - val_loss: 1.5737 - val_accuracy: 0.7473\n",
      "Epoch 393/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9721 - accuracy: 0.7615 - val_loss: 1.5754 - val_accuracy: 0.7353\n",
      "Epoch 394/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9776 - accuracy: 0.7581 - val_loss: 1.6317 - val_accuracy: 0.7128\n",
      "Epoch 395/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9731 - accuracy: 0.7589 - val_loss: 1.6014 - val_accuracy: 0.7364\n",
      "Epoch 396/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9760 - accuracy: 0.7582 - val_loss: 1.5908 - val_accuracy: 0.7279\n",
      "Epoch 397/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9724 - accuracy: 0.7611 - val_loss: 1.5991 - val_accuracy: 0.7322\n",
      "Epoch 398/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9710 - accuracy: 0.7604 - val_loss: 1.6397 - val_accuracy: 0.7333\n",
      "Epoch 399/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9723 - accuracy: 0.7567 - val_loss: 1.6062 - val_accuracy: 0.7496\n",
      "Epoch 400/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9664 - accuracy: 0.7599 - val_loss: 1.6195 - val_accuracy: 0.7295\n",
      "Epoch 401/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9683 - accuracy: 0.7599 - val_loss: 1.6211 - val_accuracy: 0.7407\n",
      "Epoch 402/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9692 - accuracy: 0.7609 - val_loss: 1.6100 - val_accuracy: 0.7395\n",
      "Epoch 403/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9678 - accuracy: 0.7606 - val_loss: 1.5958 - val_accuracy: 0.7581\n",
      "Epoch 404/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9662 - accuracy: 0.7614 - val_loss: 1.6083 - val_accuracy: 0.7430\n",
      "Epoch 405/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9661 - accuracy: 0.7608 - val_loss: 1.6418 - val_accuracy: 0.7484\n",
      "Epoch 406/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9739 - accuracy: 0.7618 - val_loss: 1.6845 - val_accuracy: 0.7298\n",
      "Epoch 407/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9561 - accuracy: 0.7689 - val_loss: 1.6446 - val_accuracy: 0.7279\n",
      "Epoch 408/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9530 - accuracy: 0.7648 - val_loss: 1.5985 - val_accuracy: 0.7341\n",
      "Epoch 409/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9526 - accuracy: 0.7660 - val_loss: 1.6197 - val_accuracy: 0.7318\n",
      "Epoch 410/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9590 - accuracy: 0.7649 - val_loss: 1.6035 - val_accuracy: 0.7267\n",
      "Epoch 411/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9546 - accuracy: 0.7641 - val_loss: 1.5976 - val_accuracy: 0.7314\n",
      "Epoch 412/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9593 - accuracy: 0.7622 - val_loss: 1.5841 - val_accuracy: 0.7554\n",
      "Epoch 413/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9609 - accuracy: 0.7592 - val_loss: 1.6351 - val_accuracy: 0.7209\n",
      "Epoch 414/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9532 - accuracy: 0.7622 - val_loss: 1.5981 - val_accuracy: 0.7636\n",
      "Epoch 415/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9577 - accuracy: 0.7625 - val_loss: 1.6252 - val_accuracy: 0.7461\n",
      "Epoch 416/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9574 - accuracy: 0.7622 - val_loss: 1.6240 - val_accuracy: 0.7411\n",
      "Epoch 417/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9523 - accuracy: 0.7650 - val_loss: 1.6039 - val_accuracy: 0.7589\n",
      "Epoch 418/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9528 - accuracy: 0.7630 - val_loss: 1.6364 - val_accuracy: 0.7426\n",
      "Epoch 419/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9589 - accuracy: 0.7637 - val_loss: 1.5643 - val_accuracy: 0.7372\n",
      "Epoch 420/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9520 - accuracy: 0.7659 - val_loss: 1.5764 - val_accuracy: 0.7395\n",
      "Epoch 421/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9545 - accuracy: 0.7611 - val_loss: 1.6151 - val_accuracy: 0.7426\n",
      "Epoch 422/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9671 - accuracy: 0.7634 - val_loss: 1.4861 - val_accuracy: 0.7531\n",
      "Epoch 423/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9372 - accuracy: 0.7713 - val_loss: 1.5088 - val_accuracy: 0.7527\n",
      "Epoch 424/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9384 - accuracy: 0.7713 - val_loss: 1.5555 - val_accuracy: 0.7213\n",
      "Epoch 425/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9448 - accuracy: 0.7687 - val_loss: 1.5040 - val_accuracy: 0.7527\n",
      "Epoch 426/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9430 - accuracy: 0.7692 - val_loss: 1.5531 - val_accuracy: 0.7442\n",
      "Epoch 427/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9433 - accuracy: 0.7647 - val_loss: 1.5468 - val_accuracy: 0.7341\n",
      "Epoch 428/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9498 - accuracy: 0.7651 - val_loss: 1.5551 - val_accuracy: 0.7395\n",
      "Epoch 429/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9445 - accuracy: 0.7647 - val_loss: 1.5783 - val_accuracy: 0.7384\n",
      "Epoch 430/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9515 - accuracy: 0.7656 - val_loss: 1.5803 - val_accuracy: 0.7465\n",
      "Epoch 431/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9448 - accuracy: 0.7650 - val_loss: 1.5715 - val_accuracy: 0.7465\n",
      "Epoch 432/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9396 - accuracy: 0.7674 - val_loss: 1.4953 - val_accuracy: 0.7562\n",
      "Epoch 433/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9498 - accuracy: 0.7628 - val_loss: 1.4921 - val_accuracy: 0.7531\n",
      "Epoch 434/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9385 - accuracy: 0.7702 - val_loss: 1.4899 - val_accuracy: 0.7481\n",
      "Epoch 435/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9392 - accuracy: 0.7668 - val_loss: 1.4857 - val_accuracy: 0.7446\n",
      "Epoch 436/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9433 - accuracy: 0.7660 - val_loss: 1.4765 - val_accuracy: 0.7601\n",
      "Epoch 437/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9362 - accuracy: 0.7697 - val_loss: 1.4896 - val_accuracy: 0.7531\n",
      "Epoch 438/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9380 - accuracy: 0.7668 - val_loss: 1.5341 - val_accuracy: 0.7357\n",
      "Epoch 439/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9403 - accuracy: 0.7659 - val_loss: 1.5201 - val_accuracy: 0.7337\n",
      "Epoch 440/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9357 - accuracy: 0.7672 - val_loss: 1.5401 - val_accuracy: 0.7333\n",
      "Epoch 441/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9392 - accuracy: 0.7671 - val_loss: 1.4825 - val_accuracy: 0.7651\n",
      "Epoch 442/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9403 - accuracy: 0.7645 - val_loss: 1.5173 - val_accuracy: 0.7446\n",
      "Epoch 443/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9372 - accuracy: 0.7645 - val_loss: 1.5866 - val_accuracy: 0.7097\n",
      "Epoch 444/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9365 - accuracy: 0.7683 - val_loss: 1.5611 - val_accuracy: 0.7504\n",
      "Epoch 445/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9356 - accuracy: 0.7665 - val_loss: 1.5734 - val_accuracy: 0.7477\n",
      "Epoch 446/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9327 - accuracy: 0.7693 - val_loss: 1.5656 - val_accuracy: 0.7388\n",
      "Epoch 447/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9309 - accuracy: 0.7699 - val_loss: 1.5762 - val_accuracy: 0.7461\n",
      "Epoch 448/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9278 - accuracy: 0.7699 - val_loss: 1.5697 - val_accuracy: 0.7527\n",
      "Epoch 449/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9289 - accuracy: 0.7702 - val_loss: 1.5554 - val_accuracy: 0.7558\n",
      "Epoch 450/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9264 - accuracy: 0.7689 - val_loss: 1.6208 - val_accuracy: 0.7376\n",
      "Epoch 451/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9292 - accuracy: 0.7664 - val_loss: 1.6036 - val_accuracy: 0.7457\n",
      "Epoch 452/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9232 - accuracy: 0.7712 - val_loss: 1.5975 - val_accuracy: 0.7415\n",
      "Epoch 453/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9317 - accuracy: 0.7692 - val_loss: 1.6152 - val_accuracy: 0.7473\n",
      "Epoch 454/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9264 - accuracy: 0.7684 - val_loss: 1.6551 - val_accuracy: 0.7341\n",
      "Epoch 455/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9264 - accuracy: 0.7688 - val_loss: 1.6677 - val_accuracy: 0.7399\n",
      "Epoch 456/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9309 - accuracy: 0.7671 - val_loss: 1.6558 - val_accuracy: 0.7422\n",
      "Epoch 457/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9256 - accuracy: 0.7709 - val_loss: 1.6181 - val_accuracy: 0.7438\n",
      "Epoch 458/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9206 - accuracy: 0.7689 - val_loss: 1.6397 - val_accuracy: 0.7523\n",
      "Epoch 459/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9236 - accuracy: 0.7684 - val_loss: 1.6609 - val_accuracy: 0.7426\n",
      "Epoch 460/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9199 - accuracy: 0.7732 - val_loss: 1.6760 - val_accuracy: 0.7430\n",
      "Epoch 461/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9174 - accuracy: 0.7725 - val_loss: 1.6417 - val_accuracy: 0.7531\n",
      "Epoch 462/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9199 - accuracy: 0.7725 - val_loss: 1.6112 - val_accuracy: 0.7298\n",
      "Epoch 463/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9200 - accuracy: 0.7725 - val_loss: 1.5432 - val_accuracy: 0.7671\n",
      "Epoch 464/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9148 - accuracy: 0.7736 - val_loss: 1.5581 - val_accuracy: 0.7512\n",
      "Epoch 465/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9207 - accuracy: 0.7709 - val_loss: 1.5594 - val_accuracy: 0.7453\n",
      "Epoch 466/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9208 - accuracy: 0.7710 - val_loss: 1.5706 - val_accuracy: 0.7566\n",
      "Epoch 467/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9150 - accuracy: 0.7737 - val_loss: 1.5765 - val_accuracy: 0.7527\n",
      "Epoch 468/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9222 - accuracy: 0.7700 - val_loss: 1.5975 - val_accuracy: 0.7558\n",
      "Epoch 469/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9153 - accuracy: 0.7718 - val_loss: 1.5954 - val_accuracy: 0.7527\n",
      "Epoch 470/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9129 - accuracy: 0.7753 - val_loss: 1.5955 - val_accuracy: 0.7640\n",
      "Epoch 471/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9146 - accuracy: 0.7727 - val_loss: 1.6220 - val_accuracy: 0.7566\n",
      "Epoch 472/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9267 - accuracy: 0.7741 - val_loss: 1.6477 - val_accuracy: 0.7519\n",
      "Epoch 473/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9088 - accuracy: 0.7756 - val_loss: 1.6228 - val_accuracy: 0.7628\n",
      "Epoch 474/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9164 - accuracy: 0.7740 - val_loss: 1.6876 - val_accuracy: 0.7380\n",
      "Epoch 475/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9072 - accuracy: 0.7759 - val_loss: 1.6946 - val_accuracy: 0.7442\n",
      "Epoch 476/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9118 - accuracy: 0.7719 - val_loss: 1.6777 - val_accuracy: 0.7655\n",
      "Epoch 477/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9063 - accuracy: 0.7739 - val_loss: 1.7744 - val_accuracy: 0.7314\n",
      "Epoch 478/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9016 - accuracy: 0.7779 - val_loss: 1.7042 - val_accuracy: 0.7636\n",
      "Epoch 479/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9101 - accuracy: 0.7746 - val_loss: 1.7051 - val_accuracy: 0.7578\n",
      "Epoch 480/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9034 - accuracy: 0.7767 - val_loss: 1.7130 - val_accuracy: 0.7450\n",
      "Epoch 481/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9115 - accuracy: 0.7702 - val_loss: 1.7454 - val_accuracy: 0.7488\n",
      "Epoch 482/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8994 - accuracy: 0.7780 - val_loss: 1.7241 - val_accuracy: 0.7550\n",
      "Epoch 483/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9022 - accuracy: 0.7768 - val_loss: 1.7305 - val_accuracy: 0.7453\n",
      "Epoch 484/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9076 - accuracy: 0.7736 - val_loss: 1.7416 - val_accuracy: 0.7512\n",
      "Epoch 485/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9084 - accuracy: 0.7726 - val_loss: 1.7942 - val_accuracy: 0.7609\n",
      "Epoch 486/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9004 - accuracy: 0.7755 - val_loss: 1.7678 - val_accuracy: 0.7736\n",
      "Epoch 487/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9058 - accuracy: 0.7735 - val_loss: 1.6762 - val_accuracy: 0.7364\n",
      "Epoch 488/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9165 - accuracy: 0.7721 - val_loss: 1.8759 - val_accuracy: 0.7457\n",
      "Epoch 489/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9216 - accuracy: 0.7784 - val_loss: 1.9404 - val_accuracy: 0.7306\n",
      "Epoch 490/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8938 - accuracy: 0.7821 - val_loss: 1.4858 - val_accuracy: 0.7508\n",
      "Epoch 491/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8861 - accuracy: 0.7837 - val_loss: 1.4859 - val_accuracy: 0.7636\n",
      "Epoch 492/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8830 - accuracy: 0.7859 - val_loss: 1.5054 - val_accuracy: 0.7508\n",
      "Epoch 493/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8839 - accuracy: 0.7826 - val_loss: 1.4818 - val_accuracy: 0.7690\n",
      "Epoch 494/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8924 - accuracy: 0.7794 - val_loss: 1.5077 - val_accuracy: 0.7605\n",
      "Epoch 495/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8906 - accuracy: 0.7820 - val_loss: 1.4906 - val_accuracy: 0.7636\n",
      "Epoch 496/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8892 - accuracy: 0.7797 - val_loss: 1.5142 - val_accuracy: 0.7395\n",
      "Epoch 497/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8945 - accuracy: 0.7787 - val_loss: 1.5650 - val_accuracy: 0.7326\n",
      "Epoch 498/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9013 - accuracy: 0.7741 - val_loss: 1.5231 - val_accuracy: 0.7620\n",
      "Epoch 499/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8873 - accuracy: 0.7799 - val_loss: 1.5382 - val_accuracy: 0.7686\n",
      "Epoch 500/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8922 - accuracy: 0.7780 - val_loss: 1.5299 - val_accuracy: 0.7647\n",
      "Epoch 501/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8922 - accuracy: 0.7790 - val_loss: 1.6171 - val_accuracy: 0.7357\n",
      "Epoch 502/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8958 - accuracy: 0.7753 - val_loss: 1.5714 - val_accuracy: 0.7636\n",
      "Epoch 503/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8895 - accuracy: 0.7780 - val_loss: 1.5597 - val_accuracy: 0.7632\n",
      "Epoch 504/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8877 - accuracy: 0.7801 - val_loss: 1.5787 - val_accuracy: 0.7550\n",
      "Epoch 505/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8833 - accuracy: 0.7802 - val_loss: 1.5791 - val_accuracy: 0.7574\n",
      "Epoch 506/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8981 - accuracy: 0.7762 - val_loss: 1.5748 - val_accuracy: 0.7628\n",
      "Epoch 507/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8887 - accuracy: 0.7802 - val_loss: 1.5758 - val_accuracy: 0.7798\n",
      "Epoch 508/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8885 - accuracy: 0.7802 - val_loss: 1.6326 - val_accuracy: 0.7609\n",
      "Epoch 509/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8937 - accuracy: 0.7790 - val_loss: 1.4749 - val_accuracy: 0.7547\n",
      "Epoch 510/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8817 - accuracy: 0.7811 - val_loss: 1.4926 - val_accuracy: 0.7612\n",
      "Epoch 511/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8877 - accuracy: 0.7819 - val_loss: 1.5290 - val_accuracy: 0.7713\n",
      "Epoch 512/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8846 - accuracy: 0.7795 - val_loss: 1.5073 - val_accuracy: 0.7740\n",
      "Epoch 513/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8834 - accuracy: 0.7803 - val_loss: 1.5629 - val_accuracy: 0.7481\n",
      "Epoch 514/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8868 - accuracy: 0.7779 - val_loss: 1.5992 - val_accuracy: 0.7357\n",
      "Epoch 515/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8863 - accuracy: 0.7784 - val_loss: 1.6190 - val_accuracy: 0.7461\n",
      "Epoch 516/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8800 - accuracy: 0.7835 - val_loss: 1.5463 - val_accuracy: 0.7403\n",
      "Epoch 517/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8886 - accuracy: 0.7785 - val_loss: 1.6527 - val_accuracy: 0.7240\n",
      "Epoch 518/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8830 - accuracy: 0.7799 - val_loss: 1.5769 - val_accuracy: 0.7411\n",
      "Epoch 519/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8854 - accuracy: 0.7795 - val_loss: 1.6250 - val_accuracy: 0.7419\n",
      "Epoch 520/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8861 - accuracy: 0.7795 - val_loss: 1.6163 - val_accuracy: 0.7484\n",
      "Epoch 521/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8843 - accuracy: 0.7805 - val_loss: 1.5543 - val_accuracy: 0.7640\n",
      "Epoch 522/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8790 - accuracy: 0.7818 - val_loss: 1.5611 - val_accuracy: 0.7574\n",
      "Epoch 523/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8808 - accuracy: 0.7809 - val_loss: 1.5727 - val_accuracy: 0.7504\n",
      "Epoch 524/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8842 - accuracy: 0.7795 - val_loss: 1.5761 - val_accuracy: 0.7643\n",
      "Epoch 525/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8799 - accuracy: 0.7834 - val_loss: 1.5712 - val_accuracy: 0.7717\n",
      "Epoch 526/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8805 - accuracy: 0.7826 - val_loss: 1.5835 - val_accuracy: 0.7702\n",
      "Epoch 527/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8760 - accuracy: 0.7812 - val_loss: 1.6024 - val_accuracy: 0.7612\n",
      "Epoch 528/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8734 - accuracy: 0.7847 - val_loss: 1.6280 - val_accuracy: 0.7488\n",
      "Epoch 529/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8744 - accuracy: 0.7839 - val_loss: 1.5688 - val_accuracy: 0.7593\n",
      "Epoch 530/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8703 - accuracy: 0.7818 - val_loss: 1.5843 - val_accuracy: 0.7690\n",
      "Epoch 531/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8748 - accuracy: 0.7835 - val_loss: 1.5577 - val_accuracy: 0.7674\n",
      "Epoch 532/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8723 - accuracy: 0.7857 - val_loss: 1.5625 - val_accuracy: 0.7713\n",
      "Epoch 533/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8750 - accuracy: 0.7835 - val_loss: 1.5965 - val_accuracy: 0.7601\n",
      "Epoch 534/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8763 - accuracy: 0.7789 - val_loss: 1.6207 - val_accuracy: 0.7504\n",
      "Epoch 535/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8711 - accuracy: 0.7835 - val_loss: 1.5679 - val_accuracy: 0.7783\n",
      "Epoch 536/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8677 - accuracy: 0.7838 - val_loss: 1.5932 - val_accuracy: 0.7624\n",
      "Epoch 537/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8697 - accuracy: 0.7821 - val_loss: 1.5995 - val_accuracy: 0.7632\n",
      "Epoch 538/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8688 - accuracy: 0.7845 - val_loss: 1.5882 - val_accuracy: 0.7667\n",
      "Epoch 539/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8692 - accuracy: 0.7816 - val_loss: 1.5871 - val_accuracy: 0.7888\n",
      "Epoch 540/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8758 - accuracy: 0.7806 - val_loss: 1.6187 - val_accuracy: 0.7659\n",
      "Epoch 541/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8604 - accuracy: 0.7862 - val_loss: 1.6139 - val_accuracy: 0.7791\n",
      "Epoch 542/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0327 - accuracy: 0.7780 - val_loss: 1.8362 - val_accuracy: 0.7516\n",
      "Epoch 543/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8627 - accuracy: 0.7904 - val_loss: 1.7214 - val_accuracy: 0.7554\n",
      "Epoch 544/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8503 - accuracy: 0.7907 - val_loss: 1.6937 - val_accuracy: 0.7671\n",
      "Epoch 545/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8515 - accuracy: 0.7930 - val_loss: 1.6952 - val_accuracy: 0.7717\n",
      "Epoch 546/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8535 - accuracy: 0.7907 - val_loss: 1.6751 - val_accuracy: 0.7787\n",
      "Epoch 547/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8525 - accuracy: 0.7912 - val_loss: 1.7049 - val_accuracy: 0.7512\n",
      "Epoch 548/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8604 - accuracy: 0.7870 - val_loss: 1.7891 - val_accuracy: 0.7504\n",
      "Epoch 549/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8666 - accuracy: 0.7864 - val_loss: 1.7163 - val_accuracy: 0.7446\n",
      "Epoch 550/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8569 - accuracy: 0.7877 - val_loss: 1.7570 - val_accuracy: 0.7593\n",
      "Epoch 551/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8609 - accuracy: 0.7858 - val_loss: 1.7188 - val_accuracy: 0.7709\n",
      "Epoch 552/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8676 - accuracy: 0.7824 - val_loss: 1.7575 - val_accuracy: 0.7752\n",
      "Epoch 553/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8676 - accuracy: 0.7850 - val_loss: 1.7648 - val_accuracy: 0.7628\n",
      "Epoch 554/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8631 - accuracy: 0.7851 - val_loss: 1.7394 - val_accuracy: 0.7783\n",
      "Epoch 555/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8597 - accuracy: 0.7852 - val_loss: 1.7792 - val_accuracy: 0.7527\n",
      "Epoch 556/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8587 - accuracy: 0.7855 - val_loss: 1.8031 - val_accuracy: 0.7411\n",
      "Epoch 557/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8689 - accuracy: 0.7835 - val_loss: 1.8215 - val_accuracy: 0.7581\n",
      "Epoch 558/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8602 - accuracy: 0.7862 - val_loss: 1.8207 - val_accuracy: 0.7376\n",
      "Epoch 559/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8606 - accuracy: 0.7826 - val_loss: 1.7700 - val_accuracy: 0.7620\n",
      "Epoch 560/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8526 - accuracy: 0.7882 - val_loss: 1.7834 - val_accuracy: 0.7581\n",
      "Epoch 561/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8572 - accuracy: 0.7863 - val_loss: 1.7357 - val_accuracy: 0.7926\n",
      "Epoch 562/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8541 - accuracy: 0.7887 - val_loss: 1.7774 - val_accuracy: 0.7702\n",
      "Epoch 563/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8631 - accuracy: 0.7854 - val_loss: 1.7910 - val_accuracy: 0.7721\n",
      "Epoch 564/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8536 - accuracy: 0.7875 - val_loss: 1.8385 - val_accuracy: 0.7508\n",
      "Epoch 565/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8541 - accuracy: 0.7863 - val_loss: 1.8416 - val_accuracy: 0.7554\n",
      "Epoch 566/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8634 - accuracy: 0.7845 - val_loss: 1.7948 - val_accuracy: 0.7659\n",
      "Epoch 567/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8532 - accuracy: 0.7888 - val_loss: 1.7747 - val_accuracy: 0.7760\n",
      "Epoch 568/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8561 - accuracy: 0.7867 - val_loss: 1.8132 - val_accuracy: 0.7694\n",
      "Epoch 569/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8552 - accuracy: 0.7868 - val_loss: 1.6641 - val_accuracy: 0.7628\n",
      "Epoch 570/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8589 - accuracy: 0.7845 - val_loss: 1.6769 - val_accuracy: 0.7833\n",
      "Epoch 571/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8528 - accuracy: 0.7879 - val_loss: 1.7502 - val_accuracy: 0.7391\n",
      "Epoch 572/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8471 - accuracy: 0.7884 - val_loss: 1.7124 - val_accuracy: 0.7698\n",
      "Epoch 573/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8497 - accuracy: 0.7881 - val_loss: 1.7396 - val_accuracy: 0.7434\n",
      "Epoch 574/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8448 - accuracy: 0.7902 - val_loss: 1.6836 - val_accuracy: 0.7884\n",
      "Epoch 575/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8505 - accuracy: 0.7894 - val_loss: 1.6220 - val_accuracy: 0.7647\n",
      "Epoch 576/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8515 - accuracy: 0.7895 - val_loss: 1.6325 - val_accuracy: 0.7783\n",
      "Epoch 577/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8509 - accuracy: 0.7857 - val_loss: 1.6132 - val_accuracy: 0.7647\n",
      "Epoch 578/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8483 - accuracy: 0.7885 - val_loss: 1.5965 - val_accuracy: 0.7872\n",
      "Epoch 579/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8514 - accuracy: 0.7891 - val_loss: 1.6183 - val_accuracy: 0.7725\n",
      "Epoch 580/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8444 - accuracy: 0.7914 - val_loss: 1.6313 - val_accuracy: 0.7640\n",
      "Epoch 581/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8577 - accuracy: 0.7862 - val_loss: 1.7270 - val_accuracy: 0.7329\n",
      "Epoch 582/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8460 - accuracy: 0.7885 - val_loss: 1.7353 - val_accuracy: 0.7713\n",
      "Epoch 583/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8478 - accuracy: 0.7885 - val_loss: 1.6947 - val_accuracy: 0.7426\n",
      "Epoch 584/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8467 - accuracy: 0.7876 - val_loss: 1.6862 - val_accuracy: 0.7748\n",
      "Epoch 585/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8490 - accuracy: 0.7887 - val_loss: 1.6419 - val_accuracy: 0.7671\n",
      "Epoch 586/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8435 - accuracy: 0.7901 - val_loss: 1.6850 - val_accuracy: 0.7694\n",
      "Epoch 587/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8421 - accuracy: 0.7904 - val_loss: 1.6645 - val_accuracy: 0.7671\n",
      "Epoch 588/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8486 - accuracy: 0.7891 - val_loss: 1.6389 - val_accuracy: 0.7826\n",
      "Epoch 589/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8482 - accuracy: 0.7881 - val_loss: 1.6633 - val_accuracy: 0.7674\n",
      "Epoch 590/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8363 - accuracy: 0.7944 - val_loss: 1.7002 - val_accuracy: 0.7651\n",
      "Epoch 591/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8412 - accuracy: 0.7901 - val_loss: 1.7567 - val_accuracy: 0.7488\n",
      "Epoch 592/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8407 - accuracy: 0.7892 - val_loss: 1.6934 - val_accuracy: 0.7822\n",
      "Epoch 593/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8446 - accuracy: 0.7886 - val_loss: 1.7327 - val_accuracy: 0.7686\n",
      "Epoch 594/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8393 - accuracy: 0.7918 - val_loss: 1.6983 - val_accuracy: 0.7725\n",
      "Epoch 595/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8366 - accuracy: 0.7929 - val_loss: 1.7137 - val_accuracy: 0.7659\n",
      "Epoch 596/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8380 - accuracy: 0.7907 - val_loss: 1.7565 - val_accuracy: 0.7496\n",
      "Epoch 597/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8436 - accuracy: 0.7894 - val_loss: 1.7688 - val_accuracy: 0.7632\n",
      "Epoch 598/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8465 - accuracy: 0.7930 - val_loss: 1.7731 - val_accuracy: 0.7671\n",
      "Epoch 599/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8237 - accuracy: 0.8013 - val_loss: 1.7615 - val_accuracy: 0.7671\n",
      "Epoch 600/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8288 - accuracy: 0.7935 - val_loss: 1.7498 - val_accuracy: 0.7833\n",
      "Epoch 601/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8324 - accuracy: 0.7945 - val_loss: 1.7542 - val_accuracy: 0.7795\n",
      "Epoch 602/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8364 - accuracy: 0.7924 - val_loss: 1.8101 - val_accuracy: 0.7655\n",
      "Epoch 603/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8267 - accuracy: 0.7945 - val_loss: 1.9058 - val_accuracy: 0.7461\n",
      "Epoch 604/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8372 - accuracy: 0.7930 - val_loss: 1.8638 - val_accuracy: 0.7360\n",
      "Epoch 605/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8253 - accuracy: 0.7944 - val_loss: 1.8054 - val_accuracy: 0.7647\n",
      "Epoch 606/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8358 - accuracy: 0.7907 - val_loss: 1.8170 - val_accuracy: 0.7682\n",
      "Epoch 607/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8433 - accuracy: 0.7915 - val_loss: 1.6889 - val_accuracy: 0.7647\n",
      "Epoch 608/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8283 - accuracy: 0.7929 - val_loss: 1.6673 - val_accuracy: 0.7733\n",
      "Epoch 609/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8327 - accuracy: 0.7919 - val_loss: 1.6779 - val_accuracy: 0.7752\n",
      "Epoch 610/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8178 - accuracy: 0.7975 - val_loss: 1.6989 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8367 - accuracy: 0.7894 - val_loss: 1.7181 - val_accuracy: 0.7647\n",
      "Epoch 612/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8399 - accuracy: 0.7904 - val_loss: 1.6343 - val_accuracy: 0.7671\n",
      "Epoch 613/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8321 - accuracy: 0.7938 - val_loss: 1.7168 - val_accuracy: 0.7791\n",
      "Epoch 614/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8432 - accuracy: 0.7907 - val_loss: 1.7057 - val_accuracy: 0.7841\n",
      "Epoch 615/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8281 - accuracy: 0.7925 - val_loss: 1.7692 - val_accuracy: 0.7407\n",
      "Epoch 616/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8250 - accuracy: 0.7950 - val_loss: 1.6902 - val_accuracy: 0.7911\n",
      "Epoch 617/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8278 - accuracy: 0.7926 - val_loss: 1.7410 - val_accuracy: 0.7659\n",
      "Epoch 618/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8274 - accuracy: 0.7951 - val_loss: 1.7208 - val_accuracy: 0.7767\n",
      "Epoch 619/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8285 - accuracy: 0.7916 - val_loss: 1.6985 - val_accuracy: 0.7829\n",
      "Epoch 620/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8284 - accuracy: 0.7906 - val_loss: 1.7539 - val_accuracy: 0.7678\n",
      "Epoch 621/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.7938 - val_loss: 1.6923 - val_accuracy: 0.7907\n",
      "Epoch 622/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8187 - accuracy: 0.7983 - val_loss: 1.7143 - val_accuracy: 0.7736\n",
      "Epoch 623/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8358 - accuracy: 0.7922 - val_loss: 1.7495 - val_accuracy: 0.7698\n",
      "Epoch 624/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8261 - accuracy: 0.7947 - val_loss: 1.7564 - val_accuracy: 0.7736\n",
      "Epoch 625/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8180 - accuracy: 0.7969 - val_loss: 1.7406 - val_accuracy: 0.7643\n",
      "Epoch 626/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8228 - accuracy: 0.7933 - val_loss: 1.7335 - val_accuracy: 0.7694\n",
      "Epoch 627/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8272 - accuracy: 0.7952 - val_loss: 1.7007 - val_accuracy: 0.8070\n",
      "Epoch 628/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8211 - accuracy: 0.7953 - val_loss: 1.7522 - val_accuracy: 0.7632\n",
      "Epoch 629/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8242 - accuracy: 0.7944 - val_loss: 1.7042 - val_accuracy: 0.7756\n",
      "Epoch 630/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8248 - accuracy: 0.7941 - val_loss: 1.8338 - val_accuracy: 0.7562\n",
      "Epoch 631/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8234 - accuracy: 0.7957 - val_loss: 1.7396 - val_accuracy: 0.7795\n",
      "Epoch 632/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8152 - accuracy: 0.7985 - val_loss: 1.8123 - val_accuracy: 0.7826\n",
      "Epoch 633/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8265 - accuracy: 0.7963 - val_loss: 1.7611 - val_accuracy: 0.7795\n",
      "Epoch 634/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8148 - accuracy: 0.7968 - val_loss: 1.7576 - val_accuracy: 0.7891\n",
      "Epoch 635/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8478 - accuracy: 0.7981 - val_loss: 1.7091 - val_accuracy: 0.7845\n",
      "Epoch 636/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8115 - accuracy: 0.7973 - val_loss: 1.7298 - val_accuracy: 0.7876\n",
      "Epoch 637/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8103 - accuracy: 0.8014 - val_loss: 1.7868 - val_accuracy: 0.7717\n",
      "Epoch 638/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8146 - accuracy: 0.7953 - val_loss: 1.7216 - val_accuracy: 0.7837\n",
      "Epoch 639/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8172 - accuracy: 0.7962 - val_loss: 1.7824 - val_accuracy: 0.7795\n",
      "Epoch 640/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8196 - accuracy: 0.7987 - val_loss: 1.8426 - val_accuracy: 0.7690\n",
      "Epoch 641/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8148 - accuracy: 0.7971 - val_loss: 1.7890 - val_accuracy: 0.7752\n",
      "Epoch 642/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8106 - accuracy: 0.8011 - val_loss: 1.7630 - val_accuracy: 0.7926\n",
      "Epoch 643/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8146 - accuracy: 0.7969 - val_loss: 1.7690 - val_accuracy: 0.7891\n",
      "Epoch 644/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8069 - accuracy: 0.8000 - val_loss: 1.8141 - val_accuracy: 0.7717\n",
      "Epoch 645/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8240 - accuracy: 0.7954 - val_loss: 1.8878 - val_accuracy: 0.7457\n",
      "Epoch 646/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8225 - accuracy: 0.7933 - val_loss: 1.8528 - val_accuracy: 0.7752\n",
      "Epoch 647/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8154 - accuracy: 0.7957 - val_loss: 1.8203 - val_accuracy: 0.7884\n",
      "Epoch 648/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8108 - accuracy: 0.7978 - val_loss: 1.8192 - val_accuracy: 0.7857\n",
      "Epoch 649/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8135 - accuracy: 0.7964 - val_loss: 1.8227 - val_accuracy: 0.7884\n",
      "Epoch 650/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8184 - accuracy: 0.7966 - val_loss: 1.8261 - val_accuracy: 0.7833\n",
      "Epoch 651/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8162 - accuracy: 0.7973 - val_loss: 1.8851 - val_accuracy: 0.7624\n",
      "Epoch 652/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8101 - accuracy: 0.7977 - val_loss: 1.8336 - val_accuracy: 0.7822\n",
      "Epoch 653/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8072 - accuracy: 0.7990 - val_loss: 1.8580 - val_accuracy: 0.7806\n",
      "Epoch 654/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8146 - accuracy: 0.7976 - val_loss: 1.8615 - val_accuracy: 0.7597\n",
      "Epoch 655/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8206 - accuracy: 0.7942 - val_loss: 1.8856 - val_accuracy: 0.7802\n",
      "Epoch 656/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8100 - accuracy: 0.7972 - val_loss: 1.8382 - val_accuracy: 0.7864\n",
      "Epoch 657/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8067 - accuracy: 0.7978 - val_loss: 1.9048 - val_accuracy: 0.7678\n",
      "Epoch 658/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8140 - accuracy: 0.7960 - val_loss: 1.8808 - val_accuracy: 0.7841\n",
      "Epoch 659/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8113 - accuracy: 0.7975 - val_loss: 1.8444 - val_accuracy: 0.8097\n",
      "Epoch 660/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8013 - accuracy: 0.7995 - val_loss: 1.8562 - val_accuracy: 0.7795\n",
      "Epoch 661/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8059 - accuracy: 0.7972 - val_loss: 1.6058 - val_accuracy: 0.7612\n",
      "Epoch 662/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8120 - accuracy: 0.7967 - val_loss: 1.3820 - val_accuracy: 0.7984\n",
      "Epoch 663/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7979 - accuracy: 0.8010 - val_loss: 1.4611 - val_accuracy: 0.7523\n",
      "Epoch 664/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8109 - accuracy: 0.7950 - val_loss: 1.4328 - val_accuracy: 0.7694\n",
      "Epoch 665/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8001 - accuracy: 0.7978 - val_loss: 1.4577 - val_accuracy: 0.7659\n",
      "Epoch 666/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8105 - accuracy: 0.7969 - val_loss: 1.4001 - val_accuracy: 0.7888\n",
      "Epoch 667/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8122 - accuracy: 0.7983 - val_loss: 1.4719 - val_accuracy: 0.7616\n",
      "Epoch 668/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8093 - accuracy: 0.7997 - val_loss: 1.4286 - val_accuracy: 0.7783\n",
      "Epoch 669/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8053 - accuracy: 0.8001 - val_loss: 1.4109 - val_accuracy: 0.7814\n",
      "Epoch 670/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8013 - accuracy: 0.8001 - val_loss: 1.4229 - val_accuracy: 0.7767\n",
      "Epoch 671/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8014 - accuracy: 0.7994 - val_loss: 1.4036 - val_accuracy: 0.7837\n",
      "Epoch 672/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8028 - accuracy: 0.8000 - val_loss: 1.4430 - val_accuracy: 0.7616\n",
      "Epoch 673/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8039 - accuracy: 0.7974 - val_loss: 1.3777 - val_accuracy: 0.8023\n",
      "Epoch 674/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7985 - accuracy: 0.8006 - val_loss: 1.4352 - val_accuracy: 0.7705\n",
      "Epoch 675/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8025 - accuracy: 0.8026 - val_loss: 1.4200 - val_accuracy: 0.7868\n",
      "Epoch 676/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8079 - accuracy: 0.7959 - val_loss: 1.4679 - val_accuracy: 0.7919\n",
      "Epoch 677/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8065 - accuracy: 0.7993 - val_loss: 1.4281 - val_accuracy: 0.7822\n",
      "Epoch 678/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7996 - accuracy: 0.8014 - val_loss: 1.3856 - val_accuracy: 0.8000\n",
      "Epoch 679/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7941 - accuracy: 0.8027 - val_loss: 1.4492 - val_accuracy: 0.7721\n",
      "Epoch 680/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7989 - accuracy: 0.8005 - val_loss: 1.4437 - val_accuracy: 0.7818\n",
      "Epoch 681/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7964 - accuracy: 0.8025 - val_loss: 1.4082 - val_accuracy: 0.8012\n",
      "Epoch 682/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8436 - accuracy: 0.7998 - val_loss: 1.4338 - val_accuracy: 0.7895\n",
      "Epoch 683/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7968 - accuracy: 0.8071 - val_loss: 1.5046 - val_accuracy: 0.7783\n",
      "Epoch 684/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7836 - accuracy: 0.8091 - val_loss: 1.5189 - val_accuracy: 0.7880\n",
      "Epoch 685/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7930 - accuracy: 0.8052 - val_loss: 1.4321 - val_accuracy: 0.7860\n",
      "Epoch 686/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7885 - accuracy: 0.8051 - val_loss: 1.4717 - val_accuracy: 0.7605\n",
      "Epoch 687/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7883 - accuracy: 0.8025 - val_loss: 1.4885 - val_accuracy: 0.7709\n",
      "Epoch 688/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7884 - accuracy: 0.8030 - val_loss: 1.5095 - val_accuracy: 0.7837\n",
      "Epoch 689/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7961 - accuracy: 0.7991 - val_loss: 1.4806 - val_accuracy: 0.7744\n",
      "Epoch 690/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8011 - accuracy: 0.7999 - val_loss: 1.5707 - val_accuracy: 0.7628\n",
      "Epoch 691/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7878 - accuracy: 0.8061 - val_loss: 1.5880 - val_accuracy: 0.7535\n",
      "Epoch 692/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7936 - accuracy: 0.8022 - val_loss: 1.5089 - val_accuracy: 0.7725\n",
      "Epoch 693/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8014 - accuracy: 0.8015 - val_loss: 1.4548 - val_accuracy: 0.7926\n",
      "Epoch 694/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7958 - accuracy: 0.8012 - val_loss: 1.4999 - val_accuracy: 0.7756\n",
      "Epoch 695/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7889 - accuracy: 0.8042 - val_loss: 1.5176 - val_accuracy: 0.7814\n",
      "Epoch 696/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7859 - accuracy: 0.8040 - val_loss: 1.4877 - val_accuracy: 0.7946\n",
      "Epoch 697/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7893 - accuracy: 0.8047 - val_loss: 1.4954 - val_accuracy: 0.7698\n",
      "Epoch 698/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8115 - accuracy: 0.8008 - val_loss: 1.5360 - val_accuracy: 0.7934\n",
      "Epoch 699/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8008 - accuracy: 0.8036 - val_loss: 1.7245 - val_accuracy: 0.8019\n",
      "Epoch 700/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8211 - accuracy: 0.8007 - val_loss: 1.6486 - val_accuracy: 0.7795\n",
      "Epoch 701/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7787 - accuracy: 0.8085 - val_loss: 1.6068 - val_accuracy: 0.7926\n",
      "Epoch 702/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7755 - accuracy: 0.8080 - val_loss: 1.6940 - val_accuracy: 0.7663\n",
      "Epoch 703/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7846 - accuracy: 0.8059 - val_loss: 1.6318 - val_accuracy: 0.7922\n",
      "Epoch 704/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7846 - accuracy: 0.8033 - val_loss: 1.6153 - val_accuracy: 0.7895\n",
      "Epoch 705/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7856 - accuracy: 0.8019 - val_loss: 1.6221 - val_accuracy: 0.7802\n",
      "Epoch 706/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7856 - accuracy: 0.8030 - val_loss: 1.7218 - val_accuracy: 0.7558\n",
      "Epoch 707/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7834 - accuracy: 0.8043 - val_loss: 1.6518 - val_accuracy: 0.7779\n",
      "Epoch 708/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7873 - accuracy: 0.8037 - val_loss: 1.6337 - val_accuracy: 0.7767\n",
      "Epoch 709/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7872 - accuracy: 0.8060 - val_loss: 1.7596 - val_accuracy: 0.7640\n",
      "Epoch 710/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7893 - accuracy: 0.8043 - val_loss: 1.7716 - val_accuracy: 0.7516\n",
      "Epoch 711/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7959 - accuracy: 0.8004 - val_loss: 1.6900 - val_accuracy: 0.7981\n",
      "Epoch 712/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8151 - accuracy: 0.8005 - val_loss: 1.7938 - val_accuracy: 0.7798\n",
      "Epoch 713/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7733 - accuracy: 0.8110 - val_loss: 1.7639 - val_accuracy: 0.7930\n",
      "Epoch 714/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7725 - accuracy: 0.8112 - val_loss: 1.7873 - val_accuracy: 0.7740\n",
      "Epoch 715/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7744 - accuracy: 0.8108 - val_loss: 1.7925 - val_accuracy: 0.7748\n",
      "Epoch 716/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7786 - accuracy: 0.8064 - val_loss: 1.8211 - val_accuracy: 0.7930\n",
      "Epoch 717/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7830 - accuracy: 0.8050 - val_loss: 1.8520 - val_accuracy: 0.7837\n",
      "Epoch 718/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7820 - accuracy: 0.8060 - val_loss: 1.8486 - val_accuracy: 0.8031\n",
      "Epoch 719/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7845 - accuracy: 0.8059 - val_loss: 1.8879 - val_accuracy: 0.7895\n",
      "Epoch 720/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7901 - accuracy: 0.8063 - val_loss: 1.9062 - val_accuracy: 0.7864\n",
      "Epoch 721/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7919 - accuracy: 0.8032 - val_loss: 1.8972 - val_accuracy: 0.7977\n",
      "Epoch 722/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7785 - accuracy: 0.8059 - val_loss: 1.9484 - val_accuracy: 0.7744\n",
      "Epoch 723/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7864 - accuracy: 0.8037 - val_loss: 1.8917 - val_accuracy: 0.7802\n",
      "Epoch 724/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7804 - accuracy: 0.8049 - val_loss: 1.8558 - val_accuracy: 0.8035\n",
      "Epoch 725/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7971 - accuracy: 0.8008 - val_loss: 1.9059 - val_accuracy: 0.7826\n",
      "Epoch 726/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7734 - accuracy: 0.8086 - val_loss: 1.9536 - val_accuracy: 0.7686\n",
      "Epoch 727/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7901 - accuracy: 0.8009 - val_loss: 1.8955 - val_accuracy: 0.7783\n",
      "Epoch 728/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7870 - accuracy: 0.8041 - val_loss: 1.9767 - val_accuracy: 0.7554\n",
      "Epoch 729/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7882 - accuracy: 0.8023 - val_loss: 1.9042 - val_accuracy: 0.7969\n",
      "Epoch 730/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7799 - accuracy: 0.8065 - val_loss: 1.9871 - val_accuracy: 0.7620\n",
      "Epoch 731/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7805 - accuracy: 0.8046 - val_loss: 1.8709 - val_accuracy: 0.7961\n",
      "Epoch 732/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7833 - accuracy: 0.8073 - val_loss: 1.8759 - val_accuracy: 0.7857\n",
      "Epoch 733/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7776 - accuracy: 0.8057 - val_loss: 1.9305 - val_accuracy: 0.7884\n",
      "Epoch 734/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7814 - accuracy: 0.8038 - val_loss: 1.8995 - val_accuracy: 0.7849\n",
      "Epoch 735/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7797 - accuracy: 0.8048 - val_loss: 2.0231 - val_accuracy: 0.7647\n",
      "Epoch 736/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7799 - accuracy: 0.8073 - val_loss: 1.8899 - val_accuracy: 0.7946\n",
      "Epoch 737/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7742 - accuracy: 0.8084 - val_loss: 1.8719 - val_accuracy: 0.8023\n",
      "Epoch 738/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7796 - accuracy: 0.8054 - val_loss: 1.9930 - val_accuracy: 0.7628\n",
      "Epoch 739/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7761 - accuracy: 0.8068 - val_loss: 1.9401 - val_accuracy: 0.7760\n",
      "Epoch 740/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7752 - accuracy: 0.8063 - val_loss: 1.8408 - val_accuracy: 0.7950\n",
      "Epoch 741/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7737 - accuracy: 0.8078 - val_loss: 1.8494 - val_accuracy: 0.7891\n",
      "Epoch 742/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7789 - accuracy: 0.8064 - val_loss: 1.8519 - val_accuracy: 0.7880\n",
      "Epoch 743/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7738 - accuracy: 0.8059 - val_loss: 1.8689 - val_accuracy: 0.7725\n",
      "Epoch 744/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7761 - accuracy: 0.8048 - val_loss: 1.8656 - val_accuracy: 0.7764\n",
      "Epoch 745/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7658 - accuracy: 0.8093 - val_loss: 1.8437 - val_accuracy: 0.7981\n",
      "Epoch 746/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7789 - accuracy: 0.8056 - val_loss: 1.9254 - val_accuracy: 0.7775\n",
      "Epoch 747/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7696 - accuracy: 0.8137 - val_loss: 1.7363 - val_accuracy: 0.8019\n",
      "Epoch 748/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7656 - accuracy: 0.8092 - val_loss: 1.7379 - val_accuracy: 0.7880\n",
      "Epoch 749/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7779 - accuracy: 0.8080 - val_loss: 1.7266 - val_accuracy: 0.7860\n",
      "Epoch 750/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7815 - accuracy: 0.8047 - val_loss: 1.7255 - val_accuracy: 0.7806\n",
      "Epoch 751/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7711 - accuracy: 0.8096 - val_loss: 1.7046 - val_accuracy: 0.7969\n",
      "Epoch 752/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7679 - accuracy: 0.8087 - val_loss: 1.6792 - val_accuracy: 0.8198\n",
      "Epoch 753/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7677 - accuracy: 0.8054 - val_loss: 1.6827 - val_accuracy: 0.8159\n",
      "Epoch 754/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7829 - accuracy: 0.8022 - val_loss: 1.9249 - val_accuracy: 0.7543\n",
      "Epoch 755/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7741 - accuracy: 0.8063 - val_loss: 1.8005 - val_accuracy: 0.7721\n",
      "Epoch 756/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7719 - accuracy: 0.8097 - val_loss: 1.7823 - val_accuracy: 0.7748\n",
      "Epoch 757/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7681 - accuracy: 0.8083 - val_loss: 1.7600 - val_accuracy: 0.7884\n",
      "Epoch 758/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7653 - accuracy: 0.8101 - val_loss: 1.8079 - val_accuracy: 0.7729\n",
      "Epoch 759/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7775 - accuracy: 0.8062 - val_loss: 1.7851 - val_accuracy: 0.7876\n",
      "Epoch 760/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7683 - accuracy: 0.8076 - val_loss: 1.7547 - val_accuracy: 0.8136\n",
      "Epoch 761/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7665 - accuracy: 0.8087 - val_loss: 1.6953 - val_accuracy: 0.7911\n",
      "Epoch 762/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7716 - accuracy: 0.8072 - val_loss: 1.7239 - val_accuracy: 0.7674\n",
      "Epoch 763/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7679 - accuracy: 0.8076 - val_loss: 1.6958 - val_accuracy: 0.7891\n",
      "Epoch 764/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7771 - accuracy: 0.8084 - val_loss: 1.7622 - val_accuracy: 0.7853\n",
      "Epoch 765/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7699 - accuracy: 0.8120 - val_loss: 1.7230 - val_accuracy: 0.7798\n",
      "Epoch 766/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7624 - accuracy: 0.8101 - val_loss: 1.7732 - val_accuracy: 0.7698\n",
      "Epoch 767/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7720 - accuracy: 0.8059 - val_loss: 1.6871 - val_accuracy: 0.7957\n",
      "Epoch 768/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7711 - accuracy: 0.8076 - val_loss: 1.7461 - val_accuracy: 0.7919\n",
      "Epoch 769/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7663 - accuracy: 0.8103 - val_loss: 1.7348 - val_accuracy: 0.7740\n",
      "Epoch 770/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7600 - accuracy: 0.8108 - val_loss: 1.6883 - val_accuracy: 0.7981\n",
      "Epoch 771/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7660 - accuracy: 0.8072 - val_loss: 1.7069 - val_accuracy: 0.8008\n",
      "Epoch 772/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7658 - accuracy: 0.8068 - val_loss: 1.7650 - val_accuracy: 0.7725\n",
      "Epoch 773/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7651 - accuracy: 0.8093 - val_loss: 1.8058 - val_accuracy: 0.7919\n",
      "Epoch 774/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7625 - accuracy: 0.8109 - val_loss: 1.7774 - val_accuracy: 0.7903\n",
      "Epoch 775/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7649 - accuracy: 0.8106 - val_loss: 1.9122 - val_accuracy: 0.7570\n",
      "Epoch 776/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7712 - accuracy: 0.8093 - val_loss: 1.8244 - val_accuracy: 0.7736\n",
      "Epoch 777/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7746 - accuracy: 0.8053 - val_loss: 1.9039 - val_accuracy: 0.7663\n",
      "Epoch 778/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7561 - accuracy: 0.8135 - val_loss: 1.8582 - val_accuracy: 0.7818\n",
      "Epoch 779/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7603 - accuracy: 0.8100 - val_loss: 1.8336 - val_accuracy: 0.7798\n",
      "Epoch 780/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7640 - accuracy: 0.8053 - val_loss: 1.8631 - val_accuracy: 0.7833\n",
      "Epoch 781/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7701 - accuracy: 0.8079 - val_loss: 1.8654 - val_accuracy: 0.7930\n",
      "Epoch 782/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7668 - accuracy: 0.8067 - val_loss: 1.8436 - val_accuracy: 0.7814\n",
      "Epoch 783/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7762 - accuracy: 0.8102 - val_loss: 2.0523 - val_accuracy: 0.7194\n",
      "Epoch 784/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8643 - accuracy: 0.8103 - val_loss: 1.8011 - val_accuracy: 0.7841\n",
      "Epoch 785/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7444 - accuracy: 0.8181 - val_loss: 1.7815 - val_accuracy: 0.8012\n",
      "Epoch 786/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7403 - accuracy: 0.8171 - val_loss: 1.9113 - val_accuracy: 0.7826\n",
      "Epoch 787/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7456 - accuracy: 0.8172 - val_loss: 1.9005 - val_accuracy: 0.7682\n",
      "Epoch 788/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7515 - accuracy: 0.8141 - val_loss: 1.8604 - val_accuracy: 0.8000\n",
      "Epoch 789/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7538 - accuracy: 0.8135 - val_loss: 1.8595 - val_accuracy: 0.7891\n",
      "Epoch 790/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7483 - accuracy: 0.8153 - val_loss: 1.8991 - val_accuracy: 0.7810\n",
      "Epoch 791/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7650 - accuracy: 0.8123 - val_loss: 1.8392 - val_accuracy: 0.8093\n",
      "Epoch 792/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7525 - accuracy: 0.8116 - val_loss: 1.8608 - val_accuracy: 0.7868\n",
      "Epoch 793/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7543 - accuracy: 0.8137 - val_loss: 1.8087 - val_accuracy: 0.8000\n",
      "Epoch 794/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7528 - accuracy: 0.8149 - val_loss: 1.7917 - val_accuracy: 0.8120\n",
      "Epoch 795/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7554 - accuracy: 0.8096 - val_loss: 1.8429 - val_accuracy: 0.7915\n",
      "Epoch 796/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7650 - accuracy: 0.8086 - val_loss: 1.8172 - val_accuracy: 0.7922\n",
      "Epoch 797/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7578 - accuracy: 0.8110 - val_loss: 2.0256 - val_accuracy: 0.7430\n",
      "Epoch 798/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7619 - accuracy: 0.8093 - val_loss: 1.9375 - val_accuracy: 0.7558\n",
      "Epoch 799/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7589 - accuracy: 0.8114 - val_loss: 1.8292 - val_accuracy: 0.7911\n",
      "Epoch 800/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7499 - accuracy: 0.8130 - val_loss: 1.8105 - val_accuracy: 0.7992\n",
      "Epoch 801/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7562 - accuracy: 0.8106 - val_loss: 1.8326 - val_accuracy: 0.8008\n",
      "Epoch 802/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7623 - accuracy: 0.8103 - val_loss: 1.9366 - val_accuracy: 0.7864\n",
      "Epoch 803/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7603 - accuracy: 0.8112 - val_loss: 1.9256 - val_accuracy: 0.7814\n",
      "Epoch 804/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7490 - accuracy: 0.8157 - val_loss: 1.9522 - val_accuracy: 0.7946\n",
      "Epoch 805/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7558 - accuracy: 0.8120 - val_loss: 1.9706 - val_accuracy: 0.7888\n",
      "Epoch 806/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7524 - accuracy: 0.8113 - val_loss: 1.9779 - val_accuracy: 0.7713\n",
      "Epoch 807/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7606 - accuracy: 0.8119 - val_loss: 1.9831 - val_accuracy: 0.7798\n",
      "Epoch 808/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7578 - accuracy: 0.8094 - val_loss: 1.9087 - val_accuracy: 0.7926\n",
      "Epoch 809/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7511 - accuracy: 0.8109 - val_loss: 1.9914 - val_accuracy: 0.7957\n",
      "Epoch 810/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7540 - accuracy: 0.8099 - val_loss: 2.0260 - val_accuracy: 0.7744\n",
      "Epoch 811/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7539 - accuracy: 0.8100 - val_loss: 1.9882 - val_accuracy: 0.7938\n",
      "Epoch 812/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7490 - accuracy: 0.8133 - val_loss: 1.9395 - val_accuracy: 0.8047\n",
      "Epoch 813/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7542 - accuracy: 0.8121 - val_loss: 2.0652 - val_accuracy: 0.7771\n",
      "Epoch 814/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7504 - accuracy: 0.8104 - val_loss: 1.9999 - val_accuracy: 0.7845\n",
      "Epoch 815/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7431 - accuracy: 0.8156 - val_loss: 1.9479 - val_accuracy: 0.8016\n",
      "Epoch 816/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7552 - accuracy: 0.8105 - val_loss: 1.9615 - val_accuracy: 0.7992\n",
      "Epoch 817/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7479 - accuracy: 0.8148 - val_loss: 1.9929 - val_accuracy: 0.7764\n",
      "Epoch 818/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7462 - accuracy: 0.8141 - val_loss: 1.9754 - val_accuracy: 0.7694\n",
      "Epoch 819/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7482 - accuracy: 0.8137 - val_loss: 1.9373 - val_accuracy: 0.8066\n",
      "Epoch 820/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7609 - accuracy: 0.8126 - val_loss: 2.0169 - val_accuracy: 0.7853\n",
      "Epoch 821/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7532 - accuracy: 0.8139 - val_loss: 2.0113 - val_accuracy: 0.7934\n",
      "Epoch 822/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7500 - accuracy: 0.8117 - val_loss: 2.0153 - val_accuracy: 0.7969\n",
      "Epoch 823/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7436 - accuracy: 0.8123 - val_loss: 2.0047 - val_accuracy: 0.8174\n",
      "Epoch 824/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7448 - accuracy: 0.8154 - val_loss: 1.9953 - val_accuracy: 0.8109\n",
      "Epoch 825/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7480 - accuracy: 0.8112 - val_loss: 2.0127 - val_accuracy: 0.8101\n",
      "Epoch 826/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7443 - accuracy: 0.8144 - val_loss: 2.0976 - val_accuracy: 0.7996\n",
      "Epoch 827/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7587 - accuracy: 0.8109 - val_loss: 2.0618 - val_accuracy: 0.8089\n",
      "Epoch 828/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7383 - accuracy: 0.8172 - val_loss: 2.0322 - val_accuracy: 0.8078\n",
      "Epoch 829/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7555 - accuracy: 0.8090 - val_loss: 2.1345 - val_accuracy: 0.7798\n",
      "Epoch 830/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7491 - accuracy: 0.8149 - val_loss: 2.0888 - val_accuracy: 0.7977\n",
      "Epoch 831/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7434 - accuracy: 0.8140 - val_loss: 2.0963 - val_accuracy: 0.8066\n",
      "Epoch 832/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7404 - accuracy: 0.8137 - val_loss: 2.1213 - val_accuracy: 0.7880\n",
      "Epoch 833/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7526 - accuracy: 0.8125 - val_loss: 2.1125 - val_accuracy: 0.8008\n",
      "Epoch 834/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7431 - accuracy: 0.8176 - val_loss: 2.1415 - val_accuracy: 0.7833\n",
      "Epoch 835/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7490 - accuracy: 0.8118 - val_loss: 2.1076 - val_accuracy: 0.7725\n",
      "Epoch 836/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7415 - accuracy: 0.8149 - val_loss: 2.0534 - val_accuracy: 0.7857\n",
      "Epoch 837/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7341 - accuracy: 0.8184 - val_loss: 2.0947 - val_accuracy: 0.7857\n",
      "Epoch 838/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7453 - accuracy: 0.8141 - val_loss: 2.0681 - val_accuracy: 0.7942\n",
      "Epoch 839/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7506 - accuracy: 0.8140 - val_loss: 1.8633 - val_accuracy: 0.7992\n",
      "Epoch 840/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7390 - accuracy: 0.8148 - val_loss: 1.8807 - val_accuracy: 0.7981\n",
      "Epoch 841/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7367 - accuracy: 0.8157 - val_loss: 1.9080 - val_accuracy: 0.7895\n",
      "Epoch 842/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7442 - accuracy: 0.8132 - val_loss: 1.9527 - val_accuracy: 0.7829\n",
      "Epoch 843/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7406 - accuracy: 0.8145 - val_loss: 1.9716 - val_accuracy: 0.7814\n",
      "Epoch 844/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7303 - accuracy: 0.8198 - val_loss: 1.9046 - val_accuracy: 0.7930\n",
      "Epoch 845/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7452 - accuracy: 0.8130 - val_loss: 1.9420 - val_accuracy: 0.8008\n",
      "Epoch 846/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7463 - accuracy: 0.8136 - val_loss: 1.9262 - val_accuracy: 0.7783\n",
      "Epoch 847/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7377 - accuracy: 0.8169 - val_loss: 1.8890 - val_accuracy: 0.7938\n",
      "Epoch 848/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7403 - accuracy: 0.8130 - val_loss: 1.8967 - val_accuracy: 0.7942\n",
      "Epoch 849/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7364 - accuracy: 0.8183 - val_loss: 1.8393 - val_accuracy: 0.8066\n",
      "Epoch 850/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7353 - accuracy: 0.8174 - val_loss: 1.9148 - val_accuracy: 0.7791\n",
      "Epoch 851/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7437 - accuracy: 0.8127 - val_loss: 1.8896 - val_accuracy: 0.7911\n",
      "Epoch 852/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7544 - accuracy: 0.8128 - val_loss: 1.8916 - val_accuracy: 0.7969\n",
      "Epoch 853/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7370 - accuracy: 0.8152 - val_loss: 1.8766 - val_accuracy: 0.8058\n",
      "Epoch 854/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7540 - accuracy: 0.8152 - val_loss: 1.8551 - val_accuracy: 0.8132\n",
      "Epoch 855/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7288 - accuracy: 0.8187 - val_loss: 1.9297 - val_accuracy: 0.7899\n",
      "Epoch 856/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7281 - accuracy: 0.8181 - val_loss: 1.8501 - val_accuracy: 0.8027\n",
      "Epoch 857/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7404 - accuracy: 0.8152 - val_loss: 1.8571 - val_accuracy: 0.8136\n",
      "Epoch 858/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7466 - accuracy: 0.8147 - val_loss: 1.8930 - val_accuracy: 0.7884\n",
      "Epoch 859/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7361 - accuracy: 0.8157 - val_loss: 1.8827 - val_accuracy: 0.7864\n",
      "Epoch 860/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7379 - accuracy: 0.8153 - val_loss: 1.8678 - val_accuracy: 0.8151\n",
      "Epoch 861/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7426 - accuracy: 0.8158 - val_loss: 1.8841 - val_accuracy: 0.8140\n",
      "Epoch 862/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7438 - accuracy: 0.8104 - val_loss: 1.9167 - val_accuracy: 0.8147\n",
      "Epoch 863/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7424 - accuracy: 0.8133 - val_loss: 1.8856 - val_accuracy: 0.7911\n",
      "Epoch 864/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7326 - accuracy: 0.8184 - val_loss: 1.8515 - val_accuracy: 0.8078\n",
      "Epoch 865/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7380 - accuracy: 0.8155 - val_loss: 1.9204 - val_accuracy: 0.7884\n",
      "Epoch 866/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7308 - accuracy: 0.8179 - val_loss: 1.8776 - val_accuracy: 0.8066\n",
      "Epoch 867/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7279 - accuracy: 0.8168 - val_loss: 1.9381 - val_accuracy: 0.7841\n",
      "Epoch 868/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7318 - accuracy: 0.8170 - val_loss: 1.8831 - val_accuracy: 0.7969\n",
      "Epoch 869/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7370 - accuracy: 0.8164 - val_loss: 1.8857 - val_accuracy: 0.7984\n",
      "Epoch 870/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7418 - accuracy: 0.8152 - val_loss: 1.9671 - val_accuracy: 0.7872\n",
      "Epoch 871/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7311 - accuracy: 0.8163 - val_loss: 1.9387 - val_accuracy: 0.8043\n",
      "Epoch 872/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7355 - accuracy: 0.8165 - val_loss: 1.8853 - val_accuracy: 0.7953\n",
      "Epoch 873/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7255 - accuracy: 0.8177 - val_loss: 1.8762 - val_accuracy: 0.8097\n",
      "Epoch 874/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7267 - accuracy: 0.8184 - val_loss: 1.9198 - val_accuracy: 0.7733\n",
      "Epoch 875/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7396 - accuracy: 0.8147 - val_loss: 1.9596 - val_accuracy: 0.7744\n",
      "Epoch 876/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7419 - accuracy: 0.8170 - val_loss: 1.8306 - val_accuracy: 0.8097\n",
      "Epoch 877/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8959 - accuracy: 0.8157 - val_loss: 1.7603 - val_accuracy: 0.7911\n",
      "Epoch 878/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7187 - accuracy: 0.8252 - val_loss: 1.7081 - val_accuracy: 0.8140\n",
      "Epoch 879/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7648 - accuracy: 0.8157 - val_loss: 1.6641 - val_accuracy: 0.8004\n",
      "Epoch 880/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7144 - accuracy: 0.8254 - val_loss: 1.6985 - val_accuracy: 0.8078\n",
      "Epoch 881/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7074 - accuracy: 0.8253 - val_loss: 1.7372 - val_accuracy: 0.7919\n",
      "Epoch 882/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7115 - accuracy: 0.8241 - val_loss: 1.8573 - val_accuracy: 0.7574\n",
      "Epoch 883/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7249 - accuracy: 0.8211 - val_loss: 1.7269 - val_accuracy: 0.8116\n",
      "Epoch 884/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7220 - accuracy: 0.8202 - val_loss: 1.7529 - val_accuracy: 0.7977\n",
      "Epoch 885/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7241 - accuracy: 0.8206 - val_loss: 1.7519 - val_accuracy: 0.7876\n",
      "Epoch 886/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7257 - accuracy: 0.8179 - val_loss: 1.7644 - val_accuracy: 0.8019\n",
      "Epoch 887/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7436 - accuracy: 0.8152 - val_loss: 1.8080 - val_accuracy: 0.7996\n",
      "Epoch 888/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7249 - accuracy: 0.8203 - val_loss: 1.8858 - val_accuracy: 0.7733\n",
      "Epoch 889/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7251 - accuracy: 0.8187 - val_loss: 1.7925 - val_accuracy: 0.8136\n",
      "Epoch 890/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7360 - accuracy: 0.8148 - val_loss: 1.7878 - val_accuracy: 0.8136\n",
      "Epoch 891/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7256 - accuracy: 0.8162 - val_loss: 1.9015 - val_accuracy: 0.7733\n",
      "Epoch 892/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7287 - accuracy: 0.8186 - val_loss: 1.8432 - val_accuracy: 0.7934\n",
      "Epoch 893/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7268 - accuracy: 0.8177 - val_loss: 1.8267 - val_accuracy: 0.8019\n",
      "Epoch 894/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7256 - accuracy: 0.8180 - val_loss: 1.8231 - val_accuracy: 0.8035\n",
      "Epoch 895/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7360 - accuracy: 0.8157 - val_loss: 1.8470 - val_accuracy: 0.7950\n",
      "Epoch 896/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7227 - accuracy: 0.8191 - val_loss: 1.8017 - val_accuracy: 0.8140\n",
      "Epoch 897/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7309 - accuracy: 0.8167 - val_loss: 1.8556 - val_accuracy: 0.7767\n",
      "Epoch 898/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7259 - accuracy: 0.8164 - val_loss: 1.8656 - val_accuracy: 0.7771\n",
      "Epoch 899/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7184 - accuracy: 0.8205 - val_loss: 1.8283 - val_accuracy: 0.7977\n",
      "Epoch 900/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7348 - accuracy: 0.8183 - val_loss: 1.8283 - val_accuracy: 0.8140\n",
      "Epoch 901/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7256 - accuracy: 0.8186 - val_loss: 1.8566 - val_accuracy: 0.8279\n",
      "Epoch 902/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7263 - accuracy: 0.8173 - val_loss: 1.8715 - val_accuracy: 0.7965\n",
      "Epoch 903/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7224 - accuracy: 0.8193 - val_loss: 1.8903 - val_accuracy: 0.7884\n",
      "Epoch 904/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7244 - accuracy: 0.8178 - val_loss: 2.0029 - val_accuracy: 0.7601\n",
      "Epoch 905/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7243 - accuracy: 0.8169 - val_loss: 1.9184 - val_accuracy: 0.8008\n",
      "Epoch 906/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7376 - accuracy: 0.8173 - val_loss: 1.9190 - val_accuracy: 0.7922\n",
      "Epoch 907/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7178 - accuracy: 0.8209 - val_loss: 1.9229 - val_accuracy: 0.7988\n",
      "Epoch 908/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7164 - accuracy: 0.8208 - val_loss: 1.9082 - val_accuracy: 0.8070\n",
      "Epoch 909/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7413 - accuracy: 0.8138 - val_loss: 2.0860 - val_accuracy: 0.7682\n",
      "Epoch 910/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7227 - accuracy: 0.8194 - val_loss: 1.9478 - val_accuracy: 0.8000\n",
      "Epoch 911/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7155 - accuracy: 0.8202 - val_loss: 1.9363 - val_accuracy: 0.8221\n",
      "Epoch 912/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7323 - accuracy: 0.8153 - val_loss: 2.2819 - val_accuracy: 0.7543\n",
      "Epoch 913/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7325 - accuracy: 0.8156 - val_loss: 2.0305 - val_accuracy: 0.7899\n",
      "Epoch 914/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7348 - accuracy: 0.8166 - val_loss: 1.9985 - val_accuracy: 0.8198\n",
      "Epoch 915/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.8236 - val_loss: 1.9961 - val_accuracy: 0.8043\n",
      "Epoch 916/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7192 - accuracy: 0.8208 - val_loss: 2.0540 - val_accuracy: 0.7957\n",
      "Epoch 917/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7189 - accuracy: 0.8213 - val_loss: 2.0216 - val_accuracy: 0.7992\n",
      "Epoch 918/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7243 - accuracy: 0.8170 - val_loss: 2.0568 - val_accuracy: 0.8012\n",
      "Epoch 919/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7223 - accuracy: 0.8190 - val_loss: 2.1318 - val_accuracy: 0.7771\n",
      "Epoch 920/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7221 - accuracy: 0.8218 - val_loss: 1.8363 - val_accuracy: 0.7880\n",
      "Epoch 921/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7249 - accuracy: 0.8208 - val_loss: 1.8905 - val_accuracy: 0.8093\n",
      "Epoch 922/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7152 - accuracy: 0.8205 - val_loss: 1.9661 - val_accuracy: 0.7744\n",
      "Epoch 923/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7135 - accuracy: 0.8217 - val_loss: 1.8433 - val_accuracy: 0.8085\n",
      "Epoch 924/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7176 - accuracy: 0.8211 - val_loss: 1.8712 - val_accuracy: 0.8136\n",
      "Epoch 925/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7114 - accuracy: 0.8236 - val_loss: 1.8838 - val_accuracy: 0.7984\n",
      "Epoch 926/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7174 - accuracy: 0.8209 - val_loss: 1.8481 - val_accuracy: 0.8302\n",
      "Epoch 927/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7231 - accuracy: 0.8145 - val_loss: 1.9790 - val_accuracy: 0.7934\n",
      "Epoch 928/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7263 - accuracy: 0.8194 - val_loss: 1.8800 - val_accuracy: 0.7907\n",
      "Epoch 929/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7202 - accuracy: 0.8176 - val_loss: 1.8667 - val_accuracy: 0.7950\n",
      "Epoch 930/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7080 - accuracy: 0.8237 - val_loss: 1.8952 - val_accuracy: 0.7919\n",
      "Epoch 931/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7238 - accuracy: 0.8179 - val_loss: 1.8857 - val_accuracy: 0.8221\n",
      "Epoch 932/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7086 - accuracy: 0.8252 - val_loss: 1.8896 - val_accuracy: 0.8074\n",
      "Epoch 933/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.8197 - val_loss: 1.9861 - val_accuracy: 0.7891\n",
      "Epoch 934/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7210 - accuracy: 0.8202 - val_loss: 2.1660 - val_accuracy: 0.7798\n",
      "Epoch 935/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7049 - accuracy: 0.8241 - val_loss: 2.5763 - val_accuracy: 0.7942\n",
      "Epoch 936/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7151 - accuracy: 0.8189 - val_loss: 1.9933 - val_accuracy: 0.7891\n",
      "Epoch 937/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7224 - accuracy: 0.8175 - val_loss: 2.0621 - val_accuracy: 0.7876\n",
      "Epoch 938/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7215 - accuracy: 0.8211 - val_loss: 2.0187 - val_accuracy: 0.7907\n",
      "Epoch 939/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7158 - accuracy: 0.8178 - val_loss: 2.7475 - val_accuracy: 0.7814\n",
      "Epoch 940/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7116 - accuracy: 0.8209 - val_loss: 2.0179 - val_accuracy: 0.8120\n",
      "Epoch 941/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7138 - accuracy: 0.8214 - val_loss: 2.0290 - val_accuracy: 0.8054\n",
      "Epoch 942/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.8221 - val_loss: 2.5340 - val_accuracy: 0.7996\n",
      "Epoch 943/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7198 - accuracy: 0.8183 - val_loss: 2.1293 - val_accuracy: 0.7880\n",
      "Epoch 944/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7099 - accuracy: 0.8236 - val_loss: 2.0535 - val_accuracy: 0.7814\n",
      "Epoch 945/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7812 - accuracy: 0.8155 - val_loss: 2.2364 - val_accuracy: 0.7981\n",
      "Epoch 946/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6960 - accuracy: 0.8309 - val_loss: 2.1849 - val_accuracy: 0.8078\n",
      "Epoch 947/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.8289 - val_loss: 2.1997 - val_accuracy: 0.8089\n",
      "Epoch 948/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6968 - accuracy: 0.8262 - val_loss: 2.1858 - val_accuracy: 0.8279\n",
      "Epoch 949/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7261 - accuracy: 0.8242 - val_loss: 1.8236 - val_accuracy: 0.8279\n",
      "Epoch 950/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6976 - accuracy: 0.8265 - val_loss: 1.8561 - val_accuracy: 0.8140\n",
      "Epoch 951/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6985 - accuracy: 0.8262 - val_loss: 1.8634 - val_accuracy: 0.8271\n",
      "Epoch 952/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7034 - accuracy: 0.8242 - val_loss: 1.8982 - val_accuracy: 0.7977\n",
      "Epoch 953/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7063 - accuracy: 0.8222 - val_loss: 1.8765 - val_accuracy: 0.8008\n",
      "Epoch 954/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6996 - accuracy: 0.8259 - val_loss: 1.8646 - val_accuracy: 0.8159\n",
      "Epoch 955/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7025 - accuracy: 0.8233 - val_loss: 1.9040 - val_accuracy: 0.7907\n",
      "Epoch 956/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7287 - accuracy: 0.8167 - val_loss: 1.9417 - val_accuracy: 0.8070\n",
      "Epoch 957/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7046 - accuracy: 0.8239 - val_loss: 2.0378 - val_accuracy: 0.7667\n",
      "Epoch 958/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7071 - accuracy: 0.8236 - val_loss: 1.9953 - val_accuracy: 0.7938\n",
      "Epoch 959/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.8232 - val_loss: 1.9722 - val_accuracy: 0.7919\n",
      "Epoch 960/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7178 - accuracy: 0.8177 - val_loss: 2.0330 - val_accuracy: 0.7826\n",
      "Epoch 961/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7101 - accuracy: 0.8225 - val_loss: 2.0013 - val_accuracy: 0.8031\n",
      "Epoch 962/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7025 - accuracy: 0.8240 - val_loss: 1.9744 - val_accuracy: 0.8163\n",
      "Epoch 963/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6997 - accuracy: 0.8256 - val_loss: 1.9958 - val_accuracy: 0.8043\n",
      "Epoch 964/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7062 - accuracy: 0.8227 - val_loss: 2.0084 - val_accuracy: 0.8217\n",
      "Epoch 965/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7073 - accuracy: 0.8238 - val_loss: 2.0294 - val_accuracy: 0.8101\n",
      "Epoch 966/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.8230 - val_loss: 2.0945 - val_accuracy: 0.7779\n",
      "Epoch 967/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7132 - accuracy: 0.8186 - val_loss: 2.1043 - val_accuracy: 0.7709\n",
      "Epoch 968/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7007 - accuracy: 0.8252 - val_loss: 2.1017 - val_accuracy: 0.7891\n",
      "Epoch 969/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7208 - accuracy: 0.8196 - val_loss: 2.0213 - val_accuracy: 0.8229\n",
      "Epoch 970/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7173 - accuracy: 0.8205 - val_loss: 2.0749 - val_accuracy: 0.7915\n",
      "Epoch 971/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6946 - accuracy: 0.8270 - val_loss: 2.1177 - val_accuracy: 0.8054\n",
      "Epoch 972/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7058 - accuracy: 0.8236 - val_loss: 2.0185 - val_accuracy: 0.8112\n",
      "Epoch 973/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7079 - accuracy: 0.8228 - val_loss: 2.0358 - val_accuracy: 0.8023\n",
      "Epoch 974/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6984 - accuracy: 0.8276 - val_loss: 2.0674 - val_accuracy: 0.7822\n",
      "Epoch 975/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7102 - accuracy: 0.8217 - val_loss: 2.0358 - val_accuracy: 0.8058\n",
      "Epoch 976/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7065 - accuracy: 0.8231 - val_loss: 2.0701 - val_accuracy: 0.8186\n",
      "Epoch 977/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7031 - accuracy: 0.8242 - val_loss: 2.0890 - val_accuracy: 0.8116\n",
      "Epoch 978/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7148 - accuracy: 0.8217 - val_loss: 1.9417 - val_accuracy: 0.8000\n",
      "Epoch 979/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6975 - accuracy: 0.8257 - val_loss: 1.9363 - val_accuracy: 0.8116\n",
      "Epoch 980/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6978 - accuracy: 0.8247 - val_loss: 1.9748 - val_accuracy: 0.8035\n",
      "Epoch 981/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.8290 - val_loss: 2.0273 - val_accuracy: 0.8023\n",
      "Epoch 982/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7036 - accuracy: 0.8222 - val_loss: 2.0133 - val_accuracy: 0.8147\n",
      "Epoch 983/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7136 - accuracy: 0.8203 - val_loss: 2.0906 - val_accuracy: 0.7934\n",
      "Epoch 984/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7007 - accuracy: 0.8264 - val_loss: 2.0733 - val_accuracy: 0.7969\n",
      "Epoch 985/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6945 - accuracy: 0.8236 - val_loss: 2.0496 - val_accuracy: 0.8136\n",
      "Epoch 986/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.8241 - val_loss: 2.0479 - val_accuracy: 0.8089\n",
      "Epoch 987/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7059 - accuracy: 0.8218 - val_loss: 2.1074 - val_accuracy: 0.7760\n",
      "Epoch 988/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7048 - accuracy: 0.8223 - val_loss: 2.1077 - val_accuracy: 0.8132\n",
      "Epoch 989/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7121 - accuracy: 0.8240 - val_loss: 2.1171 - val_accuracy: 0.8054\n",
      "Epoch 990/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6942 - accuracy: 0.8283 - val_loss: 2.1624 - val_accuracy: 0.7845\n",
      "Epoch 991/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6963 - accuracy: 0.8258 - val_loss: 2.1001 - val_accuracy: 0.8112\n",
      "Epoch 992/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7111 - accuracy: 0.8217 - val_loss: 1.9452 - val_accuracy: 0.8244\n",
      "Epoch 993/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6926 - accuracy: 0.8304 - val_loss: 1.9301 - val_accuracy: 0.8244\n",
      "Epoch 994/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7034 - accuracy: 0.8239 - val_loss: 1.9979 - val_accuracy: 0.8054\n",
      "Epoch 995/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6913 - accuracy: 0.8289 - val_loss: 2.0436 - val_accuracy: 0.7771\n",
      "Epoch 996/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7006 - accuracy: 0.8226 - val_loss: 2.0514 - val_accuracy: 0.7899\n",
      "Epoch 997/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6972 - accuracy: 0.8275 - val_loss: 2.0022 - val_accuracy: 0.8031\n",
      "Epoch 998/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7024 - accuracy: 0.8227 - val_loss: 1.9950 - val_accuracy: 0.8004\n",
      "Epoch 999/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7022 - accuracy: 0.8245 - val_loss: 2.1051 - val_accuracy: 0.7837\n",
      "Epoch 1000/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8196 - accuracy: 0.8229 - val_loss: 2.2272 - val_accuracy: 0.8074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_21_layer_call_fn, leaky_re_lu_21_layer_call_and_return_conditional_losses, leaky_re_lu_22_layer_call_fn, leaky_re_lu_22_layer_call_and_return_conditional_losses, leaky_re_lu_23_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 50s, sys: 3min 43s, total: 31min 33s\n",
      "Wall time: 15min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/sig_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy']) #.0001\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0092a047-87e7-4d41-92fe-442c1d497ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv('output/history_mlp_class_sig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "804d5dca-da51-4c35-b5fd-3f6bf937b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc413ec-1d01-4036-8bab-e4309224cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3c63e-297b-428d-8528-da0aa58098c8",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "345b8adc-5738-4839-82eb-69a6a1eb0741",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74        21\n",
      "           1       1.00      0.78      0.88        18\n",
      "           2       1.00      0.74      0.85        23\n",
      "           3       0.95      0.90      0.92        20\n",
      "           4       0.81      0.91      0.86        23\n",
      "           5       1.00      0.20      0.33        20\n",
      "           6       0.91      0.87      0.89        23\n",
      "           7       0.91      0.84      0.87        25\n",
      "           8       0.96      0.88      0.92        25\n",
      "           9       1.00      0.77      0.87        13\n",
      "          10       0.64      0.70      0.67        23\n",
      "          11       1.00      0.76      0.87        17\n",
      "          12       1.00      0.69      0.81        16\n",
      "          13       0.89      0.81      0.85        31\n",
      "          14       0.93      0.87      0.90        30\n",
      "          15       1.00      0.95      0.97        19\n",
      "          16       1.00      0.84      0.91        25\n",
      "          17       0.92      0.71      0.80        17\n",
      "          18       0.72      0.65      0.68        20\n",
      "          19       0.77      0.62      0.69        16\n",
      "          20       1.00      0.53      0.69        19\n",
      "          21       1.00      0.90      0.95        21\n",
      "          22       1.00      0.78      0.88        18\n",
      "          23       0.88      1.00      0.93        14\n",
      "          24       0.86      0.57      0.69        21\n",
      "          25       1.00      0.86      0.92        21\n",
      "          26       1.00      0.92      0.96        13\n",
      "          27       1.00      0.88      0.94        25\n",
      "          28       0.96      0.81      0.88        27\n",
      "          29       1.00      0.88      0.93        24\n",
      "          30       1.00      0.95      0.98        21\n",
      "          31       0.89      0.81      0.85        21\n",
      "          32       1.00      0.83      0.91        18\n",
      "          33       1.00      1.00      1.00        22\n",
      "          34       0.50      0.72      0.59        18\n",
      "          35       0.62      0.80      0.70        10\n",
      "          36       1.00      0.96      0.98        27\n",
      "          37       0.08      0.71      0.15        21\n",
      "          38       0.90      0.90      0.90        20\n",
      "          39       0.82      0.93      0.87        15\n",
      "          40       1.00      0.89      0.94        19\n",
      "          41       1.00      1.00      1.00        12\n",
      "          42       1.00      0.90      0.95        30\n",
      "          43       0.11      0.28      0.16        25\n",
      "          44       1.00      0.95      0.98        22\n",
      "          45       0.89      0.70      0.78        23\n",
      "          46       1.00      1.00      1.00        14\n",
      "          47       1.00      0.88      0.94        17\n",
      "          48       0.90      0.95      0.93        20\n",
      "          49       0.94      0.76      0.84        21\n",
      "          50       1.00      0.92      0.96        25\n",
      "          51       1.00      0.73      0.84        22\n",
      "          52       0.50      0.33      0.40        18\n",
      "          53       1.00      0.84      0.91        25\n",
      "          54       0.88      0.95      0.91        22\n",
      "          55       1.00      0.77      0.87        13\n",
      "          56       1.00      1.00      1.00        21\n",
      "          57       0.87      0.93      0.90        28\n",
      "          58       1.00      0.79      0.88        14\n",
      "          59       1.00      0.92      0.96        26\n",
      "          60       0.93      0.76      0.84        17\n",
      "          61       1.00      0.88      0.93        16\n",
      "          62       0.89      0.94      0.91        17\n",
      "          63       1.00      1.00      1.00        25\n",
      "          64       0.81      1.00      0.90        13\n",
      "          65       0.93      0.82      0.87        17\n",
      "          66       0.95      0.95      0.95        20\n",
      "          67       1.00      1.00      1.00        12\n",
      "          68       1.00      0.81      0.89        21\n",
      "          69       1.00      0.83      0.91        18\n",
      "          70       1.00      0.93      0.96        14\n",
      "          71       1.00      0.58      0.73        19\n",
      "          72       0.85      1.00      0.92        11\n",
      "          73       1.00      1.00      1.00        20\n",
      "          74       0.86      0.78      0.82        23\n",
      "          75       0.77      0.89      0.83        27\n",
      "          76       1.00      0.96      0.98        23\n",
      "          77       0.64      0.86      0.73        21\n",
      "          78       0.83      0.75      0.79        20\n",
      "          79       1.00      0.96      0.98        24\n",
      "          80       1.00      0.89      0.94        19\n",
      "          81       0.93      0.93      0.93        14\n",
      "          82       1.00      0.75      0.86        20\n",
      "          83       1.00      0.90      0.95        20\n",
      "          84       1.00      0.91      0.95        23\n",
      "          85       1.00      0.91      0.95        23\n",
      "          86       1.00      0.37      0.54        19\n",
      "          87       0.94      0.80      0.86        20\n",
      "          88       0.76      0.68      0.72        19\n",
      "          89       1.00      0.95      0.97        20\n",
      "          90       1.00      0.73      0.84        22\n",
      "          91       1.00      0.79      0.88        19\n",
      "          92       1.00      0.92      0.96        12\n",
      "          93       1.00      0.89      0.94        19\n",
      "          94       1.00      0.48      0.65        25\n",
      "          95       1.00      1.00      1.00        17\n",
      "          96       1.00      0.50      0.67        28\n",
      "          97       1.00      0.53      0.69        19\n",
      "          98       1.00      0.81      0.89        21\n",
      "          99       0.90      0.75      0.82        24\n",
      "         100       1.00      0.60      0.75        15\n",
      "         101       1.00      0.88      0.94        17\n",
      "         102       0.95      0.76      0.84        25\n",
      "         103       1.00      1.00      1.00        21\n",
      "         104       0.91      0.62      0.74        16\n",
      "         105       0.75      0.40      0.52        15\n",
      "         106       1.00      1.00      1.00        15\n",
      "         107       1.00      0.72      0.84        18\n",
      "         108       0.85      0.50      0.63        22\n",
      "         109       1.00      0.61      0.76        23\n",
      "         110       1.00      0.93      0.96        28\n",
      "         111       0.69      0.46      0.55        24\n",
      "         112       0.63      0.71      0.67        17\n",
      "         113       0.24      0.68      0.36        19\n",
      "         114       1.00      0.86      0.92        14\n",
      "         115       0.48      0.63      0.55        19\n",
      "         116       1.00      0.88      0.94        17\n",
      "         117       1.00      0.82      0.90        11\n",
      "         118       0.21      0.76      0.33        17\n",
      "         119       1.00      0.64      0.78        25\n",
      "         120       0.67      0.91      0.77        22\n",
      "         121       0.72      0.82      0.77        28\n",
      "         122       1.00      0.93      0.96        14\n",
      "         123       1.00      1.00      1.00        18\n",
      "         124       1.00      0.92      0.96        24\n",
      "         125       1.00      1.00      1.00        16\n",
      "         126       1.00      0.94      0.97        17\n",
      "         127       0.70      0.95      0.81        22\n",
      "         128       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.81      2580\n",
      "   macro avg       0.90      0.81      0.84      2580\n",
      "weighted avg       0.90      0.81      0.84      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3faff65-54f8-47d3-9a49-d28c736efb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
