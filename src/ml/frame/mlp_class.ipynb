{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f78aa7-15d8-4c44-8e24-810219393815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994720bf-b54a-4fb0-ae3c-eea3a5b39e24",
   "metadata": {},
   "source": [
    "<h1>Linear Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d4a403-460f-41ed-85f5-1942215d93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/results_complete_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0935dd9-210a-474b-9a82-aa077ca287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['elem_damaged', 'damage'], axis=1), df['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af628b4-0f5f-4722-bd9a-86c4e372bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab4ae95-f2fc-436c-acac-8ff44a1e1bc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 20)                13120     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 225)               4725      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,685\n",
      "Trainable params: 18,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 5.0588 - accuracy: 0.0477 - val_loss: 4.5615 - val_accuracy: 0.0973\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.9376 - accuracy: 0.2360 - val_loss: 3.2986 - val_accuracy: 0.3738\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.7998 - accuracy: 0.5019 - val_loss: 2.3231 - val_accuracy: 0.6387\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.0211 - accuracy: 0.6880 - val_loss: 1.7160 - val_accuracy: 0.7349\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5406 - accuracy: 0.7697 - val_loss: 1.3387 - val_accuracy: 0.8049\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2320 - accuracy: 0.8215 - val_loss: 1.0965 - val_accuracy: 0.8487\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0226 - accuracy: 0.8548 - val_loss: 0.9266 - val_accuracy: 0.8689\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8747 - accuracy: 0.8815 - val_loss: 0.8066 - val_accuracy: 0.8938\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7655 - accuracy: 0.8970 - val_loss: 0.7092 - val_accuracy: 0.9040\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6811 - accuracy: 0.9095 - val_loss: 0.6420 - val_accuracy: 0.9144\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6134 - accuracy: 0.9191 - val_loss: 0.5786 - val_accuracy: 0.9309\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5595 - accuracy: 0.9273 - val_loss: 0.5366 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5150 - accuracy: 0.9332 - val_loss: 0.4922 - val_accuracy: 0.9353\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4773 - accuracy: 0.9380 - val_loss: 0.4695 - val_accuracy: 0.9340\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4455 - accuracy: 0.9425 - val_loss: 0.4367 - val_accuracy: 0.9493\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4176 - accuracy: 0.9462 - val_loss: 0.4070 - val_accuracy: 0.9529\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3938 - accuracy: 0.9500 - val_loss: 0.3998 - val_accuracy: 0.9433\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3717 - accuracy: 0.9520 - val_loss: 0.3722 - val_accuracy: 0.9587\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.9564 - val_loss: 0.3553 - val_accuracy: 0.9624\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3360 - accuracy: 0.9566 - val_loss: 0.3420 - val_accuracy: 0.9598\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.3204 - accuracy: 0.9605 - val_loss: 0.3297 - val_accuracy: 0.9611\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.3056 - accuracy: 0.9618 - val_loss: 0.3139 - val_accuracy: 0.9611\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.2932 - accuracy: 0.9628 - val_loss: 0.3005 - val_accuracy: 0.9664\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.9655 - val_loss: 0.2945 - val_accuracy: 0.9656\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2706 - accuracy: 0.9666 - val_loss: 0.2828 - val_accuracy: 0.9662\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2603 - accuracy: 0.9683 - val_loss: 0.2723 - val_accuracy: 0.9704\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2510 - accuracy: 0.9692 - val_loss: 0.2686 - val_accuracy: 0.9651\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2421 - accuracy: 0.9696 - val_loss: 0.2560 - val_accuracy: 0.9678\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2342 - accuracy: 0.9709 - val_loss: 0.2561 - val_accuracy: 0.9662\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2276 - accuracy: 0.9715 - val_loss: 0.2440 - val_accuracy: 0.9713\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2196 - accuracy: 0.9733 - val_loss: 0.2456 - val_accuracy: 0.9689\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2137 - accuracy: 0.9728 - val_loss: 0.2324 - val_accuracy: 0.9771\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2071 - accuracy: 0.9750 - val_loss: 0.2240 - val_accuracy: 0.9713\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2010 - accuracy: 0.9756 - val_loss: 0.2172 - val_accuracy: 0.9764\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1971 - accuracy: 0.9759 - val_loss: 0.2219 - val_accuracy: 0.9718\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1906 - accuracy: 0.9766 - val_loss: 0.2129 - val_accuracy: 0.9740\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1838 - accuracy: 0.9778 - val_loss: 0.2041 - val_accuracy: 0.9727\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1805 - accuracy: 0.9767 - val_loss: 0.2033 - val_accuracy: 0.9742\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1762 - accuracy: 0.9779 - val_loss: 0.1947 - val_accuracy: 0.9780\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1714 - accuracy: 0.9789 - val_loss: 0.1961 - val_accuracy: 0.9760\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1669 - accuracy: 0.9800 - val_loss: 0.1912 - val_accuracy: 0.9798\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1635 - accuracy: 0.9799 - val_loss: 0.1893 - val_accuracy: 0.9780\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1601 - accuracy: 0.9803 - val_loss: 0.1860 - val_accuracy: 0.9760\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1559 - accuracy: 0.9810 - val_loss: 0.1831 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1521 - accuracy: 0.9820 - val_loss: 0.1783 - val_accuracy: 0.9802\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1508 - accuracy: 0.9815 - val_loss: 0.1859 - val_accuracy: 0.9811\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1466 - accuracy: 0.9818 - val_loss: 0.1844 - val_accuracy: 0.9802\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1430 - accuracy: 0.9827 - val_loss: 0.1730 - val_accuracy: 0.9787\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1404 - accuracy: 0.9824 - val_loss: 0.1787 - val_accuracy: 0.9780\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1384 - accuracy: 0.9824 - val_loss: 0.1713 - val_accuracy: 0.9793\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1344 - accuracy: 0.9837 - val_loss: 0.1668 - val_accuracy: 0.9829\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1321 - accuracy: 0.9840 - val_loss: 0.1675 - val_accuracy: 0.9798\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1307 - accuracy: 0.9838 - val_loss: 0.1571 - val_accuracy: 0.9800\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1274 - accuracy: 0.9846 - val_loss: 0.1589 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1246 - accuracy: 0.9848 - val_loss: 0.1516 - val_accuracy: 0.9787\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1236 - accuracy: 0.9845 - val_loss: 0.1536 - val_accuracy: 0.9829\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1203 - accuracy: 0.9856 - val_loss: 0.1577 - val_accuracy: 0.9813\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1197 - accuracy: 0.9849 - val_loss: 0.1450 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1160 - accuracy: 0.9855 - val_loss: 0.1491 - val_accuracy: 0.9787\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1135 - accuracy: 0.9861 - val_loss: 0.1475 - val_accuracy: 0.9789\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1136 - accuracy: 0.9862 - val_loss: 0.1461 - val_accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1102 - accuracy: 0.9860 - val_loss: 0.1431 - val_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1086 - accuracy: 0.9864 - val_loss: 0.1443 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1077 - accuracy: 0.9866 - val_loss: 0.1481 - val_accuracy: 0.9840\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1070 - accuracy: 0.9865 - val_loss: 0.1478 - val_accuracy: 0.9827\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1049 - accuracy: 0.9872 - val_loss: 0.1509 - val_accuracy: 0.9824\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1029 - accuracy: 0.9874 - val_loss: 0.1392 - val_accuracy: 0.9856\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1001 - accuracy: 0.9878 - val_loss: 0.1346 - val_accuracy: 0.9849\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0995 - accuracy: 0.9873 - val_loss: 0.1352 - val_accuracy: 0.9849\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0997 - accuracy: 0.9874 - val_loss: 0.1304 - val_accuracy: 0.9853\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0974 - accuracy: 0.9880 - val_loss: 0.1301 - val_accuracy: 0.9816\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0950 - accuracy: 0.9881 - val_loss: 0.1410 - val_accuracy: 0.9833\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0940 - accuracy: 0.9886 - val_loss: 0.1284 - val_accuracy: 0.9853\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0921 - accuracy: 0.9887 - val_loss: 0.1294 - val_accuracy: 0.9844\n",
      "Epoch 75/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0913 - accuracy: 0.9889 - val_loss: 0.1315 - val_accuracy: 0.9858\n",
      "Epoch 76/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0897 - accuracy: 0.9889 - val_loss: 0.1311 - val_accuracy: 0.9829\n",
      "Epoch 77/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0897 - accuracy: 0.9884 - val_loss: 0.1283 - val_accuracy: 0.9844\n",
      "Epoch 78/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0870 - accuracy: 0.9896 - val_loss: 0.1241 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0867 - accuracy: 0.9884 - val_loss: 0.1163 - val_accuracy: 0.9864\n",
      "Epoch 80/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0845 - accuracy: 0.9896 - val_loss: 0.1319 - val_accuracy: 0.9873\n",
      "Epoch 81/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9888 - val_loss: 0.1289 - val_accuracy: 0.9827\n",
      "Epoch 82/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0832 - accuracy: 0.9896 - val_loss: 0.1312 - val_accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0804 - accuracy: 0.9899 - val_loss: 0.1338 - val_accuracy: 0.9844\n",
      "Epoch 84/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0814 - accuracy: 0.9893 - val_loss: 0.1260 - val_accuracy: 0.9847\n",
      "Epoch 85/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0805 - accuracy: 0.9900 - val_loss: 0.1191 - val_accuracy: 0.9860\n",
      "Epoch 86/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0778 - accuracy: 0.9908 - val_loss: 0.1283 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0778 - accuracy: 0.9899 - val_loss: 0.1160 - val_accuracy: 0.9871\n",
      "Epoch 88/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0772 - accuracy: 0.9902 - val_loss: 0.1224 - val_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0756 - accuracy: 0.9895 - val_loss: 0.1141 - val_accuracy: 0.9858\n",
      "Epoch 90/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0765 - accuracy: 0.9905 - val_loss: 0.1279 - val_accuracy: 0.9838\n",
      "Epoch 91/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0736 - accuracy: 0.9906 - val_loss: 0.1162 - val_accuracy: 0.9869\n",
      "Epoch 92/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0736 - accuracy: 0.9904 - val_loss: 0.1201 - val_accuracy: 0.9849\n",
      "Epoch 93/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0719 - accuracy: 0.9913 - val_loss: 0.1228 - val_accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0717 - accuracy: 0.9915 - val_loss: 0.1242 - val_accuracy: 0.9860\n",
      "Epoch 95/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0716 - accuracy: 0.9911 - val_loss: 0.1182 - val_accuracy: 0.9869\n",
      "Epoch 96/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0700 - accuracy: 0.9914 - val_loss: 0.1070 - val_accuracy: 0.9869\n",
      "Epoch 97/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0705 - accuracy: 0.9916 - val_loss: 0.1160 - val_accuracy: 0.9882\n",
      "Epoch 98/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0681 - accuracy: 0.9917 - val_loss: 0.1181 - val_accuracy: 0.9856\n",
      "Epoch 99/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0688 - accuracy: 0.9912 - val_loss: 0.1147 - val_accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0671 - accuracy: 0.9915 - val_loss: 0.1144 - val_accuracy: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/linear_class\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 53.1 s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/linear_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(655)))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9be2663-ca79-46a7-bbbb-460f09cce5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091fb9e5-5ea4-48ad-8868-5b2420ad7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 830us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037eccb-a72f-4f5b-ae4c-05c283ae69dd",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb1c79d0-88fb-41e0-bdb7-0ec576ce2dbb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        19\n",
      "           1    1.00000   1.00000   1.00000        20\n",
      "           2    1.00000   1.00000   1.00000        19\n",
      "           3    0.95833   1.00000   0.97872        23\n",
      "           4    1.00000   1.00000   1.00000        26\n",
      "           5    1.00000   1.00000   1.00000        18\n",
      "           6    0.96000   1.00000   0.97959        24\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        17\n",
      "           9    1.00000   0.92308   0.96000        26\n",
      "          10    0.96154   1.00000   0.98039        25\n",
      "          11    1.00000   1.00000   1.00000        21\n",
      "          12    1.00000   1.00000   1.00000        23\n",
      "          13    1.00000   1.00000   1.00000        22\n",
      "          14    1.00000   1.00000   1.00000        23\n",
      "          15    1.00000   0.94444   0.97143        18\n",
      "          16    0.94118   1.00000   0.96970        16\n",
      "          17    0.78947   1.00000   0.88235        15\n",
      "          18    1.00000   1.00000   1.00000        18\n",
      "          19    1.00000   1.00000   1.00000        23\n",
      "          20    1.00000   1.00000   1.00000        19\n",
      "          21    1.00000   0.95238   0.97561        21\n",
      "          22    0.95455   1.00000   0.97674        21\n",
      "          23    1.00000   0.95833   0.97872        24\n",
      "          24    1.00000   0.95238   0.97561        21\n",
      "          25    1.00000   1.00000   1.00000        15\n",
      "          26    1.00000   1.00000   1.00000        25\n",
      "          27    1.00000   1.00000   1.00000        18\n",
      "          28    1.00000   1.00000   1.00000        18\n",
      "          29    1.00000   1.00000   1.00000        19\n",
      "          30    1.00000   0.95455   0.97674        22\n",
      "          31    1.00000   1.00000   1.00000        18\n",
      "          32    1.00000   1.00000   1.00000        16\n",
      "          33    1.00000   1.00000   1.00000        20\n",
      "          34    1.00000   1.00000   1.00000        17\n",
      "          35    1.00000   1.00000   1.00000        25\n",
      "          36    1.00000   0.92308   0.96000        13\n",
      "          37    0.87500   1.00000   0.93333        21\n",
      "          38    0.95238   0.95238   0.95238        21\n",
      "          39    1.00000   0.94737   0.97297        19\n",
      "          40    1.00000   0.94444   0.97143        18\n",
      "          41    1.00000   1.00000   1.00000        27\n",
      "          42    1.00000   0.95238   0.97561        21\n",
      "          43    1.00000   1.00000   1.00000        14\n",
      "          44    1.00000   1.00000   1.00000        18\n",
      "          45    1.00000   1.00000   1.00000        21\n",
      "          46    1.00000   1.00000   1.00000         9\n",
      "          47    1.00000   0.92857   0.96296        14\n",
      "          48    1.00000   1.00000   1.00000        19\n",
      "          49    1.00000   0.92308   0.96000        13\n",
      "          50    0.96429   1.00000   0.98182        27\n",
      "          51    1.00000   0.95833   0.97872        24\n",
      "          52    1.00000   0.83333   0.90909        18\n",
      "          53    0.95652   1.00000   0.97778        22\n",
      "          54    1.00000   0.95652   0.97778        23\n",
      "          55    1.00000   1.00000   1.00000        19\n",
      "          56    1.00000   1.00000   1.00000        19\n",
      "          57    1.00000   1.00000   1.00000        21\n",
      "          58    1.00000   1.00000   1.00000        21\n",
      "          59    1.00000   0.96154   0.98039        26\n",
      "          60    1.00000   1.00000   1.00000        21\n",
      "          61    1.00000   1.00000   1.00000        25\n",
      "          62    1.00000   1.00000   1.00000        19\n",
      "          63    1.00000   1.00000   1.00000        23\n",
      "          64    1.00000   1.00000   1.00000        19\n",
      "          65    1.00000   1.00000   1.00000        22\n",
      "          66    1.00000   1.00000   1.00000        18\n",
      "          67    1.00000   1.00000   1.00000        19\n",
      "          68    1.00000   1.00000   1.00000        23\n",
      "          69    1.00000   1.00000   1.00000        21\n",
      "          70    1.00000   1.00000   1.00000        12\n",
      "          71    1.00000   0.95652   0.97778        23\n",
      "          72    0.90000   1.00000   0.94737        18\n",
      "          73    0.94118   1.00000   0.96970        16\n",
      "          74    1.00000   1.00000   1.00000        20\n",
      "          75    1.00000   1.00000   1.00000        20\n",
      "          76    0.95833   1.00000   0.97872        23\n",
      "          77    1.00000   1.00000   1.00000        21\n",
      "          78    1.00000   1.00000   1.00000        19\n",
      "          79    1.00000   0.96774   0.98361        31\n",
      "          80    1.00000   0.96667   0.98305        30\n",
      "          81    0.92857   1.00000   0.96296        13\n",
      "          82    1.00000   0.92308   0.96000        13\n",
      "          83    1.00000   1.00000   1.00000        25\n",
      "          84    1.00000   1.00000   1.00000        22\n",
      "          85    1.00000   1.00000   1.00000        19\n",
      "          86    0.94118   1.00000   0.96970        16\n",
      "          87    0.60714   1.00000   0.75556        17\n",
      "          88    1.00000   1.00000   1.00000        18\n",
      "          89    1.00000   1.00000   1.00000        26\n",
      "          90    1.00000   1.00000   1.00000        16\n",
      "          91    1.00000   1.00000   1.00000        20\n",
      "          92    1.00000   1.00000   1.00000        21\n",
      "          93    0.92308   1.00000   0.96000        12\n",
      "          94    1.00000   0.95238   0.97561        21\n",
      "          95    1.00000   1.00000   1.00000        16\n",
      "          96    0.91304   1.00000   0.95455        21\n",
      "          97    1.00000   0.96154   0.98039        26\n",
      "          98    1.00000   1.00000   1.00000        25\n",
      "          99    1.00000   1.00000   1.00000        16\n",
      "         100    0.95455   1.00000   0.97674        21\n",
      "         101    1.00000   1.00000   1.00000        24\n",
      "         102    1.00000   1.00000   1.00000        20\n",
      "         103    1.00000   0.93333   0.96552        15\n",
      "         104    1.00000   1.00000   1.00000        15\n",
      "         105    1.00000   0.93333   0.96552        15\n",
      "         106    1.00000   0.91304   0.95455        23\n",
      "         107    0.95238   1.00000   0.97561        20\n",
      "         108    1.00000   1.00000   1.00000        25\n",
      "         109    1.00000   1.00000   1.00000        26\n",
      "         110    1.00000   0.95652   0.97778        23\n",
      "         111    0.95652   1.00000   0.97778        22\n",
      "         112    1.00000   1.00000   1.00000        18\n",
      "         113    1.00000   1.00000   1.00000        27\n",
      "         114    1.00000   1.00000   1.00000        15\n",
      "         115    1.00000   1.00000   1.00000        17\n",
      "         116    1.00000   1.00000   1.00000        23\n",
      "         117    1.00000   1.00000   1.00000        19\n",
      "         118    1.00000   1.00000   1.00000        19\n",
      "         119    1.00000   1.00000   1.00000        18\n",
      "         120    1.00000   1.00000   1.00000        23\n",
      "         121    1.00000   1.00000   1.00000        17\n",
      "         122    1.00000   1.00000   1.00000        19\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    1.00000   0.95000   0.97436        20\n",
      "         126    1.00000   1.00000   1.00000        16\n",
      "         127    0.92000   1.00000   0.95833        23\n",
      "         128    0.94118   1.00000   0.96970        16\n",
      "         129    1.00000   1.00000   1.00000        12\n",
      "         130    1.00000   1.00000   1.00000        20\n",
      "         131    1.00000   1.00000   1.00000        24\n",
      "         132    1.00000   1.00000   1.00000        21\n",
      "         133    1.00000   0.85714   0.92308        14\n",
      "         134    1.00000   1.00000   1.00000        15\n",
      "         135    1.00000   1.00000   1.00000        20\n",
      "         136    1.00000   1.00000   1.00000        26\n",
      "         137    1.00000   1.00000   1.00000        14\n",
      "         138    1.00000   0.95238   0.97561        21\n",
      "         139    1.00000   1.00000   1.00000        20\n",
      "         140    1.00000   1.00000   1.00000        23\n",
      "         141    1.00000   1.00000   1.00000        21\n",
      "         142    1.00000   1.00000   1.00000        17\n",
      "         143    1.00000   1.00000   1.00000        14\n",
      "         144    1.00000   1.00000   1.00000        23\n",
      "         145    0.76471   1.00000   0.86667        13\n",
      "         146    1.00000   0.92593   0.96154        27\n",
      "         147    1.00000   0.92857   0.96296        28\n",
      "         148    1.00000   1.00000   1.00000        23\n",
      "         149    1.00000   1.00000   1.00000        23\n",
      "         150    1.00000   0.96154   0.98039        26\n",
      "         151    0.95455   1.00000   0.97674        21\n",
      "         152    1.00000   1.00000   1.00000        25\n",
      "         153    1.00000   1.00000   1.00000        19\n",
      "         154    1.00000   1.00000   1.00000        22\n",
      "         155    1.00000   1.00000   1.00000        16\n",
      "         156    1.00000   1.00000   1.00000        23\n",
      "         157    1.00000   0.94118   0.96970        17\n",
      "         158    1.00000   0.95455   0.97674        22\n",
      "         159    1.00000   1.00000   1.00000        20\n",
      "         160    1.00000   1.00000   1.00000        22\n",
      "         161    1.00000   1.00000   1.00000        23\n",
      "         162    1.00000   1.00000   1.00000        14\n",
      "         163    1.00000   1.00000   1.00000        23\n",
      "         164    1.00000   1.00000   1.00000        18\n",
      "         165    1.00000   1.00000   1.00000        30\n",
      "         166    1.00000   1.00000   1.00000        19\n",
      "         167    1.00000   1.00000   1.00000        24\n",
      "         168    0.92857   1.00000   0.96296        13\n",
      "         169    0.88235   1.00000   0.93750        15\n",
      "         170    1.00000   0.92308   0.96000        26\n",
      "         171    1.00000   1.00000   1.00000        20\n",
      "         172    1.00000   1.00000   1.00000        22\n",
      "         173    1.00000   0.84615   0.91667        13\n",
      "         174    1.00000   1.00000   1.00000        20\n",
      "         175    1.00000   0.95652   0.97778        23\n",
      "         176    0.94737   0.94737   0.94737        19\n",
      "         177    1.00000   1.00000   1.00000        18\n",
      "         178    1.00000   1.00000   1.00000        16\n",
      "         179    1.00000   1.00000   1.00000        24\n",
      "         180    1.00000   1.00000   1.00000        22\n",
      "         181    1.00000   0.90909   0.95238        11\n",
      "         182    1.00000   1.00000   1.00000        15\n",
      "         183    1.00000   1.00000   1.00000        25\n",
      "         184    1.00000   1.00000   1.00000        17\n",
      "         185    1.00000   1.00000   1.00000        19\n",
      "         186    1.00000   1.00000   1.00000        27\n",
      "         187    1.00000   1.00000   1.00000        20\n",
      "         188    1.00000   1.00000   1.00000        26\n",
      "         189    1.00000   0.96667   0.98305        30\n",
      "         190    0.94737   1.00000   0.97297        18\n",
      "         191    1.00000   1.00000   1.00000        19\n",
      "         192    1.00000   1.00000   1.00000        14\n",
      "         193    1.00000   1.00000   1.00000        20\n",
      "         194    1.00000   1.00000   1.00000        23\n",
      "         195    1.00000   1.00000   1.00000        23\n",
      "         196    1.00000   1.00000   1.00000        22\n",
      "         197    1.00000   0.93333   0.96552        15\n",
      "         198    1.00000   1.00000   1.00000        20\n",
      "         199    1.00000   1.00000   1.00000        20\n",
      "         200    1.00000   1.00000   1.00000        19\n",
      "         201    1.00000   1.00000   1.00000        23\n",
      "         202    1.00000   1.00000   1.00000        17\n",
      "         203    1.00000   1.00000   1.00000        27\n",
      "         204    1.00000   1.00000   1.00000        14\n",
      "         205    1.00000   1.00000   1.00000        17\n",
      "         206    1.00000   1.00000   1.00000        13\n",
      "         207    1.00000   1.00000   1.00000        22\n",
      "         208    1.00000   1.00000   1.00000        21\n",
      "         209    1.00000   1.00000   1.00000        15\n",
      "         210    1.00000   1.00000   1.00000        22\n",
      "         211    1.00000   1.00000   1.00000        25\n",
      "         212    1.00000   1.00000   1.00000        18\n",
      "         213    1.00000   0.91667   0.95652        12\n",
      "         214    1.00000   1.00000   1.00000        19\n",
      "         215    1.00000   1.00000   1.00000        24\n",
      "         216    1.00000   1.00000   1.00000        17\n",
      "         217    1.00000   1.00000   1.00000        22\n",
      "         218    1.00000   1.00000   1.00000        20\n",
      "         219    1.00000   1.00000   1.00000        17\n",
      "         220    1.00000   1.00000   1.00000        13\n",
      "         221    1.00000   1.00000   1.00000        21\n",
      "         222    0.92857   1.00000   0.96296        13\n",
      "         223    1.00000   1.00000   1.00000        21\n",
      "         224    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        0.98844      4500\n",
      "   macro avg    0.98891   0.98800   0.98775      4500\n",
      "weighted avg    0.99029   0.98844   0.98877      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51af58-9ede-46e3-99ed-0164c6834c82",
   "metadata": {},
   "source": [
    "<h1>Exponential Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda86b57-083d-4b8a-879c-09a51d46aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.read_csv('input/results_complete_exponential.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eff74c0-769f-4685-9a72-f69724210c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_exp.drop(['elem_damaged', 'damage'], axis=1), df_exp['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815cc01f-7962-4f05-b49d-1de62fd5eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c553a7-f94f-43df-9032-385155de8e94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 20)                13120     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 225)               4725      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,685\n",
      "Trainable params: 18,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 4.8812 - accuracy: 0.0672 - val_loss: 4.1370 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 3.4298 - accuracy: 0.3052 - val_loss: 2.7782 - val_accuracy: 0.4540\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.3388 - accuracy: 0.5737 - val_loss: 1.9669 - val_accuracy: 0.6538\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7116 - accuracy: 0.7093 - val_loss: 1.4819 - val_accuracy: 0.7540\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3293 - accuracy: 0.7793 - val_loss: 1.1897 - val_accuracy: 0.7969\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0856 - accuracy: 0.8211 - val_loss: 0.9954 - val_accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9181 - accuracy: 0.8488 - val_loss: 0.8584 - val_accuracy: 0.8589\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7954 - accuracy: 0.8710 - val_loss: 0.7528 - val_accuracy: 0.8776\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7019 - accuracy: 0.8872 - val_loss: 0.6708 - val_accuracy: 0.8944\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6267 - accuracy: 0.9012 - val_loss: 0.6111 - val_accuracy: 0.9082\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5676 - accuracy: 0.9133 - val_loss: 0.5624 - val_accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5193 - accuracy: 0.9209 - val_loss: 0.5132 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4789 - accuracy: 0.9288 - val_loss: 0.4823 - val_accuracy: 0.9342\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4441 - accuracy: 0.9341 - val_loss: 0.4618 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.4138 - accuracy: 0.9385 - val_loss: 0.4302 - val_accuracy: 0.9407\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3903 - accuracy: 0.9440 - val_loss: 0.4026 - val_accuracy: 0.9489\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3679 - accuracy: 0.9474 - val_loss: 0.3888 - val_accuracy: 0.9487\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3465 - accuracy: 0.9507 - val_loss: 0.3618 - val_accuracy: 0.9562\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3291 - accuracy: 0.9535 - val_loss: 0.3484 - val_accuracy: 0.9591\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.3133 - accuracy: 0.9553 - val_loss: 0.3352 - val_accuracy: 0.9598\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2965 - accuracy: 0.9587 - val_loss: 0.3204 - val_accuracy: 0.9644\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2856 - accuracy: 0.9606 - val_loss: 0.3083 - val_accuracy: 0.9691\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2739 - accuracy: 0.9626 - val_loss: 0.3057 - val_accuracy: 0.9558\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2637 - accuracy: 0.9642 - val_loss: 0.2954 - val_accuracy: 0.9600\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2534 - accuracy: 0.9646 - val_loss: 0.2853 - val_accuracy: 0.9598\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2440 - accuracy: 0.9667 - val_loss: 0.2715 - val_accuracy: 0.9640\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2364 - accuracy: 0.9674 - val_loss: 0.2668 - val_accuracy: 0.9644\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2271 - accuracy: 0.9683 - val_loss: 0.2574 - val_accuracy: 0.9698\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2211 - accuracy: 0.9693 - val_loss: 0.2503 - val_accuracy: 0.9722\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2136 - accuracy: 0.9706 - val_loss: 0.2415 - val_accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2074 - accuracy: 0.9713 - val_loss: 0.2430 - val_accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.2023 - accuracy: 0.9727 - val_loss: 0.2371 - val_accuracy: 0.9696\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1962 - accuracy: 0.9731 - val_loss: 0.2191 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1896 - accuracy: 0.9747 - val_loss: 0.2289 - val_accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1853 - accuracy: 0.9748 - val_loss: 0.2211 - val_accuracy: 0.9702\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1811 - accuracy: 0.9747 - val_loss: 0.2127 - val_accuracy: 0.9742\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1765 - accuracy: 0.9757 - val_loss: 0.2100 - val_accuracy: 0.9729\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1720 - accuracy: 0.9767 - val_loss: 0.2121 - val_accuracy: 0.9729\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1686 - accuracy: 0.9770 - val_loss: 0.2014 - val_accuracy: 0.9751\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1641 - accuracy: 0.9778 - val_loss: 0.2068 - val_accuracy: 0.9747\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1599 - accuracy: 0.9775 - val_loss: 0.1916 - val_accuracy: 0.9767\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1569 - accuracy: 0.9784 - val_loss: 0.1879 - val_accuracy: 0.9764\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1532 - accuracy: 0.9792 - val_loss: 0.1921 - val_accuracy: 0.9769\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1509 - accuracy: 0.9796 - val_loss: 0.1906 - val_accuracy: 0.9767\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1468 - accuracy: 0.9802 - val_loss: 0.1822 - val_accuracy: 0.9773\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1447 - accuracy: 0.9797 - val_loss: 0.1829 - val_accuracy: 0.9771\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1405 - accuracy: 0.9813 - val_loss: 0.1783 - val_accuracy: 0.9804\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1387 - accuracy: 0.9812 - val_loss: 0.1742 - val_accuracy: 0.9804\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1366 - accuracy: 0.9814 - val_loss: 0.1777 - val_accuracy: 0.9776\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1330 - accuracy: 0.9816 - val_loss: 0.1760 - val_accuracy: 0.9791\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1302 - accuracy: 0.9820 - val_loss: 0.1715 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1276 - accuracy: 0.9835 - val_loss: 0.1699 - val_accuracy: 0.9742\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1258 - accuracy: 0.9829 - val_loss: 0.1704 - val_accuracy: 0.9787\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1244 - accuracy: 0.9831 - val_loss: 0.1704 - val_accuracy: 0.9793\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1218 - accuracy: 0.9836 - val_loss: 0.1673 - val_accuracy: 0.9758\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1191 - accuracy: 0.9845 - val_loss: 0.1612 - val_accuracy: 0.9780\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1173 - accuracy: 0.9842 - val_loss: 0.1720 - val_accuracy: 0.9731\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1151 - accuracy: 0.9847 - val_loss: 0.1741 - val_accuracy: 0.9778\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1134 - accuracy: 0.9848 - val_loss: 0.1527 - val_accuracy: 0.9800\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1126 - accuracy: 0.9842 - val_loss: 0.1548 - val_accuracy: 0.9836\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1111 - accuracy: 0.9849 - val_loss: 0.1510 - val_accuracy: 0.9840\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1076 - accuracy: 0.9861 - val_loss: 0.1551 - val_accuracy: 0.9824\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1060 - accuracy: 0.9857 - val_loss: 0.1470 - val_accuracy: 0.9816\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1049 - accuracy: 0.9857 - val_loss: 0.1773 - val_accuracy: 0.9809\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1044 - accuracy: 0.9856 - val_loss: 0.1523 - val_accuracy: 0.9829\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1017 - accuracy: 0.9860 - val_loss: 0.1576 - val_accuracy: 0.9804\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.1002 - accuracy: 0.9863 - val_loss: 0.1526 - val_accuracy: 0.9798\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0982 - accuracy: 0.9863 - val_loss: 0.1478 - val_accuracy: 0.9829\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0977 - accuracy: 0.9866 - val_loss: 0.1324 - val_accuracy: 0.9840\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0957 - accuracy: 0.9873 - val_loss: 0.1564 - val_accuracy: 0.9820\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0941 - accuracy: 0.9871 - val_loss: 0.1405 - val_accuracy: 0.9833\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0940 - accuracy: 0.9872 - val_loss: 0.1430 - val_accuracy: 0.9824\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0915 - accuracy: 0.9873 - val_loss: 0.1393 - val_accuracy: 0.9818\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0915 - accuracy: 0.9874 - val_loss: 0.1515 - val_accuracy: 0.9869\n",
      "Epoch 75/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0908 - accuracy: 0.9875 - val_loss: 0.1467 - val_accuracy: 0.9838\n",
      "Epoch 76/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0875 - accuracy: 0.9872 - val_loss: 0.1492 - val_accuracy: 0.9840\n",
      "Epoch 77/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0869 - accuracy: 0.9878 - val_loss: 0.1467 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0863 - accuracy: 0.9882 - val_loss: 0.1475 - val_accuracy: 0.9816\n",
      "Epoch 79/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0859 - accuracy: 0.9880 - val_loss: 0.1434 - val_accuracy: 0.9849\n",
      "Epoch 80/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0831 - accuracy: 0.9887 - val_loss: 0.1386 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0820 - accuracy: 0.9887 - val_loss: 0.1319 - val_accuracy: 0.9851\n",
      "Epoch 82/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0822 - accuracy: 0.9886 - val_loss: 0.1494 - val_accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0817 - accuracy: 0.9891 - val_loss: 0.1499 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0798 - accuracy: 0.9890 - val_loss: 0.1414 - val_accuracy: 0.9851\n",
      "Epoch 85/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0785 - accuracy: 0.9891 - val_loss: 0.1399 - val_accuracy: 0.9867\n",
      "Epoch 86/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0771 - accuracy: 0.9895 - val_loss: 0.1428 - val_accuracy: 0.9824\n",
      "Epoch 87/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0777 - accuracy: 0.9887 - val_loss: 0.1330 - val_accuracy: 0.9838\n",
      "Epoch 88/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0766 - accuracy: 0.9888 - val_loss: 0.1369 - val_accuracy: 0.9860\n",
      "Epoch 89/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0748 - accuracy: 0.9895 - val_loss: 0.1482 - val_accuracy: 0.9824\n",
      "Epoch 90/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0744 - accuracy: 0.9899 - val_loss: 0.1539 - val_accuracy: 0.9824\n",
      "Epoch 91/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0748 - accuracy: 0.9896 - val_loss: 0.1370 - val_accuracy: 0.9849\n",
      "Epoch 92/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0724 - accuracy: 0.9901 - val_loss: 0.1452 - val_accuracy: 0.9847\n",
      "Epoch 93/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0713 - accuracy: 0.9899 - val_loss: 0.1380 - val_accuracy: 0.9873\n",
      "Epoch 94/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0709 - accuracy: 0.9905 - val_loss: 0.1249 - val_accuracy: 0.9849\n",
      "Epoch 95/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0709 - accuracy: 0.9909 - val_loss: 0.1287 - val_accuracy: 0.9858\n",
      "Epoch 96/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0700 - accuracy: 0.9903 - val_loss: 0.1277 - val_accuracy: 0.9860\n",
      "Epoch 97/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0691 - accuracy: 0.9906 - val_loss: 0.1472 - val_accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0683 - accuracy: 0.9906 - val_loss: 0.1414 - val_accuracy: 0.9858\n",
      "Epoch 99/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0677 - accuracy: 0.9906 - val_loss: 0.1552 - val_accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.0671 - accuracy: 0.9911 - val_loss: 0.1539 - val_accuracy: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_9_layer_call_fn, leaky_re_lu_9_layer_call_and_return_conditional_losses, leaky_re_lu_10_layer_call_fn, leaky_re_lu_10_layer_call_and_return_conditional_losses, leaky_re_lu_11_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\exp_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\exp_class\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.2 s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models\\\\exp_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(655)))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d48b8bb-4050-4e4e-9b5d-f544ec904945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 824us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29de131-b034-4c2b-af37-24c452d2eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb94e0-76ea-48a8-9201-bb3798b826a2",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "380a789e-6c82-431c-bc0d-61f8c449e71a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        19\n",
      "           1    1.00000   1.00000   1.00000        20\n",
      "           2    0.95000   1.00000   0.97436        19\n",
      "           3    1.00000   1.00000   1.00000        23\n",
      "           4    1.00000   1.00000   1.00000        26\n",
      "           5    1.00000   1.00000   1.00000        18\n",
      "           6    1.00000   1.00000   1.00000        24\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        17\n",
      "           9    1.00000   0.96154   0.98039        26\n",
      "          10    1.00000   1.00000   1.00000        25\n",
      "          11    0.95455   1.00000   0.97674        21\n",
      "          12    0.95833   1.00000   0.97872        23\n",
      "          13    1.00000   0.95455   0.97674        22\n",
      "          14    1.00000   1.00000   1.00000        23\n",
      "          15    1.00000   0.94444   0.97143        18\n",
      "          16    0.94118   1.00000   0.96970        16\n",
      "          17    1.00000   1.00000   1.00000        15\n",
      "          18    0.94737   1.00000   0.97297        18\n",
      "          19    1.00000   0.95652   0.97778        23\n",
      "          20    1.00000   1.00000   1.00000        19\n",
      "          21    1.00000   0.90476   0.95000        21\n",
      "          22    0.95455   1.00000   0.97674        21\n",
      "          23    1.00000   0.95833   0.97872        24\n",
      "          24    0.90909   0.95238   0.93023        21\n",
      "          25    1.00000   1.00000   1.00000        15\n",
      "          26    1.00000   1.00000   1.00000        25\n",
      "          27    1.00000   1.00000   1.00000        18\n",
      "          28    1.00000   1.00000   1.00000        18\n",
      "          29    1.00000   1.00000   1.00000        19\n",
      "          30    1.00000   0.95455   0.97674        22\n",
      "          31    1.00000   1.00000   1.00000        18\n",
      "          32    0.84211   1.00000   0.91429        16\n",
      "          33    1.00000   1.00000   1.00000        20\n",
      "          34    0.94444   1.00000   0.97143        17\n",
      "          35    1.00000   1.00000   1.00000        25\n",
      "          36    1.00000   0.92308   0.96000        13\n",
      "          37    0.95455   1.00000   0.97674        21\n",
      "          38    1.00000   0.95238   0.97561        21\n",
      "          39    1.00000   0.94737   0.97297        19\n",
      "          40    1.00000   0.94444   0.97143        18\n",
      "          41    1.00000   1.00000   1.00000        27\n",
      "          42    1.00000   0.95238   0.97561        21\n",
      "          43    1.00000   1.00000   1.00000        14\n",
      "          44    1.00000   1.00000   1.00000        18\n",
      "          45    0.72414   1.00000   0.84000        21\n",
      "          46    0.90000   1.00000   0.94737         9\n",
      "          47    1.00000   0.92857   0.96296        14\n",
      "          48    1.00000   1.00000   1.00000        19\n",
      "          49    0.92308   0.92308   0.92308        13\n",
      "          50    0.96429   1.00000   0.98182        27\n",
      "          51    1.00000   0.95833   0.97872        24\n",
      "          52    0.94118   0.88889   0.91429        18\n",
      "          53    0.95652   1.00000   0.97778        22\n",
      "          54    1.00000   0.95652   0.97778        23\n",
      "          55    1.00000   1.00000   1.00000        19\n",
      "          56    1.00000   1.00000   1.00000        19\n",
      "          57    1.00000   1.00000   1.00000        21\n",
      "          58    1.00000   0.95238   0.97561        21\n",
      "          59    0.96154   0.96154   0.96154        26\n",
      "          60    1.00000   1.00000   1.00000        21\n",
      "          61    1.00000   1.00000   1.00000        25\n",
      "          62    1.00000   1.00000   1.00000        19\n",
      "          63    1.00000   1.00000   1.00000        23\n",
      "          64    1.00000   1.00000   1.00000        19\n",
      "          65    1.00000   0.95455   0.97674        22\n",
      "          66    1.00000   1.00000   1.00000        18\n",
      "          67    1.00000   1.00000   1.00000        19\n",
      "          68    1.00000   1.00000   1.00000        23\n",
      "          69    1.00000   1.00000   1.00000        21\n",
      "          70    1.00000   1.00000   1.00000        12\n",
      "          71    1.00000   0.95652   0.97778        23\n",
      "          72    0.94737   1.00000   0.97297        18\n",
      "          73    0.94118   1.00000   0.96970        16\n",
      "          74    0.95238   1.00000   0.97561        20\n",
      "          75    1.00000   0.95000   0.97436        20\n",
      "          76    1.00000   0.95652   0.97778        23\n",
      "          77    1.00000   1.00000   1.00000        21\n",
      "          78    1.00000   1.00000   1.00000        19\n",
      "          79    0.96875   1.00000   0.98413        31\n",
      "          80    0.93750   1.00000   0.96774        30\n",
      "          81    0.92857   1.00000   0.96296        13\n",
      "          82    1.00000   0.92308   0.96000        13\n",
      "          83    0.96154   1.00000   0.98039        25\n",
      "          84    1.00000   1.00000   1.00000        22\n",
      "          85    1.00000   1.00000   1.00000        19\n",
      "          86    0.94118   1.00000   0.96970        16\n",
      "          87    1.00000   1.00000   1.00000        17\n",
      "          88    1.00000   1.00000   1.00000        18\n",
      "          89    1.00000   1.00000   1.00000        26\n",
      "          90    1.00000   1.00000   1.00000        16\n",
      "          91    1.00000   0.95000   0.97436        20\n",
      "          92    1.00000   1.00000   1.00000        21\n",
      "          93    1.00000   1.00000   1.00000        12\n",
      "          94    0.91304   1.00000   0.95455        21\n",
      "          95    1.00000   1.00000   1.00000        16\n",
      "          96    0.95455   1.00000   0.97674        21\n",
      "          97    0.96154   0.96154   0.96154        26\n",
      "          98    1.00000   1.00000   1.00000        25\n",
      "          99    1.00000   1.00000   1.00000        16\n",
      "         100    0.95455   1.00000   0.97674        21\n",
      "         101    1.00000   1.00000   1.00000        24\n",
      "         102    1.00000   1.00000   1.00000        20\n",
      "         103    1.00000   0.93333   0.96552        15\n",
      "         104    1.00000   1.00000   1.00000        15\n",
      "         105    0.93333   0.93333   0.93333        15\n",
      "         106    1.00000   0.91304   0.95455        23\n",
      "         107    0.90909   1.00000   0.95238        20\n",
      "         108    0.96154   1.00000   0.98039        25\n",
      "         109    1.00000   1.00000   1.00000        26\n",
      "         110    1.00000   0.95652   0.97778        23\n",
      "         111    1.00000   1.00000   1.00000        22\n",
      "         112    0.94737   1.00000   0.97297        18\n",
      "         113    1.00000   0.96296   0.98113        27\n",
      "         114    1.00000   1.00000   1.00000        15\n",
      "         115    1.00000   1.00000   1.00000        17\n",
      "         116    1.00000   1.00000   1.00000        23\n",
      "         117    1.00000   1.00000   1.00000        19\n",
      "         118    1.00000   1.00000   1.00000        19\n",
      "         119    0.94737   1.00000   0.97297        18\n",
      "         120    1.00000   1.00000   1.00000        23\n",
      "         121    1.00000   1.00000   1.00000        17\n",
      "         122    1.00000   1.00000   1.00000        19\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    1.00000   1.00000   1.00000        20\n",
      "         126    0.94118   1.00000   0.96970        16\n",
      "         127    1.00000   1.00000   1.00000        23\n",
      "         128    1.00000   0.93750   0.96774        16\n",
      "         129    1.00000   1.00000   1.00000        12\n",
      "         130    1.00000   1.00000   1.00000        20\n",
      "         131    1.00000   1.00000   1.00000        24\n",
      "         132    1.00000   1.00000   1.00000        21\n",
      "         133    1.00000   0.92857   0.96296        14\n",
      "         134    1.00000   1.00000   1.00000        15\n",
      "         135    1.00000   1.00000   1.00000        20\n",
      "         136    1.00000   1.00000   1.00000        26\n",
      "         137    1.00000   1.00000   1.00000        14\n",
      "         138    1.00000   0.95238   0.97561        21\n",
      "         139    1.00000   1.00000   1.00000        20\n",
      "         140    1.00000   1.00000   1.00000        23\n",
      "         141    1.00000   1.00000   1.00000        21\n",
      "         142    1.00000   1.00000   1.00000        17\n",
      "         143    1.00000   1.00000   1.00000        14\n",
      "         144    1.00000   1.00000   1.00000        23\n",
      "         145    1.00000   1.00000   1.00000        13\n",
      "         146    0.96429   1.00000   0.98182        27\n",
      "         147    1.00000   0.92857   0.96296        28\n",
      "         148    1.00000   0.95652   0.97778        23\n",
      "         149    0.92000   1.00000   0.95833        23\n",
      "         150    1.00000   0.96154   0.98039        26\n",
      "         151    1.00000   1.00000   1.00000        21\n",
      "         152    1.00000   1.00000   1.00000        25\n",
      "         153    1.00000   0.94737   0.97297        19\n",
      "         154    1.00000   1.00000   1.00000        22\n",
      "         155    0.94118   1.00000   0.96970        16\n",
      "         156    1.00000   1.00000   1.00000        23\n",
      "         157    1.00000   0.94118   0.96970        17\n",
      "         158    1.00000   0.95455   0.97674        22\n",
      "         159    1.00000   1.00000   1.00000        20\n",
      "         160    1.00000   1.00000   1.00000        22\n",
      "         161    1.00000   1.00000   1.00000        23\n",
      "         162    1.00000   1.00000   1.00000        14\n",
      "         163    1.00000   1.00000   1.00000        23\n",
      "         164    1.00000   1.00000   1.00000        18\n",
      "         165    1.00000   1.00000   1.00000        30\n",
      "         166    1.00000   1.00000   1.00000        19\n",
      "         167    1.00000   1.00000   1.00000        24\n",
      "         168    1.00000   1.00000   1.00000        13\n",
      "         169    1.00000   1.00000   1.00000        15\n",
      "         170    1.00000   0.88462   0.93878        26\n",
      "         171    0.86957   1.00000   0.93023        20\n",
      "         172    1.00000   1.00000   1.00000        22\n",
      "         173    1.00000   1.00000   1.00000        13\n",
      "         174    1.00000   1.00000   1.00000        20\n",
      "         175    1.00000   0.95652   0.97778        23\n",
      "         176    0.94737   0.94737   0.94737        19\n",
      "         177    1.00000   1.00000   1.00000        18\n",
      "         178    1.00000   1.00000   1.00000        16\n",
      "         179    1.00000   1.00000   1.00000        24\n",
      "         180    1.00000   1.00000   1.00000        22\n",
      "         181    1.00000   0.90909   0.95238        11\n",
      "         182    1.00000   0.93333   0.96552        15\n",
      "         183    0.96154   1.00000   0.98039        25\n",
      "         184    1.00000   1.00000   1.00000        17\n",
      "         185    1.00000   1.00000   1.00000        19\n",
      "         186    1.00000   0.96296   0.98113        27\n",
      "         187    1.00000   1.00000   1.00000        20\n",
      "         188    1.00000   1.00000   1.00000        26\n",
      "         189    1.00000   1.00000   1.00000        30\n",
      "         190    1.00000   1.00000   1.00000        18\n",
      "         191    1.00000   1.00000   1.00000        19\n",
      "         192    1.00000   1.00000   1.00000        14\n",
      "         193    1.00000   1.00000   1.00000        20\n",
      "         194    1.00000   0.95652   0.97778        23\n",
      "         195    0.95833   1.00000   0.97872        23\n",
      "         196    1.00000   1.00000   1.00000        22\n",
      "         197    1.00000   0.86667   0.92857        15\n",
      "         198    1.00000   0.95000   0.97436        20\n",
      "         199    1.00000   1.00000   1.00000        20\n",
      "         200    1.00000   1.00000   1.00000        19\n",
      "         201    1.00000   1.00000   1.00000        23\n",
      "         202    1.00000   1.00000   1.00000        17\n",
      "         203    1.00000   1.00000   1.00000        27\n",
      "         204    1.00000   1.00000   1.00000        14\n",
      "         205    1.00000   1.00000   1.00000        17\n",
      "         206    1.00000   0.92308   0.96000        13\n",
      "         207    0.95652   1.00000   0.97778        22\n",
      "         208    1.00000   1.00000   1.00000        21\n",
      "         209    0.93750   1.00000   0.96774        15\n",
      "         210    1.00000   0.95455   0.97674        22\n",
      "         211    1.00000   1.00000   1.00000        25\n",
      "         212    1.00000   1.00000   1.00000        18\n",
      "         213    0.91667   0.91667   0.91667        12\n",
      "         214    1.00000   0.84211   0.91429        19\n",
      "         215    0.92308   1.00000   0.96000        24\n",
      "         216    1.00000   1.00000   1.00000        17\n",
      "         217    1.00000   1.00000   1.00000        22\n",
      "         218    0.95238   1.00000   0.97561        20\n",
      "         219    1.00000   0.94118   0.96970        17\n",
      "         220    1.00000   1.00000   1.00000        13\n",
      "         221    1.00000   1.00000   1.00000        21\n",
      "         222    1.00000   1.00000   1.00000        13\n",
      "         223    1.00000   1.00000   1.00000        21\n",
      "         224    1.00000   1.00000   1.00000        15\n",
      "\n",
      "    accuracy                        0.98578      4500\n",
      "   macro avg    0.98657   0.98525   0.98539      4500\n",
      "weighted avg    0.98699   0.98578   0.98589      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f47756-08c1-4e9a-a4db-0247f8432987",
   "metadata": {},
   "source": [
    "<h1>Sigmoid-like Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0488ffb-1f97-4d2a-962d-2d5b6c1de260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.read_csv('input/results_complete_sigmoid_like.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a69a9e2-9c1a-460d-8ee0-0b0906b8f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sig.drop(['elem_damaged', 'damage'], axis=1), df_sig['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4725a8a-f537-49c8-b452-b67189a6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29a28008-ffff-418d-862c-e3b1f4a69826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 80)                52480     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 225)               18225     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,665\n",
      "Trainable params: 83,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 4.9514 - accuracy: 0.1009 - val_loss: 4.3565 - val_accuracy: 0.2271\n",
      "Epoch 2/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 3.9255 - accuracy: 0.3080 - val_loss: 3.5372 - val_accuracy: 0.3960\n",
      "Epoch 3/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 3.2622 - accuracy: 0.4368 - val_loss: 3.0259 - val_accuracy: 0.5009\n",
      "Epoch 4/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 2.8397 - accuracy: 0.5203 - val_loss: 2.6820 - val_accuracy: 0.5584\n",
      "Epoch 5/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 2.5652 - accuracy: 0.5671 - val_loss: 2.4693 - val_accuracy: 0.5867\n",
      "Epoch 6/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 2.3802 - accuracy: 0.5965 - val_loss: 2.3164 - val_accuracy: 0.6167\n",
      "Epoch 7/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.2404 - accuracy: 0.6218 - val_loss: 2.1938 - val_accuracy: 0.6353\n",
      "Epoch 8/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.1300 - accuracy: 0.6410 - val_loss: 2.1116 - val_accuracy: 0.6502\n",
      "Epoch 9/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 2.0417 - accuracy: 0.6585 - val_loss: 1.9956 - val_accuracy: 0.6827\n",
      "Epoch 10/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.9606 - accuracy: 0.6737 - val_loss: 1.9365 - val_accuracy: 0.6909\n",
      "Epoch 11/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.8931 - accuracy: 0.6830 - val_loss: 1.8723 - val_accuracy: 0.6996\n",
      "Epoch 12/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.8335 - accuracy: 0.6970 - val_loss: 1.8189 - val_accuracy: 0.6978\n",
      "Epoch 13/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7772 - accuracy: 0.7074 - val_loss: 1.7478 - val_accuracy: 0.7120\n",
      "Epoch 14/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.7273 - accuracy: 0.7132 - val_loss: 1.7136 - val_accuracy: 0.7209\n",
      "Epoch 15/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.6825 - accuracy: 0.7209 - val_loss: 1.6656 - val_accuracy: 0.7144\n",
      "Epoch 16/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.6432 - accuracy: 0.7260 - val_loss: 1.6364 - val_accuracy: 0.7313\n",
      "Epoch 17/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.6055 - accuracy: 0.7334 - val_loss: 1.5995 - val_accuracy: 0.7473\n",
      "Epoch 18/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5691 - accuracy: 0.7427 - val_loss: 1.5833 - val_accuracy: 0.7431\n",
      "Epoch 19/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5377 - accuracy: 0.7450 - val_loss: 1.5385 - val_accuracy: 0.7467\n",
      "Epoch 20/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.5025 - accuracy: 0.7526 - val_loss: 1.5305 - val_accuracy: 0.7409\n",
      "Epoch 21/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4783 - accuracy: 0.7565 - val_loss: 1.5099 - val_accuracy: 0.7602\n",
      "Epoch 22/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4478 - accuracy: 0.7597 - val_loss: 1.4523 - val_accuracy: 0.7731\n",
      "Epoch 23/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.4237 - accuracy: 0.7650 - val_loss: 1.4425 - val_accuracy: 0.7649\n",
      "Epoch 24/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3976 - accuracy: 0.7687 - val_loss: 1.4142 - val_accuracy: 0.7720\n",
      "Epoch 25/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.3747 - accuracy: 0.7701 - val_loss: 1.4109 - val_accuracy: 0.7587\n",
      "Epoch 26/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3510 - accuracy: 0.7746 - val_loss: 1.4031 - val_accuracy: 0.7622\n",
      "Epoch 27/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3284 - accuracy: 0.7795 - val_loss: 1.3787 - val_accuracy: 0.7778\n",
      "Epoch 28/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.3155 - accuracy: 0.7807 - val_loss: 1.3691 - val_accuracy: 0.7811\n",
      "Epoch 29/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.2938 - accuracy: 0.7851 - val_loss: 1.3917 - val_accuracy: 0.7833\n",
      "Epoch 30/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.2722 - accuracy: 0.7876 - val_loss: 1.3448 - val_accuracy: 0.7809\n",
      "Epoch 31/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.2584 - accuracy: 0.7896 - val_loss: 1.3338 - val_accuracy: 0.8036\n",
      "Epoch 32/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2471 - accuracy: 0.7937 - val_loss: 1.2844 - val_accuracy: 0.7991\n",
      "Epoch 33/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.2222 - accuracy: 0.7973 - val_loss: 1.2759 - val_accuracy: 0.7991\n",
      "Epoch 34/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.2145 - accuracy: 0.7994 - val_loss: 1.2995 - val_accuracy: 0.7953\n",
      "Epoch 35/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.2005 - accuracy: 0.8007 - val_loss: 1.2515 - val_accuracy: 0.8120\n",
      "Epoch 36/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.1812 - accuracy: 0.8052 - val_loss: 1.2745 - val_accuracy: 0.8031\n",
      "Epoch 37/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1752 - accuracy: 0.8037 - val_loss: 1.2543 - val_accuracy: 0.8058\n",
      "Epoch 38/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.1577 - accuracy: 0.8064 - val_loss: 1.2267 - val_accuracy: 0.8056\n",
      "Epoch 39/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.1437 - accuracy: 0.8074 - val_loss: 1.2005 - val_accuracy: 0.8238\n",
      "Epoch 40/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.1407 - accuracy: 0.8111 - val_loss: 1.2018 - val_accuracy: 0.8096\n",
      "Epoch 41/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1228 - accuracy: 0.8139 - val_loss: 1.1804 - val_accuracy: 0.8129\n",
      "Epoch 42/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.1139 - accuracy: 0.8137 - val_loss: 1.1994 - val_accuracy: 0.8033\n",
      "Epoch 43/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0924 - accuracy: 0.8156 - val_loss: 1.2079 - val_accuracy: 0.8122\n",
      "Epoch 44/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0850 - accuracy: 0.8177 - val_loss: 1.1953 - val_accuracy: 0.8309\n",
      "Epoch 45/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0796 - accuracy: 0.8193 - val_loss: 1.2085 - val_accuracy: 0.8089\n",
      "Epoch 46/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0702 - accuracy: 0.8227 - val_loss: 1.1936 - val_accuracy: 0.8216\n",
      "Epoch 47/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0604 - accuracy: 0.8226 - val_loss: 1.1967 - val_accuracy: 0.8207\n",
      "Epoch 48/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0476 - accuracy: 0.8243 - val_loss: 1.1602 - val_accuracy: 0.8282\n",
      "Epoch 49/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0355 - accuracy: 0.8252 - val_loss: 1.1732 - val_accuracy: 0.8358\n",
      "Epoch 50/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0293 - accuracy: 0.8284 - val_loss: 1.1755 - val_accuracy: 0.8371\n",
      "Epoch 51/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 1.0264 - accuracy: 0.8267 - val_loss: 1.1474 - val_accuracy: 0.8158\n",
      "Epoch 52/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0122 - accuracy: 0.8291 - val_loss: 1.1715 - val_accuracy: 0.8236\n",
      "Epoch 53/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0096 - accuracy: 0.8312 - val_loss: 1.1515 - val_accuracy: 0.8373\n",
      "Epoch 54/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 1.0009 - accuracy: 0.8312 - val_loss: 1.1030 - val_accuracy: 0.8298\n",
      "Epoch 55/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9864 - accuracy: 0.8357 - val_loss: 1.0850 - val_accuracy: 0.8229\n",
      "Epoch 56/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9877 - accuracy: 0.8332 - val_loss: 1.1173 - val_accuracy: 0.8167\n",
      "Epoch 57/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9710 - accuracy: 0.8382 - val_loss: 1.1269 - val_accuracy: 0.8376\n",
      "Epoch 58/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9717 - accuracy: 0.8357 - val_loss: 1.0507 - val_accuracy: 0.8404\n",
      "Epoch 59/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.9582 - accuracy: 0.8397 - val_loss: 1.0897 - val_accuracy: 0.8264\n",
      "Epoch 60/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.9545 - accuracy: 0.8391 - val_loss: 1.0729 - val_accuracy: 0.8478\n",
      "Epoch 61/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9428 - accuracy: 0.8413 - val_loss: 1.1414 - val_accuracy: 0.8322\n",
      "Epoch 62/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9549 - accuracy: 0.8418 - val_loss: 1.1023 - val_accuracy: 0.8453\n",
      "Epoch 63/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9323 - accuracy: 0.8441 - val_loss: 1.1040 - val_accuracy: 0.8376\n",
      "Epoch 64/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9242 - accuracy: 0.8450 - val_loss: 1.0809 - val_accuracy: 0.8393\n",
      "Epoch 65/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9276 - accuracy: 0.8424 - val_loss: 1.0687 - val_accuracy: 0.8418\n",
      "Epoch 66/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.9127 - accuracy: 0.8473 - val_loss: 1.0996 - val_accuracy: 0.8356\n",
      "Epoch 67/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9175 - accuracy: 0.8448 - val_loss: 1.0793 - val_accuracy: 0.8620\n",
      "Epoch 68/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.9101 - accuracy: 0.8477 - val_loss: 1.0851 - val_accuracy: 0.8238\n",
      "Epoch 69/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8979 - accuracy: 0.8486 - val_loss: 1.0694 - val_accuracy: 0.8553\n",
      "Epoch 70/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8971 - accuracy: 0.8477 - val_loss: 1.0714 - val_accuracy: 0.8504\n",
      "Epoch 71/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8984 - accuracy: 0.8478 - val_loss: 1.1878 - val_accuracy: 0.8067\n",
      "Epoch 72/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8779 - accuracy: 0.8513 - val_loss: 1.1253 - val_accuracy: 0.8504\n",
      "Epoch 73/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8818 - accuracy: 0.8499 - val_loss: 1.0709 - val_accuracy: 0.8644\n",
      "Epoch 74/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8711 - accuracy: 0.8530 - val_loss: 1.0594 - val_accuracy: 0.8587\n",
      "Epoch 75/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8699 - accuracy: 0.8531 - val_loss: 1.0979 - val_accuracy: 0.8536\n",
      "Epoch 76/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8588 - accuracy: 0.8560 - val_loss: 1.0691 - val_accuracy: 0.8616\n",
      "Epoch 77/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8596 - accuracy: 0.8541 - val_loss: 1.0541 - val_accuracy: 0.8522\n",
      "Epoch 78/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8579 - accuracy: 0.8534 - val_loss: 1.0935 - val_accuracy: 0.8358\n",
      "Epoch 79/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8433 - accuracy: 0.8565 - val_loss: 1.0643 - val_accuracy: 0.8513\n",
      "Epoch 80/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8419 - accuracy: 0.8573 - val_loss: 1.0421 - val_accuracy: 0.8609\n",
      "Epoch 81/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8488 - accuracy: 0.8562 - val_loss: 1.1091 - val_accuracy: 0.8529\n",
      "Epoch 82/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8408 - accuracy: 0.8566 - val_loss: 0.9813 - val_accuracy: 0.8656\n",
      "Epoch 83/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8329 - accuracy: 0.8560 - val_loss: 1.0785 - val_accuracy: 0.8704\n",
      "Epoch 84/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8324 - accuracy: 0.8577 - val_loss: 1.0790 - val_accuracy: 0.8453\n",
      "Epoch 85/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8218 - accuracy: 0.8592 - val_loss: 1.0885 - val_accuracy: 0.8551\n",
      "Epoch 86/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8228 - accuracy: 0.8603 - val_loss: 0.9975 - val_accuracy: 0.8627\n",
      "Epoch 87/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8186 - accuracy: 0.8590 - val_loss: 1.0861 - val_accuracy: 0.8564\n",
      "Epoch 88/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.8206 - accuracy: 0.8588 - val_loss: 1.0671 - val_accuracy: 0.8538\n",
      "Epoch 89/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8127 - accuracy: 0.8602 - val_loss: 1.0738 - val_accuracy: 0.8607\n",
      "Epoch 90/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7940 - accuracy: 0.8631 - val_loss: 1.0525 - val_accuracy: 0.8596\n",
      "Epoch 91/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7996 - accuracy: 0.8601 - val_loss: 1.1274 - val_accuracy: 0.8591\n",
      "Epoch 92/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.8063 - accuracy: 0.8604 - val_loss: 1.0968 - val_accuracy: 0.8524\n",
      "Epoch 93/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7974 - accuracy: 0.8603 - val_loss: 1.0204 - val_accuracy: 0.8404\n",
      "Epoch 94/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7866 - accuracy: 0.8656 - val_loss: 1.0398 - val_accuracy: 0.8722\n",
      "Epoch 95/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7875 - accuracy: 0.8650 - val_loss: 1.0002 - val_accuracy: 0.8724\n",
      "Epoch 96/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7887 - accuracy: 0.8638 - val_loss: 1.0631 - val_accuracy: 0.8556\n",
      "Epoch 97/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7876 - accuracy: 0.8639 - val_loss: 0.9863 - val_accuracy: 0.8724\n",
      "Epoch 98/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7825 - accuracy: 0.8660 - val_loss: 0.9570 - val_accuracy: 0.8584\n",
      "Epoch 99/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7665 - accuracy: 0.8678 - val_loss: 0.9595 - val_accuracy: 0.8800\n",
      "Epoch 100/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7658 - accuracy: 0.8662 - val_loss: 1.0012 - val_accuracy: 0.8798\n",
      "Epoch 101/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7684 - accuracy: 0.8656 - val_loss: 0.9957 - val_accuracy: 0.8651\n",
      "Epoch 102/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7582 - accuracy: 0.8670 - val_loss: 0.9544 - val_accuracy: 0.8747\n",
      "Epoch 103/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7576 - accuracy: 0.8674 - val_loss: 0.9791 - val_accuracy: 0.8613\n",
      "Epoch 104/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7672 - accuracy: 0.8683 - val_loss: 1.0705 - val_accuracy: 0.8569\n",
      "Epoch 105/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7670 - accuracy: 0.8673 - val_loss: 1.0512 - val_accuracy: 0.8478\n",
      "Epoch 106/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7524 - accuracy: 0.8690 - val_loss: 1.0693 - val_accuracy: 0.8756\n",
      "Epoch 107/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7423 - accuracy: 0.8724 - val_loss: 1.0155 - val_accuracy: 0.8742\n",
      "Epoch 108/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7539 - accuracy: 0.8696 - val_loss: 1.0556 - val_accuracy: 0.8698\n",
      "Epoch 109/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7382 - accuracy: 0.8705 - val_loss: 1.0080 - val_accuracy: 0.8867\n",
      "Epoch 110/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7575 - accuracy: 0.8681 - val_loss: 0.9830 - val_accuracy: 0.8596\n",
      "Epoch 111/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7324 - accuracy: 0.8720 - val_loss: 1.0035 - val_accuracy: 0.8767\n",
      "Epoch 112/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7396 - accuracy: 0.8704 - val_loss: 1.0517 - val_accuracy: 0.8560\n",
      "Epoch 113/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7425 - accuracy: 0.8724 - val_loss: 0.9261 - val_accuracy: 0.8813\n",
      "Epoch 114/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7251 - accuracy: 0.8754 - val_loss: 0.9320 - val_accuracy: 0.8804\n",
      "Epoch 115/300\n",
      "1266/1266 [==============================] - 3s 2ms/step - loss: 0.7249 - accuracy: 0.8725 - val_loss: 0.9990 - val_accuracy: 0.8678\n",
      "Epoch 116/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7236 - accuracy: 0.8722 - val_loss: 1.0358 - val_accuracy: 0.8611\n",
      "Epoch 117/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7196 - accuracy: 0.8722 - val_loss: 0.9941 - val_accuracy: 0.8782\n",
      "Epoch 118/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7225 - accuracy: 0.8721 - val_loss: 1.0054 - val_accuracy: 0.8727\n",
      "Epoch 119/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7104 - accuracy: 0.8756 - val_loss: 0.9608 - val_accuracy: 0.8833\n",
      "Epoch 120/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7241 - accuracy: 0.8736 - val_loss: 1.0591 - val_accuracy: 0.8798\n",
      "Epoch 121/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7141 - accuracy: 0.8760 - val_loss: 1.0742 - val_accuracy: 0.8751\n",
      "Epoch 122/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7091 - accuracy: 0.8759 - val_loss: 1.0450 - val_accuracy: 0.8729\n",
      "Epoch 123/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.7077 - accuracy: 0.8755 - val_loss: 1.1132 - val_accuracy: 0.8658\n",
      "Epoch 124/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7106 - accuracy: 0.8755 - val_loss: 1.0177 - val_accuracy: 0.8771\n",
      "Epoch 125/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7022 - accuracy: 0.8784 - val_loss: 1.0958 - val_accuracy: 0.8593\n",
      "Epoch 126/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7044 - accuracy: 0.8771 - val_loss: 0.9835 - val_accuracy: 0.8689\n",
      "Epoch 127/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6942 - accuracy: 0.8776 - val_loss: 1.0024 - val_accuracy: 0.8922\n",
      "Epoch 128/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.7024 - accuracy: 0.8790 - val_loss: 0.9909 - val_accuracy: 0.8960\n",
      "Epoch 129/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6943 - accuracy: 0.8780 - val_loss: 1.1223 - val_accuracy: 0.8811\n",
      "Epoch 130/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6967 - accuracy: 0.8772 - val_loss: 1.1362 - val_accuracy: 0.8936\n",
      "Epoch 131/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6903 - accuracy: 0.8784 - val_loss: 0.9870 - val_accuracy: 0.8882\n",
      "Epoch 132/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6919 - accuracy: 0.8786 - val_loss: 1.0947 - val_accuracy: 0.8820\n",
      "Epoch 133/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6833 - accuracy: 0.8786 - val_loss: 1.0500 - val_accuracy: 0.8849\n",
      "Epoch 134/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.8808 - val_loss: 1.0559 - val_accuracy: 0.8898\n",
      "Epoch 135/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6732 - accuracy: 0.8814 - val_loss: 1.0451 - val_accuracy: 0.8676\n",
      "Epoch 136/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6962 - accuracy: 0.8777 - val_loss: 1.0479 - val_accuracy: 0.8944\n",
      "Epoch 137/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6786 - accuracy: 0.8808 - val_loss: 0.9862 - val_accuracy: 0.8744\n",
      "Epoch 138/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6884 - accuracy: 0.8809 - val_loss: 1.1167 - val_accuracy: 0.8749\n",
      "Epoch 139/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6638 - accuracy: 0.8838 - val_loss: 1.0679 - val_accuracy: 0.8904\n",
      "Epoch 140/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6634 - accuracy: 0.8816 - val_loss: 1.0203 - val_accuracy: 0.8969\n",
      "Epoch 141/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6724 - accuracy: 0.8807 - val_loss: 1.0263 - val_accuracy: 0.8753\n",
      "Epoch 142/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6596 - accuracy: 0.8842 - val_loss: 1.0465 - val_accuracy: 0.8818\n",
      "Epoch 143/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6608 - accuracy: 0.8826 - val_loss: 1.0634 - val_accuracy: 0.8911\n",
      "Epoch 144/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6659 - accuracy: 0.8827 - val_loss: 1.0739 - val_accuracy: 0.8873\n",
      "Epoch 145/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6682 - accuracy: 0.8841 - val_loss: 1.1430 - val_accuracy: 0.8804\n",
      "Epoch 146/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6684 - accuracy: 0.8835 - val_loss: 1.0574 - val_accuracy: 0.8987\n",
      "Epoch 147/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6569 - accuracy: 0.8848 - val_loss: 1.1076 - val_accuracy: 0.8767\n",
      "Epoch 148/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6553 - accuracy: 0.8825 - val_loss: 1.1518 - val_accuracy: 0.8604\n",
      "Epoch 149/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6531 - accuracy: 0.8840 - val_loss: 1.0921 - val_accuracy: 0.8909\n",
      "Epoch 150/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6532 - accuracy: 0.8830 - val_loss: 1.0781 - val_accuracy: 0.8840\n",
      "Epoch 151/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6504 - accuracy: 0.8844 - val_loss: 1.0549 - val_accuracy: 0.8927\n",
      "Epoch 152/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6525 - accuracy: 0.8840 - val_loss: 1.1759 - val_accuracy: 0.8716\n",
      "Epoch 153/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6613 - accuracy: 0.8837 - val_loss: 1.1951 - val_accuracy: 0.8633\n",
      "Epoch 154/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6426 - accuracy: 0.8838 - val_loss: 1.1101 - val_accuracy: 0.8709\n",
      "Epoch 155/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.8833 - val_loss: 0.9906 - val_accuracy: 0.8936\n",
      "Epoch 156/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6413 - accuracy: 0.8856 - val_loss: 0.9960 - val_accuracy: 0.8911\n",
      "Epoch 157/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6329 - accuracy: 0.8859 - val_loss: 1.1342 - val_accuracy: 0.8844\n",
      "Epoch 158/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6606 - accuracy: 0.8828 - val_loss: 1.0230 - val_accuracy: 0.9024\n",
      "Epoch 159/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6333 - accuracy: 0.8862 - val_loss: 0.9804 - val_accuracy: 0.8829\n",
      "Epoch 160/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6338 - accuracy: 0.8863 - val_loss: 1.0150 - val_accuracy: 0.9060\n",
      "Epoch 161/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.8867 - val_loss: 1.0909 - val_accuracy: 0.8827\n",
      "Epoch 162/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6399 - accuracy: 0.8861 - val_loss: 1.0022 - val_accuracy: 0.8964\n",
      "Epoch 163/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6256 - accuracy: 0.8893 - val_loss: 1.0181 - val_accuracy: 0.9044\n",
      "Epoch 164/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6273 - accuracy: 0.8893 - val_loss: 1.0430 - val_accuracy: 0.9016\n",
      "Epoch 165/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6334 - accuracy: 0.8874 - val_loss: 1.2219 - val_accuracy: 0.8707\n",
      "Epoch 166/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6273 - accuracy: 0.8890 - val_loss: 1.1138 - val_accuracy: 0.8731\n",
      "Epoch 167/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6183 - accuracy: 0.8893 - val_loss: 1.1797 - val_accuracy: 0.8882\n",
      "Epoch 168/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6247 - accuracy: 0.8890 - val_loss: 1.1050 - val_accuracy: 0.8762\n",
      "Epoch 169/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6215 - accuracy: 0.8896 - val_loss: 1.1417 - val_accuracy: 0.8607\n",
      "Epoch 170/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6224 - accuracy: 0.8887 - val_loss: 1.0528 - val_accuracy: 0.9089\n",
      "Epoch 171/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6233 - accuracy: 0.8896 - val_loss: 1.1032 - val_accuracy: 0.8836\n",
      "Epoch 172/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6230 - accuracy: 0.8899 - val_loss: 1.1006 - val_accuracy: 0.8913\n",
      "Epoch 173/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6165 - accuracy: 0.8893 - val_loss: 1.1470 - val_accuracy: 0.8991\n",
      "Epoch 174/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6129 - accuracy: 0.8911 - val_loss: 1.1688 - val_accuracy: 0.9042\n",
      "Epoch 175/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6108 - accuracy: 0.8893 - val_loss: 1.1360 - val_accuracy: 0.8878\n",
      "Epoch 176/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6172 - accuracy: 0.8892 - val_loss: 1.0523 - val_accuracy: 0.8980\n",
      "Epoch 177/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6102 - accuracy: 0.8895 - val_loss: 1.1184 - val_accuracy: 0.8947\n",
      "Epoch 178/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6136 - accuracy: 0.8904 - val_loss: 1.0905 - val_accuracy: 0.9073\n",
      "Epoch 179/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6096 - accuracy: 0.8900 - val_loss: 1.1141 - val_accuracy: 0.8951\n",
      "Epoch 180/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6067 - accuracy: 0.8916 - val_loss: 1.1055 - val_accuracy: 0.8849\n",
      "Epoch 181/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6062 - accuracy: 0.8909 - val_loss: 1.0652 - val_accuracy: 0.8909\n",
      "Epoch 182/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6023 - accuracy: 0.8901 - val_loss: 1.1601 - val_accuracy: 0.8913\n",
      "Epoch 183/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6189 - accuracy: 0.8912 - val_loss: 1.2444 - val_accuracy: 0.8884\n",
      "Epoch 184/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.6003 - accuracy: 0.8924 - val_loss: 1.1638 - val_accuracy: 0.8842\n",
      "Epoch 185/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5982 - accuracy: 0.8929 - val_loss: 1.0910 - val_accuracy: 0.9036\n",
      "Epoch 186/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6062 - accuracy: 0.8895 - val_loss: 1.3823 - val_accuracy: 0.8393\n",
      "Epoch 187/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6026 - accuracy: 0.8908 - val_loss: 1.1897 - val_accuracy: 0.8827\n",
      "Epoch 188/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5910 - accuracy: 0.8941 - val_loss: 1.2070 - val_accuracy: 0.8767\n",
      "Epoch 189/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5997 - accuracy: 0.8916 - val_loss: 1.0958 - val_accuracy: 0.9029\n",
      "Epoch 190/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5971 - accuracy: 0.8906 - val_loss: 1.0758 - val_accuracy: 0.8847\n",
      "Epoch 191/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.6032 - accuracy: 0.8921 - val_loss: 1.0701 - val_accuracy: 0.8969\n",
      "Epoch 192/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5918 - accuracy: 0.8914 - val_loss: 1.2086 - val_accuracy: 0.8973\n",
      "Epoch 193/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5928 - accuracy: 0.8918 - val_loss: 1.1804 - val_accuracy: 0.8958\n",
      "Epoch 194/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5920 - accuracy: 0.8939 - val_loss: 1.0613 - val_accuracy: 0.9011\n",
      "Epoch 195/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5928 - accuracy: 0.8907 - val_loss: 1.2702 - val_accuracy: 0.8887\n",
      "Epoch 196/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5856 - accuracy: 0.8937 - val_loss: 1.1532 - val_accuracy: 0.8782\n",
      "Epoch 197/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5940 - accuracy: 0.8920 - val_loss: 1.0944 - val_accuracy: 0.9029\n",
      "Epoch 198/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5965 - accuracy: 0.8946 - val_loss: 1.0920 - val_accuracy: 0.8933\n",
      "Epoch 199/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5892 - accuracy: 0.8940 - val_loss: 1.0001 - val_accuracy: 0.9044\n",
      "Epoch 200/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5833 - accuracy: 0.8949 - val_loss: 1.1227 - val_accuracy: 0.8882\n",
      "Epoch 201/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5947 - accuracy: 0.8939 - val_loss: 1.1091 - val_accuracy: 0.9107\n",
      "Epoch 202/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5806 - accuracy: 0.8940 - val_loss: 1.1573 - val_accuracy: 0.8862\n",
      "Epoch 203/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5847 - accuracy: 0.8927 - val_loss: 1.0533 - val_accuracy: 0.8960\n",
      "Epoch 204/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5784 - accuracy: 0.8940 - val_loss: 1.0862 - val_accuracy: 0.8984\n",
      "Epoch 205/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5818 - accuracy: 0.8931 - val_loss: 1.1568 - val_accuracy: 0.8944\n",
      "Epoch 206/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5808 - accuracy: 0.8952 - val_loss: 1.1321 - val_accuracy: 0.8949\n",
      "Epoch 207/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.8963 - val_loss: 1.1104 - val_accuracy: 0.8804\n",
      "Epoch 208/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5639 - accuracy: 0.8965 - val_loss: 1.0983 - val_accuracy: 0.9071\n",
      "Epoch 209/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.8952 - val_loss: 1.0986 - val_accuracy: 0.9062\n",
      "Epoch 210/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5785 - accuracy: 0.8943 - val_loss: 1.1972 - val_accuracy: 0.8838\n",
      "Epoch 211/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5896 - accuracy: 0.8931 - val_loss: 1.2197 - val_accuracy: 0.9040\n",
      "Epoch 212/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.8971 - val_loss: 1.2578 - val_accuracy: 0.9133\n",
      "Epoch 213/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5727 - accuracy: 0.8961 - val_loss: 1.0565 - val_accuracy: 0.8940\n",
      "Epoch 214/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5662 - accuracy: 0.8964 - val_loss: 1.1852 - val_accuracy: 0.9053\n",
      "Epoch 215/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5623 - accuracy: 0.8962 - val_loss: 1.2685 - val_accuracy: 0.8913\n",
      "Epoch 216/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5648 - accuracy: 0.8967 - val_loss: 1.1767 - val_accuracy: 0.8951\n",
      "Epoch 217/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5634 - accuracy: 0.8981 - val_loss: 1.1387 - val_accuracy: 0.9089\n",
      "Epoch 218/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5661 - accuracy: 0.8958 - val_loss: 1.2237 - val_accuracy: 0.9236\n",
      "Epoch 219/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5804 - accuracy: 0.8962 - val_loss: 1.3287 - val_accuracy: 0.9069\n",
      "Epoch 220/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5631 - accuracy: 0.8972 - val_loss: 1.1405 - val_accuracy: 0.8858\n",
      "Epoch 221/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.8966 - val_loss: 1.2726 - val_accuracy: 0.8851\n",
      "Epoch 222/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5767 - accuracy: 0.8966 - val_loss: 1.2401 - val_accuracy: 0.8958\n",
      "Epoch 223/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5543 - accuracy: 0.8986 - val_loss: 1.2119 - val_accuracy: 0.8933\n",
      "Epoch 224/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5628 - accuracy: 0.8980 - val_loss: 1.2336 - val_accuracy: 0.8982\n",
      "Epoch 225/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5641 - accuracy: 0.8968 - val_loss: 0.9465 - val_accuracy: 0.9120\n",
      "Epoch 226/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5619 - accuracy: 0.8965 - val_loss: 1.1099 - val_accuracy: 0.8980\n",
      "Epoch 227/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5676 - accuracy: 0.8963 - val_loss: 1.0813 - val_accuracy: 0.8924\n",
      "Epoch 228/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5567 - accuracy: 0.8985 - val_loss: 1.0872 - val_accuracy: 0.8864\n",
      "Epoch 229/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5517 - accuracy: 0.8979 - val_loss: 1.2312 - val_accuracy: 0.8720\n",
      "Epoch 230/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5620 - accuracy: 0.8976 - val_loss: 1.1821 - val_accuracy: 0.8851\n",
      "Epoch 231/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5510 - accuracy: 0.8975 - val_loss: 1.1815 - val_accuracy: 0.9009\n",
      "Epoch 232/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5613 - accuracy: 0.8980 - val_loss: 1.1279 - val_accuracy: 0.9011\n",
      "Epoch 233/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5808 - accuracy: 0.8975 - val_loss: 1.2088 - val_accuracy: 0.8918\n",
      "Epoch 234/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5576 - accuracy: 0.8991 - val_loss: 1.2644 - val_accuracy: 0.9111\n",
      "Epoch 235/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5468 - accuracy: 0.8996 - val_loss: 1.2933 - val_accuracy: 0.8767\n",
      "Epoch 236/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5523 - accuracy: 0.8974 - val_loss: 1.2086 - val_accuracy: 0.9089\n",
      "Epoch 237/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.8998 - val_loss: 1.0302 - val_accuracy: 0.9129\n",
      "Epoch 238/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.9000 - val_loss: 1.3144 - val_accuracy: 0.9002\n",
      "Epoch 239/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.8988 - val_loss: 1.1097 - val_accuracy: 0.9100\n",
      "Epoch 240/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5525 - accuracy: 0.8981 - val_loss: 1.0679 - val_accuracy: 0.8991\n",
      "Epoch 241/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5454 - accuracy: 0.8984 - val_loss: 1.0337 - val_accuracy: 0.9013\n",
      "Epoch 242/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5506 - accuracy: 0.8988 - val_loss: 1.2479 - val_accuracy: 0.8862\n",
      "Epoch 243/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5521 - accuracy: 0.8978 - val_loss: 1.1250 - val_accuracy: 0.8856\n",
      "Epoch 244/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5421 - accuracy: 0.8997 - val_loss: 1.1618 - val_accuracy: 0.8922\n",
      "Epoch 245/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5503 - accuracy: 0.8998 - val_loss: 1.2291 - val_accuracy: 0.8896\n",
      "Epoch 246/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5529 - accuracy: 0.8989 - val_loss: 1.1668 - val_accuracy: 0.8964\n",
      "Epoch 247/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5439 - accuracy: 0.8989 - val_loss: 1.2219 - val_accuracy: 0.8953\n",
      "Epoch 248/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5445 - accuracy: 0.9001 - val_loss: 1.1598 - val_accuracy: 0.9078\n",
      "Epoch 249/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5331 - accuracy: 0.9025 - val_loss: 1.2365 - val_accuracy: 0.9089\n",
      "Epoch 250/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5387 - accuracy: 0.8999 - val_loss: 1.1154 - val_accuracy: 0.9018\n",
      "Epoch 251/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5296 - accuracy: 0.9015 - val_loss: 1.1175 - val_accuracy: 0.9084\n",
      "Epoch 252/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5549 - accuracy: 0.9000 - val_loss: 1.1437 - val_accuracy: 0.9084\n",
      "Epoch 253/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5406 - accuracy: 0.9012 - val_loss: 1.1442 - val_accuracy: 0.8907\n",
      "Epoch 254/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5385 - accuracy: 0.9008 - val_loss: 1.2893 - val_accuracy: 0.8949\n",
      "Epoch 255/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.9027 - val_loss: 1.0682 - val_accuracy: 0.9004\n",
      "Epoch 256/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.8988 - val_loss: 1.1384 - val_accuracy: 0.9033\n",
      "Epoch 257/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.9007 - val_loss: 1.2517 - val_accuracy: 0.8973\n",
      "Epoch 258/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.9009 - val_loss: 1.1402 - val_accuracy: 0.9004\n",
      "Epoch 259/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.9020 - val_loss: 1.4101 - val_accuracy: 0.8942\n",
      "Epoch 260/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5430 - accuracy: 0.8988 - val_loss: 1.3883 - val_accuracy: 0.8920\n",
      "Epoch 261/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5519 - accuracy: 0.9017 - val_loss: 1.4608 - val_accuracy: 0.8984\n",
      "Epoch 262/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5343 - accuracy: 0.9011 - val_loss: 1.3613 - val_accuracy: 0.8924\n",
      "Epoch 263/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5310 - accuracy: 0.9030 - val_loss: 1.3528 - val_accuracy: 0.8882\n",
      "Epoch 264/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5235 - accuracy: 0.9018 - val_loss: 1.2821 - val_accuracy: 0.9113\n",
      "Epoch 265/300\n",
      "1266/1266 [==============================] - 2s 1ms/step - loss: 0.5361 - accuracy: 0.9002 - val_loss: 1.3544 - val_accuracy: 0.8800\n",
      "Epoch 266/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5213 - accuracy: 0.9015 - val_loss: 1.2685 - val_accuracy: 0.8971\n",
      "Epoch 267/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5248 - accuracy: 0.9013 - val_loss: 1.0282 - val_accuracy: 0.8938\n",
      "Epoch 268/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.9025 - val_loss: 1.2942 - val_accuracy: 0.9084\n",
      "Epoch 269/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.9022 - val_loss: 1.2182 - val_accuracy: 0.8929\n",
      "Epoch 270/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.9027 - val_loss: 1.4371 - val_accuracy: 0.8813\n",
      "Epoch 271/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.9026 - val_loss: 1.2290 - val_accuracy: 0.9009\n",
      "Epoch 272/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5097 - accuracy: 0.9054 - val_loss: 1.2783 - val_accuracy: 0.8829\n",
      "Epoch 273/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.9015 - val_loss: 1.1011 - val_accuracy: 0.9080\n",
      "Epoch 274/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5260 - accuracy: 0.9017 - val_loss: 1.2800 - val_accuracy: 0.8924\n",
      "Epoch 275/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.9017 - val_loss: 1.2184 - val_accuracy: 0.9047\n",
      "Epoch 276/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5271 - accuracy: 0.9014 - val_loss: 1.0467 - val_accuracy: 0.9076\n",
      "Epoch 277/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5215 - accuracy: 0.9036 - val_loss: 1.3385 - val_accuracy: 0.8976\n",
      "Epoch 278/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.9040 - val_loss: 1.2976 - val_accuracy: 0.8896\n",
      "Epoch 279/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.9018 - val_loss: 1.3207 - val_accuracy: 0.9160\n",
      "Epoch 280/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5142 - accuracy: 0.9056 - val_loss: 1.1116 - val_accuracy: 0.9180\n",
      "Epoch 281/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5193 - accuracy: 0.9029 - val_loss: 1.2863 - val_accuracy: 0.9118\n",
      "Epoch 282/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5225 - accuracy: 0.9033 - val_loss: 1.2690 - val_accuracy: 0.9051\n",
      "Epoch 283/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5145 - accuracy: 0.9027 - val_loss: 1.2337 - val_accuracy: 0.9200\n",
      "Epoch 284/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5254 - accuracy: 0.9017 - val_loss: 1.2383 - val_accuracy: 0.9056\n",
      "Epoch 285/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5201 - accuracy: 0.9026 - val_loss: 1.3206 - val_accuracy: 0.9218\n",
      "Epoch 286/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5220 - accuracy: 0.9043 - val_loss: 1.2655 - val_accuracy: 0.9176\n",
      "Epoch 287/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5240 - accuracy: 0.9021 - val_loss: 1.6192 - val_accuracy: 0.8782\n",
      "Epoch 288/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5220 - accuracy: 0.9032 - val_loss: 1.4192 - val_accuracy: 0.9071\n",
      "Epoch 289/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5173 - accuracy: 0.9042 - val_loss: 1.2708 - val_accuracy: 0.9216\n",
      "Epoch 290/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5162 - accuracy: 0.9059 - val_loss: 1.2317 - val_accuracy: 0.8989\n",
      "Epoch 291/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5255 - accuracy: 0.9036 - val_loss: 1.3828 - val_accuracy: 0.8907\n",
      "Epoch 292/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5218 - accuracy: 0.9035 - val_loss: 1.2000 - val_accuracy: 0.8936\n",
      "Epoch 293/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5092 - accuracy: 0.9047 - val_loss: 1.1791 - val_accuracy: 0.9000\n",
      "Epoch 294/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5108 - accuracy: 0.9049 - val_loss: 1.1865 - val_accuracy: 0.8836\n",
      "Epoch 295/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5124 - accuracy: 0.9052 - val_loss: 1.0923 - val_accuracy: 0.9067\n",
      "Epoch 296/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5131 - accuracy: 0.9049 - val_loss: 1.1585 - val_accuracy: 0.8953\n",
      "Epoch 297/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5006 - accuracy: 0.9065 - val_loss: 1.2150 - val_accuracy: 0.8904\n",
      "Epoch 298/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5240 - accuracy: 0.9006 - val_loss: 1.1328 - val_accuracy: 0.9098\n",
      "Epoch 299/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5147 - accuracy: 0.9043 - val_loss: 1.1707 - val_accuracy: 0.8911\n",
      "Epoch 300/300\n",
      "1266/1266 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.9024 - val_loss: 1.1632 - val_accuracy: 0.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_18_layer_call_fn, leaky_re_lu_18_layer_call_and_return_conditional_losses, leaky_re_lu_19_layer_call_fn, leaky_re_lu_19_layer_call_and_return_conditional_losses, leaky_re_lu_20_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 47s\n",
      "Wall time: 9min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/sig_class_test'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(655)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(225, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy']) #.0001\n",
    "    history = model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0092a047-87e7-4d41-92fe-442c1d497ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv('output/history_mlp_class_sig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "804d5dca-da51-4c35-b5fd-3f6bf937b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdc413ec-1d01-4036-8bab-e4309224cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 933us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3c63e-297b-428d-8528-da0aa58098c8",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "345b8adc-5738-4839-82eb-69a6a1eb0741",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       1.00      0.85      0.92        20\n",
      "           2       0.76      1.00      0.86        19\n",
      "           3       0.92      1.00      0.96        23\n",
      "           4       1.00      0.81      0.89        26\n",
      "           5       1.00      0.89      0.94        18\n",
      "           6       1.00      0.92      0.96        24\n",
      "           7       1.00      0.96      0.98        25\n",
      "           8       1.00      1.00      1.00        17\n",
      "           9       1.00      0.85      0.92        26\n",
      "          10       1.00      1.00      1.00        25\n",
      "          11       1.00      0.86      0.92        21\n",
      "          12       0.92      0.96      0.94        23\n",
      "          13       1.00      0.91      0.95        22\n",
      "          14       1.00      0.96      0.98        23\n",
      "          15       1.00      0.94      0.97        18\n",
      "          16       0.94      0.94      0.94        16\n",
      "          17       0.83      1.00      0.91        15\n",
      "          18       1.00      0.94      0.97        18\n",
      "          19       1.00      0.96      0.98        23\n",
      "          20       1.00      0.89      0.94        19\n",
      "          21       1.00      0.90      0.95        21\n",
      "          22       1.00      0.95      0.98        21\n",
      "          23       1.00      0.83      0.91        24\n",
      "          24       1.00      0.81      0.89        21\n",
      "          25       0.94      1.00      0.97        15\n",
      "          26       1.00      1.00      1.00        25\n",
      "          27       1.00      0.83      0.91        18\n",
      "          28       1.00      1.00      1.00        18\n",
      "          29       1.00      0.84      0.91        19\n",
      "          30       1.00      0.91      0.95        22\n",
      "          31       1.00      0.94      0.97        18\n",
      "          32       1.00      0.81      0.90        16\n",
      "          33       1.00      0.90      0.95        20\n",
      "          34       1.00      0.82      0.90        17\n",
      "          35       1.00      0.96      0.98        25\n",
      "          36       1.00      0.77      0.87        13\n",
      "          37       1.00      0.81      0.89        21\n",
      "          38       1.00      0.90      0.95        21\n",
      "          39       1.00      0.79      0.88        19\n",
      "          40       1.00      0.89      0.94        18\n",
      "          41       1.00      0.93      0.96        27\n",
      "          42       0.95      0.86      0.90        21\n",
      "          43       1.00      0.93      0.96        14\n",
      "          44       1.00      0.89      0.94        18\n",
      "          45       0.68      0.90      0.78        21\n",
      "          46       0.89      0.89      0.89         9\n",
      "          47       1.00      0.93      0.96        14\n",
      "          48       1.00      1.00      1.00        19\n",
      "          49       1.00      0.92      0.96        13\n",
      "          50       1.00      0.96      0.98        27\n",
      "          51       1.00      0.88      0.93        24\n",
      "          52       1.00      0.44      0.62        18\n",
      "          53       1.00      0.95      0.98        22\n",
      "          54       1.00      0.91      0.95        23\n",
      "          55       1.00      1.00      1.00        19\n",
      "          56       1.00      1.00      1.00        19\n",
      "          57       0.95      0.95      0.95        21\n",
      "          58       1.00      0.86      0.92        21\n",
      "          59       0.92      0.88      0.90        26\n",
      "          60       1.00      1.00      1.00        21\n",
      "          61       0.96      0.96      0.96        25\n",
      "          62       1.00      0.95      0.97        19\n",
      "          63       1.00      1.00      1.00        23\n",
      "          64       1.00      0.89      0.94        19\n",
      "          65       1.00      0.86      0.93        22\n",
      "          66       1.00      0.83      0.91        18\n",
      "          67       1.00      0.95      0.97        19\n",
      "          68       1.00      0.83      0.90        23\n",
      "          69       1.00      0.95      0.98        21\n",
      "          70       1.00      1.00      1.00        12\n",
      "          71       1.00      0.83      0.90        23\n",
      "          72       1.00      0.83      0.91        18\n",
      "          73       1.00      0.81      0.90        16\n",
      "          74       0.90      0.95      0.93        20\n",
      "          75       1.00      0.85      0.92        20\n",
      "          76       0.81      0.96      0.88        23\n",
      "          77       0.78      0.86      0.82        21\n",
      "          78       0.82      0.95      0.88        19\n",
      "          79       1.00      0.94      0.97        31\n",
      "          80       1.00      0.83      0.91        30\n",
      "          81       1.00      0.92      0.96        13\n",
      "          82       1.00      0.92      0.96        13\n",
      "          83       1.00      1.00      1.00        25\n",
      "          84       1.00      1.00      1.00        22\n",
      "          85       1.00      0.84      0.91        19\n",
      "          86       1.00      0.94      0.97        16\n",
      "          87       0.06      1.00      0.12        17\n",
      "          88       1.00      0.89      0.94        18\n",
      "          89       0.96      0.85      0.90        26\n",
      "          90       1.00      0.88      0.93        16\n",
      "          91       1.00      0.90      0.95        20\n",
      "          92       1.00      0.95      0.98        21\n",
      "          93       0.71      0.83      0.77        12\n",
      "          94       1.00      0.81      0.89        21\n",
      "          95       1.00      0.75      0.86        16\n",
      "          96       1.00      1.00      1.00        21\n",
      "          97       1.00      0.88      0.94        26\n",
      "          98       1.00      0.80      0.89        25\n",
      "          99       0.60      0.94      0.73        16\n",
      "         100       0.94      0.76      0.84        21\n",
      "         101       1.00      0.92      0.96        24\n",
      "         102       1.00      1.00      1.00        20\n",
      "         103       0.65      1.00      0.79        15\n",
      "         104       1.00      0.93      0.97        15\n",
      "         105       1.00      0.73      0.85        15\n",
      "         106       1.00      0.87      0.93        23\n",
      "         107       1.00      0.70      0.82        20\n",
      "         108       0.95      0.84      0.89        25\n",
      "         109       0.92      0.92      0.92        26\n",
      "         110       1.00      0.57      0.72        23\n",
      "         111       0.71      1.00      0.83        22\n",
      "         112       0.94      0.89      0.91        18\n",
      "         113       0.96      0.81      0.88        27\n",
      "         114       0.48      1.00      0.65        15\n",
      "         115       1.00      0.94      0.97        17\n",
      "         116       1.00      0.91      0.95        23\n",
      "         117       1.00      0.95      0.97        19\n",
      "         118       0.94      0.79      0.86        19\n",
      "         119       1.00      0.78      0.88        18\n",
      "         120       1.00      0.78      0.88        23\n",
      "         121       0.94      0.88      0.91        17\n",
      "         122       0.95      1.00      0.97        19\n",
      "         123       1.00      0.83      0.91        18\n",
      "         124       1.00      0.83      0.91        24\n",
      "         125       1.00      0.80      0.89        20\n",
      "         126       1.00      0.88      0.93        16\n",
      "         127       0.86      0.83      0.84        23\n",
      "         128       1.00      0.88      0.93        16\n",
      "         129       1.00      1.00      1.00        12\n",
      "         130       0.95      1.00      0.98        20\n",
      "         131       1.00      0.79      0.88        24\n",
      "         132       1.00      0.90      0.95        21\n",
      "         133       1.00      0.71      0.83        14\n",
      "         134       1.00      1.00      1.00        15\n",
      "         135       1.00      0.95      0.97        20\n",
      "         136       0.96      0.96      0.96        26\n",
      "         137       1.00      1.00      1.00        14\n",
      "         138       1.00      0.67      0.80        21\n",
      "         139       0.87      1.00      0.93        20\n",
      "         140       1.00      1.00      1.00        23\n",
      "         141       1.00      0.95      0.98        21\n",
      "         142       1.00      0.94      0.97        17\n",
      "         143       0.92      0.86      0.89        14\n",
      "         144       0.82      1.00      0.90        23\n",
      "         145       0.72      1.00      0.84        13\n",
      "         146       0.85      0.81      0.83        27\n",
      "         147       1.00      0.71      0.83        28\n",
      "         148       1.00      0.87      0.93        23\n",
      "         149       1.00      0.91      0.95        23\n",
      "         150       1.00      0.81      0.89        26\n",
      "         151       0.95      0.90      0.93        21\n",
      "         152       0.78      1.00      0.88        25\n",
      "         153       1.00      0.84      0.91        19\n",
      "         154       1.00      0.95      0.98        22\n",
      "         155       0.89      1.00      0.94        16\n",
      "         156       0.88      0.96      0.92        23\n",
      "         157       0.89      0.94      0.91        17\n",
      "         158       0.95      0.86      0.90        22\n",
      "         159       0.95      0.90      0.92        20\n",
      "         160       1.00      0.95      0.98        22\n",
      "         161       1.00      0.96      0.98        23\n",
      "         162       1.00      0.86      0.92        14\n",
      "         163       1.00      1.00      1.00        23\n",
      "         164       1.00      1.00      1.00        18\n",
      "         165       1.00      0.97      0.98        30\n",
      "         166       0.83      1.00      0.90        19\n",
      "         167       1.00      0.75      0.86        24\n",
      "         168       1.00      0.85      0.92        13\n",
      "         169       1.00      0.87      0.93        15\n",
      "         170       1.00      0.81      0.89        26\n",
      "         171       0.90      0.95      0.93        20\n",
      "         172       1.00      0.91      0.95        22\n",
      "         173       0.79      0.85      0.81        13\n",
      "         174       0.81      0.85      0.83        20\n",
      "         175       1.00      0.83      0.90        23\n",
      "         176       1.00      0.89      0.94        19\n",
      "         177       0.82      1.00      0.90        18\n",
      "         178       1.00      0.94      0.97        16\n",
      "         179       0.95      0.88      0.91        24\n",
      "         180       1.00      0.91      0.95        22\n",
      "         181       1.00      0.91      0.95        11\n",
      "         182       1.00      0.87      0.93        15\n",
      "         183       0.89      1.00      0.94        25\n",
      "         184       0.70      0.82      0.76        17\n",
      "         185       0.70      0.84      0.76        19\n",
      "         186       1.00      0.89      0.94        27\n",
      "         187       1.00      0.95      0.97        20\n",
      "         188       1.00      0.88      0.94        26\n",
      "         189       0.88      0.97      0.92        30\n",
      "         190       1.00      0.78      0.88        18\n",
      "         191       1.00      0.95      0.97        19\n",
      "         192       1.00      0.86      0.92        14\n",
      "         193       0.86      0.95      0.90        20\n",
      "         194       0.95      0.83      0.88        23\n",
      "         195       0.95      0.91      0.93        23\n",
      "         196       1.00      0.82      0.90        22\n",
      "         197       1.00      0.87      0.93        15\n",
      "         198       1.00      0.80      0.89        20\n",
      "         199       1.00      0.85      0.92        20\n",
      "         200       1.00      0.95      0.97        19\n",
      "         201       0.96      0.96      0.96        23\n",
      "         202       1.00      0.88      0.94        17\n",
      "         203       1.00      0.74      0.85        27\n",
      "         204       1.00      0.71      0.83        14\n",
      "         205       0.76      0.94      0.84        17\n",
      "         206       0.90      0.69      0.78        13\n",
      "         207       0.90      0.86      0.88        22\n",
      "         208       0.94      0.81      0.87        21\n",
      "         209       1.00      0.93      0.97        15\n",
      "         210       1.00      0.91      0.95        22\n",
      "         211       1.00      1.00      1.00        25\n",
      "         212       1.00      0.94      0.97        18\n",
      "         213       1.00      0.83      0.91        12\n",
      "         214       1.00      0.89      0.94        19\n",
      "         215       1.00      0.88      0.93        24\n",
      "         216       1.00      0.88      0.94        17\n",
      "         217       1.00      1.00      1.00        22\n",
      "         218       1.00      0.90      0.95        20\n",
      "         219       0.94      0.88      0.91        17\n",
      "         220       0.93      1.00      0.96        13\n",
      "         221       1.00      1.00      1.00        21\n",
      "         222       0.60      0.92      0.73        13\n",
      "         223       1.00      0.90      0.95        21\n",
      "         224       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.90      4500\n",
      "   macro avg       0.96      0.90      0.92      4500\n",
      "weighted avg       0.96      0.90      0.92      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3faff65-54f8-47d3-9a49-d28c736efb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
