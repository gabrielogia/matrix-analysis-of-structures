{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f78aa7-15d8-4c44-8e24-810219393815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994720bf-b54a-4fb0-ae3c-eea3a5b39e24",
   "metadata": {},
   "source": [
    "<h1>Linear Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d4a403-460f-41ed-85f5-1942215d93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/results_complete_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0935dd9-210a-474b-9a82-aa077ca287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['elem_damaged', 'damage'], axis=1), df['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af628b4-0f5f-4722-bd9a-86c4e372bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab4ae95-f2fc-436c-acac-8ff44a1e1bc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 560 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/linear_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9be2663-ca79-46a7-bbbb-460f09cce5e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091fb9e5-5ea4-48ad-8868-5b2420ad7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037eccb-a72f-4f5b-ae4c-05c283ae69dd",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1c79d0-88fb-41e0-bdb7-0ec576ce2dbb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.91304   1.00000   0.95455        21\n",
      "           1    1.00000   1.00000   1.00000        18\n",
      "           2    1.00000   0.95652   0.97778        23\n",
      "           3    1.00000   1.00000   1.00000        20\n",
      "           4    1.00000   1.00000   1.00000        23\n",
      "           5    0.88889   0.80000   0.84211        20\n",
      "           6    1.00000   0.95652   0.97778        23\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        25\n",
      "           9    1.00000   1.00000   1.00000        13\n",
      "          10    1.00000   0.73913   0.85000        23\n",
      "          11    1.00000   0.94118   0.96970        17\n",
      "          12    1.00000   0.93750   0.96774        16\n",
      "          13    1.00000   1.00000   1.00000        31\n",
      "          14    1.00000   1.00000   1.00000        30\n",
      "          15    1.00000   1.00000   1.00000        19\n",
      "          16    1.00000   1.00000   1.00000        25\n",
      "          17    1.00000   1.00000   1.00000        17\n",
      "          18    0.94737   0.90000   0.92308        20\n",
      "          19    1.00000   1.00000   1.00000        16\n",
      "          20    0.95000   1.00000   0.97436        19\n",
      "          21    1.00000   1.00000   1.00000        21\n",
      "          22    1.00000   0.94444   0.97143        18\n",
      "          23    1.00000   1.00000   1.00000        14\n",
      "          24    1.00000   0.95238   0.97561        21\n",
      "          25    1.00000   0.95238   0.97561        21\n",
      "          26    0.92857   1.00000   0.96296        13\n",
      "          27    1.00000   1.00000   1.00000        25\n",
      "          28    1.00000   1.00000   1.00000        27\n",
      "          29    1.00000   1.00000   1.00000        24\n",
      "          30    1.00000   1.00000   1.00000        21\n",
      "          31    1.00000   0.95238   0.97561        21\n",
      "          32    1.00000   1.00000   1.00000        18\n",
      "          33    1.00000   1.00000   1.00000        22\n",
      "          34    1.00000   0.88889   0.94118        18\n",
      "          35    1.00000   1.00000   1.00000        10\n",
      "          36    1.00000   1.00000   1.00000        27\n",
      "          37    0.93333   0.66667   0.77778        21\n",
      "          38    1.00000   1.00000   1.00000        20\n",
      "          39    1.00000   1.00000   1.00000        15\n",
      "          40    1.00000   0.94737   0.97297        19\n",
      "          41    0.92308   1.00000   0.96000        12\n",
      "          42    1.00000   1.00000   1.00000        30\n",
      "          43    0.54762   0.92000   0.68657        25\n",
      "          44    1.00000   0.95455   0.97674        22\n",
      "          45    1.00000   1.00000   1.00000        23\n",
      "          46    1.00000   1.00000   1.00000        14\n",
      "          47    1.00000   1.00000   1.00000        17\n",
      "          48    1.00000   1.00000   1.00000        20\n",
      "          49    1.00000   0.95238   0.97561        21\n",
      "          50    1.00000   1.00000   1.00000        25\n",
      "          51    1.00000   1.00000   1.00000        22\n",
      "          52    0.84211   0.88889   0.86486        18\n",
      "          53    0.96154   1.00000   0.98039        25\n",
      "          54    1.00000   1.00000   1.00000        22\n",
      "          55    1.00000   1.00000   1.00000        13\n",
      "          56    1.00000   1.00000   1.00000        21\n",
      "          57    1.00000   1.00000   1.00000        28\n",
      "          58    1.00000   1.00000   1.00000        14\n",
      "          59    1.00000   1.00000   1.00000        26\n",
      "          60    1.00000   1.00000   1.00000        17\n",
      "          61    1.00000   1.00000   1.00000        16\n",
      "          62    1.00000   1.00000   1.00000        17\n",
      "          63    1.00000   1.00000   1.00000        25\n",
      "          64    1.00000   1.00000   1.00000        13\n",
      "          65    1.00000   1.00000   1.00000        17\n",
      "          66    1.00000   1.00000   1.00000        20\n",
      "          67    1.00000   1.00000   1.00000        12\n",
      "          68    1.00000   1.00000   1.00000        21\n",
      "          69    1.00000   1.00000   1.00000        18\n",
      "          70    1.00000   1.00000   1.00000        14\n",
      "          71    1.00000   1.00000   1.00000        19\n",
      "          72    1.00000   1.00000   1.00000        11\n",
      "          73    1.00000   1.00000   1.00000        20\n",
      "          74    1.00000   1.00000   1.00000        23\n",
      "          75    1.00000   0.96296   0.98113        27\n",
      "          76    1.00000   1.00000   1.00000        23\n",
      "          77    0.72414   1.00000   0.84000        21\n",
      "          78    1.00000   0.85000   0.91892        20\n",
      "          79    1.00000   1.00000   1.00000        24\n",
      "          80    1.00000   0.94737   0.97297        19\n",
      "          81    1.00000   1.00000   1.00000        14\n",
      "          82    1.00000   1.00000   1.00000        20\n",
      "          83    0.94737   0.90000   0.92308        20\n",
      "          84    1.00000   0.95652   0.97778        23\n",
      "          85    1.00000   1.00000   1.00000        23\n",
      "          86    1.00000   1.00000   1.00000        19\n",
      "          87    0.95238   1.00000   0.97561        20\n",
      "          88    1.00000   1.00000   1.00000        19\n",
      "          89    1.00000   1.00000   1.00000        20\n",
      "          90    1.00000   0.95455   0.97674        22\n",
      "          91    1.00000   1.00000   1.00000        19\n",
      "          92    1.00000   1.00000   1.00000        12\n",
      "          93    1.00000   1.00000   1.00000        19\n",
      "          94    0.89286   1.00000   0.94340        25\n",
      "          95    1.00000   1.00000   1.00000        17\n",
      "          96    1.00000   0.96429   0.98182        28\n",
      "          97    1.00000   0.94737   0.97297        19\n",
      "          98    1.00000   1.00000   1.00000        21\n",
      "          99    1.00000   0.91667   0.95652        24\n",
      "         100    1.00000   1.00000   1.00000        15\n",
      "         101    1.00000   0.94118   0.96970        17\n",
      "         102    0.96154   1.00000   0.98039        25\n",
      "         103    1.00000   1.00000   1.00000        21\n",
      "         104    0.93750   0.93750   0.93750        16\n",
      "         105    1.00000   0.93333   0.96552        15\n",
      "         106    1.00000   1.00000   1.00000        15\n",
      "         107    1.00000   1.00000   1.00000        18\n",
      "         108    1.00000   0.81818   0.90000        22\n",
      "         109    1.00000   1.00000   1.00000        23\n",
      "         110    1.00000   1.00000   1.00000        28\n",
      "         111    0.95833   0.95833   0.95833        24\n",
      "         112    0.93750   0.88235   0.90909        17\n",
      "         113    1.00000   0.89474   0.94444        19\n",
      "         114    1.00000   1.00000   1.00000        14\n",
      "         115    1.00000   0.94737   0.97297        19\n",
      "         116    1.00000   1.00000   1.00000        17\n",
      "         117    1.00000   1.00000   1.00000        11\n",
      "         118    0.51515   1.00000   0.68000        17\n",
      "         119    1.00000   1.00000   1.00000        25\n",
      "         120    1.00000   1.00000   1.00000        22\n",
      "         121    1.00000   0.92857   0.96296        28\n",
      "         122    1.00000   1.00000   1.00000        14\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    1.00000   1.00000   1.00000        16\n",
      "         126    1.00000   1.00000   1.00000        17\n",
      "         127    1.00000   0.95455   0.97674        22\n",
      "         128    1.00000   1.00000   1.00000        22\n",
      "\n",
      "    accuracy                        0.97481      2580\n",
      "   macro avg    0.98188   0.97556   0.97684      2580\n",
      "weighted avg    0.98172   0.97481   0.97634      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51af58-9ede-46e3-99ed-0164c6834c82",
   "metadata": {},
   "source": [
    "<h1>Exponential Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda86b57-083d-4b8a-879c-09a51d46aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.read_csv('input/results_complete_exponential.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eff74c0-769f-4685-9a72-f69724210c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_exp.drop(['elem_damaged', 'damage'], axis=1), df_exp['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815cc01f-7962-4f05-b49d-1de62fd5eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45c553a7-f94f-43df-9032-385155de8e94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 80)                10160     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 129)               10449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,569\n",
      "Trainable params: 33,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 4.6004 - accuracy: 0.0757 - val_loss: 4.2247 - val_accuracy: 0.1372\n",
      "Epoch 2/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.7676 - accuracy: 0.2136 - val_loss: 3.4905 - val_accuracy: 0.2484\n",
      "Epoch 3/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.1169 - accuracy: 0.3081 - val_loss: 2.9522 - val_accuracy: 0.3302\n",
      "Epoch 4/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.6675 - accuracy: 0.3832 - val_loss: 2.5705 - val_accuracy: 0.4074\n",
      "Epoch 5/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3591 - accuracy: 0.4405 - val_loss: 2.3077 - val_accuracy: 0.4585\n",
      "Epoch 6/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1492 - accuracy: 0.4888 - val_loss: 2.1348 - val_accuracy: 0.4899\n",
      "Epoch 7/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9970 - accuracy: 0.5227 - val_loss: 2.0067 - val_accuracy: 0.5291\n",
      "Epoch 8/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8772 - accuracy: 0.5507 - val_loss: 1.9003 - val_accuracy: 0.5360\n",
      "Epoch 9/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7771 - accuracy: 0.5771 - val_loss: 1.8064 - val_accuracy: 0.5647\n",
      "Epoch 10/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6907 - accuracy: 0.6002 - val_loss: 1.7219 - val_accuracy: 0.6078\n",
      "Epoch 11/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6142 - accuracy: 0.6167 - val_loss: 1.6501 - val_accuracy: 0.6209\n",
      "Epoch 12/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5528 - accuracy: 0.6322 - val_loss: 1.6030 - val_accuracy: 0.6225\n",
      "Epoch 13/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4999 - accuracy: 0.6447 - val_loss: 1.5535 - val_accuracy: 0.6477\n",
      "Epoch 14/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4506 - accuracy: 0.6618 - val_loss: 1.5048 - val_accuracy: 0.6484\n",
      "Epoch 15/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4069 - accuracy: 0.6716 - val_loss: 1.4639 - val_accuracy: 0.6477\n",
      "Epoch 16/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3651 - accuracy: 0.6799 - val_loss: 1.4237 - val_accuracy: 0.6806\n",
      "Epoch 17/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3261 - accuracy: 0.6888 - val_loss: 1.3927 - val_accuracy: 0.6841\n",
      "Epoch 18/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2919 - accuracy: 0.6992 - val_loss: 1.3577 - val_accuracy: 0.6895\n",
      "Epoch 19/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2589 - accuracy: 0.7074 - val_loss: 1.3209 - val_accuracy: 0.6953\n",
      "Epoch 20/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2240 - accuracy: 0.7136 - val_loss: 1.3425 - val_accuracy: 0.6791\n",
      "Epoch 21/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2004 - accuracy: 0.7206 - val_loss: 1.2779 - val_accuracy: 0.6981\n",
      "Epoch 22/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1740 - accuracy: 0.7239 - val_loss: 1.2583 - val_accuracy: 0.7163\n",
      "Epoch 23/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1477 - accuracy: 0.7350 - val_loss: 1.2410 - val_accuracy: 0.7116\n",
      "Epoch 24/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1252 - accuracy: 0.7364 - val_loss: 1.2207 - val_accuracy: 0.7163\n",
      "Epoch 25/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1032 - accuracy: 0.7413 - val_loss: 1.1983 - val_accuracy: 0.7291\n",
      "Epoch 26/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0798 - accuracy: 0.7472 - val_loss: 1.1956 - val_accuracy: 0.7116\n",
      "Epoch 27/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0636 - accuracy: 0.7519 - val_loss: 1.1418 - val_accuracy: 0.7167\n",
      "Epoch 28/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0391 - accuracy: 0.7612 - val_loss: 1.1345 - val_accuracy: 0.7360\n",
      "Epoch 29/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0210 - accuracy: 0.7627 - val_loss: 1.1121 - val_accuracy: 0.7407\n",
      "Epoch 30/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0073 - accuracy: 0.7653 - val_loss: 1.1027 - val_accuracy: 0.7550\n",
      "Epoch 31/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9887 - accuracy: 0.7703 - val_loss: 1.0851 - val_accuracy: 0.7589\n",
      "Epoch 32/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9756 - accuracy: 0.7738 - val_loss: 1.0806 - val_accuracy: 0.7492\n",
      "Epoch 33/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9595 - accuracy: 0.7783 - val_loss: 1.0705 - val_accuracy: 0.7496\n",
      "Epoch 34/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9463 - accuracy: 0.7768 - val_loss: 1.0368 - val_accuracy: 0.7632\n",
      "Epoch 35/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9299 - accuracy: 0.7851 - val_loss: 1.0180 - val_accuracy: 0.7709\n",
      "Epoch 36/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9153 - accuracy: 0.7870 - val_loss: 1.0086 - val_accuracy: 0.7806\n",
      "Epoch 37/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8999 - accuracy: 0.7892 - val_loss: 1.0025 - val_accuracy: 0.7636\n",
      "Epoch 38/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8853 - accuracy: 0.7920 - val_loss: 0.9856 - val_accuracy: 0.7667\n",
      "Epoch 39/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8707 - accuracy: 0.7934 - val_loss: 0.9810 - val_accuracy: 0.7740\n",
      "Epoch 40/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8570 - accuracy: 0.7995 - val_loss: 0.9686 - val_accuracy: 0.7752\n",
      "Epoch 41/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8431 - accuracy: 0.8016 - val_loss: 0.9473 - val_accuracy: 0.7953\n",
      "Epoch 42/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8310 - accuracy: 0.8037 - val_loss: 0.9452 - val_accuracy: 0.7806\n",
      "Epoch 43/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8230 - accuracy: 0.8071 - val_loss: 0.9357 - val_accuracy: 0.7973\n",
      "Epoch 44/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8054 - accuracy: 0.8134 - val_loss: 0.9089 - val_accuracy: 0.7926\n",
      "Epoch 45/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7959 - accuracy: 0.8108 - val_loss: 0.9214 - val_accuracy: 0.7767\n",
      "Epoch 46/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7857 - accuracy: 0.8133 - val_loss: 0.9136 - val_accuracy: 0.8023\n",
      "Epoch 47/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7748 - accuracy: 0.8170 - val_loss: 0.9021 - val_accuracy: 0.7996\n",
      "Epoch 48/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7720 - accuracy: 0.8163 - val_loss: 0.8698 - val_accuracy: 0.8078\n",
      "Epoch 49/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7553 - accuracy: 0.8230 - val_loss: 0.8716 - val_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7489 - accuracy: 0.8233 - val_loss: 0.8909 - val_accuracy: 0.8047\n",
      "Epoch 51/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7410 - accuracy: 0.8264 - val_loss: 0.8695 - val_accuracy: 0.8054\n",
      "Epoch 52/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7335 - accuracy: 0.8267 - val_loss: 0.8528 - val_accuracy: 0.8136\n",
      "Epoch 53/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7248 - accuracy: 0.8278 - val_loss: 0.8457 - val_accuracy: 0.8132\n",
      "Epoch 54/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7176 - accuracy: 0.8289 - val_loss: 0.8411 - val_accuracy: 0.8155\n",
      "Epoch 55/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7088 - accuracy: 0.8329 - val_loss: 0.8391 - val_accuracy: 0.8302\n",
      "Epoch 56/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7018 - accuracy: 0.8300 - val_loss: 0.8450 - val_accuracy: 0.8039\n",
      "Epoch 57/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6925 - accuracy: 0.8332 - val_loss: 0.8074 - val_accuracy: 0.8248\n",
      "Epoch 58/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6830 - accuracy: 0.8373 - val_loss: 0.8095 - val_accuracy: 0.8116\n",
      "Epoch 59/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.8375 - val_loss: 0.7940 - val_accuracy: 0.8205\n",
      "Epoch 60/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6683 - accuracy: 0.8408 - val_loss: 0.7984 - val_accuracy: 0.8182\n",
      "Epoch 61/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6604 - accuracy: 0.8408 - val_loss: 0.7853 - val_accuracy: 0.8171\n",
      "Epoch 62/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6515 - accuracy: 0.8433 - val_loss: 0.7659 - val_accuracy: 0.8399\n",
      "Epoch 63/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6479 - accuracy: 0.8456 - val_loss: 0.7715 - val_accuracy: 0.8349\n",
      "Epoch 64/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.8479 - val_loss: 0.7665 - val_accuracy: 0.8326\n",
      "Epoch 65/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.8495 - val_loss: 0.7716 - val_accuracy: 0.8384\n",
      "Epoch 66/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.8497 - val_loss: 0.7733 - val_accuracy: 0.8384\n",
      "Epoch 67/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6207 - accuracy: 0.8494 - val_loss: 0.7365 - val_accuracy: 0.8349\n",
      "Epoch 68/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.8543 - val_loss: 0.7575 - val_accuracy: 0.8357\n",
      "Epoch 69/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6100 - accuracy: 0.8558 - val_loss: 0.7509 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.8603 - val_loss: 0.7380 - val_accuracy: 0.8419\n",
      "Epoch 71/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5945 - accuracy: 0.8608 - val_loss: 0.7416 - val_accuracy: 0.8395\n",
      "Epoch 72/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5913 - accuracy: 0.8588 - val_loss: 0.7322 - val_accuracy: 0.8523\n",
      "Epoch 73/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5857 - accuracy: 0.8592 - val_loss: 0.7344 - val_accuracy: 0.8453\n",
      "Epoch 74/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5801 - accuracy: 0.8619 - val_loss: 0.6644 - val_accuracy: 0.8488\n",
      "Epoch 75/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5759 - accuracy: 0.8619 - val_loss: 0.6690 - val_accuracy: 0.8601\n",
      "Epoch 76/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.8634 - val_loss: 0.6725 - val_accuracy: 0.8574\n",
      "Epoch 77/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5637 - accuracy: 0.8686 - val_loss: 0.6718 - val_accuracy: 0.8512\n",
      "Epoch 78/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5599 - accuracy: 0.8681 - val_loss: 0.6800 - val_accuracy: 0.8477\n",
      "Epoch 79/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5527 - accuracy: 0.8697 - val_loss: 0.6716 - val_accuracy: 0.8450\n",
      "Epoch 80/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.8690 - val_loss: 0.6646 - val_accuracy: 0.8550\n",
      "Epoch 81/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.8739 - val_loss: 0.6532 - val_accuracy: 0.8543\n",
      "Epoch 82/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.8742 - val_loss: 0.6535 - val_accuracy: 0.8643\n",
      "Epoch 83/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.8752 - val_loss: 0.6606 - val_accuracy: 0.8574\n",
      "Epoch 84/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.8755 - val_loss: 0.6397 - val_accuracy: 0.8531\n",
      "Epoch 85/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.8788 - val_loss: 0.6325 - val_accuracy: 0.8632\n",
      "Epoch 86/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5231 - accuracy: 0.8761 - val_loss: 0.6494 - val_accuracy: 0.8562\n",
      "Epoch 87/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5177 - accuracy: 0.8764 - val_loss: 0.6282 - val_accuracy: 0.8702\n",
      "Epoch 88/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5130 - accuracy: 0.8813 - val_loss: 0.6303 - val_accuracy: 0.8682\n",
      "Epoch 89/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5085 - accuracy: 0.8807 - val_loss: 0.6289 - val_accuracy: 0.8620\n",
      "Epoch 90/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.5037 - accuracy: 0.8835 - val_loss: 0.6322 - val_accuracy: 0.8593\n",
      "Epoch 91/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.8835 - val_loss: 0.6196 - val_accuracy: 0.8744\n",
      "Epoch 92/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4939 - accuracy: 0.8845 - val_loss: 0.6149 - val_accuracy: 0.8857\n",
      "Epoch 93/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4899 - accuracy: 0.8864 - val_loss: 0.6180 - val_accuracy: 0.8744\n",
      "Epoch 94/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.8888 - val_loss: 0.6099 - val_accuracy: 0.8802\n",
      "Epoch 95/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.8871 - val_loss: 0.6376 - val_accuracy: 0.8806\n",
      "Epoch 96/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.8894 - val_loss: 0.6212 - val_accuracy: 0.8744\n",
      "Epoch 97/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4701 - accuracy: 0.8939 - val_loss: 0.6207 - val_accuracy: 0.8864\n",
      "Epoch 98/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8947 - val_loss: 0.6128 - val_accuracy: 0.8829\n",
      "Epoch 99/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4653 - accuracy: 0.8940 - val_loss: 0.5980 - val_accuracy: 0.8888\n",
      "Epoch 100/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8947 - val_loss: 0.5928 - val_accuracy: 0.8729\n",
      "Epoch 101/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4592 - accuracy: 0.8938 - val_loss: 0.5874 - val_accuracy: 0.8717\n",
      "Epoch 102/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4557 - accuracy: 0.8959 - val_loss: 0.5526 - val_accuracy: 0.8946\n",
      "Epoch 103/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4649 - accuracy: 0.8956 - val_loss: 0.5788 - val_accuracy: 0.8853\n",
      "Epoch 104/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.8989 - val_loss: 0.5689 - val_accuracy: 0.8729\n",
      "Epoch 105/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.8989 - val_loss: 0.5566 - val_accuracy: 0.9004\n",
      "Epoch 106/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4417 - accuracy: 0.8988 - val_loss: 0.5639 - val_accuracy: 0.8899\n",
      "Epoch 107/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4373 - accuracy: 0.9025 - val_loss: 0.5809 - val_accuracy: 0.8678\n",
      "Epoch 108/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4370 - accuracy: 0.8975 - val_loss: 0.5529 - val_accuracy: 0.8969\n",
      "Epoch 109/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4322 - accuracy: 0.9008 - val_loss: 0.5802 - val_accuracy: 0.8733\n",
      "Epoch 110/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4313 - accuracy: 0.8990 - val_loss: 0.5847 - val_accuracy: 0.8810\n",
      "Epoch 111/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4291 - accuracy: 0.9001 - val_loss: 0.5605 - val_accuracy: 0.9031\n",
      "Epoch 112/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4233 - accuracy: 0.9031 - val_loss: 0.5658 - val_accuracy: 0.8837\n",
      "Epoch 113/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4183 - accuracy: 0.9061 - val_loss: 0.5491 - val_accuracy: 0.8938\n",
      "Epoch 114/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4214 - accuracy: 0.9044 - val_loss: 0.5601 - val_accuracy: 0.9054\n",
      "Epoch 115/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4152 - accuracy: 0.9056 - val_loss: 0.5623 - val_accuracy: 0.8922\n",
      "Epoch 116/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.9062 - val_loss: 0.5553 - val_accuracy: 0.8934\n",
      "Epoch 117/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4078 - accuracy: 0.9089 - val_loss: 0.5617 - val_accuracy: 0.9019\n",
      "Epoch 118/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.9076 - val_loss: 0.5633 - val_accuracy: 0.9019\n",
      "Epoch 119/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4027 - accuracy: 0.9089 - val_loss: 0.5568 - val_accuracy: 0.8884\n",
      "Epoch 120/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.9103 - val_loss: 0.5690 - val_accuracy: 0.9031\n",
      "Epoch 121/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.9081 - val_loss: 0.5449 - val_accuracy: 0.8919\n",
      "Epoch 122/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.9107 - val_loss: 0.5711 - val_accuracy: 0.9070\n",
      "Epoch 123/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3942 - accuracy: 0.9094 - val_loss: 0.5152 - val_accuracy: 0.9112\n",
      "Epoch 124/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.9102 - val_loss: 0.5176 - val_accuracy: 0.9112\n",
      "Epoch 125/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3875 - accuracy: 0.9130 - val_loss: 0.5221 - val_accuracy: 0.9039\n",
      "Epoch 126/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.9112 - val_loss: 0.5521 - val_accuracy: 0.9112\n",
      "Epoch 127/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3826 - accuracy: 0.9115 - val_loss: 0.5423 - val_accuracy: 0.9085\n",
      "Epoch 128/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3790 - accuracy: 0.9138 - val_loss: 0.5255 - val_accuracy: 0.9159\n",
      "Epoch 129/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3750 - accuracy: 0.9140 - val_loss: 0.5333 - val_accuracy: 0.9143\n",
      "Epoch 130/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3719 - accuracy: 0.9153 - val_loss: 0.5461 - val_accuracy: 0.9147\n",
      "Epoch 131/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.9159 - val_loss: 0.5482 - val_accuracy: 0.8988\n",
      "Epoch 132/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3693 - accuracy: 0.9165 - val_loss: 0.4689 - val_accuracy: 0.9143\n",
      "Epoch 133/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.9174 - val_loss: 0.4273 - val_accuracy: 0.9004\n",
      "Epoch 134/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.9161 - val_loss: 0.4443 - val_accuracy: 0.9190\n",
      "Epoch 135/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3608 - accuracy: 0.9200 - val_loss: 0.4240 - val_accuracy: 0.9267\n",
      "Epoch 136/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3597 - accuracy: 0.9197 - val_loss: 0.4301 - val_accuracy: 0.9116\n",
      "Epoch 137/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.9204 - val_loss: 0.4268 - val_accuracy: 0.9159\n",
      "Epoch 138/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3525 - accuracy: 0.9197 - val_loss: 0.4372 - val_accuracy: 0.9070\n",
      "Epoch 139/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3499 - accuracy: 0.9224 - val_loss: 0.4391 - val_accuracy: 0.9182\n",
      "Epoch 140/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3494 - accuracy: 0.9204 - val_loss: 0.4473 - val_accuracy: 0.9019\n",
      "Epoch 141/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3475 - accuracy: 0.9214 - val_loss: 0.4582 - val_accuracy: 0.9008\n",
      "Epoch 142/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.9211 - val_loss: 0.4427 - val_accuracy: 0.9190\n",
      "Epoch 143/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3440 - accuracy: 0.9219 - val_loss: 0.4692 - val_accuracy: 0.9136\n",
      "Epoch 144/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3700 - accuracy: 0.9193 - val_loss: 0.3788 - val_accuracy: 0.9256\n",
      "Epoch 145/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9275 - val_loss: 0.3943 - val_accuracy: 0.9174\n",
      "Epoch 146/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3323 - accuracy: 0.9281 - val_loss: 0.3893 - val_accuracy: 0.9194\n",
      "Epoch 147/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3352 - accuracy: 0.9257 - val_loss: 0.4005 - val_accuracy: 0.9081\n",
      "Epoch 148/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.9268 - val_loss: 0.3834 - val_accuracy: 0.9097\n",
      "Epoch 149/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.9254 - val_loss: 0.3755 - val_accuracy: 0.9198\n",
      "Epoch 150/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3313 - accuracy: 0.9248 - val_loss: 0.3907 - val_accuracy: 0.9074\n",
      "Epoch 151/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.9248 - val_loss: 0.3946 - val_accuracy: 0.9186\n",
      "Epoch 152/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.9265 - val_loss: 0.4066 - val_accuracy: 0.9244\n",
      "Epoch 153/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.9255 - val_loss: 0.3910 - val_accuracy: 0.9217\n",
      "Epoch 154/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.9285 - val_loss: 0.3943 - val_accuracy: 0.9267\n",
      "Epoch 155/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.9269 - val_loss: 0.4063 - val_accuracy: 0.9109\n",
      "Epoch 156/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3205 - accuracy: 0.9281 - val_loss: 0.4009 - val_accuracy: 0.9120\n",
      "Epoch 157/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3162 - accuracy: 0.9300 - val_loss: 0.4083 - val_accuracy: 0.9109\n",
      "Epoch 158/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.9275 - val_loss: 0.3994 - val_accuracy: 0.9306\n",
      "Epoch 159/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3158 - accuracy: 0.9288 - val_loss: 0.4232 - val_accuracy: 0.9186\n",
      "Epoch 160/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.9278 - val_loss: 0.4083 - val_accuracy: 0.9186\n",
      "Epoch 161/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3114 - accuracy: 0.9285 - val_loss: 0.4246 - val_accuracy: 0.9267\n",
      "Epoch 162/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3131 - accuracy: 0.9285 - val_loss: 0.4114 - val_accuracy: 0.9337\n",
      "Epoch 163/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3084 - accuracy: 0.9307 - val_loss: 0.4246 - val_accuracy: 0.9291\n",
      "Epoch 164/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3049 - accuracy: 0.9316 - val_loss: 0.4007 - val_accuracy: 0.9310\n",
      "Epoch 165/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3031 - accuracy: 0.9317 - val_loss: 0.4033 - val_accuracy: 0.9252\n",
      "Epoch 166/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3006 - accuracy: 0.9331 - val_loss: 0.4126 - val_accuracy: 0.9124\n",
      "Epoch 167/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.3067 - accuracy: 0.9306 - val_loss: 0.3565 - val_accuracy: 0.9349\n",
      "Epoch 168/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2973 - accuracy: 0.9334 - val_loss: 0.3671 - val_accuracy: 0.9264\n",
      "Epoch 169/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2973 - accuracy: 0.9327 - val_loss: 0.3543 - val_accuracy: 0.9399\n",
      "Epoch 170/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2971 - accuracy: 0.9339 - val_loss: 0.3822 - val_accuracy: 0.9004\n",
      "Epoch 171/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.9330 - val_loss: 0.3755 - val_accuracy: 0.9209\n",
      "Epoch 172/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2945 - accuracy: 0.9330 - val_loss: 0.3840 - val_accuracy: 0.9112\n",
      "Epoch 173/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2914 - accuracy: 0.9335 - val_loss: 0.3756 - val_accuracy: 0.9167\n",
      "Epoch 174/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2889 - accuracy: 0.9357 - val_loss: 0.3873 - val_accuracy: 0.9260\n",
      "Epoch 175/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2908 - accuracy: 0.9312 - val_loss: 0.3771 - val_accuracy: 0.9267\n",
      "Epoch 176/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2868 - accuracy: 0.9333 - val_loss: 0.4075 - val_accuracy: 0.9205\n",
      "Epoch 177/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2846 - accuracy: 0.9353 - val_loss: 0.4118 - val_accuracy: 0.9213\n",
      "Epoch 178/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2842 - accuracy: 0.9335 - val_loss: 0.4206 - val_accuracy: 0.9116\n",
      "Epoch 179/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2811 - accuracy: 0.9354 - val_loss: 0.4202 - val_accuracy: 0.9283\n",
      "Epoch 180/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2843 - accuracy: 0.9324 - val_loss: 0.3825 - val_accuracy: 0.9287\n",
      "Epoch 181/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2794 - accuracy: 0.9348 - val_loss: 0.3915 - val_accuracy: 0.9279\n",
      "Epoch 182/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.9364 - val_loss: 0.3907 - val_accuracy: 0.9159\n",
      "Epoch 183/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2757 - accuracy: 0.9359 - val_loss: 0.3922 - val_accuracy: 0.9233\n",
      "Epoch 184/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2741 - accuracy: 0.9360 - val_loss: 0.3972 - val_accuracy: 0.9221\n",
      "Epoch 185/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2686 - accuracy: 0.9388 - val_loss: 0.3953 - val_accuracy: 0.9283\n",
      "Epoch 186/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2757 - accuracy: 0.9343 - val_loss: 0.4305 - val_accuracy: 0.9023\n",
      "Epoch 187/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2693 - accuracy: 0.9391 - val_loss: 0.3850 - val_accuracy: 0.9314\n",
      "Epoch 188/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.9413 - val_loss: 0.4043 - val_accuracy: 0.9120\n",
      "Epoch 189/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2628 - accuracy: 0.9420 - val_loss: 0.3702 - val_accuracy: 0.9473\n",
      "Epoch 190/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2651 - accuracy: 0.9384 - val_loss: 0.4199 - val_accuracy: 0.9194\n",
      "Epoch 191/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2640 - accuracy: 0.9382 - val_loss: 0.4016 - val_accuracy: 0.9360\n",
      "Epoch 192/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2629 - accuracy: 0.9397 - val_loss: 0.3976 - val_accuracy: 0.9430\n",
      "Epoch 193/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.9390 - val_loss: 0.3997 - val_accuracy: 0.9372\n",
      "Epoch 194/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2593 - accuracy: 0.9407 - val_loss: 0.4215 - val_accuracy: 0.9372\n",
      "Epoch 195/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2617 - accuracy: 0.9397 - val_loss: 0.4311 - val_accuracy: 0.9318\n",
      "Epoch 196/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2602 - accuracy: 0.9385 - val_loss: 0.4375 - val_accuracy: 0.9403\n",
      "Epoch 197/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.9406 - val_loss: 0.4535 - val_accuracy: 0.9233\n",
      "Epoch 198/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2565 - accuracy: 0.9395 - val_loss: 0.4509 - val_accuracy: 0.9333\n",
      "Epoch 199/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2968 - accuracy: 0.9401 - val_loss: 0.4493 - val_accuracy: 0.9353\n",
      "Epoch 200/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.9453 - val_loss: 0.4565 - val_accuracy: 0.9260\n",
      "Epoch 201/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2473 - accuracy: 0.9436 - val_loss: 0.4340 - val_accuracy: 0.9411\n",
      "Epoch 202/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2479 - accuracy: 0.9434 - val_loss: 0.4361 - val_accuracy: 0.9419\n",
      "Epoch 203/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.9432 - val_loss: 0.3757 - val_accuracy: 0.9473\n",
      "Epoch 204/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2486 - accuracy: 0.9447 - val_loss: 0.4002 - val_accuracy: 0.9364\n",
      "Epoch 205/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.9445 - val_loss: 0.3608 - val_accuracy: 0.9287\n",
      "Epoch 206/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2488 - accuracy: 0.9431 - val_loss: 0.3709 - val_accuracy: 0.9368\n",
      "Epoch 207/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.9420 - val_loss: 0.3906 - val_accuracy: 0.9407\n",
      "Epoch 208/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.9419 - val_loss: 0.3706 - val_accuracy: 0.9484\n",
      "Epoch 209/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.9439 - val_loss: 0.3760 - val_accuracy: 0.9442\n",
      "Epoch 210/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9435 - val_loss: 0.3738 - val_accuracy: 0.9512\n",
      "Epoch 211/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.9435 - val_loss: 0.3745 - val_accuracy: 0.9469\n",
      "Epoch 212/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9430 - val_loss: 0.3806 - val_accuracy: 0.9376\n",
      "Epoch 213/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2422 - accuracy: 0.9441 - val_loss: 0.3855 - val_accuracy: 0.9318\n",
      "Epoch 214/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9432 - val_loss: 0.3962 - val_accuracy: 0.9302\n",
      "Epoch 215/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2379 - accuracy: 0.9455 - val_loss: 0.3767 - val_accuracy: 0.9535\n",
      "Epoch 216/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2364 - accuracy: 0.9456 - val_loss: 0.3817 - val_accuracy: 0.9279\n",
      "Epoch 217/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.9454 - val_loss: 0.3532 - val_accuracy: 0.9484\n",
      "Epoch 218/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2337 - accuracy: 0.9460 - val_loss: 0.3477 - val_accuracy: 0.9508\n",
      "Epoch 219/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2369 - accuracy: 0.9454 - val_loss: 0.3565 - val_accuracy: 0.9469\n",
      "Epoch 220/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.9463 - val_loss: 0.3806 - val_accuracy: 0.9233\n",
      "Epoch 221/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2338 - accuracy: 0.9455 - val_loss: 0.4143 - val_accuracy: 0.9240\n",
      "Epoch 222/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2299 - accuracy: 0.9472 - val_loss: 0.3740 - val_accuracy: 0.9341\n",
      "Epoch 223/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9433 - val_loss: 0.3513 - val_accuracy: 0.9504\n",
      "Epoch 224/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2252 - accuracy: 0.9495 - val_loss: 0.3524 - val_accuracy: 0.9477\n",
      "Epoch 225/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2248 - accuracy: 0.9491 - val_loss: 0.3818 - val_accuracy: 0.9318\n",
      "Epoch 226/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2262 - accuracy: 0.9468 - val_loss: 0.3718 - val_accuracy: 0.9430\n",
      "Epoch 227/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9467 - val_loss: 0.3423 - val_accuracy: 0.9461\n",
      "Epoch 228/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2248 - accuracy: 0.9482 - val_loss: 0.3818 - val_accuracy: 0.9329\n",
      "Epoch 229/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2267 - accuracy: 0.9469 - val_loss: 0.3725 - val_accuracy: 0.9349\n",
      "Epoch 230/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2246 - accuracy: 0.9473 - val_loss: 0.3668 - val_accuracy: 0.9601\n",
      "Epoch 231/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2219 - accuracy: 0.9484 - val_loss: 0.3549 - val_accuracy: 0.9438\n",
      "Epoch 232/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2252 - accuracy: 0.9461 - val_loss: 0.3491 - val_accuracy: 0.9578\n",
      "Epoch 233/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2209 - accuracy: 0.9484 - val_loss: 0.3614 - val_accuracy: 0.9593\n",
      "Epoch 234/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9491 - val_loss: 0.3575 - val_accuracy: 0.9465\n",
      "Epoch 235/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2192 - accuracy: 0.9472 - val_loss: 0.4012 - val_accuracy: 0.9248\n",
      "Epoch 236/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2237 - accuracy: 0.9485 - val_loss: 0.3674 - val_accuracy: 0.9457\n",
      "Epoch 237/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2151 - accuracy: 0.9519 - val_loss: 0.3514 - val_accuracy: 0.9442\n",
      "Epoch 238/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2158 - accuracy: 0.9497 - val_loss: 0.3471 - val_accuracy: 0.9531\n",
      "Epoch 239/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2136 - accuracy: 0.9506 - val_loss: 0.3612 - val_accuracy: 0.9388\n",
      "Epoch 240/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2149 - accuracy: 0.9490 - val_loss: 0.3604 - val_accuracy: 0.9442\n",
      "Epoch 241/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2166 - accuracy: 0.9491 - val_loss: 0.3733 - val_accuracy: 0.9430\n",
      "Epoch 242/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2143 - accuracy: 0.9488 - val_loss: 0.3736 - val_accuracy: 0.9380\n",
      "Epoch 243/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2156 - accuracy: 0.9493 - val_loss: 0.3888 - val_accuracy: 0.9512\n",
      "Epoch 244/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2118 - accuracy: 0.9491 - val_loss: 0.4171 - val_accuracy: 0.9353\n",
      "Epoch 245/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2117 - accuracy: 0.9491 - val_loss: 0.4240 - val_accuracy: 0.9306\n",
      "Epoch 246/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2124 - accuracy: 0.9494 - val_loss: 0.4159 - val_accuracy: 0.9527\n",
      "Epoch 247/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2104 - accuracy: 0.9501 - val_loss: 0.4238 - val_accuracy: 0.9457\n",
      "Epoch 248/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9500 - val_loss: 0.4275 - val_accuracy: 0.9337\n",
      "Epoch 249/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2109 - accuracy: 0.9490 - val_loss: 0.4291 - val_accuracy: 0.9407\n",
      "Epoch 250/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2080 - accuracy: 0.9500 - val_loss: 0.4152 - val_accuracy: 0.9508\n",
      "Epoch 251/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2078 - accuracy: 0.9506 - val_loss: 0.4597 - val_accuracy: 0.9287\n",
      "Epoch 252/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2058 - accuracy: 0.9524 - val_loss: 0.4329 - val_accuracy: 0.9419\n",
      "Epoch 253/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2042 - accuracy: 0.9506 - val_loss: 0.4160 - val_accuracy: 0.9473\n",
      "Epoch 254/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9516 - val_loss: 0.4640 - val_accuracy: 0.9372\n",
      "Epoch 255/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2029 - accuracy: 0.9512 - val_loss: 0.4504 - val_accuracy: 0.9388\n",
      "Epoch 256/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2042 - accuracy: 0.9497 - val_loss: 0.4376 - val_accuracy: 0.9585\n",
      "Epoch 257/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2332 - accuracy: 0.9516 - val_loss: 0.4313 - val_accuracy: 0.9488\n",
      "Epoch 258/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1957 - accuracy: 0.9561 - val_loss: 0.4430 - val_accuracy: 0.9519\n",
      "Epoch 259/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1981 - accuracy: 0.9541 - val_loss: 0.4423 - val_accuracy: 0.9364\n",
      "Epoch 260/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.9542 - val_loss: 0.4400 - val_accuracy: 0.9326\n",
      "Epoch 261/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9550 - val_loss: 0.4386 - val_accuracy: 0.9473\n",
      "Epoch 262/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1986 - accuracy: 0.9508 - val_loss: 0.4290 - val_accuracy: 0.9523\n",
      "Epoch 263/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1988 - accuracy: 0.9532 - val_loss: 0.4321 - val_accuracy: 0.9543\n",
      "Epoch 264/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1960 - accuracy: 0.9546 - val_loss: 0.4466 - val_accuracy: 0.9446\n",
      "Epoch 265/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1992 - accuracy: 0.9517 - val_loss: 0.4260 - val_accuracy: 0.9550\n",
      "Epoch 266/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1975 - accuracy: 0.9540 - val_loss: 0.4720 - val_accuracy: 0.9306\n",
      "Epoch 267/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.9535 - val_loss: 0.4663 - val_accuracy: 0.9395\n",
      "Epoch 268/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.2016 - accuracy: 0.9492 - val_loss: 0.4999 - val_accuracy: 0.9349\n",
      "Epoch 269/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1940 - accuracy: 0.9536 - val_loss: 0.4688 - val_accuracy: 0.9446\n",
      "Epoch 270/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1954 - accuracy: 0.9527 - val_loss: 0.5002 - val_accuracy: 0.9357\n",
      "Epoch 271/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9550 - val_loss: 0.4593 - val_accuracy: 0.9585\n",
      "Epoch 272/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9545 - val_loss: 0.4795 - val_accuracy: 0.9453\n",
      "Epoch 273/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9534 - val_loss: 0.4864 - val_accuracy: 0.9477\n",
      "Epoch 274/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1991 - accuracy: 0.9514 - val_loss: 0.4935 - val_accuracy: 0.9504\n",
      "Epoch 275/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1902 - accuracy: 0.9547 - val_loss: 0.4902 - val_accuracy: 0.9570\n",
      "Epoch 276/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1912 - accuracy: 0.9544 - val_loss: 0.5018 - val_accuracy: 0.9562\n",
      "Epoch 277/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1893 - accuracy: 0.9544 - val_loss: 0.5092 - val_accuracy: 0.9597\n",
      "Epoch 278/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1940 - accuracy: 0.9523 - val_loss: 0.5814 - val_accuracy: 0.9147\n",
      "Epoch 279/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9536 - val_loss: 0.5234 - val_accuracy: 0.9419\n",
      "Epoch 280/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1877 - accuracy: 0.9548 - val_loss: 0.5387 - val_accuracy: 0.9422\n",
      "Epoch 281/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9544 - val_loss: 0.5107 - val_accuracy: 0.9578\n",
      "Epoch 282/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1858 - accuracy: 0.9538 - val_loss: 0.5344 - val_accuracy: 0.9415\n",
      "Epoch 283/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1921 - accuracy: 0.9547 - val_loss: 0.3908 - val_accuracy: 0.9620\n",
      "Epoch 284/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1935 - accuracy: 0.9537 - val_loss: 0.4144 - val_accuracy: 0.9566\n",
      "Epoch 285/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1828 - accuracy: 0.9562 - val_loss: 0.3903 - val_accuracy: 0.9581\n",
      "Epoch 286/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1823 - accuracy: 0.9568 - val_loss: 0.3993 - val_accuracy: 0.9581\n",
      "Epoch 287/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1838 - accuracy: 0.9536 - val_loss: 0.4169 - val_accuracy: 0.9407\n",
      "Epoch 288/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1851 - accuracy: 0.9554 - val_loss: 0.4028 - val_accuracy: 0.9527\n",
      "Epoch 289/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1829 - accuracy: 0.9547 - val_loss: 0.4193 - val_accuracy: 0.9535\n",
      "Epoch 290/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1849 - accuracy: 0.9556 - val_loss: 0.4242 - val_accuracy: 0.9574\n",
      "Epoch 291/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1809 - accuracy: 0.9560 - val_loss: 0.4607 - val_accuracy: 0.9473\n",
      "Epoch 292/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1798 - accuracy: 0.9567 - val_loss: 0.4464 - val_accuracy: 0.9484\n",
      "Epoch 293/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1828 - accuracy: 0.9556 - val_loss: 0.4315 - val_accuracy: 0.9550\n",
      "Epoch 294/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1801 - accuracy: 0.9560 - val_loss: 0.4344 - val_accuracy: 0.9516\n",
      "Epoch 295/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1808 - accuracy: 0.9557 - val_loss: 0.4202 - val_accuracy: 0.9694\n",
      "Epoch 296/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1808 - accuracy: 0.9554 - val_loss: 0.4497 - val_accuracy: 0.9461\n",
      "Epoch 297/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9565 - val_loss: 0.4465 - val_accuracy: 0.9543\n",
      "Epoch 298/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.9537 - val_loss: 0.4446 - val_accuracy: 0.9516\n",
      "Epoch 299/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.9568 - val_loss: 0.4645 - val_accuracy: 0.9554\n",
      "Epoch 300/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9569 - val_loss: 0.4539 - val_accuracy: 0.9585\n",
      "Epoch 301/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9578 - val_loss: 0.4815 - val_accuracy: 0.9430\n",
      "Epoch 302/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1816 - accuracy: 0.9550 - val_loss: 0.4524 - val_accuracy: 0.9523\n",
      "Epoch 303/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1799 - accuracy: 0.9564 - val_loss: 0.4003 - val_accuracy: 0.9516\n",
      "Epoch 304/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1750 - accuracy: 0.9578 - val_loss: 0.4348 - val_accuracy: 0.9415\n",
      "Epoch 305/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.9568 - val_loss: 0.4303 - val_accuracy: 0.9450\n",
      "Epoch 306/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1733 - accuracy: 0.9575 - val_loss: 0.4008 - val_accuracy: 0.9578\n",
      "Epoch 307/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1730 - accuracy: 0.9574 - val_loss: 0.4061 - val_accuracy: 0.9492\n",
      "Epoch 308/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1786 - accuracy: 0.9560 - val_loss: 0.4357 - val_accuracy: 0.9403\n",
      "Epoch 309/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9570 - val_loss: 0.4018 - val_accuracy: 0.9376\n",
      "Epoch 310/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1717 - accuracy: 0.9568 - val_loss: 0.3731 - val_accuracy: 0.9504\n",
      "Epoch 311/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1706 - accuracy: 0.9590 - val_loss: 0.3693 - val_accuracy: 0.9566\n",
      "Epoch 312/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1761 - accuracy: 0.9551 - val_loss: 0.3829 - val_accuracy: 0.9438\n",
      "Epoch 313/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1715 - accuracy: 0.9572 - val_loss: 0.3850 - val_accuracy: 0.9628\n",
      "Epoch 314/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1680 - accuracy: 0.9591 - val_loss: 0.3393 - val_accuracy: 0.9636\n",
      "Epoch 315/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1723 - accuracy: 0.9567 - val_loss: 0.3396 - val_accuracy: 0.9597\n",
      "Epoch 316/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1775 - accuracy: 0.9572 - val_loss: 0.4189 - val_accuracy: 0.9260\n",
      "Epoch 317/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1686 - accuracy: 0.9581 - val_loss: 0.3509 - val_accuracy: 0.9574\n",
      "Epoch 318/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1648 - accuracy: 0.9610 - val_loss: 0.3852 - val_accuracy: 0.9372\n",
      "Epoch 319/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9579 - val_loss: 0.3766 - val_accuracy: 0.9446\n",
      "Epoch 320/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.9577 - val_loss: 0.3409 - val_accuracy: 0.9609\n",
      "Epoch 321/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1674 - accuracy: 0.9601 - val_loss: 0.3404 - val_accuracy: 0.9632\n",
      "Epoch 322/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1679 - accuracy: 0.9584 - val_loss: 0.3322 - val_accuracy: 0.9601\n",
      "Epoch 323/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1705 - accuracy: 0.9578 - val_loss: 0.3887 - val_accuracy: 0.9403\n",
      "Epoch 324/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1637 - accuracy: 0.9604 - val_loss: 0.3733 - val_accuracy: 0.9496\n",
      "Epoch 325/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9574 - val_loss: 0.3198 - val_accuracy: 0.9461\n",
      "Epoch 326/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1662 - accuracy: 0.9591 - val_loss: 0.3209 - val_accuracy: 0.9636\n",
      "Epoch 327/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9583 - val_loss: 0.3330 - val_accuracy: 0.9570\n",
      "Epoch 328/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9574 - val_loss: 0.4067 - val_accuracy: 0.9492\n",
      "Epoch 329/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1632 - accuracy: 0.9615 - val_loss: 0.4449 - val_accuracy: 0.9434\n",
      "Epoch 330/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1713 - accuracy: 0.9599 - val_loss: 0.2724 - val_accuracy: 0.9667\n",
      "Epoch 331/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1619 - accuracy: 0.9616 - val_loss: 0.2535 - val_accuracy: 0.9655\n",
      "Epoch 332/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1606 - accuracy: 0.9621 - val_loss: 0.2660 - val_accuracy: 0.9667\n",
      "Epoch 333/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.9603 - val_loss: 0.3200 - val_accuracy: 0.9578\n",
      "Epoch 334/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9640 - val_loss: 0.3016 - val_accuracy: 0.9574\n",
      "Epoch 335/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1578 - accuracy: 0.9621 - val_loss: 0.2920 - val_accuracy: 0.9671\n",
      "Epoch 336/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1559 - accuracy: 0.9630 - val_loss: 0.3074 - val_accuracy: 0.9519\n",
      "Epoch 337/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1578 - accuracy: 0.9608 - val_loss: 0.3031 - val_accuracy: 0.9589\n",
      "Epoch 338/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1595 - accuracy: 0.9606 - val_loss: 0.3676 - val_accuracy: 0.9287\n",
      "Epoch 339/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1606 - accuracy: 0.9607 - val_loss: 0.3094 - val_accuracy: 0.9601\n",
      "Epoch 340/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1604 - accuracy: 0.9595 - val_loss: 0.2975 - val_accuracy: 0.9558\n",
      "Epoch 341/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1601 - accuracy: 0.9605 - val_loss: 0.2990 - val_accuracy: 0.9496\n",
      "Epoch 342/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1636 - accuracy: 0.9613 - val_loss: 0.2961 - val_accuracy: 0.9597\n",
      "Epoch 343/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1593 - accuracy: 0.9611 - val_loss: 0.2777 - val_accuracy: 0.9667\n",
      "Epoch 344/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1587 - accuracy: 0.9607 - val_loss: 0.2870 - val_accuracy: 0.9601\n",
      "Epoch 345/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1545 - accuracy: 0.9640 - val_loss: 0.3560 - val_accuracy: 0.9221\n",
      "Epoch 346/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1571 - accuracy: 0.9609 - val_loss: 0.3349 - val_accuracy: 0.9562\n",
      "Epoch 347/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9597 - val_loss: 0.3340 - val_accuracy: 0.9663\n",
      "Epoch 348/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9606 - val_loss: 0.3144 - val_accuracy: 0.9632\n",
      "Epoch 349/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9609 - val_loss: 0.3322 - val_accuracy: 0.9543\n",
      "Epoch 350/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1610 - accuracy: 0.9593 - val_loss: 0.3216 - val_accuracy: 0.9620\n",
      "Epoch 351/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1612 - accuracy: 0.9591 - val_loss: 0.3906 - val_accuracy: 0.9310\n",
      "Epoch 352/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.9604 - val_loss: 0.3522 - val_accuracy: 0.9601\n",
      "Epoch 353/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9607 - val_loss: 0.3598 - val_accuracy: 0.9411\n",
      "Epoch 354/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1563 - accuracy: 0.9609 - val_loss: 0.3647 - val_accuracy: 0.9484\n",
      "Epoch 355/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1603 - accuracy: 0.9593 - val_loss: 0.3753 - val_accuracy: 0.9593\n",
      "Epoch 356/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1552 - accuracy: 0.9620 - val_loss: 0.3646 - val_accuracy: 0.9647\n",
      "Epoch 357/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1570 - accuracy: 0.9596 - val_loss: 0.3874 - val_accuracy: 0.9488\n",
      "Epoch 358/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1560 - accuracy: 0.9609 - val_loss: 0.3976 - val_accuracy: 0.9473\n",
      "Epoch 359/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1563 - accuracy: 0.9609 - val_loss: 0.3645 - val_accuracy: 0.9640\n",
      "Epoch 360/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9619 - val_loss: 0.3798 - val_accuracy: 0.9628\n",
      "Epoch 361/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9634 - val_loss: 0.3790 - val_accuracy: 0.9659\n",
      "Epoch 362/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9626 - val_loss: 0.4193 - val_accuracy: 0.9508\n",
      "Epoch 363/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1530 - accuracy: 0.9616 - val_loss: 0.3954 - val_accuracy: 0.9566\n",
      "Epoch 364/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1563 - accuracy: 0.9597 - val_loss: 0.3992 - val_accuracy: 0.9578\n",
      "Epoch 365/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.9632 - val_loss: 0.3645 - val_accuracy: 0.9709\n",
      "Epoch 366/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9614 - val_loss: 0.4091 - val_accuracy: 0.9434\n",
      "Epoch 367/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1528 - accuracy: 0.9614 - val_loss: 0.4172 - val_accuracy: 0.9488\n",
      "Epoch 368/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9612 - val_loss: 0.4091 - val_accuracy: 0.9643\n",
      "Epoch 369/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9600 - val_loss: 0.4233 - val_accuracy: 0.9616\n",
      "Epoch 370/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1495 - accuracy: 0.9625 - val_loss: 0.4230 - val_accuracy: 0.9663\n",
      "Epoch 371/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.9629 - val_loss: 0.4214 - val_accuracy: 0.9686\n",
      "Epoch 372/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1536 - accuracy: 0.9613 - val_loss: 0.4170 - val_accuracy: 0.9640\n",
      "Epoch 373/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.9605 - val_loss: 0.4416 - val_accuracy: 0.9527\n",
      "Epoch 374/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.9630 - val_loss: 0.4508 - val_accuracy: 0.9554\n",
      "Epoch 375/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1445 - accuracy: 0.9640 - val_loss: 0.4231 - val_accuracy: 0.9593\n",
      "Epoch 376/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1488 - accuracy: 0.9624 - val_loss: 0.4352 - val_accuracy: 0.9671\n",
      "Epoch 377/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1458 - accuracy: 0.9628 - val_loss: 0.4511 - val_accuracy: 0.9612\n",
      "Epoch 378/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1509 - accuracy: 0.9617 - val_loss: 0.4523 - val_accuracy: 0.9589\n",
      "Epoch 379/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.3681 - val_accuracy: 0.9527\n",
      "Epoch 380/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1457 - accuracy: 0.9641 - val_loss: 0.3736 - val_accuracy: 0.9547\n",
      "Epoch 381/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1461 - accuracy: 0.9627 - val_loss: 0.4239 - val_accuracy: 0.9368\n",
      "Epoch 382/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1484 - accuracy: 0.9620 - val_loss: 0.3470 - val_accuracy: 0.9566\n",
      "Epoch 383/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1494 - accuracy: 0.9621 - val_loss: 0.3306 - val_accuracy: 0.9686\n",
      "Epoch 384/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1461 - accuracy: 0.9635 - val_loss: 0.3335 - val_accuracy: 0.9667\n",
      "Epoch 385/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.9634 - val_loss: 0.3804 - val_accuracy: 0.9558\n",
      "Epoch 386/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1485 - accuracy: 0.9623 - val_loss: 0.3655 - val_accuracy: 0.9574\n",
      "Epoch 387/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1507 - accuracy: 0.9610 - val_loss: 0.3379 - val_accuracy: 0.9609\n",
      "Epoch 388/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1450 - accuracy: 0.9627 - val_loss: 0.3784 - val_accuracy: 0.9523\n",
      "Epoch 389/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1443 - accuracy: 0.9634 - val_loss: 0.3637 - val_accuracy: 0.9616\n",
      "Epoch 390/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1430 - accuracy: 0.9652 - val_loss: 0.3561 - val_accuracy: 0.9632\n",
      "Epoch 391/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1448 - accuracy: 0.9624 - val_loss: 0.3478 - val_accuracy: 0.9709\n",
      "Epoch 392/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1494 - accuracy: 0.9618 - val_loss: 0.3559 - val_accuracy: 0.9667\n",
      "Epoch 393/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1468 - accuracy: 0.9629 - val_loss: 0.3297 - val_accuracy: 0.9667\n",
      "Epoch 394/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1405 - accuracy: 0.9650 - val_loss: 0.3312 - val_accuracy: 0.9717\n",
      "Epoch 395/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1435 - accuracy: 0.9639 - val_loss: 0.3390 - val_accuracy: 0.9663\n",
      "Epoch 396/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1440 - accuracy: 0.9645 - val_loss: 0.3578 - val_accuracy: 0.9516\n",
      "Epoch 397/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1445 - accuracy: 0.9621 - val_loss: 0.3757 - val_accuracy: 0.9585\n",
      "Epoch 398/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1457 - accuracy: 0.9616 - val_loss: 0.3813 - val_accuracy: 0.9605\n",
      "Epoch 399/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1440 - accuracy: 0.9656 - val_loss: 0.4219 - val_accuracy: 0.9632\n",
      "Epoch 400/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1378 - accuracy: 0.9652 - val_loss: 0.4185 - val_accuracy: 0.9640\n",
      "Epoch 401/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1442 - accuracy: 0.9629 - val_loss: 0.4458 - val_accuracy: 0.9643\n",
      "Epoch 402/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9636 - val_loss: 0.4298 - val_accuracy: 0.9748\n",
      "Epoch 403/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1468 - accuracy: 0.9615 - val_loss: 0.4891 - val_accuracy: 0.9407\n",
      "Epoch 404/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1364 - accuracy: 0.9653 - val_loss: 0.4746 - val_accuracy: 0.9446\n",
      "Epoch 405/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1468 - accuracy: 0.9618 - val_loss: 0.4635 - val_accuracy: 0.9539\n",
      "Epoch 406/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9635 - val_loss: 0.4549 - val_accuracy: 0.9655\n",
      "Epoch 407/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.9639 - val_loss: 0.4763 - val_accuracy: 0.9690\n",
      "Epoch 408/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9623 - val_loss: 0.5452 - val_accuracy: 0.9442\n",
      "Epoch 409/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1394 - accuracy: 0.9652 - val_loss: 0.5018 - val_accuracy: 0.9698\n",
      "Epoch 410/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1398 - accuracy: 0.9642 - val_loss: 0.5391 - val_accuracy: 0.9562\n",
      "Epoch 411/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1390 - accuracy: 0.9640 - val_loss: 0.5569 - val_accuracy: 0.9566\n",
      "Epoch 412/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.9648 - val_loss: 0.5500 - val_accuracy: 0.9643\n",
      "Epoch 413/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.9643 - val_loss: 0.5404 - val_accuracy: 0.9674\n",
      "Epoch 414/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1416 - accuracy: 0.9632 - val_loss: 0.5796 - val_accuracy: 0.9488\n",
      "Epoch 415/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9647 - val_loss: 0.5240 - val_accuracy: 0.9593\n",
      "Epoch 416/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1415 - accuracy: 0.9632 - val_loss: 0.5609 - val_accuracy: 0.9535\n",
      "Epoch 417/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1366 - accuracy: 0.9640 - val_loss: 0.5593 - val_accuracy: 0.9562\n",
      "Epoch 418/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9634 - val_loss: 0.5674 - val_accuracy: 0.9581\n",
      "Epoch 419/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1366 - accuracy: 0.9655 - val_loss: 0.4481 - val_accuracy: 0.9678\n",
      "Epoch 420/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.9629 - val_loss: 0.4620 - val_accuracy: 0.9566\n",
      "Epoch 421/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1343 - accuracy: 0.9653 - val_loss: 0.4346 - val_accuracy: 0.9663\n",
      "Epoch 422/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.9652 - val_loss: 0.4532 - val_accuracy: 0.9624\n",
      "Epoch 423/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1330 - accuracy: 0.9665 - val_loss: 0.5029 - val_accuracy: 0.9516\n",
      "Epoch 424/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1381 - accuracy: 0.9639 - val_loss: 0.5098 - val_accuracy: 0.9516\n",
      "Epoch 425/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1789 - accuracy: 0.9639 - val_loss: 0.5345 - val_accuracy: 0.9667\n",
      "Epoch 426/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1214 - accuracy: 0.9712 - val_loss: 0.4835 - val_accuracy: 0.9628\n",
      "Epoch 427/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1247 - accuracy: 0.9697 - val_loss: 0.4909 - val_accuracy: 0.9636\n",
      "Epoch 428/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1328 - accuracy: 0.9662 - val_loss: 0.5054 - val_accuracy: 0.9558\n",
      "Epoch 429/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1286 - accuracy: 0.9682 - val_loss: 0.5234 - val_accuracy: 0.9481\n",
      "Epoch 430/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1342 - accuracy: 0.9650 - val_loss: 0.4992 - val_accuracy: 0.9651\n",
      "Epoch 431/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1315 - accuracy: 0.9667 - val_loss: 0.5368 - val_accuracy: 0.9558\n",
      "Epoch 432/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9660 - val_loss: 0.5623 - val_accuracy: 0.9543\n",
      "Epoch 433/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.9643 - val_loss: 0.5214 - val_accuracy: 0.9659\n",
      "Epoch 434/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9664 - val_loss: 0.5364 - val_accuracy: 0.9609\n",
      "Epoch 435/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1326 - accuracy: 0.9663 - val_loss: 0.5472 - val_accuracy: 0.9570\n",
      "Epoch 436/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.9673 - val_loss: 0.5811 - val_accuracy: 0.9566\n",
      "Epoch 437/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1327 - accuracy: 0.9658 - val_loss: 0.5608 - val_accuracy: 0.9678\n",
      "Epoch 438/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1347 - accuracy: 0.9657 - val_loss: 0.5624 - val_accuracy: 0.9740\n",
      "Epoch 439/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1292 - accuracy: 0.9669 - val_loss: 0.5475 - val_accuracy: 0.9702\n",
      "Epoch 440/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.9643 - val_loss: 0.5723 - val_accuracy: 0.9574\n",
      "Epoch 441/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.9661 - val_loss: 0.5428 - val_accuracy: 0.9705\n",
      "Epoch 442/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9640 - val_loss: 0.5462 - val_accuracy: 0.9659\n",
      "Epoch 443/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9674 - val_loss: 0.5719 - val_accuracy: 0.9702\n",
      "Epoch 444/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.9698 - val_loss: 0.5781 - val_accuracy: 0.9690\n",
      "Epoch 445/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9679 - val_loss: 0.5616 - val_accuracy: 0.9729\n",
      "Epoch 446/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9667 - val_loss: 0.6065 - val_accuracy: 0.9543\n",
      "Epoch 447/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.9667 - val_loss: 0.6052 - val_accuracy: 0.9585\n",
      "Epoch 448/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.6096 - val_accuracy: 0.9620\n",
      "Epoch 449/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1315 - accuracy: 0.9668 - val_loss: 0.6208 - val_accuracy: 0.9671\n",
      "Epoch 450/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9668 - val_loss: 0.6493 - val_accuracy: 0.9523\n",
      "Epoch 451/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.9664 - val_loss: 0.6386 - val_accuracy: 0.9705\n",
      "Epoch 452/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9629 - val_loss: 0.6442 - val_accuracy: 0.9632\n",
      "Epoch 453/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1332 - accuracy: 0.9657 - val_loss: 0.6411 - val_accuracy: 0.9709\n",
      "Epoch 454/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.9652 - val_loss: 0.6521 - val_accuracy: 0.9578\n",
      "Epoch 455/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1297 - accuracy: 0.9657 - val_loss: 0.6638 - val_accuracy: 0.9640\n",
      "Epoch 456/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1302 - accuracy: 0.9665 - val_loss: 0.6391 - val_accuracy: 0.9702\n",
      "Epoch 457/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.9656 - val_loss: 0.6772 - val_accuracy: 0.9523\n",
      "Epoch 458/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1318 - accuracy: 0.9657 - val_loss: 0.6097 - val_accuracy: 0.9612\n",
      "Epoch 459/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1271 - accuracy: 0.9665 - val_loss: 0.6367 - val_accuracy: 0.9593\n",
      "Epoch 460/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9692 - val_loss: 0.5748 - val_accuracy: 0.9771\n",
      "Epoch 461/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1330 - accuracy: 0.9641 - val_loss: 0.6679 - val_accuracy: 0.9442\n",
      "Epoch 462/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.9673 - val_loss: 0.5911 - val_accuracy: 0.9721\n",
      "Epoch 463/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1297 - accuracy: 0.9671 - val_loss: 0.6540 - val_accuracy: 0.9543\n",
      "Epoch 464/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1266 - accuracy: 0.9688 - val_loss: 0.6127 - val_accuracy: 0.9686\n",
      "Epoch 465/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1316 - accuracy: 0.9652 - val_loss: 0.6345 - val_accuracy: 0.9578\n",
      "Epoch 466/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.9673 - val_loss: 0.5892 - val_accuracy: 0.9733\n",
      "Epoch 467/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1271 - accuracy: 0.9660 - val_loss: 0.6049 - val_accuracy: 0.9709\n",
      "Epoch 468/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1257 - accuracy: 0.9670 - val_loss: 0.6590 - val_accuracy: 0.9612\n",
      "Epoch 469/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9661 - val_loss: 0.6401 - val_accuracy: 0.9636\n",
      "Epoch 470/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1360 - accuracy: 0.9675 - val_loss: 0.6799 - val_accuracy: 0.9539\n",
      "Epoch 471/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1310 - accuracy: 0.9659 - val_loss: 0.6729 - val_accuracy: 0.9620\n",
      "Epoch 472/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9661 - val_loss: 0.7054 - val_accuracy: 0.9438\n",
      "Epoch 473/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.7050 - val_accuracy: 0.9566\n",
      "Epoch 474/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.6909 - val_accuracy: 0.9640\n",
      "Epoch 475/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1287 - accuracy: 0.9674 - val_loss: 0.6906 - val_accuracy: 0.9647\n",
      "Epoch 476/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1245 - accuracy: 0.9674 - val_loss: 0.6906 - val_accuracy: 0.9694\n",
      "Epoch 477/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.9662 - val_loss: 0.7117 - val_accuracy: 0.9655\n",
      "Epoch 478/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9661 - val_loss: 0.7446 - val_accuracy: 0.9682\n",
      "Epoch 479/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.9692 - val_loss: 0.7333 - val_accuracy: 0.9748\n",
      "Epoch 480/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9665 - val_loss: 0.7621 - val_accuracy: 0.9640\n",
      "Epoch 481/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1268 - accuracy: 0.9672 - val_loss: 0.7803 - val_accuracy: 0.9461\n",
      "Epoch 482/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.9677 - val_loss: 0.7109 - val_accuracy: 0.9744\n",
      "Epoch 483/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.7504 - val_accuracy: 0.9733\n",
      "Epoch 484/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.9669 - val_loss: 0.7845 - val_accuracy: 0.9640\n",
      "Epoch 485/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1278 - accuracy: 0.9665 - val_loss: 0.7714 - val_accuracy: 0.9609\n",
      "Epoch 486/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.9671 - val_loss: 0.7693 - val_accuracy: 0.9748\n",
      "Epoch 487/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1209 - accuracy: 0.9678 - val_loss: 0.7664 - val_accuracy: 0.9694\n",
      "Epoch 488/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9651 - val_loss: 0.7244 - val_accuracy: 0.9740\n",
      "Epoch 489/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1299 - accuracy: 0.9661 - val_loss: 0.7390 - val_accuracy: 0.9713\n",
      "Epoch 490/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.9695 - val_loss: 0.7520 - val_accuracy: 0.9686\n",
      "Epoch 491/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1214 - accuracy: 0.9695 - val_loss: 0.7386 - val_accuracy: 0.9705\n",
      "Epoch 492/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.9694 - val_loss: 0.7968 - val_accuracy: 0.9620\n",
      "Epoch 493/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.9670 - val_loss: 0.7842 - val_accuracy: 0.9616\n",
      "Epoch 494/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.9675 - val_loss: 0.7706 - val_accuracy: 0.9733\n",
      "Epoch 495/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.9684 - val_loss: 0.7588 - val_accuracy: 0.9705\n",
      "Epoch 496/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.9666 - val_loss: 0.7734 - val_accuracy: 0.9709\n",
      "Epoch 497/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9665 - val_loss: 0.8343 - val_accuracy: 0.9461\n",
      "Epoch 498/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.9700 - val_loss: 0.7663 - val_accuracy: 0.9713\n",
      "Epoch 499/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.9673 - val_loss: 0.7932 - val_accuracy: 0.9609\n",
      "Epoch 500/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9673 - val_loss: 0.7669 - val_accuracy: 0.9717\n",
      "Epoch 501/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.9670 - val_loss: 0.7951 - val_accuracy: 0.9655\n",
      "Epoch 502/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1256 - accuracy: 0.9671 - val_loss: 0.8155 - val_accuracy: 0.9581\n",
      "Epoch 503/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.9678 - val_loss: 0.8067 - val_accuracy: 0.9682\n",
      "Epoch 504/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9676 - val_loss: 0.8147 - val_accuracy: 0.9709\n",
      "Epoch 505/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.9679 - val_loss: 0.8200 - val_accuracy: 0.9721\n",
      "Epoch 506/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9679 - val_loss: 0.8717 - val_accuracy: 0.9481\n",
      "Epoch 507/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.9652 - val_loss: 0.8269 - val_accuracy: 0.9624\n",
      "Epoch 508/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9661 - val_loss: 0.7844 - val_accuracy: 0.9690\n",
      "Epoch 509/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9687 - val_loss: 1.0036 - val_accuracy: 0.9155\n",
      "Epoch 510/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.9677 - val_loss: 0.7821 - val_accuracy: 0.9705\n",
      "Epoch 511/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9681 - val_loss: 0.8064 - val_accuracy: 0.9628\n",
      "Epoch 512/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.9676 - val_loss: 0.8039 - val_accuracy: 0.9667\n",
      "Epoch 513/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1204 - accuracy: 0.9666 - val_loss: 0.7955 - val_accuracy: 0.9717\n",
      "Epoch 514/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9681 - val_loss: 0.8050 - val_accuracy: 0.9667\n",
      "Epoch 515/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1213 - accuracy: 0.9679 - val_loss: 0.8050 - val_accuracy: 0.9694\n",
      "Epoch 516/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.9700 - val_loss: 0.9029 - val_accuracy: 0.9465\n",
      "Epoch 517/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9683 - val_loss: 0.6944 - val_accuracy: 0.9698\n",
      "Epoch 518/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1208 - accuracy: 0.9691 - val_loss: 0.7103 - val_accuracy: 0.9682\n",
      "Epoch 519/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9716 - val_loss: 0.6864 - val_accuracy: 0.9717\n",
      "Epoch 520/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.9693 - val_loss: 0.7572 - val_accuracy: 0.9736\n",
      "Epoch 521/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.9686 - val_loss: 0.8048 - val_accuracy: 0.9578\n",
      "Epoch 522/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9687 - val_loss: 0.7720 - val_accuracy: 0.9694\n",
      "Epoch 523/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.9690 - val_loss: 0.7789 - val_accuracy: 0.9593\n",
      "Epoch 524/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9682 - val_loss: 0.7874 - val_accuracy: 0.9632\n",
      "Epoch 525/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.9689 - val_loss: 0.9027 - val_accuracy: 0.9403\n",
      "Epoch 526/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1154 - accuracy: 0.9705 - val_loss: 0.7741 - val_accuracy: 0.9736\n",
      "Epoch 527/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.9670 - val_loss: 0.7830 - val_accuracy: 0.9651\n",
      "Epoch 528/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9700 - val_loss: 0.8006 - val_accuracy: 0.9612\n",
      "Epoch 529/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9686 - val_loss: 0.5901 - val_accuracy: 0.9651\n",
      "Epoch 530/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1157 - accuracy: 0.9696 - val_loss: 0.5780 - val_accuracy: 0.9686\n",
      "Epoch 531/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.9668 - val_loss: 0.6555 - val_accuracy: 0.9519\n",
      "Epoch 532/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9698 - val_loss: 0.6116 - val_accuracy: 0.9605\n",
      "Epoch 533/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9707 - val_loss: 0.6793 - val_accuracy: 0.9508\n",
      "Epoch 534/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.9693 - val_loss: 0.6539 - val_accuracy: 0.9624\n",
      "Epoch 535/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9668 - val_loss: 0.6488 - val_accuracy: 0.9705\n",
      "Epoch 536/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9685 - val_loss: 0.6565 - val_accuracy: 0.9636\n",
      "Epoch 537/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9702 - val_loss: 0.6539 - val_accuracy: 0.9698\n",
      "Epoch 538/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9681 - val_loss: 0.6582 - val_accuracy: 0.9729\n",
      "Epoch 539/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.9692 - val_loss: 0.6587 - val_accuracy: 0.9717\n",
      "Epoch 540/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.9653 - val_loss: 0.6880 - val_accuracy: 0.9674\n",
      "Epoch 541/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9679 - val_loss: 0.6940 - val_accuracy: 0.9721\n",
      "Epoch 542/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9687 - val_loss: 0.6932 - val_accuracy: 0.9663\n",
      "Epoch 543/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9702 - val_loss: 0.8736 - val_accuracy: 0.9729\n",
      "Epoch 544/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.9692 - val_loss: 0.3299 - val_accuracy: 0.9550\n",
      "Epoch 545/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.9684 - val_loss: 0.2878 - val_accuracy: 0.9682\n",
      "Epoch 546/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.9708 - val_loss: 0.2865 - val_accuracy: 0.9663\n",
      "Epoch 547/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9695 - val_loss: 0.2828 - val_accuracy: 0.9702\n",
      "Epoch 548/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.9699 - val_loss: 0.3411 - val_accuracy: 0.9543\n",
      "Epoch 549/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.9679 - val_loss: 0.3116 - val_accuracy: 0.9516\n",
      "Epoch 550/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9683 - val_loss: 0.4030 - val_accuracy: 0.9368\n",
      "Epoch 551/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.9706 - val_loss: 0.2922 - val_accuracy: 0.9686\n",
      "Epoch 552/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.9698 - val_loss: 0.3548 - val_accuracy: 0.9426\n",
      "Epoch 553/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.9694 - val_loss: 0.3322 - val_accuracy: 0.9686\n",
      "Epoch 554/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.9706 - val_loss: 0.3558 - val_accuracy: 0.9632\n",
      "Epoch 555/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.9688 - val_loss: 0.3003 - val_accuracy: 0.9721\n",
      "Epoch 556/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.9730 - val_loss: 0.2866 - val_accuracy: 0.9787\n",
      "Epoch 557/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9728 - val_loss: 0.2996 - val_accuracy: 0.9740\n",
      "Epoch 558/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.9715 - val_loss: 0.2945 - val_accuracy: 0.9612\n",
      "Epoch 559/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9715 - val_loss: 0.2858 - val_accuracy: 0.9663\n",
      "Epoch 560/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9722 - val_loss: 0.2816 - val_accuracy: 0.9713\n",
      "Epoch 561/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9696 - val_loss: 0.2777 - val_accuracy: 0.9764\n",
      "Epoch 562/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.9695 - val_loss: 0.2818 - val_accuracy: 0.9682\n",
      "Epoch 563/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9707 - val_loss: 0.3095 - val_accuracy: 0.9636\n",
      "Epoch 564/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9691 - val_loss: 0.3708 - val_accuracy: 0.9547\n",
      "Epoch 565/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1209 - accuracy: 0.9658 - val_loss: 0.3825 - val_accuracy: 0.9531\n",
      "Epoch 566/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9686 - val_loss: 0.3093 - val_accuracy: 0.9705\n",
      "Epoch 567/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9709 - val_loss: 0.3397 - val_accuracy: 0.9543\n",
      "Epoch 568/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9692 - val_loss: 0.3348 - val_accuracy: 0.9655\n",
      "Epoch 569/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1157 - accuracy: 0.9699 - val_loss: 0.3548 - val_accuracy: 0.9632\n",
      "Epoch 570/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9673 - val_loss: 0.3437 - val_accuracy: 0.9581\n",
      "Epoch 571/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9699 - val_loss: 0.3166 - val_accuracy: 0.9736\n",
      "Epoch 572/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9709 - val_loss: 0.3603 - val_accuracy: 0.9558\n",
      "Epoch 573/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9710 - val_loss: 0.3422 - val_accuracy: 0.9694\n",
      "Epoch 574/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.9694 - val_loss: 0.3923 - val_accuracy: 0.9419\n",
      "Epoch 575/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9687 - val_loss: 0.3061 - val_accuracy: 0.9694\n",
      "Epoch 576/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9711 - val_loss: 0.2904 - val_accuracy: 0.9682\n",
      "Epoch 577/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9714 - val_loss: 0.3696 - val_accuracy: 0.9721\n",
      "Epoch 578/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9713 - val_loss: 0.3656 - val_accuracy: 0.9671\n",
      "Epoch 579/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.9714 - val_loss: 0.3916 - val_accuracy: 0.9605\n",
      "Epoch 580/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9709 - val_loss: 0.4037 - val_accuracy: 0.9508\n",
      "Epoch 581/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9701 - val_loss: 0.3843 - val_accuracy: 0.9752\n",
      "Epoch 582/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9717 - val_loss: 0.4686 - val_accuracy: 0.9399\n",
      "Epoch 583/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.9695 - val_loss: 0.4221 - val_accuracy: 0.9671\n",
      "Epoch 584/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.9678 - val_loss: 0.2644 - val_accuracy: 0.9647\n",
      "Epoch 585/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.9717 - val_loss: 0.2423 - val_accuracy: 0.9717\n",
      "Epoch 586/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9724 - val_loss: 0.2670 - val_accuracy: 0.9616\n",
      "Epoch 587/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.9730 - val_loss: 0.2342 - val_accuracy: 0.9748\n",
      "Epoch 588/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9692 - val_loss: 0.2561 - val_accuracy: 0.9636\n",
      "Epoch 589/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.9721 - val_loss: 0.2492 - val_accuracy: 0.9609\n",
      "Epoch 590/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.9708 - val_loss: 0.2354 - val_accuracy: 0.9752\n",
      "Epoch 591/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1091 - accuracy: 0.9698 - val_loss: 0.2884 - val_accuracy: 0.9694\n",
      "Epoch 592/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9686\n",
      "Epoch 593/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.9689 - val_loss: 0.2940 - val_accuracy: 0.9767\n",
      "Epoch 594/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9693 - val_loss: 0.3711 - val_accuracy: 0.9581\n",
      "Epoch 595/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.3376 - val_accuracy: 0.9554\n",
      "Epoch 596/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9708 - val_loss: 0.3166 - val_accuracy: 0.9717\n",
      "Epoch 597/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9675 - val_loss: 0.3557 - val_accuracy: 0.9562\n",
      "Epoch 598/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.9700 - val_loss: 0.4401 - val_accuracy: 0.9403\n",
      "Epoch 599/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1119 - accuracy: 0.9699 - val_loss: 0.3334 - val_accuracy: 0.9651\n",
      "Epoch 600/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.9720 - val_loss: 0.3535 - val_accuracy: 0.9713\n",
      "Epoch 601/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9712 - val_loss: 0.3561 - val_accuracy: 0.9717\n",
      "Epoch 602/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.9672 - val_loss: 0.3383 - val_accuracy: 0.9690\n",
      "Epoch 603/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9726 - val_loss: 0.4089 - val_accuracy: 0.9543\n",
      "Epoch 604/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.9707 - val_loss: 0.3476 - val_accuracy: 0.9779\n",
      "Epoch 605/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9724 - val_loss: 0.3873 - val_accuracy: 0.9628\n",
      "Epoch 606/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9694 - val_loss: 0.3619 - val_accuracy: 0.9744\n",
      "Epoch 607/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.9699 - val_loss: 0.3695 - val_accuracy: 0.9655\n",
      "Epoch 608/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.9714 - val_loss: 0.3700 - val_accuracy: 0.9671\n",
      "Epoch 609/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9698 - val_loss: 0.3623 - val_accuracy: 0.9725\n",
      "Epoch 610/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.9708 - val_loss: 0.3593 - val_accuracy: 0.9752\n",
      "Epoch 611/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9696 - val_loss: 0.3970 - val_accuracy: 0.9702\n",
      "Epoch 612/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.9694 - val_loss: 0.3846 - val_accuracy: 0.9814\n",
      "Epoch 613/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9716 - val_loss: 0.4102 - val_accuracy: 0.9744\n",
      "Epoch 614/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9675 - val_loss: 0.4125 - val_accuracy: 0.9659\n",
      "Epoch 615/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9717 - val_loss: 0.3922 - val_accuracy: 0.9798\n",
      "Epoch 616/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9720 - val_loss: 0.4195 - val_accuracy: 0.9752\n",
      "Epoch 617/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9704 - val_loss: 0.4829 - val_accuracy: 0.9760\n",
      "Epoch 618/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9701 - val_loss: 0.4802 - val_accuracy: 0.9612\n",
      "Epoch 619/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.9718 - val_loss: 0.4484 - val_accuracy: 0.9779\n",
      "Epoch 620/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.9719 - val_loss: 0.4475 - val_accuracy: 0.9771\n",
      "Epoch 621/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9712 - val_loss: 0.4981 - val_accuracy: 0.9636\n",
      "Epoch 622/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9711 - val_loss: 0.5455 - val_accuracy: 0.9605\n",
      "Epoch 623/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.9726 - val_loss: 0.5920 - val_accuracy: 0.9609\n",
      "Epoch 624/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9684 - val_loss: 0.6399 - val_accuracy: 0.9500\n",
      "Epoch 625/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9677 - val_loss: 0.6397 - val_accuracy: 0.9434\n",
      "Epoch 626/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9733 - val_loss: 0.6121 - val_accuracy: 0.9554\n",
      "Epoch 627/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.9714 - val_loss: 0.5854 - val_accuracy: 0.9736\n",
      "Epoch 628/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9706 - val_loss: 0.6573 - val_accuracy: 0.9674\n",
      "Epoch 629/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9730 - val_loss: 0.5837 - val_accuracy: 0.9709\n",
      "Epoch 630/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.9718 - val_loss: 0.5690 - val_accuracy: 0.9659\n",
      "Epoch 631/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.9724 - val_loss: 0.5933 - val_accuracy: 0.9655\n",
      "Epoch 632/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9719 - val_loss: 0.6222 - val_accuracy: 0.9616\n",
      "Epoch 633/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9701 - val_loss: 0.6539 - val_accuracy: 0.9574\n",
      "Epoch 634/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.9712 - val_loss: 0.5840 - val_accuracy: 0.9671\n",
      "Epoch 635/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9717 - val_loss: 0.5666 - val_accuracy: 0.9671\n",
      "Epoch 636/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9698 - val_loss: 0.5804 - val_accuracy: 0.9682\n",
      "Epoch 637/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.9717 - val_loss: 0.6456 - val_accuracy: 0.9516\n",
      "Epoch 638/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.9712 - val_loss: 0.6442 - val_accuracy: 0.9655\n",
      "Epoch 639/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9729 - val_loss: 0.6187 - val_accuracy: 0.9736\n",
      "Epoch 640/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9728 - val_loss: 0.6328 - val_accuracy: 0.9709\n",
      "Epoch 641/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9709 - val_loss: 0.6823 - val_accuracy: 0.9558\n",
      "Epoch 642/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1092 - accuracy: 0.9706 - val_loss: 0.6399 - val_accuracy: 0.9667\n",
      "Epoch 643/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9706 - val_loss: 0.6693 - val_accuracy: 0.9783\n",
      "Epoch 644/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.9694 - val_loss: 0.6853 - val_accuracy: 0.9663\n",
      "Epoch 645/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9724 - val_loss: 0.7217 - val_accuracy: 0.9624\n",
      "Epoch 646/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.9703 - val_loss: 0.6702 - val_accuracy: 0.9655\n",
      "Epoch 647/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9728 - val_loss: 0.5075 - val_accuracy: 0.9713\n",
      "Epoch 648/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9736 - val_loss: 0.5118 - val_accuracy: 0.9721\n",
      "Epoch 649/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9711 - val_loss: 0.5422 - val_accuracy: 0.9620\n",
      "Epoch 650/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.9714 - val_loss: 0.5591 - val_accuracy: 0.9574\n",
      "Epoch 651/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.9702 - val_loss: 0.5888 - val_accuracy: 0.9581\n",
      "Epoch 652/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9699 - val_loss: 0.5703 - val_accuracy: 0.9601\n",
      "Epoch 653/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9693 - val_loss: 0.2991 - val_accuracy: 0.9779\n",
      "Epoch 654/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9734 - val_loss: 0.3318 - val_accuracy: 0.9628\n",
      "Epoch 655/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9717 - val_loss: 0.3340 - val_accuracy: 0.9686\n",
      "Epoch 656/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9730 - val_loss: 0.3612 - val_accuracy: 0.9678\n",
      "Epoch 657/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9731 - val_loss: 0.3523 - val_accuracy: 0.9671\n",
      "Epoch 658/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9728 - val_loss: 0.4074 - val_accuracy: 0.9562\n",
      "Epoch 659/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1082 - accuracy: 0.9708 - val_loss: 0.3969 - val_accuracy: 0.9705\n",
      "Epoch 660/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9719 - val_loss: 0.3891 - val_accuracy: 0.9713\n",
      "Epoch 661/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.9705 - val_loss: 0.3836 - val_accuracy: 0.9733\n",
      "Epoch 662/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.3897 - val_accuracy: 0.9671\n",
      "Epoch 663/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9711 - val_loss: 0.3895 - val_accuracy: 0.9713\n",
      "Epoch 664/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9720 - val_loss: 0.3727 - val_accuracy: 0.9667\n",
      "Epoch 665/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9721 - val_loss: 0.4078 - val_accuracy: 0.9678\n",
      "Epoch 666/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9718 - val_loss: 0.4159 - val_accuracy: 0.9585\n",
      "Epoch 667/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9730 - val_loss: 0.3871 - val_accuracy: 0.9729\n",
      "Epoch 668/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9742 - val_loss: 0.4148 - val_accuracy: 0.9609\n",
      "Epoch 669/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.9714 - val_loss: 0.4332 - val_accuracy: 0.9709\n",
      "Epoch 670/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.9730 - val_loss: 0.4966 - val_accuracy: 0.9624\n",
      "Epoch 671/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9699 - val_loss: 0.5102 - val_accuracy: 0.9535\n",
      "Epoch 672/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.9739 - val_loss: 0.4920 - val_accuracy: 0.9609\n",
      "Epoch 673/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.9712 - val_loss: 0.4671 - val_accuracy: 0.9686\n",
      "Epoch 674/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.9722 - val_loss: 0.4977 - val_accuracy: 0.9643\n",
      "Epoch 675/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9740 - val_loss: 0.4662 - val_accuracy: 0.9767\n",
      "Epoch 676/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.9705 - val_loss: 0.4607 - val_accuracy: 0.9764\n",
      "Epoch 677/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.9697 - val_loss: 0.4576 - val_accuracy: 0.9756\n",
      "Epoch 678/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9747 - val_loss: 0.5461 - val_accuracy: 0.9512\n",
      "Epoch 679/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9715 - val_loss: 0.4807 - val_accuracy: 0.9682\n",
      "Epoch 680/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9727 - val_loss: 0.5254 - val_accuracy: 0.9512\n",
      "Epoch 681/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.9718 - val_loss: 0.4754 - val_accuracy: 0.9713\n",
      "Epoch 682/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9727 - val_loss: 0.4459 - val_accuracy: 0.9779\n",
      "Epoch 683/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9742 - val_loss: 0.4602 - val_accuracy: 0.9767\n",
      "Epoch 684/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9722 - val_loss: 0.4976 - val_accuracy: 0.9554\n",
      "Epoch 685/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.9703 - val_loss: 0.3938 - val_accuracy: 0.9767\n",
      "Epoch 686/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9708 - val_loss: 0.3852 - val_accuracy: 0.9764\n",
      "Epoch 687/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.9712 - val_loss: 0.4243 - val_accuracy: 0.9775\n",
      "Epoch 688/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9742 - val_loss: 1.0576 - val_accuracy: 0.9709\n",
      "Epoch 689/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1572 - accuracy: 0.9703 - val_loss: 0.4293 - val_accuracy: 0.9713\n",
      "Epoch 690/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0873 - accuracy: 0.9781 - val_loss: 0.4768 - val_accuracy: 0.9581\n",
      "Epoch 691/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9735 - val_loss: 0.4191 - val_accuracy: 0.9733\n",
      "Epoch 692/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9759 - val_loss: 0.4207 - val_accuracy: 0.9783\n",
      "Epoch 693/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9741 - val_loss: 0.4353 - val_accuracy: 0.9705\n",
      "Epoch 694/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9714 - val_loss: 0.4240 - val_accuracy: 0.9752\n",
      "Epoch 695/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9720 - val_loss: 0.4178 - val_accuracy: 0.9771\n",
      "Epoch 696/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.9728 - val_loss: 0.4564 - val_accuracy: 0.9624\n",
      "Epoch 697/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.9719 - val_loss: 0.4725 - val_accuracy: 0.9570\n",
      "Epoch 698/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9735 - val_loss: 0.4492 - val_accuracy: 0.9593\n",
      "Epoch 699/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9718 - val_loss: 0.4736 - val_accuracy: 0.9585\n",
      "Epoch 700/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9725 - val_loss: 0.4191 - val_accuracy: 0.9736\n",
      "Epoch 701/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9724 - val_loss: 0.4512 - val_accuracy: 0.9764\n",
      "Epoch 702/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9715 - val_loss: 0.6800 - val_accuracy: 0.9306\n",
      "Epoch 703/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9742 - val_loss: 0.5572 - val_accuracy: 0.9593\n",
      "Epoch 704/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9720 - val_loss: 0.5080 - val_accuracy: 0.9694\n",
      "Epoch 705/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9704 - val_loss: 0.5465 - val_accuracy: 0.9682\n",
      "Epoch 706/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9725 - val_loss: 0.4913 - val_accuracy: 0.9806\n",
      "Epoch 707/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9737 - val_loss: 0.5062 - val_accuracy: 0.9721\n",
      "Epoch 708/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9717 - val_loss: 0.5067 - val_accuracy: 0.9667\n",
      "Epoch 709/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9723 - val_loss: 0.4930 - val_accuracy: 0.9752\n",
      "Epoch 710/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9727 - val_loss: 0.5114 - val_accuracy: 0.9709\n",
      "Epoch 711/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9736 - val_loss: 0.5365 - val_accuracy: 0.9605\n",
      "Epoch 712/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.5179 - val_accuracy: 0.9783\n",
      "Epoch 713/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1011 - accuracy: 0.9733 - val_loss: 0.5571 - val_accuracy: 0.9667\n",
      "Epoch 714/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9752 - val_loss: 0.5414 - val_accuracy: 0.9686\n",
      "Epoch 715/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9722 - val_loss: 0.5706 - val_accuracy: 0.9581\n",
      "Epoch 716/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9733 - val_loss: 0.5840 - val_accuracy: 0.9535\n",
      "Epoch 717/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.9720 - val_loss: 0.5406 - val_accuracy: 0.9702\n",
      "Epoch 718/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9726 - val_loss: 0.5491 - val_accuracy: 0.9682\n",
      "Epoch 719/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9724 - val_loss: 0.5787 - val_accuracy: 0.9593\n",
      "Epoch 720/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9741 - val_loss: 0.5692 - val_accuracy: 0.9667\n",
      "Epoch 721/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9699 - val_loss: 0.5893 - val_accuracy: 0.9636\n",
      "Epoch 722/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9748 - val_loss: 0.5613 - val_accuracy: 0.9760\n",
      "Epoch 723/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9710 - val_loss: 0.5361 - val_accuracy: 0.9779\n",
      "Epoch 724/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9738 - val_loss: 0.5623 - val_accuracy: 0.9783\n",
      "Epoch 725/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9733 - val_loss: 0.5686 - val_accuracy: 0.9798\n",
      "Epoch 726/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9713 - val_loss: 0.5985 - val_accuracy: 0.9721\n",
      "Epoch 727/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9711 - val_loss: 0.6112 - val_accuracy: 0.9733\n",
      "Epoch 728/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.9716 - val_loss: 0.4108 - val_accuracy: 0.9729\n",
      "Epoch 729/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0937 - accuracy: 0.9739 - val_loss: 0.4163 - val_accuracy: 0.9729\n",
      "Epoch 730/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9729 - val_loss: 0.4408 - val_accuracy: 0.9674\n",
      "Epoch 731/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.4289 - val_accuracy: 0.9702\n",
      "Epoch 732/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9735 - val_loss: 0.4347 - val_accuracy: 0.9802\n",
      "Epoch 733/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9757 - val_loss: 0.4392 - val_accuracy: 0.9779\n",
      "Epoch 734/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9726 - val_loss: 0.4535 - val_accuracy: 0.9686\n",
      "Epoch 735/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9729 - val_loss: 0.5757 - val_accuracy: 0.9426\n",
      "Epoch 736/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0961 - accuracy: 0.9733 - val_loss: 0.4873 - val_accuracy: 0.9585\n",
      "Epoch 737/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9748 - val_loss: 0.5645 - val_accuracy: 0.9419\n",
      "Epoch 738/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9721 - val_loss: 0.4385 - val_accuracy: 0.9705\n",
      "Epoch 739/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1062 - accuracy: 0.9708 - val_loss: 0.4518 - val_accuracy: 0.9756\n",
      "Epoch 740/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9719 - val_loss: 0.4472 - val_accuracy: 0.9721\n",
      "Epoch 741/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9720 - val_loss: 0.4308 - val_accuracy: 0.9826\n",
      "Epoch 742/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9721 - val_loss: 0.4402 - val_accuracy: 0.9740\n",
      "Epoch 743/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9737 - val_loss: 0.4511 - val_accuracy: 0.9717\n",
      "Epoch 744/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9737 - val_loss: 0.4457 - val_accuracy: 0.9744\n",
      "Epoch 745/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9745 - val_loss: 0.4227 - val_accuracy: 0.9806\n",
      "Epoch 746/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9739 - val_loss: 0.5749 - val_accuracy: 0.9655\n",
      "Epoch 747/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9733 - val_loss: 0.2496 - val_accuracy: 0.9709\n",
      "Epoch 748/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9712 - val_loss: 0.2753 - val_accuracy: 0.9659\n",
      "Epoch 749/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9716 - val_loss: 0.2880 - val_accuracy: 0.9771\n",
      "Epoch 750/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9728 - val_loss: 0.3233 - val_accuracy: 0.9616\n",
      "Epoch 751/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.9705 - val_loss: 0.2837 - val_accuracy: 0.9748\n",
      "Epoch 752/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9735 - val_loss: 0.3231 - val_accuracy: 0.9744\n",
      "Epoch 753/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9745 - val_loss: 0.3063 - val_accuracy: 0.9674\n",
      "Epoch 754/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9730 - val_loss: 0.3004 - val_accuracy: 0.9705\n",
      "Epoch 755/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9741 - val_loss: 0.3124 - val_accuracy: 0.9709\n",
      "Epoch 756/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.9728 - val_loss: 0.3228 - val_accuracy: 0.9698\n",
      "Epoch 757/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9747 - val_loss: 0.2937 - val_accuracy: 0.9702\n",
      "Epoch 758/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.9747 - val_loss: 0.2486 - val_accuracy: 0.9783\n",
      "Epoch 759/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9748 - val_loss: 0.3180 - val_accuracy: 0.9612\n",
      "Epoch 760/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9740 - val_loss: 0.2982 - val_accuracy: 0.9744\n",
      "Epoch 761/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9749 - val_loss: 0.3134 - val_accuracy: 0.9725\n",
      "Epoch 762/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9722 - val_loss: 0.2994 - val_accuracy: 0.9717\n",
      "Epoch 763/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9734 - val_loss: 0.3138 - val_accuracy: 0.9783\n",
      "Epoch 764/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9752 - val_loss: 0.3122 - val_accuracy: 0.9798\n",
      "Epoch 765/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9745 - val_loss: 0.4167 - val_accuracy: 0.9562\n",
      "Epoch 766/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9736 - val_loss: 0.3568 - val_accuracy: 0.9713\n",
      "Epoch 767/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9736 - val_loss: 0.3684 - val_accuracy: 0.9736\n",
      "Epoch 768/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0939 - accuracy: 0.9748 - val_loss: 0.3990 - val_accuracy: 0.9787\n",
      "Epoch 769/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9711 - val_loss: 0.4017 - val_accuracy: 0.9655\n",
      "Epoch 770/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9716 - val_loss: 0.4404 - val_accuracy: 0.9574\n",
      "Epoch 771/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9735 - val_loss: 0.4026 - val_accuracy: 0.9740\n",
      "Epoch 772/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9733 - val_loss: 0.4690 - val_accuracy: 0.9682\n",
      "Epoch 773/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9743 - val_loss: 0.4219 - val_accuracy: 0.9783\n",
      "Epoch 774/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.4096 - val_accuracy: 0.9760\n",
      "Epoch 775/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9740 - val_loss: 0.4439 - val_accuracy: 0.9694\n",
      "Epoch 776/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9752 - val_loss: 0.4017 - val_accuracy: 0.9775\n",
      "Epoch 777/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9725 - val_loss: 0.4902 - val_accuracy: 0.9678\n",
      "Epoch 778/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.4515 - val_accuracy: 0.9760\n",
      "Epoch 779/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9732 - val_loss: 0.4049 - val_accuracy: 0.9810\n",
      "Epoch 780/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.4106 - val_accuracy: 0.9752\n",
      "Epoch 781/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9743 - val_loss: 0.4286 - val_accuracy: 0.9705\n",
      "Epoch 782/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0937 - accuracy: 0.9729 - val_loss: 0.4630 - val_accuracy: 0.9682\n",
      "Epoch 783/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9730 - val_loss: 0.4625 - val_accuracy: 0.9791\n",
      "Epoch 784/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9740 - val_loss: 0.4771 - val_accuracy: 0.9767\n",
      "Epoch 785/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.4652 - val_accuracy: 0.9764\n",
      "Epoch 786/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9732 - val_loss: 0.4918 - val_accuracy: 0.9756\n",
      "Epoch 787/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9745 - val_loss: 0.4779 - val_accuracy: 0.9767\n",
      "Epoch 788/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9735 - val_loss: 0.5148 - val_accuracy: 0.9690\n",
      "Epoch 789/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9726 - val_loss: 0.5210 - val_accuracy: 0.9810\n",
      "Epoch 790/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9751 - val_loss: 0.5450 - val_accuracy: 0.9736\n",
      "Epoch 791/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9740 - val_loss: 0.4172 - val_accuracy: 0.9702\n",
      "Epoch 792/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9762 - val_loss: 0.4740 - val_accuracy: 0.9616\n",
      "Epoch 793/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9732 - val_loss: 0.4987 - val_accuracy: 0.9531\n",
      "Epoch 794/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9713 - val_loss: 0.4910 - val_accuracy: 0.9667\n",
      "Epoch 795/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9751 - val_loss: 0.4690 - val_accuracy: 0.9791\n",
      "Epoch 796/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.9757 - val_loss: 0.4581 - val_accuracy: 0.9674\n",
      "Epoch 797/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0961 - accuracy: 0.9717 - val_loss: 0.4532 - val_accuracy: 0.9767\n",
      "Epoch 798/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9757 - val_loss: 0.4689 - val_accuracy: 0.9752\n",
      "Epoch 799/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9762 - val_loss: 0.4472 - val_accuracy: 0.9756\n",
      "Epoch 800/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9728 - val_loss: 0.4697 - val_accuracy: 0.9752\n",
      "Epoch 801/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.9746 - val_loss: 0.4891 - val_accuracy: 0.9632\n",
      "Epoch 802/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9753 - val_loss: 0.4535 - val_accuracy: 0.9818\n",
      "Epoch 803/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9730 - val_loss: 0.5041 - val_accuracy: 0.9647\n",
      "Epoch 804/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9755 - val_loss: 0.4753 - val_accuracy: 0.9779\n",
      "Epoch 805/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 0.4982 - val_accuracy: 0.9767\n",
      "Epoch 806/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9738 - val_loss: 0.4937 - val_accuracy: 0.9705\n",
      "Epoch 807/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9737 - val_loss: 0.4862 - val_accuracy: 0.9775\n",
      "Epoch 808/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9741 - val_loss: 0.5455 - val_accuracy: 0.9547\n",
      "Epoch 809/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.5329 - val_accuracy: 0.9616\n",
      "Epoch 810/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9714 - val_loss: 0.4971 - val_accuracy: 0.9709\n",
      "Epoch 811/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9747 - val_loss: 0.5340 - val_accuracy: 0.9643\n",
      "Epoch 812/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0875 - accuracy: 0.9765 - val_loss: 0.4650 - val_accuracy: 0.9795\n",
      "Epoch 813/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9750 - val_loss: 0.4662 - val_accuracy: 0.9822\n",
      "Epoch 814/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9752 - val_loss: 0.5386 - val_accuracy: 0.9756\n",
      "Epoch 815/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9734 - val_loss: 0.5105 - val_accuracy: 0.9752\n",
      "Epoch 816/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9728 - val_loss: 0.5950 - val_accuracy: 0.9570\n",
      "Epoch 817/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9733 - val_loss: 0.5395 - val_accuracy: 0.9628\n",
      "Epoch 818/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9740 - val_loss: 0.5847 - val_accuracy: 0.9744\n",
      "Epoch 819/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9741 - val_loss: 0.5981 - val_accuracy: 0.9725\n",
      "Epoch 820/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9736 - val_loss: 0.6283 - val_accuracy: 0.9667\n",
      "Epoch 821/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9755 - val_loss: 0.5979 - val_accuracy: 0.9748\n",
      "Epoch 822/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9739 - val_loss: 0.5759 - val_accuracy: 0.9810\n",
      "Epoch 823/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9733 - val_loss: 0.6331 - val_accuracy: 0.9674\n",
      "Epoch 824/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0981 - accuracy: 0.9734 - val_loss: 0.6288 - val_accuracy: 0.9729\n",
      "Epoch 825/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9737 - val_loss: 0.6862 - val_accuracy: 0.9705\n",
      "Epoch 826/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9712 - val_loss: 0.6745 - val_accuracy: 0.9721\n",
      "Epoch 827/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9751 - val_loss: 0.6629 - val_accuracy: 0.9837\n",
      "Epoch 828/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.6597 - val_accuracy: 0.9725\n",
      "Epoch 829/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9734 - val_loss: 0.6697 - val_accuracy: 0.9740\n",
      "Epoch 830/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9752 - val_loss: 0.6505 - val_accuracy: 0.9802\n",
      "Epoch 831/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9752 - val_loss: 0.7195 - val_accuracy: 0.9624\n",
      "Epoch 832/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9731 - val_loss: 0.6583 - val_accuracy: 0.9798\n",
      "Epoch 833/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9732 - val_loss: 0.6483 - val_accuracy: 0.9760\n",
      "Epoch 834/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9739 - val_loss: 0.6479 - val_accuracy: 0.9690\n",
      "Epoch 835/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9758 - val_loss: 0.6548 - val_accuracy: 0.9717\n",
      "Epoch 836/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9723 - val_loss: 0.6540 - val_accuracy: 0.9709\n",
      "Epoch 837/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9746 - val_loss: 0.6523 - val_accuracy: 0.9783\n",
      "Epoch 838/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9719 - val_loss: 0.6686 - val_accuracy: 0.9678\n",
      "Epoch 839/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9742 - val_loss: 0.6460 - val_accuracy: 0.9764\n",
      "Epoch 840/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9740 - val_loss: 0.6926 - val_accuracy: 0.9690\n",
      "Epoch 841/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9714 - val_loss: 0.6553 - val_accuracy: 0.9829\n",
      "Epoch 842/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9742 - val_loss: 0.8526 - val_accuracy: 0.9496\n",
      "Epoch 843/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0975 - accuracy: 0.9741 - val_loss: 0.7627 - val_accuracy: 0.9682\n",
      "Epoch 844/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9765 - val_loss: 0.7989 - val_accuracy: 0.9574\n",
      "Epoch 845/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0889 - accuracy: 0.9751 - val_loss: 0.7494 - val_accuracy: 0.9605\n",
      "Epoch 846/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9735 - val_loss: 0.7322 - val_accuracy: 0.9721\n",
      "Epoch 847/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9736 - val_loss: 0.5316 - val_accuracy: 0.9826\n",
      "Epoch 848/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0868 - accuracy: 0.9766 - val_loss: 0.6311 - val_accuracy: 0.9574\n",
      "Epoch 849/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9748 - val_loss: 0.5879 - val_accuracy: 0.9733\n",
      "Epoch 850/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9735 - val_loss: 0.6305 - val_accuracy: 0.9674\n",
      "Epoch 851/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9733 - val_loss: 0.6011 - val_accuracy: 0.9760\n",
      "Epoch 852/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9751 - val_loss: 0.5947 - val_accuracy: 0.9760\n",
      "Epoch 853/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9747 - val_loss: 0.6239 - val_accuracy: 0.9729\n",
      "Epoch 854/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9727 - val_loss: 0.6037 - val_accuracy: 0.9744\n",
      "Epoch 855/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9756 - val_loss: 0.5939 - val_accuracy: 0.9775\n",
      "Epoch 856/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9742 - val_loss: 0.5957 - val_accuracy: 0.9779\n",
      "Epoch 857/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9751 - val_loss: 0.5986 - val_accuracy: 0.9748\n",
      "Epoch 858/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9756 - val_loss: 0.5989 - val_accuracy: 0.9756\n",
      "Epoch 859/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9760 - val_loss: 0.5898 - val_accuracy: 0.9748\n",
      "Epoch 860/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0883 - accuracy: 0.9758 - val_loss: 0.6243 - val_accuracy: 0.9690\n",
      "Epoch 861/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9759 - val_loss: 0.6383 - val_accuracy: 0.9717\n",
      "Epoch 862/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9737 - val_loss: 0.7068 - val_accuracy: 0.9516\n",
      "Epoch 863/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9748 - val_loss: 0.5979 - val_accuracy: 0.9783\n",
      "Epoch 864/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9719 - val_loss: 0.6769 - val_accuracy: 0.9717\n",
      "Epoch 865/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9723 - val_loss: 0.6227 - val_accuracy: 0.9822\n",
      "Epoch 866/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.9740 - val_loss: 0.7269 - val_accuracy: 0.9624\n",
      "Epoch 867/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 0.6703 - val_accuracy: 0.9694\n",
      "Epoch 868/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9752 - val_loss: 0.6882 - val_accuracy: 0.9733\n",
      "Epoch 869/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9752 - val_loss: 0.6599 - val_accuracy: 0.9775\n",
      "Epoch 870/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9736 - val_loss: 0.6479 - val_accuracy: 0.9853\n",
      "Epoch 871/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9748 - val_loss: 0.6483 - val_accuracy: 0.9760\n",
      "Epoch 872/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9741 - val_loss: 0.6618 - val_accuracy: 0.9810\n",
      "Epoch 873/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0881 - accuracy: 0.9753 - val_loss: 0.6519 - val_accuracy: 0.9771\n",
      "Epoch 874/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9750 - val_loss: 0.6197 - val_accuracy: 0.9705\n",
      "Epoch 875/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9736 - val_loss: 0.6502 - val_accuracy: 0.9655\n",
      "Epoch 876/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9731 - val_loss: 0.7329 - val_accuracy: 0.9764\n",
      "Epoch 877/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9774 - val_loss: 0.7234 - val_accuracy: 0.9791\n",
      "Epoch 878/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9745 - val_loss: 0.7322 - val_accuracy: 0.9795\n",
      "Epoch 879/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9738 - val_loss: 0.7472 - val_accuracy: 0.9709\n",
      "Epoch 880/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9742 - val_loss: 0.7354 - val_accuracy: 0.9818\n",
      "Epoch 881/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9743 - val_loss: 0.7530 - val_accuracy: 0.9833\n",
      "Epoch 882/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9754 - val_loss: 0.8274 - val_accuracy: 0.9585\n",
      "Epoch 883/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9737 - val_loss: 0.7714 - val_accuracy: 0.9733\n",
      "Epoch 884/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9729 - val_loss: 0.8505 - val_accuracy: 0.9597\n",
      "Epoch 885/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9767 - val_loss: 0.7989 - val_accuracy: 0.9736\n",
      "Epoch 886/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9721 - val_loss: 0.7844 - val_accuracy: 0.9729\n",
      "Epoch 887/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9765 - val_loss: 0.7937 - val_accuracy: 0.9767\n",
      "Epoch 888/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9764 - val_loss: 0.7742 - val_accuracy: 0.9764\n",
      "Epoch 889/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9746 - val_loss: 0.8677 - val_accuracy: 0.9740\n",
      "Epoch 890/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9741 - val_loss: 0.9606 - val_accuracy: 0.9539\n",
      "Epoch 891/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0830 - accuracy: 0.9768 - val_loss: 0.8476 - val_accuracy: 0.9806\n",
      "Epoch 892/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9734 - val_loss: 0.9148 - val_accuracy: 0.9547\n",
      "Epoch 893/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9721 - val_loss: 1.0852 - val_accuracy: 0.9457\n",
      "Epoch 894/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9726 - val_loss: 0.7458 - val_accuracy: 0.9717\n",
      "Epoch 895/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9750 - val_loss: 0.8143 - val_accuracy: 0.9659\n",
      "Epoch 896/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9722 - val_loss: 0.7147 - val_accuracy: 0.9752\n",
      "Epoch 897/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9752 - val_loss: 0.7956 - val_accuracy: 0.9814\n",
      "Epoch 898/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9769 - val_loss: 0.8496 - val_accuracy: 0.9663\n",
      "Epoch 899/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9724 - val_loss: 0.8167 - val_accuracy: 0.9795\n",
      "Epoch 900/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9764 - val_loss: 0.5741 - val_accuracy: 0.9686\n",
      "Epoch 901/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0881 - accuracy: 0.9756 - val_loss: 0.6172 - val_accuracy: 0.9570\n",
      "Epoch 902/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0917 - accuracy: 0.9762 - val_loss: 0.5555 - val_accuracy: 0.9849\n",
      "Epoch 903/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9740 - val_loss: 0.5865 - val_accuracy: 0.9733\n",
      "Epoch 904/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0889 - accuracy: 0.9776 - val_loss: 0.2849 - val_accuracy: 0.9686\n",
      "Epoch 905/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0804 - accuracy: 0.9776 - val_loss: 0.2671 - val_accuracy: 0.9748\n",
      "Epoch 906/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9725 - val_loss: 0.2956 - val_accuracy: 0.9717\n",
      "Epoch 907/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9756 - val_loss: 0.2957 - val_accuracy: 0.9779\n",
      "Epoch 908/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9758 - val_loss: 0.3208 - val_accuracy: 0.9760\n",
      "Epoch 909/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.9730 - val_loss: 0.3286 - val_accuracy: 0.9678\n",
      "Epoch 910/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9741 - val_loss: 0.3231 - val_accuracy: 0.9752\n",
      "Epoch 911/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9742 - val_loss: 0.3503 - val_accuracy: 0.9709\n",
      "Epoch 912/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9732 - val_loss: 0.4145 - val_accuracy: 0.9535\n",
      "Epoch 913/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.4201 - val_accuracy: 0.9620\n",
      "Epoch 914/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9761 - val_loss: 0.3513 - val_accuracy: 0.9756\n",
      "Epoch 915/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9768 - val_loss: 0.3814 - val_accuracy: 0.9709\n",
      "Epoch 916/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9747 - val_loss: 0.3098 - val_accuracy: 0.9760\n",
      "Epoch 917/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9760 - val_loss: 0.3303 - val_accuracy: 0.9818\n",
      "Epoch 918/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9725 - val_loss: 0.3666 - val_accuracy: 0.9760\n",
      "Epoch 919/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9746 - val_loss: 0.3946 - val_accuracy: 0.9725\n",
      "Epoch 920/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9769 - val_loss: 0.5000 - val_accuracy: 0.9783\n",
      "Epoch 921/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9761 - val_loss: 0.4973 - val_accuracy: 0.9826\n",
      "Epoch 922/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9724 - val_loss: 0.5039 - val_accuracy: 0.9748\n",
      "Epoch 923/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9739 - val_loss: 0.5207 - val_accuracy: 0.9682\n",
      "Epoch 924/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9758 - val_loss: 0.5704 - val_accuracy: 0.9690\n",
      "Epoch 925/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0915 - accuracy: 0.9746 - val_loss: 0.5189 - val_accuracy: 0.9659\n",
      "Epoch 926/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9737 - val_loss: 0.5149 - val_accuracy: 0.9713\n",
      "Epoch 927/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9741 - val_loss: 0.5486 - val_accuracy: 0.9748\n",
      "Epoch 928/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9751 - val_loss: 0.6345 - val_accuracy: 0.9539\n",
      "Epoch 929/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9767 - val_loss: 0.5341 - val_accuracy: 0.9818\n",
      "Epoch 930/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0918 - accuracy: 0.9730 - val_loss: 0.5250 - val_accuracy: 0.9791\n",
      "Epoch 931/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0843 - accuracy: 0.9770 - val_loss: 0.7190 - val_accuracy: 0.9376\n",
      "Epoch 932/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9745 - val_loss: 0.5395 - val_accuracy: 0.9748\n",
      "Epoch 933/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9754 - val_loss: 0.5502 - val_accuracy: 0.9721\n",
      "Epoch 934/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9748 - val_loss: 0.4235 - val_accuracy: 0.9671\n",
      "Epoch 935/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9793 - val_loss: 0.4659 - val_accuracy: 0.9612\n",
      "Epoch 936/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9759 - val_loss: 0.4332 - val_accuracy: 0.9686\n",
      "Epoch 937/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0918 - accuracy: 0.9736 - val_loss: 0.4277 - val_accuracy: 0.9686\n",
      "Epoch 938/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9774 - val_loss: 0.4296 - val_accuracy: 0.9740\n",
      "Epoch 939/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9736 - val_loss: 0.4567 - val_accuracy: 0.9609\n",
      "Epoch 940/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9761 - val_loss: 0.3953 - val_accuracy: 0.9798\n",
      "Epoch 941/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0967 - accuracy: 0.9736 - val_loss: 0.4052 - val_accuracy: 0.9779\n",
      "Epoch 942/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9763 - val_loss: 0.4369 - val_accuracy: 0.9686\n",
      "Epoch 943/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9729 - val_loss: 0.4083 - val_accuracy: 0.9736\n",
      "Epoch 944/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0846 - accuracy: 0.9764 - val_loss: 0.4415 - val_accuracy: 0.9721\n",
      "Epoch 945/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9747 - val_loss: 0.4559 - val_accuracy: 0.9733\n",
      "Epoch 946/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9761 - val_loss: 0.4663 - val_accuracy: 0.9760\n",
      "Epoch 947/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9756 - val_loss: 0.4676 - val_accuracy: 0.9795\n",
      "Epoch 948/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9764 - val_loss: 0.4991 - val_accuracy: 0.9729\n",
      "Epoch 949/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9756 - val_loss: 0.5533 - val_accuracy: 0.9733\n",
      "Epoch 950/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.9761 - val_loss: 0.6072 - val_accuracy: 0.9601\n",
      "Epoch 951/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9775 - val_loss: 0.5578 - val_accuracy: 0.9756\n",
      "Epoch 952/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9758 - val_loss: 0.6010 - val_accuracy: 0.9694\n",
      "Epoch 953/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9754 - val_loss: 0.5589 - val_accuracy: 0.9756\n",
      "Epoch 954/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9752 - val_loss: 0.5671 - val_accuracy: 0.9709\n",
      "Epoch 955/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 0.5420 - val_accuracy: 0.9674\n",
      "Epoch 956/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9765 - val_loss: 0.5487 - val_accuracy: 0.9740\n",
      "Epoch 957/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9721 - val_loss: 0.5695 - val_accuracy: 0.9667\n",
      "Epoch 958/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0874 - accuracy: 0.9764 - val_loss: 0.5744 - val_accuracy: 0.9744\n",
      "Epoch 959/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9745 - val_loss: 0.6385 - val_accuracy: 0.9589\n",
      "Epoch 960/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9736 - val_loss: 0.5688 - val_accuracy: 0.9771\n",
      "Epoch 961/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9770 - val_loss: 0.5978 - val_accuracy: 0.9721\n",
      "Epoch 962/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9757 - val_loss: 0.7116 - val_accuracy: 0.9562\n",
      "Epoch 963/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.9770 - val_loss: 0.6850 - val_accuracy: 0.9775\n",
      "Epoch 964/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9751 - val_loss: 0.4286 - val_accuracy: 0.9698\n",
      "Epoch 965/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9757 - val_loss: 0.3962 - val_accuracy: 0.9775\n",
      "Epoch 966/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9752 - val_loss: 0.3834 - val_accuracy: 0.9841\n",
      "Epoch 967/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9754 - val_loss: 0.4758 - val_accuracy: 0.9585\n",
      "Epoch 968/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9749 - val_loss: 0.4079 - val_accuracy: 0.9713\n",
      "Epoch 969/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9737 - val_loss: 0.4038 - val_accuracy: 0.9713\n",
      "Epoch 970/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9762 - val_loss: 0.3575 - val_accuracy: 0.9814\n",
      "Epoch 971/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0855 - accuracy: 0.9767 - val_loss: 0.3927 - val_accuracy: 0.9694\n",
      "Epoch 972/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9746 - val_loss: 0.3437 - val_accuracy: 0.9822\n",
      "Epoch 973/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9746 - val_loss: 0.3823 - val_accuracy: 0.9647\n",
      "Epoch 974/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9767 - val_loss: 0.3399 - val_accuracy: 0.9810\n",
      "Epoch 975/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9762 - val_loss: 0.3613 - val_accuracy: 0.9783\n",
      "Epoch 976/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9742 - val_loss: 0.4005 - val_accuracy: 0.9748\n",
      "Epoch 977/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0831 - accuracy: 0.9765 - val_loss: 0.4490 - val_accuracy: 0.9605\n",
      "Epoch 978/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0875 - accuracy: 0.9755 - val_loss: 0.3852 - val_accuracy: 0.9798\n",
      "Epoch 979/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9771 - val_loss: 0.4402 - val_accuracy: 0.9713\n",
      "Epoch 980/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9745 - val_loss: 0.5848 - val_accuracy: 0.9605\n",
      "Epoch 981/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0845 - accuracy: 0.9754 - val_loss: 0.5129 - val_accuracy: 0.9829\n",
      "Epoch 982/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0893 - accuracy: 0.9752 - val_loss: 0.5087 - val_accuracy: 0.9756\n",
      "Epoch 983/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9748 - val_loss: 0.5266 - val_accuracy: 0.9663\n",
      "Epoch 984/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.5276 - val_accuracy: 0.9729\n",
      "Epoch 985/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9740 - val_loss: 0.6610 - val_accuracy: 0.9504\n",
      "Epoch 986/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9755 - val_loss: 0.5586 - val_accuracy: 0.9671\n",
      "Epoch 987/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.9768 - val_loss: 0.5161 - val_accuracy: 0.9783\n",
      "Epoch 988/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0789 - accuracy: 0.9777 - val_loss: 0.5414 - val_accuracy: 0.9733\n",
      "Epoch 989/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9731 - val_loss: 0.5329 - val_accuracy: 0.9620\n",
      "Epoch 990/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0764 - accuracy: 0.9790 - val_loss: 0.4617 - val_accuracy: 0.9787\n",
      "Epoch 991/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9764 - val_loss: 0.5004 - val_accuracy: 0.9663\n",
      "Epoch 992/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9767 - val_loss: 0.4576 - val_accuracy: 0.9795\n",
      "Epoch 993/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0773 - accuracy: 0.9784 - val_loss: 0.5217 - val_accuracy: 0.9547\n",
      "Epoch 994/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0810 - accuracy: 0.9780 - val_loss: 0.4678 - val_accuracy: 0.9764\n",
      "Epoch 995/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9750 - val_loss: 0.4758 - val_accuracy: 0.9744\n",
      "Epoch 996/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0854 - accuracy: 0.9759 - val_loss: 0.4495 - val_accuracy: 0.9818\n",
      "Epoch 997/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9765 - val_loss: 0.5979 - val_accuracy: 0.9450\n",
      "Epoch 998/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9742 - val_loss: 0.4883 - val_accuracy: 0.9798\n",
      "Epoch 999/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9764 - val_loss: 0.4594 - val_accuracy: 0.9798\n",
      "Epoch 1000/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9753 - val_loss: 0.5119 - val_accuracy: 0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses, leaky_re_lu_4_layer_call_fn, leaky_re_lu_4_layer_call_and_return_conditional_losses, leaky_re_lu_5_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/exp_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/exp_class\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 32s\n",
      "Wall time: 16min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/exp_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.5), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d48b8bb-4050-4e4e-9b5d-f544ec904945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 773us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29de131-b034-4c2b-af37-24c452d2eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb94e0-76ea-48a8-9201-bb3798b826a2",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "380a789e-6c82-431c-bc0d-61f8c449e71a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95455   1.00000   0.97674        21\n",
      "           1    0.94444   0.94444   0.94444        18\n",
      "           2    1.00000   0.95652   0.97778        23\n",
      "           3    1.00000   1.00000   1.00000        20\n",
      "           4    1.00000   1.00000   1.00000        23\n",
      "           5    1.00000   0.50000   0.66667        20\n",
      "           6    1.00000   0.95652   0.97778        23\n",
      "           7    1.00000   1.00000   1.00000        25\n",
      "           8    1.00000   1.00000   1.00000        25\n",
      "           9    1.00000   1.00000   1.00000        13\n",
      "          10    0.65714   1.00000   0.79310        23\n",
      "          11    1.00000   0.94118   0.96970        17\n",
      "          12    1.00000   0.93750   0.96774        16\n",
      "          13    0.93939   1.00000   0.96875        31\n",
      "          14    1.00000   1.00000   1.00000        30\n",
      "          15    1.00000   1.00000   1.00000        19\n",
      "          16    1.00000   1.00000   1.00000        25\n",
      "          17    1.00000   1.00000   1.00000        17\n",
      "          18    0.94737   0.90000   0.92308        20\n",
      "          19    0.88235   0.93750   0.90909        16\n",
      "          20    1.00000   0.89474   0.94444        19\n",
      "          21    1.00000   1.00000   1.00000        21\n",
      "          22    1.00000   1.00000   1.00000        18\n",
      "          23    1.00000   1.00000   1.00000        14\n",
      "          24    1.00000   0.95238   0.97561        21\n",
      "          25    1.00000   0.95238   0.97561        21\n",
      "          26    1.00000   1.00000   1.00000        13\n",
      "          27    1.00000   0.96000   0.97959        25\n",
      "          28    0.96429   1.00000   0.98182        27\n",
      "          29    1.00000   1.00000   1.00000        24\n",
      "          30    1.00000   1.00000   1.00000        21\n",
      "          31    1.00000   0.95238   0.97561        21\n",
      "          32    1.00000   1.00000   1.00000        18\n",
      "          33    1.00000   1.00000   1.00000        22\n",
      "          34    0.70833   0.94444   0.80952        18\n",
      "          35    1.00000   1.00000   1.00000        10\n",
      "          36    1.00000   1.00000   1.00000        27\n",
      "          37    0.76000   0.90476   0.82609        21\n",
      "          38    1.00000   0.95000   0.97436        20\n",
      "          39    1.00000   1.00000   1.00000        15\n",
      "          40    1.00000   0.94737   0.97297        19\n",
      "          41    1.00000   1.00000   1.00000        12\n",
      "          42    1.00000   1.00000   1.00000        30\n",
      "          43    0.87500   0.56000   0.68293        25\n",
      "          44    1.00000   0.95455   0.97674        22\n",
      "          45    1.00000   0.95652   0.97778        23\n",
      "          46    1.00000   1.00000   1.00000        14\n",
      "          47    1.00000   1.00000   1.00000        17\n",
      "          48    0.95238   1.00000   0.97561        20\n",
      "          49    1.00000   0.95238   0.97561        21\n",
      "          50    1.00000   1.00000   1.00000        25\n",
      "          51    1.00000   1.00000   1.00000        22\n",
      "          52    0.91667   0.61111   0.73333        18\n",
      "          53    1.00000   1.00000   1.00000        25\n",
      "          54    1.00000   1.00000   1.00000        22\n",
      "          55    0.92857   1.00000   0.96296        13\n",
      "          56    1.00000   1.00000   1.00000        21\n",
      "          57    0.96429   0.96429   0.96429        28\n",
      "          58    0.82353   1.00000   0.90323        14\n",
      "          59    0.96296   1.00000   0.98113        26\n",
      "          60    1.00000   0.88235   0.93750        17\n",
      "          61    1.00000   1.00000   1.00000        16\n",
      "          62    1.00000   1.00000   1.00000        17\n",
      "          63    1.00000   1.00000   1.00000        25\n",
      "          64    1.00000   1.00000   1.00000        13\n",
      "          65    1.00000   1.00000   1.00000        17\n",
      "          66    1.00000   0.95000   0.97436        20\n",
      "          67    1.00000   1.00000   1.00000        12\n",
      "          68    1.00000   1.00000   1.00000        21\n",
      "          69    1.00000   1.00000   1.00000        18\n",
      "          70    1.00000   1.00000   1.00000        14\n",
      "          71    1.00000   1.00000   1.00000        19\n",
      "          72    1.00000   1.00000   1.00000        11\n",
      "          73    1.00000   1.00000   1.00000        20\n",
      "          74    1.00000   1.00000   1.00000        23\n",
      "          75    1.00000   1.00000   1.00000        27\n",
      "          76    1.00000   1.00000   1.00000        23\n",
      "          77    1.00000   0.85714   0.92308        21\n",
      "          78    1.00000   0.90000   0.94737        20\n",
      "          79    1.00000   1.00000   1.00000        24\n",
      "          80    1.00000   1.00000   1.00000        19\n",
      "          81    1.00000   1.00000   1.00000        14\n",
      "          82    1.00000   1.00000   1.00000        20\n",
      "          83    1.00000   0.95000   0.97436        20\n",
      "          84    0.91667   0.95652   0.93617        23\n",
      "          85    1.00000   1.00000   1.00000        23\n",
      "          86    1.00000   1.00000   1.00000        19\n",
      "          87    0.95238   1.00000   0.97561        20\n",
      "          88    0.95000   1.00000   0.97436        19\n",
      "          89    1.00000   1.00000   1.00000        20\n",
      "          90    1.00000   1.00000   1.00000        22\n",
      "          91    1.00000   1.00000   1.00000        19\n",
      "          92    1.00000   1.00000   1.00000        12\n",
      "          93    1.00000   1.00000   1.00000        19\n",
      "          94    1.00000   0.92000   0.95833        25\n",
      "          95    1.00000   1.00000   1.00000        17\n",
      "          96    0.96154   0.89286   0.92593        28\n",
      "          97    0.75000   0.94737   0.83721        19\n",
      "          98    0.91304   1.00000   0.95455        21\n",
      "          99    1.00000   0.95833   0.97872        24\n",
      "         100    1.00000   0.80000   0.88889        15\n",
      "         101    1.00000   0.94118   0.96970        17\n",
      "         102    1.00000   0.92000   0.95833        25\n",
      "         103    1.00000   1.00000   1.00000        21\n",
      "         104    0.34783   1.00000   0.51613        16\n",
      "         105    1.00000   0.93333   0.96552        15\n",
      "         106    1.00000   1.00000   1.00000        15\n",
      "         107    1.00000   1.00000   1.00000        18\n",
      "         108    1.00000   0.77273   0.87179        22\n",
      "         109    1.00000   0.69565   0.82051        23\n",
      "         110    1.00000   1.00000   1.00000        28\n",
      "         111    1.00000   0.95833   0.97872        24\n",
      "         112    0.88235   0.88235   0.88235        17\n",
      "         113    1.00000   0.57895   0.73333        19\n",
      "         114    1.00000   1.00000   1.00000        14\n",
      "         115    0.62963   0.89474   0.73913        19\n",
      "         116    1.00000   1.00000   1.00000        17\n",
      "         117    1.00000   1.00000   1.00000        11\n",
      "         118    0.57143   0.70588   0.63158        17\n",
      "         119    1.00000   0.56000   0.71795        25\n",
      "         120    1.00000   0.95455   0.97674        22\n",
      "         121    0.68421   0.92857   0.78788        28\n",
      "         122    1.00000   1.00000   1.00000        14\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   1.00000   1.00000        24\n",
      "         125    0.94118   1.00000   0.96970        16\n",
      "         126    1.00000   1.00000   1.00000        17\n",
      "         127    1.00000   0.95455   0.97674        22\n",
      "         128    1.00000   1.00000   1.00000        22\n",
      "\n",
      "    accuracy                        0.95349      2580\n",
      "   macro avg    0.96652   0.95524   0.95587      2580\n",
      "weighted avg    0.96711   0.95349   0.95531      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f47756-08c1-4e9a-a4db-0247f8432987",
   "metadata": {},
   "source": [
    "<h1>Sigmoid-like Damage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0488ffb-1f97-4d2a-962d-2d5b6c1de260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.read_csv('input/results_complete_sigmoid_like.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a69a9e2-9c1a-460d-8ee0-0b0906b8f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sig.drop(['elem_damaged', 'damage'], axis=1), df_sig['elem_damaged'], test_size=0.10, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4725a8a-f537-49c8-b452-b67189a6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = hot_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = hot_encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a28008-ffff-418d-862c-e3b1f4a69826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                10160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 129)               10449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,569\n",
      "Trainable params: 33,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 4.7802 - accuracy: 0.0292 - val_loss: 4.6348 - val_accuracy: 0.0547\n",
      "Epoch 2/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.4135 - accuracy: 0.0765 - val_loss: 4.2649 - val_accuracy: 0.0841\n",
      "Epoch 3/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 4.0417 - accuracy: 0.1111 - val_loss: 3.9257 - val_accuracy: 0.1233\n",
      "Epoch 4/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.7322 - accuracy: 0.1571 - val_loss: 3.6593 - val_accuracy: 0.1721\n",
      "Epoch 5/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.4983 - accuracy: 0.1939 - val_loss: 3.4562 - val_accuracy: 0.1930\n",
      "Epoch 6/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.3163 - accuracy: 0.2112 - val_loss: 3.2911 - val_accuracy: 0.2209\n",
      "Epoch 7/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.1718 - accuracy: 0.2332 - val_loss: 3.1659 - val_accuracy: 0.2287\n",
      "Epoch 8/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.0616 - accuracy: 0.2442 - val_loss: 3.0657 - val_accuracy: 0.2446\n",
      "Epoch 9/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.9722 - accuracy: 0.2587 - val_loss: 2.9853 - val_accuracy: 0.2543\n",
      "Epoch 10/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.8966 - accuracy: 0.2727 - val_loss: 2.9169 - val_accuracy: 0.2721\n",
      "Epoch 11/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.8319 - accuracy: 0.2840 - val_loss: 2.8495 - val_accuracy: 0.2806\n",
      "Epoch 12/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.7747 - accuracy: 0.2923 - val_loss: 2.7976 - val_accuracy: 0.2888\n",
      "Epoch 13/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.7192 - accuracy: 0.3071 - val_loss: 2.7488 - val_accuracy: 0.2992\n",
      "Epoch 14/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.6698 - accuracy: 0.3169 - val_loss: 2.6949 - val_accuracy: 0.3093\n",
      "Epoch 15/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.6240 - accuracy: 0.3283 - val_loss: 2.6586 - val_accuracy: 0.3081\n",
      "Epoch 16/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.5859 - accuracy: 0.3334 - val_loss: 2.6120 - val_accuracy: 0.3341\n",
      "Epoch 17/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.5486 - accuracy: 0.3416 - val_loss: 2.5778 - val_accuracy: 0.3353\n",
      "Epoch 18/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.5128 - accuracy: 0.3562 - val_loss: 2.5458 - val_accuracy: 0.3244\n",
      "Epoch 19/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.4820 - accuracy: 0.3546 - val_loss: 2.5151 - val_accuracy: 0.3640\n",
      "Epoch 20/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4488 - accuracy: 0.3668 - val_loss: 2.4874 - val_accuracy: 0.3632\n",
      "Epoch 21/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.4243 - accuracy: 0.3704 - val_loss: 2.4626 - val_accuracy: 0.3655\n",
      "Epoch 22/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3979 - accuracy: 0.3739 - val_loss: 2.4396 - val_accuracy: 0.3636\n",
      "Epoch 23/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3739 - accuracy: 0.3821 - val_loss: 2.4185 - val_accuracy: 0.3802\n",
      "Epoch 24/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3497 - accuracy: 0.3927 - val_loss: 2.3855 - val_accuracy: 0.3961\n",
      "Epoch 25/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3284 - accuracy: 0.3956 - val_loss: 2.3727 - val_accuracy: 0.3802\n",
      "Epoch 26/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.3063 - accuracy: 0.3967 - val_loss: 2.3534 - val_accuracy: 0.3752\n",
      "Epoch 27/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2876 - accuracy: 0.4031 - val_loss: 2.3333 - val_accuracy: 0.3876\n",
      "Epoch 28/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2667 - accuracy: 0.4109 - val_loss: 2.3119 - val_accuracy: 0.3837\n",
      "Epoch 29/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2492 - accuracy: 0.4111 - val_loss: 2.2971 - val_accuracy: 0.3938\n",
      "Epoch 30/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2306 - accuracy: 0.4186 - val_loss: 2.2733 - val_accuracy: 0.4167\n",
      "Epoch 31/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.2119 - accuracy: 0.4259 - val_loss: 2.2480 - val_accuracy: 0.4248\n",
      "Epoch 32/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1953 - accuracy: 0.4292 - val_loss: 2.2461 - val_accuracy: 0.4159\n",
      "Epoch 33/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 2.1756 - accuracy: 0.4343 - val_loss: 2.2317 - val_accuracy: 0.4081\n",
      "Epoch 34/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1600 - accuracy: 0.4388 - val_loss: 2.2165 - val_accuracy: 0.4275\n",
      "Epoch 35/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1432 - accuracy: 0.4409 - val_loss: 2.1916 - val_accuracy: 0.4322\n",
      "Epoch 36/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1251 - accuracy: 0.4471 - val_loss: 2.1713 - val_accuracy: 0.4329\n",
      "Epoch 37/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.1097 - accuracy: 0.4488 - val_loss: 2.1571 - val_accuracy: 0.4419\n",
      "Epoch 38/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0974 - accuracy: 0.4545 - val_loss: 2.1471 - val_accuracy: 0.4516\n",
      "Epoch 39/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0807 - accuracy: 0.4578 - val_loss: 2.1380 - val_accuracy: 0.4651\n",
      "Epoch 40/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0677 - accuracy: 0.4622 - val_loss: 2.1157 - val_accuracy: 0.4461\n",
      "Epoch 41/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0554 - accuracy: 0.4644 - val_loss: 2.1060 - val_accuracy: 0.4771\n",
      "Epoch 42/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0401 - accuracy: 0.4720 - val_loss: 2.0821 - val_accuracy: 0.4616\n",
      "Epoch 43/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0258 - accuracy: 0.4731 - val_loss: 2.0791 - val_accuracy: 0.4581\n",
      "Epoch 44/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0144 - accuracy: 0.4754 - val_loss: 2.0580 - val_accuracy: 0.4771\n",
      "Epoch 45/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 2.0010 - accuracy: 0.4776 - val_loss: 2.0635 - val_accuracy: 0.4562\n",
      "Epoch 46/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9884 - accuracy: 0.4805 - val_loss: 2.0374 - val_accuracy: 0.4814\n",
      "Epoch 47/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9742 - accuracy: 0.4856 - val_loss: 2.0236 - val_accuracy: 0.4674\n",
      "Epoch 48/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9631 - accuracy: 0.4943 - val_loss: 2.0272 - val_accuracy: 0.4562\n",
      "Epoch 49/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9528 - accuracy: 0.4898 - val_loss: 1.9980 - val_accuracy: 0.4674\n",
      "Epoch 50/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9393 - accuracy: 0.4984 - val_loss: 2.0111 - val_accuracy: 0.4810\n",
      "Epoch 51/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9277 - accuracy: 0.4996 - val_loss: 1.9866 - val_accuracy: 0.4810\n",
      "Epoch 52/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9204 - accuracy: 0.5025 - val_loss: 1.9645 - val_accuracy: 0.5000\n",
      "Epoch 53/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.9065 - accuracy: 0.5057 - val_loss: 1.9685 - val_accuracy: 0.4822\n",
      "Epoch 54/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8985 - accuracy: 0.5069 - val_loss: 1.9656 - val_accuracy: 0.4950\n",
      "Epoch 55/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8872 - accuracy: 0.5146 - val_loss: 1.9530 - val_accuracy: 0.4880\n",
      "Epoch 56/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8794 - accuracy: 0.5193 - val_loss: 1.9523 - val_accuracy: 0.4891\n",
      "Epoch 57/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8697 - accuracy: 0.5158 - val_loss: 1.9376 - val_accuracy: 0.5039\n",
      "Epoch 58/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8609 - accuracy: 0.5189 - val_loss: 1.9092 - val_accuracy: 0.5054\n",
      "Epoch 59/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8503 - accuracy: 0.5223 - val_loss: 1.9128 - val_accuracy: 0.5016\n",
      "Epoch 60/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8406 - accuracy: 0.5234 - val_loss: 1.9003 - val_accuracy: 0.5147\n",
      "Epoch 61/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8308 - accuracy: 0.5276 - val_loss: 1.8928 - val_accuracy: 0.5105\n",
      "Epoch 62/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8221 - accuracy: 0.5306 - val_loss: 1.9004 - val_accuracy: 0.5167\n",
      "Epoch 63/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8121 - accuracy: 0.5334 - val_loss: 1.8823 - val_accuracy: 0.5120\n",
      "Epoch 64/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.8045 - accuracy: 0.5327 - val_loss: 1.8753 - val_accuracy: 0.5205\n",
      "Epoch 65/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7971 - accuracy: 0.5396 - val_loss: 1.8414 - val_accuracy: 0.5298\n",
      "Epoch 66/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7837 - accuracy: 0.5410 - val_loss: 1.8407 - val_accuracy: 0.5229\n",
      "Epoch 67/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7768 - accuracy: 0.5429 - val_loss: 1.8472 - val_accuracy: 0.5267\n",
      "Epoch 68/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7707 - accuracy: 0.5436 - val_loss: 1.8319 - val_accuracy: 0.5256\n",
      "Epoch 69/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7628 - accuracy: 0.5432 - val_loss: 1.8135 - val_accuracy: 0.5341\n",
      "Epoch 70/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7577 - accuracy: 0.5472 - val_loss: 1.8145 - val_accuracy: 0.5341\n",
      "Epoch 71/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7474 - accuracy: 0.5528 - val_loss: 1.8003 - val_accuracy: 0.5279\n",
      "Epoch 72/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7399 - accuracy: 0.5548 - val_loss: 1.8105 - val_accuracy: 0.5349\n",
      "Epoch 73/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7310 - accuracy: 0.5557 - val_loss: 1.8025 - val_accuracy: 0.5283\n",
      "Epoch 74/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7286 - accuracy: 0.5571 - val_loss: 1.8039 - val_accuracy: 0.5267\n",
      "Epoch 75/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7142 - accuracy: 0.5608 - val_loss: 1.7718 - val_accuracy: 0.5341\n",
      "Epoch 76/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7076 - accuracy: 0.5654 - val_loss: 1.7820 - val_accuracy: 0.5372\n",
      "Epoch 77/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.7023 - accuracy: 0.5663 - val_loss: 1.7581 - val_accuracy: 0.5527\n",
      "Epoch 78/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6958 - accuracy: 0.5670 - val_loss: 1.7635 - val_accuracy: 0.5473\n",
      "Epoch 79/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6886 - accuracy: 0.5708 - val_loss: 1.7609 - val_accuracy: 0.5372\n",
      "Epoch 80/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6824 - accuracy: 0.5702 - val_loss: 1.7422 - val_accuracy: 0.5593\n",
      "Epoch 81/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6763 - accuracy: 0.5696 - val_loss: 1.7454 - val_accuracy: 0.5612\n",
      "Epoch 82/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6713 - accuracy: 0.5720 - val_loss: 1.7433 - val_accuracy: 0.5547\n",
      "Epoch 83/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6638 - accuracy: 0.5772 - val_loss: 1.7197 - val_accuracy: 0.5597\n",
      "Epoch 84/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6583 - accuracy: 0.5755 - val_loss: 1.7125 - val_accuracy: 0.5667\n",
      "Epoch 85/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6485 - accuracy: 0.5824 - val_loss: 1.7347 - val_accuracy: 0.5430\n",
      "Epoch 86/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6449 - accuracy: 0.5783 - val_loss: 1.7225 - val_accuracy: 0.5457\n",
      "Epoch 87/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6387 - accuracy: 0.5802 - val_loss: 1.7167 - val_accuracy: 0.5581\n",
      "Epoch 88/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6307 - accuracy: 0.5836 - val_loss: 1.6887 - val_accuracy: 0.5643\n",
      "Epoch 89/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6259 - accuracy: 0.5850 - val_loss: 1.6792 - val_accuracy: 0.5643\n",
      "Epoch 90/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.6201 - accuracy: 0.5878 - val_loss: 1.6798 - val_accuracy: 0.5651\n",
      "Epoch 91/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6112 - accuracy: 0.5904 - val_loss: 1.6805 - val_accuracy: 0.5597\n",
      "Epoch 92/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.6067 - accuracy: 0.5908 - val_loss: 1.6638 - val_accuracy: 0.5841\n",
      "Epoch 93/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.6023 - accuracy: 0.5904 - val_loss: 1.6619 - val_accuracy: 0.5690\n",
      "Epoch 94/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5955 - accuracy: 0.5963 - val_loss: 1.6514 - val_accuracy: 0.5837\n",
      "Epoch 95/1000\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 1.5868 - accuracy: 0.5937 - val_loss: 1.6608 - val_accuracy: 0.5550\n",
      "Epoch 96/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5807 - accuracy: 0.6022 - val_loss: 1.6398 - val_accuracy: 0.5798\n",
      "Epoch 97/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5755 - accuracy: 0.6001 - val_loss: 1.6483 - val_accuracy: 0.5659\n",
      "Epoch 98/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5698 - accuracy: 0.5990 - val_loss: 1.6210 - val_accuracy: 0.5837\n",
      "Epoch 99/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5647 - accuracy: 0.6003 - val_loss: 1.6335 - val_accuracy: 0.5864\n",
      "Epoch 100/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5609 - accuracy: 0.6021 - val_loss: 1.6485 - val_accuracy: 0.5826\n",
      "Epoch 101/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5533 - accuracy: 0.6054 - val_loss: 1.6237 - val_accuracy: 0.5895\n",
      "Epoch 102/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5493 - accuracy: 0.6113 - val_loss: 1.6086 - val_accuracy: 0.6066\n",
      "Epoch 103/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5516 - accuracy: 0.6082 - val_loss: 1.6404 - val_accuracy: 0.5833\n",
      "Epoch 104/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5377 - accuracy: 0.6098 - val_loss: 1.5991 - val_accuracy: 0.5829\n",
      "Epoch 105/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5315 - accuracy: 0.6157 - val_loss: 1.6048 - val_accuracy: 0.5934\n",
      "Epoch 106/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5279 - accuracy: 0.6155 - val_loss: 1.5892 - val_accuracy: 0.6023\n",
      "Epoch 107/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.5236 - accuracy: 0.6163 - val_loss: 1.5825 - val_accuracy: 0.5957\n",
      "Epoch 108/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5220 - accuracy: 0.6176 - val_loss: 1.5804 - val_accuracy: 0.5996\n",
      "Epoch 109/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5180 - accuracy: 0.6180 - val_loss: 1.5844 - val_accuracy: 0.6070\n",
      "Epoch 110/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5118 - accuracy: 0.6192 - val_loss: 1.5771 - val_accuracy: 0.5857\n",
      "Epoch 111/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5066 - accuracy: 0.6196 - val_loss: 1.5640 - val_accuracy: 0.6027\n",
      "Epoch 112/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.5034 - accuracy: 0.6203 - val_loss: 1.5866 - val_accuracy: 0.5915\n",
      "Epoch 113/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4982 - accuracy: 0.6246 - val_loss: 1.5624 - val_accuracy: 0.6039\n",
      "Epoch 114/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4921 - accuracy: 0.6235 - val_loss: 1.5595 - val_accuracy: 0.5946\n",
      "Epoch 115/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4889 - accuracy: 0.6265 - val_loss: 1.5618 - val_accuracy: 0.5895\n",
      "Epoch 116/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4835 - accuracy: 0.6266 - val_loss: 1.5552 - val_accuracy: 0.5953\n",
      "Epoch 117/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4780 - accuracy: 0.6273 - val_loss: 1.5440 - val_accuracy: 0.5926\n",
      "Epoch 118/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4744 - accuracy: 0.6303 - val_loss: 1.5393 - val_accuracy: 0.6186\n",
      "Epoch 119/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4704 - accuracy: 0.6282 - val_loss: 1.5402 - val_accuracy: 0.6058\n",
      "Epoch 120/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4643 - accuracy: 0.6333 - val_loss: 1.5334 - val_accuracy: 0.6151\n",
      "Epoch 121/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4620 - accuracy: 0.6299 - val_loss: 1.5087 - val_accuracy: 0.6213\n",
      "Epoch 122/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4534 - accuracy: 0.6360 - val_loss: 1.5565 - val_accuracy: 0.6085\n",
      "Epoch 123/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4529 - accuracy: 0.6370 - val_loss: 1.5116 - val_accuracy: 0.6202\n",
      "Epoch 124/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4453 - accuracy: 0.6392 - val_loss: 1.5110 - val_accuracy: 0.6120\n",
      "Epoch 125/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4442 - accuracy: 0.6393 - val_loss: 1.5244 - val_accuracy: 0.5981\n",
      "Epoch 126/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4384 - accuracy: 0.6385 - val_loss: 1.5094 - val_accuracy: 0.6101\n",
      "Epoch 127/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4357 - accuracy: 0.6404 - val_loss: 1.5017 - val_accuracy: 0.6217\n",
      "Epoch 128/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4424 - accuracy: 0.6410 - val_loss: 1.4871 - val_accuracy: 0.6345\n",
      "Epoch 129/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4240 - accuracy: 0.6480 - val_loss: 1.4937 - val_accuracy: 0.6244\n",
      "Epoch 130/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4223 - accuracy: 0.6451 - val_loss: 1.4984 - val_accuracy: 0.6186\n",
      "Epoch 131/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.4167 - accuracy: 0.6468 - val_loss: 1.4936 - val_accuracy: 0.6244\n",
      "Epoch 132/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4170 - accuracy: 0.6458 - val_loss: 1.4980 - val_accuracy: 0.6267\n",
      "Epoch 133/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4180 - accuracy: 0.6475 - val_loss: 1.4915 - val_accuracy: 0.6109\n",
      "Epoch 134/1000\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 1.4057 - accuracy: 0.6510 - val_loss: 1.4744 - val_accuracy: 0.6256\n",
      "Epoch 135/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4055 - accuracy: 0.6516 - val_loss: 1.4683 - val_accuracy: 0.6341\n",
      "Epoch 136/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.4004 - accuracy: 0.6528 - val_loss: 1.4658 - val_accuracy: 0.6318\n",
      "Epoch 137/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3978 - accuracy: 0.6528 - val_loss: 1.4627 - val_accuracy: 0.6291\n",
      "Epoch 138/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3950 - accuracy: 0.6524 - val_loss: 1.4664 - val_accuracy: 0.6453\n",
      "Epoch 139/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3906 - accuracy: 0.6533 - val_loss: 1.4819 - val_accuracy: 0.6167\n",
      "Epoch 140/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3867 - accuracy: 0.6540 - val_loss: 1.4853 - val_accuracy: 0.6209\n",
      "Epoch 141/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3857 - accuracy: 0.6553 - val_loss: 1.5014 - val_accuracy: 0.6136\n",
      "Epoch 142/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3840 - accuracy: 0.6526 - val_loss: 1.4387 - val_accuracy: 0.6391\n",
      "Epoch 143/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3780 - accuracy: 0.6576 - val_loss: 1.4489 - val_accuracy: 0.6229\n",
      "Epoch 144/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3763 - accuracy: 0.6569 - val_loss: 1.4284 - val_accuracy: 0.6376\n",
      "Epoch 145/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3714 - accuracy: 0.6587 - val_loss: 1.4468 - val_accuracy: 0.6306\n",
      "Epoch 146/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3652 - accuracy: 0.6606 - val_loss: 1.4312 - val_accuracy: 0.6430\n",
      "Epoch 147/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3630 - accuracy: 0.6633 - val_loss: 1.4195 - val_accuracy: 0.6450\n",
      "Epoch 148/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3599 - accuracy: 0.6590 - val_loss: 1.4296 - val_accuracy: 0.6329\n",
      "Epoch 149/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3546 - accuracy: 0.6672 - val_loss: 1.4100 - val_accuracy: 0.6415\n",
      "Epoch 150/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3539 - accuracy: 0.6623 - val_loss: 1.4182 - val_accuracy: 0.6333\n",
      "Epoch 151/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3492 - accuracy: 0.6619 - val_loss: 1.4128 - val_accuracy: 0.6508\n",
      "Epoch 152/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3467 - accuracy: 0.6657 - val_loss: 1.4019 - val_accuracy: 0.6519\n",
      "Epoch 153/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3417 - accuracy: 0.6683 - val_loss: 1.4034 - val_accuracy: 0.6446\n",
      "Epoch 154/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3362 - accuracy: 0.6719 - val_loss: 1.4168 - val_accuracy: 0.6543\n",
      "Epoch 155/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3338 - accuracy: 0.6693 - val_loss: 1.4185 - val_accuracy: 0.6430\n",
      "Epoch 156/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3322 - accuracy: 0.6696 - val_loss: 1.4149 - val_accuracy: 0.6516\n",
      "Epoch 157/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3299 - accuracy: 0.6688 - val_loss: 1.4251 - val_accuracy: 0.6442\n",
      "Epoch 158/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3276 - accuracy: 0.6694 - val_loss: 1.3732 - val_accuracy: 0.6578\n",
      "Epoch 159/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3234 - accuracy: 0.6714 - val_loss: 1.3811 - val_accuracy: 0.6562\n",
      "Epoch 160/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3179 - accuracy: 0.6749 - val_loss: 1.4181 - val_accuracy: 0.6442\n",
      "Epoch 161/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3250 - accuracy: 0.6717 - val_loss: 1.4561 - val_accuracy: 0.6481\n",
      "Epoch 162/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3090 - accuracy: 0.6791 - val_loss: 1.3817 - val_accuracy: 0.6539\n",
      "Epoch 163/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3080 - accuracy: 0.6739 - val_loss: 1.3746 - val_accuracy: 0.6643\n",
      "Epoch 164/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.3032 - accuracy: 0.6769 - val_loss: 1.3820 - val_accuracy: 0.6430\n",
      "Epoch 165/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3030 - accuracy: 0.6795 - val_loss: 1.3586 - val_accuracy: 0.6628\n",
      "Epoch 166/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.3006 - accuracy: 0.6785 - val_loss: 1.3585 - val_accuracy: 0.6787\n",
      "Epoch 167/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2955 - accuracy: 0.6799 - val_loss: 1.3495 - val_accuracy: 0.6655\n",
      "Epoch 168/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2983 - accuracy: 0.6767 - val_loss: 1.3580 - val_accuracy: 0.6632\n",
      "Epoch 169/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2936 - accuracy: 0.6777 - val_loss: 1.4115 - val_accuracy: 0.6287\n",
      "Epoch 170/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2959 - accuracy: 0.6797 - val_loss: 1.3493 - val_accuracy: 0.6671\n",
      "Epoch 171/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2892 - accuracy: 0.6800 - val_loss: 1.3539 - val_accuracy: 0.6620\n",
      "Epoch 172/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2955 - accuracy: 0.6819 - val_loss: 1.3555 - val_accuracy: 0.6516\n",
      "Epoch 173/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2845 - accuracy: 0.6819 - val_loss: 1.3500 - val_accuracy: 0.6647\n",
      "Epoch 174/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2759 - accuracy: 0.6869 - val_loss: 1.3394 - val_accuracy: 0.6682\n",
      "Epoch 175/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2756 - accuracy: 0.6862 - val_loss: 1.3367 - val_accuracy: 0.6581\n",
      "Epoch 176/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2726 - accuracy: 0.6861 - val_loss: 1.3477 - val_accuracy: 0.6678\n",
      "Epoch 177/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2720 - accuracy: 0.6870 - val_loss: 1.3464 - val_accuracy: 0.6667\n",
      "Epoch 178/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2688 - accuracy: 0.6873 - val_loss: 1.3546 - val_accuracy: 0.6558\n",
      "Epoch 179/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2699 - accuracy: 0.6879 - val_loss: 1.3327 - val_accuracy: 0.6651\n",
      "Epoch 180/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2687 - accuracy: 0.6850 - val_loss: 1.3450 - val_accuracy: 0.6651\n",
      "Epoch 181/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2609 - accuracy: 0.6912 - val_loss: 1.3649 - val_accuracy: 0.6469\n",
      "Epoch 182/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2612 - accuracy: 0.6889 - val_loss: 1.3278 - val_accuracy: 0.6686\n",
      "Epoch 183/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2590 - accuracy: 0.6864 - val_loss: 1.3244 - val_accuracy: 0.6632\n",
      "Epoch 184/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2565 - accuracy: 0.6887 - val_loss: 1.3174 - val_accuracy: 0.6702\n",
      "Epoch 185/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2513 - accuracy: 0.6899 - val_loss: 1.3223 - val_accuracy: 0.6736\n",
      "Epoch 186/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2484 - accuracy: 0.6890 - val_loss: 1.3596 - val_accuracy: 0.6589\n",
      "Epoch 187/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2564 - accuracy: 0.6874 - val_loss: 1.4002 - val_accuracy: 0.6779\n",
      "Epoch 188/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2433 - accuracy: 0.6949 - val_loss: 1.3091 - val_accuracy: 0.6651\n",
      "Epoch 189/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2402 - accuracy: 0.6969 - val_loss: 1.3111 - val_accuracy: 0.6729\n",
      "Epoch 190/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2386 - accuracy: 0.6936 - val_loss: 1.3260 - val_accuracy: 0.6721\n",
      "Epoch 191/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2398 - accuracy: 0.6938 - val_loss: 1.3077 - val_accuracy: 0.6798\n",
      "Epoch 192/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2380 - accuracy: 0.6943 - val_loss: 1.2962 - val_accuracy: 0.6736\n",
      "Epoch 193/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2327 - accuracy: 0.6955 - val_loss: 1.3014 - val_accuracy: 0.6690\n",
      "Epoch 194/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2327 - accuracy: 0.6928 - val_loss: 1.2913 - val_accuracy: 0.6915\n",
      "Epoch 195/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2293 - accuracy: 0.6949 - val_loss: 1.3109 - val_accuracy: 0.6570\n",
      "Epoch 196/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2274 - accuracy: 0.6977 - val_loss: 1.3070 - val_accuracy: 0.6690\n",
      "Epoch 197/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2238 - accuracy: 0.6991 - val_loss: 1.3043 - val_accuracy: 0.6814\n",
      "Epoch 198/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2208 - accuracy: 0.7008 - val_loss: 1.2776 - val_accuracy: 0.6911\n",
      "Epoch 199/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2211 - accuracy: 0.6982 - val_loss: 1.3034 - val_accuracy: 0.6709\n",
      "Epoch 200/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2177 - accuracy: 0.6967 - val_loss: 1.2859 - val_accuracy: 0.6779\n",
      "Epoch 201/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2151 - accuracy: 0.7004 - val_loss: 1.2840 - val_accuracy: 0.6771\n",
      "Epoch 202/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2131 - accuracy: 0.6993 - val_loss: 1.3093 - val_accuracy: 0.6686\n",
      "Epoch 203/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2108 - accuracy: 0.6988 - val_loss: 1.2754 - val_accuracy: 0.6686\n",
      "Epoch 204/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2125 - accuracy: 0.6999 - val_loss: 1.3050 - val_accuracy: 0.6729\n",
      "Epoch 205/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2104 - accuracy: 0.7008 - val_loss: 1.2943 - val_accuracy: 0.6705\n",
      "Epoch 206/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2086 - accuracy: 0.6986 - val_loss: 1.2761 - val_accuracy: 0.6926\n",
      "Epoch 207/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2036 - accuracy: 0.7020 - val_loss: 1.2878 - val_accuracy: 0.6791\n",
      "Epoch 208/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.2020 - accuracy: 0.7013 - val_loss: 1.2816 - val_accuracy: 0.6764\n",
      "Epoch 209/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.2004 - accuracy: 0.7019 - val_loss: 1.2739 - val_accuracy: 0.6791\n",
      "Epoch 210/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1967 - accuracy: 0.7023 - val_loss: 1.2688 - val_accuracy: 0.6868\n",
      "Epoch 211/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1997 - accuracy: 0.7031 - val_loss: 1.2836 - val_accuracy: 0.6798\n",
      "Epoch 212/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1938 - accuracy: 0.7027 - val_loss: 1.2676 - val_accuracy: 0.6725\n",
      "Epoch 213/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1901 - accuracy: 0.7064 - val_loss: 1.2398 - val_accuracy: 0.7047\n",
      "Epoch 214/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1903 - accuracy: 0.7040 - val_loss: 1.2635 - val_accuracy: 0.6740\n",
      "Epoch 215/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1882 - accuracy: 0.7055 - val_loss: 1.2424 - val_accuracy: 0.6965\n",
      "Epoch 216/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1848 - accuracy: 0.7067 - val_loss: 1.2814 - val_accuracy: 0.6740\n",
      "Epoch 217/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1827 - accuracy: 0.7099 - val_loss: 1.2738 - val_accuracy: 0.6721\n",
      "Epoch 218/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1787 - accuracy: 0.7045 - val_loss: 1.2539 - val_accuracy: 0.6891\n",
      "Epoch 219/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1762 - accuracy: 0.7084 - val_loss: 1.2613 - val_accuracy: 0.6798\n",
      "Epoch 220/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1757 - accuracy: 0.7068 - val_loss: 1.2561 - val_accuracy: 0.6992\n",
      "Epoch 221/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1721 - accuracy: 0.7096 - val_loss: 1.2710 - val_accuracy: 0.6791\n",
      "Epoch 222/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1676 - accuracy: 0.7115 - val_loss: 1.2602 - val_accuracy: 0.6810\n",
      "Epoch 223/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1675 - accuracy: 0.7112 - val_loss: 1.2489 - val_accuracy: 0.6895\n",
      "Epoch 224/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1655 - accuracy: 0.7126 - val_loss: 1.2677 - val_accuracy: 0.6713\n",
      "Epoch 225/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1635 - accuracy: 0.7107 - val_loss: 1.2389 - val_accuracy: 0.6891\n",
      "Epoch 226/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1634 - accuracy: 0.7171 - val_loss: 1.2358 - val_accuracy: 0.6822\n",
      "Epoch 227/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1599 - accuracy: 0.7126 - val_loss: 1.2622 - val_accuracy: 0.6767\n",
      "Epoch 228/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1569 - accuracy: 0.7109 - val_loss: 1.2737 - val_accuracy: 0.6818\n",
      "Epoch 229/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1580 - accuracy: 0.7137 - val_loss: 1.2101 - val_accuracy: 0.7109\n",
      "Epoch 230/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1504 - accuracy: 0.7175 - val_loss: 1.2616 - val_accuracy: 0.6736\n",
      "Epoch 231/1000\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 1.1565 - accuracy: 0.7096 - val_loss: 1.2619 - val_accuracy: 0.6783\n",
      "Epoch 232/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1758 - accuracy: 0.7105 - val_loss: 1.1982 - val_accuracy: 0.7136\n",
      "Epoch 233/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1404 - accuracy: 0.7207 - val_loss: 1.2131 - val_accuracy: 0.7043\n",
      "Epoch 234/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1396 - accuracy: 0.7207 - val_loss: 1.2124 - val_accuracy: 0.6911\n",
      "Epoch 235/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1424 - accuracy: 0.7217 - val_loss: 1.2144 - val_accuracy: 0.7043\n",
      "Epoch 236/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1391 - accuracy: 0.7193 - val_loss: 1.2173 - val_accuracy: 0.7089\n",
      "Epoch 237/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1380 - accuracy: 0.7192 - val_loss: 1.2129 - val_accuracy: 0.6996\n",
      "Epoch 238/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1403 - accuracy: 0.7169 - val_loss: 1.2158 - val_accuracy: 0.7019\n",
      "Epoch 239/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1365 - accuracy: 0.7162 - val_loss: 1.2138 - val_accuracy: 0.7074\n",
      "Epoch 240/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1386 - accuracy: 0.7171 - val_loss: 1.2281 - val_accuracy: 0.6911\n",
      "Epoch 241/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1352 - accuracy: 0.7218 - val_loss: 1.2497 - val_accuracy: 0.6884\n",
      "Epoch 242/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1315 - accuracy: 0.7179 - val_loss: 1.1986 - val_accuracy: 0.7205\n",
      "Epoch 243/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1364 - accuracy: 0.7186 - val_loss: 1.2205 - val_accuracy: 0.6926\n",
      "Epoch 244/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1337 - accuracy: 0.7181 - val_loss: 1.2484 - val_accuracy: 0.6864\n",
      "Epoch 245/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1326 - accuracy: 0.7222 - val_loss: 1.2245 - val_accuracy: 0.7023\n",
      "Epoch 246/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1271 - accuracy: 0.7200 - val_loss: 1.2352 - val_accuracy: 0.7004\n",
      "Epoch 247/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1238 - accuracy: 0.7227 - val_loss: 1.2625 - val_accuracy: 0.6915\n",
      "Epoch 248/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1222 - accuracy: 0.7221 - val_loss: 1.2953 - val_accuracy: 0.6922\n",
      "Epoch 249/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1232 - accuracy: 0.7224 - val_loss: 1.2623 - val_accuracy: 0.7109\n",
      "Epoch 250/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1183 - accuracy: 0.7244 - val_loss: 1.2957 - val_accuracy: 0.6876\n",
      "Epoch 251/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1227 - accuracy: 0.7221 - val_loss: 1.2729 - val_accuracy: 0.6934\n",
      "Epoch 252/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1174 - accuracy: 0.7218 - val_loss: 1.1965 - val_accuracy: 0.7012\n",
      "Epoch 253/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1181 - accuracy: 0.7219 - val_loss: 1.1817 - val_accuracy: 0.7031\n",
      "Epoch 254/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1090 - accuracy: 0.7264 - val_loss: 1.1921 - val_accuracy: 0.6895\n",
      "Epoch 255/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1095 - accuracy: 0.7254 - val_loss: 1.1958 - val_accuracy: 0.7031\n",
      "Epoch 256/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1228 - accuracy: 0.7218 - val_loss: 1.1902 - val_accuracy: 0.7043\n",
      "Epoch 257/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1108 - accuracy: 0.7257 - val_loss: 1.1648 - val_accuracy: 0.7178\n",
      "Epoch 258/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0994 - accuracy: 0.7298 - val_loss: 1.1690 - val_accuracy: 0.7120\n",
      "Epoch 259/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.1044 - accuracy: 0.7242 - val_loss: 1.1613 - val_accuracy: 0.7174\n",
      "Epoch 260/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1018 - accuracy: 0.7270 - val_loss: 1.1780 - val_accuracy: 0.6965\n",
      "Epoch 261/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0974 - accuracy: 0.7268 - val_loss: 1.1777 - val_accuracy: 0.6957\n",
      "Epoch 262/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0998 - accuracy: 0.7278 - val_loss: 1.1730 - val_accuracy: 0.7116\n",
      "Epoch 263/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1032 - accuracy: 0.7257 - val_loss: 1.2361 - val_accuracy: 0.6853\n",
      "Epoch 264/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.1001 - accuracy: 0.7251 - val_loss: 1.1970 - val_accuracy: 0.7039\n",
      "Epoch 265/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0947 - accuracy: 0.7304 - val_loss: 1.1836 - val_accuracy: 0.7031\n",
      "Epoch 266/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0943 - accuracy: 0.7307 - val_loss: 1.1632 - val_accuracy: 0.7112\n",
      "Epoch 267/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0905 - accuracy: 0.7305 - val_loss: 1.2081 - val_accuracy: 0.6961\n",
      "Epoch 268/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0918 - accuracy: 0.7295 - val_loss: 1.1963 - val_accuracy: 0.6946\n",
      "Epoch 269/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0931 - accuracy: 0.7292 - val_loss: 1.1670 - val_accuracy: 0.7023\n",
      "Epoch 270/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0909 - accuracy: 0.7304 - val_loss: 1.1583 - val_accuracy: 0.7171\n",
      "Epoch 271/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0889 - accuracy: 0.7330 - val_loss: 1.1592 - val_accuracy: 0.7194\n",
      "Epoch 272/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0855 - accuracy: 0.7304 - val_loss: 1.2024 - val_accuracy: 0.6977\n",
      "Epoch 273/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0844 - accuracy: 0.7301 - val_loss: 1.1784 - val_accuracy: 0.7019\n",
      "Epoch 274/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0825 - accuracy: 0.7299 - val_loss: 1.1471 - val_accuracy: 0.7275\n",
      "Epoch 275/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0945 - accuracy: 0.7301 - val_loss: 1.1520 - val_accuracy: 0.7194\n",
      "Epoch 276/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0771 - accuracy: 0.7348 - val_loss: 1.1479 - val_accuracy: 0.7147\n",
      "Epoch 277/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0724 - accuracy: 0.7348 - val_loss: 1.1371 - val_accuracy: 0.7256\n",
      "Epoch 278/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0697 - accuracy: 0.7393 - val_loss: 1.2045 - val_accuracy: 0.7000\n",
      "Epoch 279/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0765 - accuracy: 0.7332 - val_loss: 1.1985 - val_accuracy: 0.6930\n",
      "Epoch 280/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0705 - accuracy: 0.7354 - val_loss: 1.1659 - val_accuracy: 0.7019\n",
      "Epoch 281/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0708 - accuracy: 0.7345 - val_loss: 1.1387 - val_accuracy: 0.7112\n",
      "Epoch 282/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0771 - accuracy: 0.7336 - val_loss: 1.1542 - val_accuracy: 0.7078\n",
      "Epoch 283/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0751 - accuracy: 0.7331 - val_loss: 1.1562 - val_accuracy: 0.7016\n",
      "Epoch 284/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0720 - accuracy: 0.7335 - val_loss: 1.1548 - val_accuracy: 0.7058\n",
      "Epoch 285/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0663 - accuracy: 0.7334 - val_loss: 1.1368 - val_accuracy: 0.7229\n",
      "Epoch 286/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0652 - accuracy: 0.7359 - val_loss: 1.1196 - val_accuracy: 0.7229\n",
      "Epoch 287/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0611 - accuracy: 0.7374 - val_loss: 1.1508 - val_accuracy: 0.7031\n",
      "Epoch 288/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0654 - accuracy: 0.7354 - val_loss: 1.1233 - val_accuracy: 0.7217\n",
      "Epoch 289/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0618 - accuracy: 0.7358 - val_loss: 1.1963 - val_accuracy: 0.6965\n",
      "Epoch 290/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0608 - accuracy: 0.7378 - val_loss: 1.1388 - val_accuracy: 0.7198\n",
      "Epoch 291/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0597 - accuracy: 0.7346 - val_loss: 1.1508 - val_accuracy: 0.7186\n",
      "Epoch 292/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0615 - accuracy: 0.7363 - val_loss: 1.2179 - val_accuracy: 0.6957\n",
      "Epoch 293/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0550 - accuracy: 0.7372 - val_loss: 1.1645 - val_accuracy: 0.6961\n",
      "Epoch 294/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0588 - accuracy: 0.7351 - val_loss: 1.1177 - val_accuracy: 0.7310\n",
      "Epoch 295/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0515 - accuracy: 0.7400 - val_loss: 1.1353 - val_accuracy: 0.7054\n",
      "Epoch 296/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0524 - accuracy: 0.7407 - val_loss: 1.1153 - val_accuracy: 0.7167\n",
      "Epoch 297/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0528 - accuracy: 0.7392 - val_loss: 1.1163 - val_accuracy: 0.7221\n",
      "Epoch 298/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0494 - accuracy: 0.7394 - val_loss: 1.1219 - val_accuracy: 0.7155\n",
      "Epoch 299/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0469 - accuracy: 0.7415 - val_loss: 1.1161 - val_accuracy: 0.7264\n",
      "Epoch 300/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0465 - accuracy: 0.7402 - val_loss: 1.1175 - val_accuracy: 0.7178\n",
      "Epoch 301/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0490 - accuracy: 0.7400 - val_loss: 1.1268 - val_accuracy: 0.7143\n",
      "Epoch 302/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0479 - accuracy: 0.7398 - val_loss: 1.2027 - val_accuracy: 0.6829\n",
      "Epoch 303/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0441 - accuracy: 0.7399 - val_loss: 1.1264 - val_accuracy: 0.7194\n",
      "Epoch 304/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0403 - accuracy: 0.7408 - val_loss: 1.1624 - val_accuracy: 0.6934\n",
      "Epoch 305/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0455 - accuracy: 0.7401 - val_loss: 1.1272 - val_accuracy: 0.7147\n",
      "Epoch 306/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0382 - accuracy: 0.7414 - val_loss: 1.1146 - val_accuracy: 0.7221\n",
      "Epoch 307/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0359 - accuracy: 0.7432 - val_loss: 1.1284 - val_accuracy: 0.7093\n",
      "Epoch 308/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0400 - accuracy: 0.7407 - val_loss: 1.2520 - val_accuracy: 0.6853\n",
      "Epoch 309/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0359 - accuracy: 0.7448 - val_loss: 1.0965 - val_accuracy: 0.7159\n",
      "Epoch 310/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0355 - accuracy: 0.7425 - val_loss: 1.0942 - val_accuracy: 0.7337\n",
      "Epoch 311/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0365 - accuracy: 0.7421 - val_loss: 1.0873 - val_accuracy: 0.7372\n",
      "Epoch 312/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0352 - accuracy: 0.7410 - val_loss: 1.1418 - val_accuracy: 0.7186\n",
      "Epoch 313/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0282 - accuracy: 0.7457 - val_loss: 1.1050 - val_accuracy: 0.7244\n",
      "Epoch 314/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0257 - accuracy: 0.7419 - val_loss: 1.1342 - val_accuracy: 0.7140\n",
      "Epoch 315/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0271 - accuracy: 0.7457 - val_loss: 1.0865 - val_accuracy: 0.7202\n",
      "Epoch 316/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0463 - accuracy: 0.7398 - val_loss: 1.1093 - val_accuracy: 0.7116\n",
      "Epoch 317/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0271 - accuracy: 0.7510 - val_loss: 1.0970 - val_accuracy: 0.7275\n",
      "Epoch 318/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0152 - accuracy: 0.7506 - val_loss: 1.0952 - val_accuracy: 0.7236\n",
      "Epoch 319/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0139 - accuracy: 0.7515 - val_loss: 1.1230 - val_accuracy: 0.7291\n",
      "Epoch 320/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0198 - accuracy: 0.7470 - val_loss: 1.1023 - val_accuracy: 0.7236\n",
      "Epoch 321/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0206 - accuracy: 0.7491 - val_loss: 1.1077 - val_accuracy: 0.7163\n",
      "Epoch 322/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0217 - accuracy: 0.7465 - val_loss: 1.0863 - val_accuracy: 0.7360\n",
      "Epoch 323/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0190 - accuracy: 0.7483 - val_loss: 1.1665 - val_accuracy: 0.6977\n",
      "Epoch 324/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0190 - accuracy: 0.7483 - val_loss: 1.1146 - val_accuracy: 0.7283\n",
      "Epoch 325/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0132 - accuracy: 0.7484 - val_loss: 1.1338 - val_accuracy: 0.7329\n",
      "Epoch 326/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0151 - accuracy: 0.7469 - val_loss: 1.1367 - val_accuracy: 0.7174\n",
      "Epoch 327/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0285 - accuracy: 0.7475 - val_loss: 1.0743 - val_accuracy: 0.7267\n",
      "Epoch 328/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0062 - accuracy: 0.7530 - val_loss: 1.0779 - val_accuracy: 0.7252\n",
      "Epoch 329/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0094 - accuracy: 0.7505 - val_loss: 1.0828 - val_accuracy: 0.7322\n",
      "Epoch 330/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0095 - accuracy: 0.7495 - val_loss: 1.0979 - val_accuracy: 0.7283\n",
      "Epoch 331/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0087 - accuracy: 0.7503 - val_loss: 1.0853 - val_accuracy: 0.7295\n",
      "Epoch 332/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0081 - accuracy: 0.7512 - val_loss: 1.1312 - val_accuracy: 0.7043\n",
      "Epoch 333/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0076 - accuracy: 0.7504 - val_loss: 1.1157 - val_accuracy: 0.7085\n",
      "Epoch 334/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0134 - accuracy: 0.7496 - val_loss: 1.0731 - val_accuracy: 0.7283\n",
      "Epoch 335/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0103 - accuracy: 0.7486 - val_loss: 1.0658 - val_accuracy: 0.7360\n",
      "Epoch 336/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0076 - accuracy: 0.7491 - val_loss: 1.1208 - val_accuracy: 0.7155\n",
      "Epoch 337/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0088 - accuracy: 0.7489 - val_loss: 1.0672 - val_accuracy: 0.7426\n",
      "Epoch 338/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0076 - accuracy: 0.7495 - val_loss: 1.0965 - val_accuracy: 0.7143\n",
      "Epoch 339/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0032 - accuracy: 0.7519 - val_loss: 1.0780 - val_accuracy: 0.7318\n",
      "Epoch 340/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0011 - accuracy: 0.7526 - val_loss: 1.0924 - val_accuracy: 0.7182\n",
      "Epoch 341/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 1.0027 - accuracy: 0.7521 - val_loss: 1.0591 - val_accuracy: 0.7461\n",
      "Epoch 342/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0060 - accuracy: 0.7497 - val_loss: 1.0881 - val_accuracy: 0.7341\n",
      "Epoch 343/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0003 - accuracy: 0.7505 - val_loss: 1.0682 - val_accuracy: 0.7353\n",
      "Epoch 344/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9954 - accuracy: 0.7503 - val_loss: 1.0902 - val_accuracy: 0.7260\n",
      "Epoch 345/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9959 - accuracy: 0.7520 - val_loss: 1.0843 - val_accuracy: 0.7209\n",
      "Epoch 346/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0034 - accuracy: 0.7495 - val_loss: 1.0660 - val_accuracy: 0.7407\n",
      "Epoch 347/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9946 - accuracy: 0.7515 - val_loss: 1.0842 - val_accuracy: 0.7407\n",
      "Epoch 348/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9981 - accuracy: 0.7510 - val_loss: 1.0778 - val_accuracy: 0.7287\n",
      "Epoch 349/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9989 - accuracy: 0.7530 - val_loss: 1.0838 - val_accuracy: 0.7314\n",
      "Epoch 350/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9956 - accuracy: 0.7509 - val_loss: 1.0581 - val_accuracy: 0.7333\n",
      "Epoch 351/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9889 - accuracy: 0.7524 - val_loss: 1.0478 - val_accuracy: 0.7457\n",
      "Epoch 352/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9909 - accuracy: 0.7534 - val_loss: 1.0942 - val_accuracy: 0.7434\n",
      "Epoch 353/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9934 - accuracy: 0.7548 - val_loss: 1.0531 - val_accuracy: 0.7302\n",
      "Epoch 354/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9985 - accuracy: 0.7500 - val_loss: 1.0780 - val_accuracy: 0.7271\n",
      "Epoch 355/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9787 - accuracy: 0.7578 - val_loss: 1.0603 - val_accuracy: 0.7337\n",
      "Epoch 356/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9821 - accuracy: 0.7578 - val_loss: 1.0519 - val_accuracy: 0.7368\n",
      "Epoch 357/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9938 - accuracy: 0.7532 - val_loss: 1.1626 - val_accuracy: 0.7182\n",
      "Epoch 358/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9809 - accuracy: 0.7557 - val_loss: 1.1059 - val_accuracy: 0.7074\n",
      "Epoch 359/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9758 - accuracy: 0.7573 - val_loss: 1.0604 - val_accuracy: 0.7295\n",
      "Epoch 360/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9785 - accuracy: 0.7582 - val_loss: 1.0541 - val_accuracy: 0.7368\n",
      "Epoch 361/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9798 - accuracy: 0.7567 - val_loss: 1.0812 - val_accuracy: 0.7159\n",
      "Epoch 362/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9824 - accuracy: 0.7553 - val_loss: 1.0581 - val_accuracy: 0.7291\n",
      "Epoch 363/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9763 - accuracy: 0.7588 - val_loss: 1.0521 - val_accuracy: 0.7283\n",
      "Epoch 364/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9864 - accuracy: 0.7551 - val_loss: 1.0322 - val_accuracy: 0.7450\n",
      "Epoch 365/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9739 - accuracy: 0.7575 - val_loss: 1.0279 - val_accuracy: 0.7422\n",
      "Epoch 366/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9808 - accuracy: 0.7544 - val_loss: 1.1300 - val_accuracy: 0.7047\n",
      "Epoch 367/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9751 - accuracy: 0.7576 - val_loss: 1.0552 - val_accuracy: 0.7360\n",
      "Epoch 368/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9750 - accuracy: 0.7553 - val_loss: 1.0948 - val_accuracy: 0.7244\n",
      "Epoch 369/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9792 - accuracy: 0.7581 - val_loss: 1.1587 - val_accuracy: 0.7105\n",
      "Epoch 370/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9701 - accuracy: 0.7585 - val_loss: 1.0651 - val_accuracy: 0.7353\n",
      "Epoch 371/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9754 - accuracy: 0.7565 - val_loss: 1.0771 - val_accuracy: 0.7314\n",
      "Epoch 372/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9723 - accuracy: 0.7552 - val_loss: 1.1113 - val_accuracy: 0.7267\n",
      "Epoch 373/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9705 - accuracy: 0.7558 - val_loss: 1.1057 - val_accuracy: 0.7357\n",
      "Epoch 374/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9703 - accuracy: 0.7583 - val_loss: 1.1262 - val_accuracy: 0.7337\n",
      "Epoch 375/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9707 - accuracy: 0.7598 - val_loss: 1.1348 - val_accuracy: 0.7283\n",
      "Epoch 376/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9679 - accuracy: 0.7600 - val_loss: 1.1550 - val_accuracy: 0.7252\n",
      "Epoch 377/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9643 - accuracy: 0.7615 - val_loss: 1.1320 - val_accuracy: 0.7337\n",
      "Epoch 378/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9700 - accuracy: 0.7590 - val_loss: 1.0730 - val_accuracy: 0.7438\n",
      "Epoch 379/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9593 - accuracy: 0.7625 - val_loss: 1.0977 - val_accuracy: 0.7357\n",
      "Epoch 380/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9620 - accuracy: 0.7608 - val_loss: 1.0999 - val_accuracy: 0.7434\n",
      "Epoch 381/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9563 - accuracy: 0.7606 - val_loss: 1.1111 - val_accuracy: 0.7543\n",
      "Epoch 382/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9653 - accuracy: 0.7575 - val_loss: 1.0409 - val_accuracy: 0.7368\n",
      "Epoch 383/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9604 - accuracy: 0.7617 - val_loss: 1.0685 - val_accuracy: 0.7349\n",
      "Epoch 384/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9607 - accuracy: 0.7614 - val_loss: 1.0922 - val_accuracy: 0.7167\n",
      "Epoch 385/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9553 - accuracy: 0.7621 - val_loss: 1.0734 - val_accuracy: 0.7159\n",
      "Epoch 386/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9599 - accuracy: 0.7612 - val_loss: 1.0547 - val_accuracy: 0.7384\n",
      "Epoch 387/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9590 - accuracy: 0.7616 - val_loss: 1.0644 - val_accuracy: 0.7337\n",
      "Epoch 388/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9553 - accuracy: 0.7616 - val_loss: 1.0445 - val_accuracy: 0.7388\n",
      "Epoch 389/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9547 - accuracy: 0.7611 - val_loss: 1.0947 - val_accuracy: 0.7368\n",
      "Epoch 390/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9530 - accuracy: 0.7637 - val_loss: 1.0676 - val_accuracy: 0.7372\n",
      "Epoch 391/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9551 - accuracy: 0.7620 - val_loss: 1.0167 - val_accuracy: 0.7496\n",
      "Epoch 392/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9546 - accuracy: 0.7602 - val_loss: 1.0409 - val_accuracy: 0.7446\n",
      "Epoch 393/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9537 - accuracy: 0.7633 - val_loss: 1.0133 - val_accuracy: 0.7465\n",
      "Epoch 394/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9692 - accuracy: 0.7590 - val_loss: 1.2769 - val_accuracy: 0.6961\n",
      "Epoch 395/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9518 - accuracy: 0.7715 - val_loss: 1.1281 - val_accuracy: 0.7562\n",
      "Epoch 396/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9390 - accuracy: 0.7680 - val_loss: 1.1864 - val_accuracy: 0.7302\n",
      "Epoch 397/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9473 - accuracy: 0.7644 - val_loss: 1.1401 - val_accuracy: 0.7442\n",
      "Epoch 398/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9482 - accuracy: 0.7663 - val_loss: 1.1412 - val_accuracy: 0.7492\n",
      "Epoch 399/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9413 - accuracy: 0.7661 - val_loss: 1.1794 - val_accuracy: 0.7496\n",
      "Epoch 400/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9522 - accuracy: 0.7643 - val_loss: 1.1957 - val_accuracy: 0.7450\n",
      "Epoch 401/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9404 - accuracy: 0.7673 - val_loss: 1.1830 - val_accuracy: 0.7516\n",
      "Epoch 402/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9421 - accuracy: 0.7669 - val_loss: 1.0339 - val_accuracy: 0.7279\n",
      "Epoch 403/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9423 - accuracy: 0.7683 - val_loss: 1.0706 - val_accuracy: 0.7271\n",
      "Epoch 404/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9462 - accuracy: 0.7662 - val_loss: 1.0216 - val_accuracy: 0.7438\n",
      "Epoch 405/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9420 - accuracy: 0.7651 - val_loss: 1.0144 - val_accuracy: 0.7461\n",
      "Epoch 406/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9386 - accuracy: 0.7672 - val_loss: 1.0159 - val_accuracy: 0.7384\n",
      "Epoch 407/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9385 - accuracy: 0.7667 - val_loss: 1.0270 - val_accuracy: 0.7349\n",
      "Epoch 408/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9371 - accuracy: 0.7669 - val_loss: 0.9997 - val_accuracy: 0.7430\n",
      "Epoch 409/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9418 - accuracy: 0.7655 - val_loss: 1.1139 - val_accuracy: 0.7182\n",
      "Epoch 410/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9327 - accuracy: 0.7695 - val_loss: 1.0012 - val_accuracy: 0.7589\n",
      "Epoch 411/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9453 - accuracy: 0.7655 - val_loss: 0.9936 - val_accuracy: 0.7422\n",
      "Epoch 412/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9369 - accuracy: 0.7656 - val_loss: 1.0303 - val_accuracy: 0.7419\n",
      "Epoch 413/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9357 - accuracy: 0.7678 - val_loss: 1.0849 - val_accuracy: 0.7163\n",
      "Epoch 414/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9463 - accuracy: 0.7633 - val_loss: 1.0063 - val_accuracy: 0.7659\n",
      "Epoch 415/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9339 - accuracy: 0.7682 - val_loss: 1.0119 - val_accuracy: 0.7349\n",
      "Epoch 416/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9365 - accuracy: 0.7708 - val_loss: 1.0064 - val_accuracy: 0.7419\n",
      "Epoch 417/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9270 - accuracy: 0.7689 - val_loss: 1.0183 - val_accuracy: 0.7364\n",
      "Epoch 418/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9228 - accuracy: 0.7690 - val_loss: 0.9868 - val_accuracy: 0.7550\n",
      "Epoch 419/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9321 - accuracy: 0.7685 - val_loss: 0.9968 - val_accuracy: 0.7554\n",
      "Epoch 420/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9288 - accuracy: 0.7675 - val_loss: 1.0052 - val_accuracy: 0.7446\n",
      "Epoch 421/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9461 - accuracy: 0.7687 - val_loss: 1.0072 - val_accuracy: 0.7539\n",
      "Epoch 422/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9246 - accuracy: 0.7732 - val_loss: 0.9869 - val_accuracy: 0.7566\n",
      "Epoch 423/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9230 - accuracy: 0.7717 - val_loss: 1.0265 - val_accuracy: 0.7453\n",
      "Epoch 424/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9206 - accuracy: 0.7735 - val_loss: 1.0623 - val_accuracy: 0.7360\n",
      "Epoch 425/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9270 - accuracy: 0.7686 - val_loss: 1.0097 - val_accuracy: 0.7399\n",
      "Epoch 426/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9201 - accuracy: 0.7702 - val_loss: 0.9977 - val_accuracy: 0.7570\n",
      "Epoch 427/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9269 - accuracy: 0.7713 - val_loss: 1.0158 - val_accuracy: 0.7380\n",
      "Epoch 428/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9246 - accuracy: 0.7691 - val_loss: 0.9788 - val_accuracy: 0.7636\n",
      "Epoch 429/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9258 - accuracy: 0.7711 - val_loss: 1.0244 - val_accuracy: 0.7566\n",
      "Epoch 430/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9213 - accuracy: 0.7713 - val_loss: 1.0869 - val_accuracy: 0.7473\n",
      "Epoch 431/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9299 - accuracy: 0.7701 - val_loss: 1.1180 - val_accuracy: 0.7516\n",
      "Epoch 432/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9280 - accuracy: 0.7673 - val_loss: 1.1127 - val_accuracy: 0.7326\n",
      "Epoch 433/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9251 - accuracy: 0.7692 - val_loss: 1.0639 - val_accuracy: 0.7519\n",
      "Epoch 434/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9173 - accuracy: 0.7717 - val_loss: 1.1037 - val_accuracy: 0.7407\n",
      "Epoch 435/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9184 - accuracy: 0.7735 - val_loss: 1.0980 - val_accuracy: 0.7453\n",
      "Epoch 436/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9190 - accuracy: 0.7702 - val_loss: 1.1602 - val_accuracy: 0.7295\n",
      "Epoch 437/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9141 - accuracy: 0.7737 - val_loss: 1.0964 - val_accuracy: 0.7438\n",
      "Epoch 438/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9175 - accuracy: 0.7693 - val_loss: 1.1428 - val_accuracy: 0.7329\n",
      "Epoch 439/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9209 - accuracy: 0.7692 - val_loss: 1.1353 - val_accuracy: 0.7481\n",
      "Epoch 440/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9209 - accuracy: 0.7705 - val_loss: 1.1648 - val_accuracy: 0.7360\n",
      "Epoch 441/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9165 - accuracy: 0.7726 - val_loss: 1.1165 - val_accuracy: 0.7488\n",
      "Epoch 442/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9107 - accuracy: 0.7733 - val_loss: 1.1632 - val_accuracy: 0.7368\n",
      "Epoch 443/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9230 - accuracy: 0.7691 - val_loss: 1.1389 - val_accuracy: 0.7496\n",
      "Epoch 444/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9127 - accuracy: 0.7757 - val_loss: 1.1557 - val_accuracy: 0.7519\n",
      "Epoch 445/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9175 - accuracy: 0.7709 - val_loss: 1.1943 - val_accuracy: 0.7484\n",
      "Epoch 446/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9163 - accuracy: 0.7740 - val_loss: 1.2044 - val_accuracy: 0.7093\n",
      "Epoch 447/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9100 - accuracy: 0.7742 - val_loss: 1.0856 - val_accuracy: 0.7380\n",
      "Epoch 448/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9031 - accuracy: 0.7778 - val_loss: 1.0727 - val_accuracy: 0.7430\n",
      "Epoch 449/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9095 - accuracy: 0.7740 - val_loss: 1.0542 - val_accuracy: 0.7581\n",
      "Epoch 450/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9057 - accuracy: 0.7774 - val_loss: 1.0812 - val_accuracy: 0.7519\n",
      "Epoch 451/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9050 - accuracy: 0.7742 - val_loss: 1.0903 - val_accuracy: 0.7434\n",
      "Epoch 452/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9039 - accuracy: 0.7761 - val_loss: 1.0959 - val_accuracy: 0.7457\n",
      "Epoch 453/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9063 - accuracy: 0.7746 - val_loss: 1.1257 - val_accuracy: 0.7512\n",
      "Epoch 454/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9095 - accuracy: 0.7732 - val_loss: 1.0882 - val_accuracy: 0.7581\n",
      "Epoch 455/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9062 - accuracy: 0.7763 - val_loss: 1.1475 - val_accuracy: 0.7523\n",
      "Epoch 456/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9054 - accuracy: 0.7720 - val_loss: 1.1008 - val_accuracy: 0.7616\n",
      "Epoch 457/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9010 - accuracy: 0.7757 - val_loss: 1.1170 - val_accuracy: 0.7500\n",
      "Epoch 458/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9031 - accuracy: 0.7773 - val_loss: 1.2244 - val_accuracy: 0.7357\n",
      "Epoch 459/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9097 - accuracy: 0.7738 - val_loss: 1.1345 - val_accuracy: 0.7717\n",
      "Epoch 460/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9045 - accuracy: 0.7760 - val_loss: 1.1527 - val_accuracy: 0.7504\n",
      "Epoch 461/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8992 - accuracy: 0.7749 - val_loss: 0.9566 - val_accuracy: 0.7647\n",
      "Epoch 462/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9032 - accuracy: 0.7748 - val_loss: 0.9926 - val_accuracy: 0.7481\n",
      "Epoch 463/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9005 - accuracy: 0.7751 - val_loss: 0.9463 - val_accuracy: 0.7764\n",
      "Epoch 464/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.9013 - accuracy: 0.7752 - val_loss: 0.9927 - val_accuracy: 0.7407\n",
      "Epoch 465/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.9028 - accuracy: 0.7779 - val_loss: 0.9771 - val_accuracy: 0.7457\n",
      "Epoch 466/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8990 - accuracy: 0.7756 - val_loss: 0.9753 - val_accuracy: 0.7558\n",
      "Epoch 467/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8930 - accuracy: 0.7773 - val_loss: 0.9952 - val_accuracy: 0.7399\n",
      "Epoch 468/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8964 - accuracy: 0.7744 - val_loss: 1.0325 - val_accuracy: 0.7337\n",
      "Epoch 469/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8933 - accuracy: 0.7771 - val_loss: 0.9706 - val_accuracy: 0.7554\n",
      "Epoch 470/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8980 - accuracy: 0.7776 - val_loss: 0.9550 - val_accuracy: 0.7678\n",
      "Epoch 471/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8986 - accuracy: 0.7764 - val_loss: 0.9439 - val_accuracy: 0.7721\n",
      "Epoch 472/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8869 - accuracy: 0.7788 - val_loss: 0.9794 - val_accuracy: 0.7496\n",
      "Epoch 473/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8947 - accuracy: 0.7780 - val_loss: 0.9779 - val_accuracy: 0.7500\n",
      "Epoch 474/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8923 - accuracy: 0.7773 - val_loss: 0.9682 - val_accuracy: 0.7469\n",
      "Epoch 475/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8922 - accuracy: 0.7765 - val_loss: 0.9921 - val_accuracy: 0.7488\n",
      "Epoch 476/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8924 - accuracy: 0.7779 - val_loss: 1.0004 - val_accuracy: 0.7341\n",
      "Epoch 477/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8905 - accuracy: 0.7784 - val_loss: 0.9370 - val_accuracy: 0.7748\n",
      "Epoch 478/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8972 - accuracy: 0.7764 - val_loss: 0.9627 - val_accuracy: 0.7605\n",
      "Epoch 479/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8852 - accuracy: 0.7803 - val_loss: 1.0430 - val_accuracy: 0.7368\n",
      "Epoch 480/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8971 - accuracy: 0.7781 - val_loss: 0.9457 - val_accuracy: 0.7694\n",
      "Epoch 481/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8830 - accuracy: 0.7801 - val_loss: 0.9970 - val_accuracy: 0.7341\n",
      "Epoch 482/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8876 - accuracy: 0.7792 - val_loss: 0.9381 - val_accuracy: 0.7783\n",
      "Epoch 483/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8881 - accuracy: 0.7781 - val_loss: 1.0833 - val_accuracy: 0.7248\n",
      "Epoch 484/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8854 - accuracy: 0.7769 - val_loss: 0.9824 - val_accuracy: 0.7628\n",
      "Epoch 485/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8870 - accuracy: 0.7778 - val_loss: 0.9527 - val_accuracy: 0.7620\n",
      "Epoch 486/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8926 - accuracy: 0.7773 - val_loss: 0.9451 - val_accuracy: 0.7702\n",
      "Epoch 487/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8783 - accuracy: 0.7823 - val_loss: 0.9833 - val_accuracy: 0.7477\n",
      "Epoch 488/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8898 - accuracy: 0.7767 - val_loss: 0.9450 - val_accuracy: 0.7671\n",
      "Epoch 489/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8809 - accuracy: 0.7788 - val_loss: 0.9592 - val_accuracy: 0.7535\n",
      "Epoch 490/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8941 - accuracy: 0.7794 - val_loss: 0.9960 - val_accuracy: 0.7543\n",
      "Epoch 491/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8705 - accuracy: 0.7839 - val_loss: 0.9666 - val_accuracy: 0.7771\n",
      "Epoch 492/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8845 - accuracy: 0.7811 - val_loss: 1.0639 - val_accuracy: 0.7484\n",
      "Epoch 493/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8717 - accuracy: 0.7829 - val_loss: 0.9818 - val_accuracy: 0.7709\n",
      "Epoch 494/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8837 - accuracy: 0.7781 - val_loss: 1.1364 - val_accuracy: 0.7279\n",
      "Epoch 495/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8839 - accuracy: 0.7794 - val_loss: 1.0200 - val_accuracy: 0.7543\n",
      "Epoch 496/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8768 - accuracy: 0.7812 - val_loss: 1.0453 - val_accuracy: 0.7550\n",
      "Epoch 497/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8765 - accuracy: 0.7823 - val_loss: 1.0499 - val_accuracy: 0.7609\n",
      "Epoch 498/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8832 - accuracy: 0.7823 - val_loss: 1.0356 - val_accuracy: 0.7795\n",
      "Epoch 499/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8754 - accuracy: 0.7826 - val_loss: 1.0599 - val_accuracy: 0.7547\n",
      "Epoch 500/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8746 - accuracy: 0.7812 - val_loss: 1.0759 - val_accuracy: 0.7539\n",
      "Epoch 501/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8813 - accuracy: 0.7792 - val_loss: 1.0558 - val_accuracy: 0.7702\n",
      "Epoch 502/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8759 - accuracy: 0.7814 - val_loss: 1.1528 - val_accuracy: 0.7461\n",
      "Epoch 503/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8751 - accuracy: 0.7807 - val_loss: 1.1382 - val_accuracy: 0.7705\n",
      "Epoch 504/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8750 - accuracy: 0.7827 - val_loss: 1.0361 - val_accuracy: 0.7329\n",
      "Epoch 505/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8732 - accuracy: 0.7817 - val_loss: 1.0078 - val_accuracy: 0.7508\n",
      "Epoch 506/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8773 - accuracy: 0.7784 - val_loss: 0.9928 - val_accuracy: 0.7647\n",
      "Epoch 507/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8724 - accuracy: 0.7819 - val_loss: 0.9983 - val_accuracy: 0.7488\n",
      "Epoch 508/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8666 - accuracy: 0.7836 - val_loss: 1.0375 - val_accuracy: 0.7496\n",
      "Epoch 509/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8664 - accuracy: 0.7835 - val_loss: 1.0134 - val_accuracy: 0.7496\n",
      "Epoch 510/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8747 - accuracy: 0.7821 - val_loss: 1.0157 - val_accuracy: 0.7612\n",
      "Epoch 511/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8895 - accuracy: 0.7828 - val_loss: 1.1957 - val_accuracy: 0.7845\n",
      "Epoch 512/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8548 - accuracy: 0.7919 - val_loss: 1.1772 - val_accuracy: 0.7849\n",
      "Epoch 513/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8616 - accuracy: 0.7885 - val_loss: 1.2142 - val_accuracy: 0.7671\n",
      "Epoch 514/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8621 - accuracy: 0.7839 - val_loss: 1.1796 - val_accuracy: 0.7795\n",
      "Epoch 515/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8580 - accuracy: 0.7887 - val_loss: 1.2063 - val_accuracy: 0.7721\n",
      "Epoch 516/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8590 - accuracy: 0.7869 - val_loss: 1.2038 - val_accuracy: 0.7864\n",
      "Epoch 517/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8674 - accuracy: 0.7836 - val_loss: 1.3383 - val_accuracy: 0.7376\n",
      "Epoch 518/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8667 - accuracy: 0.7809 - val_loss: 1.2223 - val_accuracy: 0.7802\n",
      "Epoch 519/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8623 - accuracy: 0.7866 - val_loss: 1.3007 - val_accuracy: 0.7469\n",
      "Epoch 520/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8703 - accuracy: 0.7846 - val_loss: 1.2783 - val_accuracy: 0.7512\n",
      "Epoch 521/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8807 - accuracy: 0.7789 - val_loss: 1.4438 - val_accuracy: 0.7605\n",
      "Epoch 522/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8647 - accuracy: 0.7908 - val_loss: 0.9284 - val_accuracy: 0.7767\n",
      "Epoch 523/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8491 - accuracy: 0.7910 - val_loss: 0.9188 - val_accuracy: 0.7725\n",
      "Epoch 524/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8521 - accuracy: 0.7880 - val_loss: 0.9583 - val_accuracy: 0.7581\n",
      "Epoch 525/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8554 - accuracy: 0.7892 - val_loss: 0.9575 - val_accuracy: 0.7609\n",
      "Epoch 526/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8582 - accuracy: 0.7896 - val_loss: 0.9350 - val_accuracy: 0.7655\n",
      "Epoch 527/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8597 - accuracy: 0.7868 - val_loss: 0.9322 - val_accuracy: 0.7744\n",
      "Epoch 528/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8598 - accuracy: 0.7857 - val_loss: 0.9118 - val_accuracy: 0.7810\n",
      "Epoch 529/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8610 - accuracy: 0.7852 - val_loss: 0.9505 - val_accuracy: 0.7713\n",
      "Epoch 530/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8553 - accuracy: 0.7895 - val_loss: 1.0164 - val_accuracy: 0.7473\n",
      "Epoch 531/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8527 - accuracy: 0.7892 - val_loss: 0.9895 - val_accuracy: 0.7570\n",
      "Epoch 532/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8517 - accuracy: 0.7895 - val_loss: 1.0294 - val_accuracy: 0.7438\n",
      "Epoch 533/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8711 - accuracy: 0.7811 - val_loss: 0.9849 - val_accuracy: 0.7771\n",
      "Epoch 534/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8656 - accuracy: 0.7843 - val_loss: 0.9854 - val_accuracy: 0.7636\n",
      "Epoch 535/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8630 - accuracy: 0.7884 - val_loss: 0.9882 - val_accuracy: 0.7698\n",
      "Epoch 536/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8570 - accuracy: 0.7870 - val_loss: 0.9988 - val_accuracy: 0.7647\n",
      "Epoch 537/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8464 - accuracy: 0.7898 - val_loss: 0.9887 - val_accuracy: 0.7884\n",
      "Epoch 538/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8540 - accuracy: 0.7897 - val_loss: 1.0681 - val_accuracy: 0.7508\n",
      "Epoch 539/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8636 - accuracy: 0.7828 - val_loss: 1.0217 - val_accuracy: 0.7671\n",
      "Epoch 540/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8613 - accuracy: 0.7853 - val_loss: 1.0505 - val_accuracy: 0.7729\n",
      "Epoch 541/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8553 - accuracy: 0.7856 - val_loss: 1.0895 - val_accuracy: 0.7527\n",
      "Epoch 542/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8589 - accuracy: 0.7856 - val_loss: 1.0815 - val_accuracy: 0.7659\n",
      "Epoch 543/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8573 - accuracy: 0.7869 - val_loss: 1.0773 - val_accuracy: 0.7798\n",
      "Epoch 544/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8715 - accuracy: 0.7881 - val_loss: 0.9226 - val_accuracy: 0.7702\n",
      "Epoch 545/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8440 - accuracy: 0.7915 - val_loss: 0.9240 - val_accuracy: 0.7748\n",
      "Epoch 546/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8471 - accuracy: 0.7903 - val_loss: 0.9207 - val_accuracy: 0.7709\n",
      "Epoch 547/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8415 - accuracy: 0.7905 - val_loss: 0.9420 - val_accuracy: 0.7756\n",
      "Epoch 548/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8467 - accuracy: 0.7908 - val_loss: 1.0586 - val_accuracy: 0.7345\n",
      "Epoch 549/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8499 - accuracy: 0.7889 - val_loss: 0.9455 - val_accuracy: 0.7705\n",
      "Epoch 550/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8448 - accuracy: 0.7891 - val_loss: 0.9829 - val_accuracy: 0.7717\n",
      "Epoch 551/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8441 - accuracy: 0.7894 - val_loss: 0.9988 - val_accuracy: 0.7702\n",
      "Epoch 552/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8565 - accuracy: 0.7865 - val_loss: 0.9560 - val_accuracy: 0.7597\n",
      "Epoch 553/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8418 - accuracy: 0.7904 - val_loss: 0.9726 - val_accuracy: 0.7612\n",
      "Epoch 554/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8439 - accuracy: 0.7882 - val_loss: 0.9701 - val_accuracy: 0.7748\n",
      "Epoch 555/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8473 - accuracy: 0.7908 - val_loss: 0.9999 - val_accuracy: 0.7655\n",
      "Epoch 556/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8495 - accuracy: 0.7876 - val_loss: 1.0117 - val_accuracy: 0.7779\n",
      "Epoch 557/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8418 - accuracy: 0.7910 - val_loss: 1.0465 - val_accuracy: 0.7643\n",
      "Epoch 558/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8392 - accuracy: 0.7905 - val_loss: 1.0460 - val_accuracy: 0.7667\n",
      "Epoch 559/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8571 - accuracy: 0.7862 - val_loss: 1.0802 - val_accuracy: 0.7616\n",
      "Epoch 560/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8510 - accuracy: 0.7891 - val_loss: 1.1949 - val_accuracy: 0.7384\n",
      "Epoch 561/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8399 - accuracy: 0.7914 - val_loss: 1.0688 - val_accuracy: 0.7767\n",
      "Epoch 562/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8401 - accuracy: 0.7902 - val_loss: 1.1186 - val_accuracy: 0.7585\n",
      "Epoch 563/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8412 - accuracy: 0.7894 - val_loss: 1.1495 - val_accuracy: 0.7554\n",
      "Epoch 564/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8368 - accuracy: 0.7919 - val_loss: 1.1292 - val_accuracy: 0.7671\n",
      "Epoch 565/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8533 - accuracy: 0.7854 - val_loss: 1.1760 - val_accuracy: 0.7597\n",
      "Epoch 566/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8399 - accuracy: 0.7894 - val_loss: 1.1756 - val_accuracy: 0.7624\n",
      "Epoch 567/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8497 - accuracy: 0.7894 - val_loss: 1.1672 - val_accuracy: 0.7705\n",
      "Epoch 568/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8388 - accuracy: 0.7912 - val_loss: 1.2071 - val_accuracy: 0.7620\n",
      "Epoch 569/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8385 - accuracy: 0.7913 - val_loss: 1.2538 - val_accuracy: 0.7539\n",
      "Epoch 570/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8384 - accuracy: 0.7951 - val_loss: 1.2022 - val_accuracy: 0.7733\n",
      "Epoch 571/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8410 - accuracy: 0.7888 - val_loss: 1.2743 - val_accuracy: 0.7484\n",
      "Epoch 572/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8325 - accuracy: 0.7928 - val_loss: 1.2254 - val_accuracy: 0.7791\n",
      "Epoch 573/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8435 - accuracy: 0.7880 - val_loss: 1.2622 - val_accuracy: 0.7690\n",
      "Epoch 574/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8412 - accuracy: 0.7902 - val_loss: 1.2685 - val_accuracy: 0.7612\n",
      "Epoch 575/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8294 - accuracy: 0.7933 - val_loss: 1.2652 - val_accuracy: 0.7748\n",
      "Epoch 576/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8339 - accuracy: 0.7944 - val_loss: 1.2834 - val_accuracy: 0.7802\n",
      "Epoch 577/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8360 - accuracy: 0.7919 - val_loss: 1.3691 - val_accuracy: 0.7492\n",
      "Epoch 578/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8357 - accuracy: 0.7933 - val_loss: 1.2578 - val_accuracy: 0.7775\n",
      "Epoch 579/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8394 - accuracy: 0.7895 - val_loss: 0.8966 - val_accuracy: 0.7818\n",
      "Epoch 580/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8307 - accuracy: 0.7916 - val_loss: 1.0136 - val_accuracy: 0.7388\n",
      "Epoch 581/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8391 - accuracy: 0.7917 - val_loss: 0.8867 - val_accuracy: 0.7736\n",
      "Epoch 582/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8334 - accuracy: 0.7964 - val_loss: 0.8909 - val_accuracy: 0.7736\n",
      "Epoch 583/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8273 - accuracy: 0.7923 - val_loss: 0.9276 - val_accuracy: 0.7609\n",
      "Epoch 584/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8458 - accuracy: 0.7913 - val_loss: 0.9571 - val_accuracy: 0.7492\n",
      "Epoch 585/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8265 - accuracy: 0.7952 - val_loss: 0.9515 - val_accuracy: 0.7550\n",
      "Epoch 586/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8337 - accuracy: 0.7927 - val_loss: 0.8822 - val_accuracy: 0.7907\n",
      "Epoch 587/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8312 - accuracy: 0.7919 - val_loss: 0.9316 - val_accuracy: 0.7771\n",
      "Epoch 588/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.7941 - val_loss: 0.8935 - val_accuracy: 0.7798\n",
      "Epoch 589/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8205 - accuracy: 0.7971 - val_loss: 0.8632 - val_accuracy: 0.8043\n",
      "Epoch 590/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8278 - accuracy: 0.7937 - val_loss: 0.9179 - val_accuracy: 0.7678\n",
      "Epoch 591/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8283 - accuracy: 0.7942 - val_loss: 0.9710 - val_accuracy: 0.7457\n",
      "Epoch 592/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.7893 - val_loss: 0.8944 - val_accuracy: 0.7795\n",
      "Epoch 593/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8286 - accuracy: 0.7951 - val_loss: 0.8772 - val_accuracy: 0.7833\n",
      "Epoch 594/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8218 - accuracy: 0.7954 - val_loss: 0.9308 - val_accuracy: 0.7682\n",
      "Epoch 595/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8138 - accuracy: 0.7998 - val_loss: 0.9124 - val_accuracy: 0.7628\n",
      "Epoch 596/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8240 - accuracy: 0.7920 - val_loss: 0.8710 - val_accuracy: 0.7926\n",
      "Epoch 597/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8259 - accuracy: 0.7937 - val_loss: 0.9232 - val_accuracy: 0.7628\n",
      "Epoch 598/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8216 - accuracy: 0.7940 - val_loss: 0.8826 - val_accuracy: 0.7810\n",
      "Epoch 599/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8233 - accuracy: 0.7941 - val_loss: 0.8829 - val_accuracy: 0.7876\n",
      "Epoch 600/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8189 - accuracy: 0.7980 - val_loss: 0.9227 - val_accuracy: 0.7574\n",
      "Epoch 601/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8241 - accuracy: 0.7960 - val_loss: 0.8694 - val_accuracy: 0.7930\n",
      "Epoch 602/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8233 - accuracy: 0.7940 - val_loss: 0.9018 - val_accuracy: 0.7690\n",
      "Epoch 603/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8172 - accuracy: 0.7974 - val_loss: 0.8921 - val_accuracy: 0.7841\n",
      "Epoch 604/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8253 - accuracy: 0.7951 - val_loss: 0.9227 - val_accuracy: 0.7643\n",
      "Epoch 605/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8230 - accuracy: 0.7937 - val_loss: 0.8838 - val_accuracy: 0.7864\n",
      "Epoch 606/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8183 - accuracy: 0.7966 - val_loss: 0.8652 - val_accuracy: 0.7849\n",
      "Epoch 607/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8208 - accuracy: 0.7939 - val_loss: 0.9077 - val_accuracy: 0.7694\n",
      "Epoch 608/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8169 - accuracy: 0.7952 - val_loss: 0.8754 - val_accuracy: 0.7841\n",
      "Epoch 609/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8217 - accuracy: 0.7951 - val_loss: 0.9065 - val_accuracy: 0.7628\n",
      "Epoch 610/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8158 - accuracy: 0.7981 - val_loss: 0.8750 - val_accuracy: 0.7849\n",
      "Epoch 611/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8110 - accuracy: 0.7997 - val_loss: 0.8680 - val_accuracy: 0.7961\n",
      "Epoch 612/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8150 - accuracy: 0.7979 - val_loss: 0.8869 - val_accuracy: 0.7779\n",
      "Epoch 613/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8261 - accuracy: 0.7933 - val_loss: 0.8748 - val_accuracy: 0.7818\n",
      "Epoch 614/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8151 - accuracy: 0.7976 - val_loss: 0.8805 - val_accuracy: 0.7721\n",
      "Epoch 615/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8109 - accuracy: 0.7992 - val_loss: 0.9014 - val_accuracy: 0.7756\n",
      "Epoch 616/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8127 - accuracy: 0.7977 - val_loss: 0.8866 - val_accuracy: 0.7663\n",
      "Epoch 617/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8142 - accuracy: 0.7955 - val_loss: 0.9030 - val_accuracy: 0.7663\n",
      "Epoch 618/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8143 - accuracy: 0.7971 - val_loss: 0.8899 - val_accuracy: 0.7721\n",
      "Epoch 619/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8219 - accuracy: 0.7982 - val_loss: 0.9029 - val_accuracy: 0.7690\n",
      "Epoch 620/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8122 - accuracy: 0.7983 - val_loss: 0.8950 - val_accuracy: 0.7748\n",
      "Epoch 621/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8093 - accuracy: 0.7982 - val_loss: 0.8998 - val_accuracy: 0.7655\n",
      "Epoch 622/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8102 - accuracy: 0.7994 - val_loss: 0.8772 - val_accuracy: 0.7795\n",
      "Epoch 623/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8059 - accuracy: 0.7980 - val_loss: 0.9122 - val_accuracy: 0.7957\n",
      "Epoch 624/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8202 - accuracy: 0.7951 - val_loss: 1.0038 - val_accuracy: 0.7543\n",
      "Epoch 625/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8209 - accuracy: 0.7944 - val_loss: 1.0613 - val_accuracy: 0.7477\n",
      "Epoch 626/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8032 - accuracy: 0.8018 - val_loss: 1.0168 - val_accuracy: 0.7578\n",
      "Epoch 627/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8008 - accuracy: 0.8029 - val_loss: 0.9572 - val_accuracy: 0.7853\n",
      "Epoch 628/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8081 - accuracy: 0.8017 - val_loss: 0.9768 - val_accuracy: 0.7760\n",
      "Epoch 629/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8200 - accuracy: 0.7957 - val_loss: 0.9995 - val_accuracy: 0.7659\n",
      "Epoch 630/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8106 - accuracy: 0.7991 - val_loss: 0.9393 - val_accuracy: 0.7938\n",
      "Epoch 631/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8015 - accuracy: 0.7992 - val_loss: 0.9647 - val_accuracy: 0.7857\n",
      "Epoch 632/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8078 - accuracy: 0.8003 - val_loss: 1.0712 - val_accuracy: 0.7550\n",
      "Epoch 633/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 1.0979 - accuracy: 0.8020 - val_loss: 1.0824 - val_accuracy: 0.7822\n",
      "Epoch 634/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7936 - accuracy: 0.8067 - val_loss: 1.0732 - val_accuracy: 0.8023\n",
      "Epoch 635/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7959 - accuracy: 0.8047 - val_loss: 1.0907 - val_accuracy: 0.7942\n",
      "Epoch 636/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7975 - accuracy: 0.8002 - val_loss: 1.1257 - val_accuracy: 0.7919\n",
      "Epoch 637/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8017 - accuracy: 0.8037 - val_loss: 1.1562 - val_accuracy: 0.7845\n",
      "Epoch 638/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8044 - accuracy: 0.7984 - val_loss: 1.1883 - val_accuracy: 0.7740\n",
      "Epoch 639/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7984 - accuracy: 0.8025 - val_loss: 1.2094 - val_accuracy: 0.7698\n",
      "Epoch 640/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7986 - accuracy: 0.8056 - val_loss: 1.1834 - val_accuracy: 0.7818\n",
      "Epoch 641/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7971 - accuracy: 0.8013 - val_loss: 1.2207 - val_accuracy: 0.7686\n",
      "Epoch 642/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8024 - accuracy: 0.8003 - val_loss: 1.2321 - val_accuracy: 0.7783\n",
      "Epoch 643/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8018 - accuracy: 0.7990 - val_loss: 1.2081 - val_accuracy: 0.7775\n",
      "Epoch 644/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8043 - accuracy: 0.8000 - val_loss: 1.2954 - val_accuracy: 0.7674\n",
      "Epoch 645/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8048 - accuracy: 0.7990 - val_loss: 1.2709 - val_accuracy: 0.7911\n",
      "Epoch 646/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7983 - accuracy: 0.8031 - val_loss: 1.2919 - val_accuracy: 0.7729\n",
      "Epoch 647/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8072 - accuracy: 0.7950 - val_loss: 1.3928 - val_accuracy: 0.7461\n",
      "Epoch 648/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8023 - accuracy: 0.7985 - val_loss: 1.2309 - val_accuracy: 0.7709\n",
      "Epoch 649/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7993 - accuracy: 0.8016 - val_loss: 1.2132 - val_accuracy: 0.7895\n",
      "Epoch 650/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8095 - accuracy: 0.8007 - val_loss: 1.2498 - val_accuracy: 0.7919\n",
      "Epoch 651/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8043 - accuracy: 0.7980 - val_loss: 1.2682 - val_accuracy: 0.7837\n",
      "Epoch 652/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7986 - accuracy: 0.8013 - val_loss: 1.2807 - val_accuracy: 0.7783\n",
      "Epoch 653/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7962 - accuracy: 0.7994 - val_loss: 1.3355 - val_accuracy: 0.7651\n",
      "Epoch 654/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8031 - accuracy: 0.7998 - val_loss: 1.3943 - val_accuracy: 0.7512\n",
      "Epoch 655/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8054 - accuracy: 0.8015 - val_loss: 1.3053 - val_accuracy: 0.7802\n",
      "Epoch 656/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7937 - accuracy: 0.8009 - val_loss: 1.3024 - val_accuracy: 0.8023\n",
      "Epoch 657/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.8067 - accuracy: 0.7978 - val_loss: 1.3610 - val_accuracy: 0.7829\n",
      "Epoch 658/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7974 - accuracy: 0.8011 - val_loss: 1.4207 - val_accuracy: 0.7771\n",
      "Epoch 659/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7955 - accuracy: 0.8027 - val_loss: 0.8290 - val_accuracy: 0.8058\n",
      "Epoch 660/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7964 - accuracy: 0.7999 - val_loss: 0.8755 - val_accuracy: 0.7802\n",
      "Epoch 661/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7927 - accuracy: 0.8028 - val_loss: 0.8534 - val_accuracy: 0.7752\n",
      "Epoch 662/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7926 - accuracy: 0.8023 - val_loss: 0.8814 - val_accuracy: 0.7748\n",
      "Epoch 663/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7972 - accuracy: 0.8011 - val_loss: 0.8707 - val_accuracy: 0.7795\n",
      "Epoch 664/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7930 - accuracy: 0.7995 - val_loss: 0.9298 - val_accuracy: 0.7512\n",
      "Epoch 665/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7923 - accuracy: 0.8045 - val_loss: 0.8479 - val_accuracy: 0.7837\n",
      "Epoch 666/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7952 - accuracy: 0.8023 - val_loss: 0.8820 - val_accuracy: 0.7787\n",
      "Epoch 667/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7959 - accuracy: 0.8009 - val_loss: 0.8960 - val_accuracy: 0.7616\n",
      "Epoch 668/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7905 - accuracy: 0.8044 - val_loss: 0.8637 - val_accuracy: 0.7977\n",
      "Epoch 669/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7954 - accuracy: 0.7998 - val_loss: 0.9126 - val_accuracy: 0.7752\n",
      "Epoch 670/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7919 - accuracy: 0.8025 - val_loss: 0.8513 - val_accuracy: 0.7930\n",
      "Epoch 671/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7861 - accuracy: 0.8048 - val_loss: 0.9207 - val_accuracy: 0.7628\n",
      "Epoch 672/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7977 - accuracy: 0.8023 - val_loss: 0.8708 - val_accuracy: 0.7907\n",
      "Epoch 673/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7930 - accuracy: 0.8032 - val_loss: 0.9601 - val_accuracy: 0.7655\n",
      "Epoch 674/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7956 - accuracy: 0.8023 - val_loss: 0.8890 - val_accuracy: 0.7647\n",
      "Epoch 675/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7992 - accuracy: 0.7991 - val_loss: 0.9240 - val_accuracy: 0.7601\n",
      "Epoch 676/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7820 - accuracy: 0.8061 - val_loss: 0.8295 - val_accuracy: 0.8109\n",
      "Epoch 677/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7894 - accuracy: 0.8019 - val_loss: 0.8968 - val_accuracy: 0.7771\n",
      "Epoch 678/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8006 - accuracy: 0.8022 - val_loss: 0.8472 - val_accuracy: 0.7915\n",
      "Epoch 679/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7885 - accuracy: 0.8019 - val_loss: 0.9759 - val_accuracy: 0.7523\n",
      "Epoch 680/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7847 - accuracy: 0.8073 - val_loss: 0.9193 - val_accuracy: 0.7678\n",
      "Epoch 681/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7874 - accuracy: 0.8050 - val_loss: 0.8909 - val_accuracy: 0.7717\n",
      "Epoch 682/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7958 - accuracy: 0.8017 - val_loss: 0.8714 - val_accuracy: 0.7872\n",
      "Epoch 683/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7783 - accuracy: 0.8073 - val_loss: 0.8310 - val_accuracy: 0.7957\n",
      "Epoch 684/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7898 - accuracy: 0.8042 - val_loss: 0.9056 - val_accuracy: 0.7740\n",
      "Epoch 685/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7824 - accuracy: 0.8047 - val_loss: 0.8762 - val_accuracy: 0.7609\n",
      "Epoch 686/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7891 - accuracy: 0.8054 - val_loss: 1.0578 - val_accuracy: 0.7434\n",
      "Epoch 687/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7956 - accuracy: 0.8037 - val_loss: 0.8641 - val_accuracy: 0.7795\n",
      "Epoch 688/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8087 - accuracy: 0.8068 - val_loss: 0.8961 - val_accuracy: 0.7686\n",
      "Epoch 689/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7736 - accuracy: 0.8110 - val_loss: 0.8227 - val_accuracy: 0.8112\n",
      "Epoch 690/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7748 - accuracy: 0.8099 - val_loss: 0.8170 - val_accuracy: 0.7977\n",
      "Epoch 691/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7729 - accuracy: 0.8124 - val_loss: 0.9339 - val_accuracy: 0.7523\n",
      "Epoch 692/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7775 - accuracy: 0.8095 - val_loss: 0.8169 - val_accuracy: 0.7938\n",
      "Epoch 693/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7742 - accuracy: 0.8103 - val_loss: 0.8493 - val_accuracy: 0.7996\n",
      "Epoch 694/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7926 - accuracy: 0.8025 - val_loss: 0.8701 - val_accuracy: 0.7748\n",
      "Epoch 695/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7890 - accuracy: 0.8016 - val_loss: 0.8641 - val_accuracy: 0.7690\n",
      "Epoch 696/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7770 - accuracy: 0.8085 - val_loss: 0.8722 - val_accuracy: 0.7678\n",
      "Epoch 697/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7797 - accuracy: 0.8062 - val_loss: 0.8839 - val_accuracy: 0.7787\n",
      "Epoch 698/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7729 - accuracy: 0.8094 - val_loss: 0.8903 - val_accuracy: 0.7678\n",
      "Epoch 699/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7736 - accuracy: 0.8075 - val_loss: 0.8555 - val_accuracy: 0.7795\n",
      "Epoch 700/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7811 - accuracy: 0.8056 - val_loss: 0.8138 - val_accuracy: 0.8043\n",
      "Epoch 701/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8037 - accuracy: 0.8003 - val_loss: 0.8276 - val_accuracy: 0.8035\n",
      "Epoch 702/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7782 - accuracy: 0.8077 - val_loss: 0.9078 - val_accuracy: 0.7585\n",
      "Epoch 703/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7744 - accuracy: 0.8093 - val_loss: 0.9149 - val_accuracy: 0.7678\n",
      "Epoch 704/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7813 - accuracy: 0.8038 - val_loss: 0.8463 - val_accuracy: 0.7829\n",
      "Epoch 705/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7786 - accuracy: 0.8065 - val_loss: 0.8338 - val_accuracy: 0.7950\n",
      "Epoch 706/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7822 - accuracy: 0.8058 - val_loss: 0.8517 - val_accuracy: 0.7748\n",
      "Epoch 707/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7797 - accuracy: 0.8041 - val_loss: 0.8422 - val_accuracy: 0.7930\n",
      "Epoch 708/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7777 - accuracy: 0.8083 - val_loss: 0.8724 - val_accuracy: 0.7771\n",
      "Epoch 709/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7879 - accuracy: 0.8016 - val_loss: 0.8306 - val_accuracy: 0.7946\n",
      "Epoch 710/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7781 - accuracy: 0.8043 - val_loss: 0.8406 - val_accuracy: 0.7857\n",
      "Epoch 711/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7883 - accuracy: 0.8059 - val_loss: 0.8344 - val_accuracy: 0.7845\n",
      "Epoch 712/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7756 - accuracy: 0.8047 - val_loss: 0.8348 - val_accuracy: 0.7818\n",
      "Epoch 713/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7797 - accuracy: 0.8039 - val_loss: 0.8465 - val_accuracy: 0.7884\n",
      "Epoch 714/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7786 - accuracy: 0.8055 - val_loss: 0.8204 - val_accuracy: 0.7926\n",
      "Epoch 715/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7705 - accuracy: 0.8085 - val_loss: 0.8187 - val_accuracy: 0.8019\n",
      "Epoch 716/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7713 - accuracy: 0.8077 - val_loss: 0.8993 - val_accuracy: 0.7643\n",
      "Epoch 717/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7883 - accuracy: 0.8019 - val_loss: 0.8570 - val_accuracy: 0.7798\n",
      "Epoch 718/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7798 - accuracy: 0.8027 - val_loss: 0.8447 - val_accuracy: 0.7938\n",
      "Epoch 719/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7760 - accuracy: 0.8067 - val_loss: 0.8614 - val_accuracy: 0.7853\n",
      "Epoch 720/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7868 - accuracy: 0.8068 - val_loss: 1.1998 - val_accuracy: 0.8016\n",
      "Epoch 721/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7670 - accuracy: 0.8111 - val_loss: 1.2456 - val_accuracy: 0.7705\n",
      "Epoch 722/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7599 - accuracy: 0.8137 - val_loss: 1.2262 - val_accuracy: 0.7810\n",
      "Epoch 723/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7624 - accuracy: 0.8127 - val_loss: 1.1943 - val_accuracy: 0.8050\n",
      "Epoch 724/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7661 - accuracy: 0.8102 - val_loss: 1.2032 - val_accuracy: 0.7880\n",
      "Epoch 725/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7784 - accuracy: 0.8084 - val_loss: 1.1759 - val_accuracy: 0.7996\n",
      "Epoch 726/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7649 - accuracy: 0.8087 - val_loss: 1.1972 - val_accuracy: 0.7814\n",
      "Epoch 727/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7695 - accuracy: 0.8076 - val_loss: 1.1891 - val_accuracy: 0.7752\n",
      "Epoch 728/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7727 - accuracy: 0.8060 - val_loss: 1.1612 - val_accuracy: 0.7915\n",
      "Epoch 729/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7629 - accuracy: 0.8106 - val_loss: 1.1844 - val_accuracy: 0.7891\n",
      "Epoch 730/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7647 - accuracy: 0.8090 - val_loss: 1.1925 - val_accuracy: 0.7841\n",
      "Epoch 731/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7720 - accuracy: 0.8087 - val_loss: 1.2327 - val_accuracy: 0.7713\n",
      "Epoch 732/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7727 - accuracy: 0.8070 - val_loss: 1.1726 - val_accuracy: 0.7996\n",
      "Epoch 733/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7763 - accuracy: 0.8080 - val_loss: 1.2668 - val_accuracy: 0.7806\n",
      "Epoch 734/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7740 - accuracy: 0.8068 - val_loss: 1.2321 - val_accuracy: 0.7864\n",
      "Epoch 735/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7725 - accuracy: 0.8060 - val_loss: 1.2729 - val_accuracy: 0.7795\n",
      "Epoch 736/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7835 - accuracy: 0.8069 - val_loss: 1.2907 - val_accuracy: 0.7787\n",
      "Epoch 737/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7587 - accuracy: 0.8110 - val_loss: 1.3380 - val_accuracy: 0.7783\n",
      "Epoch 738/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7660 - accuracy: 0.8081 - val_loss: 1.2907 - val_accuracy: 0.7895\n",
      "Epoch 739/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7648 - accuracy: 0.8110 - val_loss: 1.2710 - val_accuracy: 0.7860\n",
      "Epoch 740/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7616 - accuracy: 0.8095 - val_loss: 1.2853 - val_accuracy: 0.7977\n",
      "Epoch 741/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7692 - accuracy: 0.8092 - val_loss: 1.3766 - val_accuracy: 0.7640\n",
      "Epoch 742/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.8074 - val_loss: 1.3464 - val_accuracy: 0.7938\n",
      "Epoch 743/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7722 - accuracy: 0.8077 - val_loss: 1.3958 - val_accuracy: 0.8112\n",
      "Epoch 744/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7740 - accuracy: 0.8070 - val_loss: 1.4246 - val_accuracy: 0.7756\n",
      "Epoch 745/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7640 - accuracy: 0.8094 - val_loss: 1.5063 - val_accuracy: 0.7562\n",
      "Epoch 746/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7578 - accuracy: 0.8103 - val_loss: 1.4500 - val_accuracy: 0.7822\n",
      "Epoch 747/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7712 - accuracy: 0.8087 - val_loss: 1.4817 - val_accuracy: 0.8004\n",
      "Epoch 748/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7652 - accuracy: 0.8099 - val_loss: 1.5929 - val_accuracy: 0.7570\n",
      "Epoch 749/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7666 - accuracy: 0.8073 - val_loss: 1.4478 - val_accuracy: 0.8074\n",
      "Epoch 750/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7573 - accuracy: 0.8121 - val_loss: 1.5361 - val_accuracy: 0.7771\n",
      "Epoch 751/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7640 - accuracy: 0.8127 - val_loss: 1.4027 - val_accuracy: 0.7953\n",
      "Epoch 752/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7583 - accuracy: 0.8115 - val_loss: 1.4627 - val_accuracy: 0.7798\n",
      "Epoch 753/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7718 - accuracy: 0.8056 - val_loss: 1.4646 - val_accuracy: 0.7930\n",
      "Epoch 754/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7725 - accuracy: 0.8068 - val_loss: 1.5044 - val_accuracy: 0.7872\n",
      "Epoch 755/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7567 - accuracy: 0.8115 - val_loss: 1.5206 - val_accuracy: 0.7725\n",
      "Epoch 756/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7641 - accuracy: 0.8113 - val_loss: 1.5024 - val_accuracy: 0.7977\n",
      "Epoch 757/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7609 - accuracy: 0.8123 - val_loss: 0.8498 - val_accuracy: 0.7915\n",
      "Epoch 758/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7615 - accuracy: 0.8116 - val_loss: 0.9427 - val_accuracy: 0.7663\n",
      "Epoch 759/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7670 - accuracy: 0.8075 - val_loss: 0.8526 - val_accuracy: 0.8140\n",
      "Epoch 760/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7514 - accuracy: 0.8120 - val_loss: 0.8883 - val_accuracy: 0.7899\n",
      "Epoch 761/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7606 - accuracy: 0.8093 - val_loss: 0.9060 - val_accuracy: 0.7973\n",
      "Epoch 762/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7560 - accuracy: 0.8107 - val_loss: 0.9057 - val_accuracy: 0.7818\n",
      "Epoch 763/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7626 - accuracy: 0.8102 - val_loss: 0.9586 - val_accuracy: 0.7795\n",
      "Epoch 764/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7658 - accuracy: 0.8056 - val_loss: 0.8894 - val_accuracy: 0.7791\n",
      "Epoch 765/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7518 - accuracy: 0.8153 - val_loss: 0.8970 - val_accuracy: 0.7725\n",
      "Epoch 766/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7550 - accuracy: 0.8118 - val_loss: 0.8814 - val_accuracy: 0.7721\n",
      "Epoch 767/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7548 - accuracy: 0.8129 - val_loss: 0.8456 - val_accuracy: 0.7779\n",
      "Epoch 768/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7589 - accuracy: 0.8106 - val_loss: 0.8432 - val_accuracy: 0.8081\n",
      "Epoch 769/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7628 - accuracy: 0.8083 - val_loss: 0.8497 - val_accuracy: 0.7961\n",
      "Epoch 770/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7562 - accuracy: 0.8106 - val_loss: 0.9268 - val_accuracy: 0.7922\n",
      "Epoch 771/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7535 - accuracy: 0.8109 - val_loss: 0.8873 - val_accuracy: 0.7895\n",
      "Epoch 772/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7581 - accuracy: 0.8099 - val_loss: 0.9664 - val_accuracy: 0.7705\n",
      "Epoch 773/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7476 - accuracy: 0.8116 - val_loss: 0.9660 - val_accuracy: 0.7783\n",
      "Epoch 774/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7521 - accuracy: 0.8134 - val_loss: 0.9370 - val_accuracy: 0.7930\n",
      "Epoch 775/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7588 - accuracy: 0.8105 - val_loss: 0.9187 - val_accuracy: 0.8031\n",
      "Epoch 776/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7581 - accuracy: 0.8102 - val_loss: 0.9363 - val_accuracy: 0.7981\n",
      "Epoch 777/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7477 - accuracy: 0.8129 - val_loss: 0.9746 - val_accuracy: 0.7849\n",
      "Epoch 778/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7564 - accuracy: 0.8119 - val_loss: 1.0334 - val_accuracy: 0.7767\n",
      "Epoch 779/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7535 - accuracy: 0.8126 - val_loss: 1.0127 - val_accuracy: 0.7822\n",
      "Epoch 780/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7507 - accuracy: 0.8132 - val_loss: 1.0050 - val_accuracy: 0.8031\n",
      "Epoch 781/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7569 - accuracy: 0.8101 - val_loss: 1.0657 - val_accuracy: 0.7729\n",
      "Epoch 782/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7585 - accuracy: 0.8085 - val_loss: 1.1092 - val_accuracy: 0.7748\n",
      "Epoch 783/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7538 - accuracy: 0.8119 - val_loss: 1.1356 - val_accuracy: 0.7698\n",
      "Epoch 784/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7560 - accuracy: 0.8139 - val_loss: 1.1206 - val_accuracy: 0.7783\n",
      "Epoch 785/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7568 - accuracy: 0.8102 - val_loss: 1.0767 - val_accuracy: 0.8004\n",
      "Epoch 786/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7575 - accuracy: 0.8105 - val_loss: 1.0914 - val_accuracy: 0.7938\n",
      "Epoch 787/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7447 - accuracy: 0.8132 - val_loss: 1.1099 - val_accuracy: 0.7992\n",
      "Epoch 788/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7615 - accuracy: 0.8094 - val_loss: 1.1787 - val_accuracy: 0.7911\n",
      "Epoch 789/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7459 - accuracy: 0.8144 - val_loss: 1.1316 - val_accuracy: 0.7953\n",
      "Epoch 790/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7483 - accuracy: 0.8147 - val_loss: 1.0776 - val_accuracy: 0.8019\n",
      "Epoch 791/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7511 - accuracy: 0.8129 - val_loss: 1.1371 - val_accuracy: 0.7868\n",
      "Epoch 792/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7559 - accuracy: 0.8093 - val_loss: 1.1981 - val_accuracy: 0.7946\n",
      "Epoch 793/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7518 - accuracy: 0.8133 - val_loss: 1.1406 - val_accuracy: 0.7919\n",
      "Epoch 794/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7519 - accuracy: 0.8115 - val_loss: 1.1788 - val_accuracy: 0.7764\n",
      "Epoch 795/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7378 - accuracy: 0.8155 - val_loss: 1.2188 - val_accuracy: 0.7899\n",
      "Epoch 796/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7547 - accuracy: 0.8110 - val_loss: 1.1961 - val_accuracy: 0.7942\n",
      "Epoch 797/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7424 - accuracy: 0.8131 - val_loss: 1.2684 - val_accuracy: 0.7810\n",
      "Epoch 798/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7533 - accuracy: 0.8115 - val_loss: 1.2404 - val_accuracy: 0.7922\n",
      "Epoch 799/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7464 - accuracy: 0.8127 - val_loss: 1.2941 - val_accuracy: 0.7717\n",
      "Epoch 800/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7496 - accuracy: 0.8132 - val_loss: 1.3691 - val_accuracy: 0.7589\n",
      "Epoch 801/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7468 - accuracy: 0.8130 - val_loss: 1.3189 - val_accuracy: 0.7953\n",
      "Epoch 802/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7498 - accuracy: 0.8146 - val_loss: 1.3248 - val_accuracy: 0.7911\n",
      "Epoch 803/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7442 - accuracy: 0.8135 - val_loss: 1.3247 - val_accuracy: 0.8000\n",
      "Epoch 804/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7444 - accuracy: 0.8162 - val_loss: 1.3707 - val_accuracy: 0.7783\n",
      "Epoch 805/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7367 - accuracy: 0.8184 - val_loss: 1.3833 - val_accuracy: 0.7868\n",
      "Epoch 806/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7446 - accuracy: 0.8144 - val_loss: 1.3552 - val_accuracy: 0.7984\n",
      "Epoch 807/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7445 - accuracy: 0.8149 - val_loss: 1.3643 - val_accuracy: 0.7841\n",
      "Epoch 808/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7546 - accuracy: 0.8143 - val_loss: 1.3554 - val_accuracy: 0.7981\n",
      "Epoch 809/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7427 - accuracy: 0.8148 - val_loss: 1.3444 - val_accuracy: 0.8163\n",
      "Epoch 810/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7333 - accuracy: 0.8182 - val_loss: 1.3788 - val_accuracy: 0.7973\n",
      "Epoch 811/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7765 - accuracy: 0.8105 - val_loss: 1.1862 - val_accuracy: 0.8012\n",
      "Epoch 812/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7346 - accuracy: 0.8191 - val_loss: 1.2668 - val_accuracy: 0.8074\n",
      "Epoch 813/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7233 - accuracy: 0.8244 - val_loss: 1.2559 - val_accuracy: 0.8027\n",
      "Epoch 814/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7278 - accuracy: 0.8170 - val_loss: 1.2219 - val_accuracy: 0.8039\n",
      "Epoch 815/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7376 - accuracy: 0.8185 - val_loss: 1.2395 - val_accuracy: 0.7849\n",
      "Epoch 816/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7429 - accuracy: 0.8156 - val_loss: 1.2901 - val_accuracy: 0.7988\n",
      "Epoch 817/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7401 - accuracy: 0.8167 - val_loss: 1.2608 - val_accuracy: 0.7868\n",
      "Epoch 818/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7430 - accuracy: 0.8144 - val_loss: 1.2750 - val_accuracy: 0.8008\n",
      "Epoch 819/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7348 - accuracy: 0.8169 - val_loss: 1.2967 - val_accuracy: 0.7810\n",
      "Epoch 820/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7516 - accuracy: 0.8138 - val_loss: 1.3927 - val_accuracy: 0.7694\n",
      "Epoch 821/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7397 - accuracy: 0.8171 - val_loss: 1.2516 - val_accuracy: 0.8155\n",
      "Epoch 822/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7304 - accuracy: 0.8181 - val_loss: 1.2572 - val_accuracy: 0.7969\n",
      "Epoch 823/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7372 - accuracy: 0.8187 - val_loss: 1.2301 - val_accuracy: 0.8128\n",
      "Epoch 824/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7253 - accuracy: 0.8195 - val_loss: 1.2371 - val_accuracy: 0.7981\n",
      "Epoch 825/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7362 - accuracy: 0.8176 - val_loss: 1.2937 - val_accuracy: 0.7895\n",
      "Epoch 826/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7448 - accuracy: 0.8160 - val_loss: 1.3061 - val_accuracy: 0.7950\n",
      "Epoch 827/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7347 - accuracy: 0.8175 - val_loss: 1.3426 - val_accuracy: 0.7992\n",
      "Epoch 828/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7323 - accuracy: 0.8173 - val_loss: 1.3493 - val_accuracy: 0.8035\n",
      "Epoch 829/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7461 - accuracy: 0.8155 - val_loss: 1.3190 - val_accuracy: 0.7922\n",
      "Epoch 830/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7323 - accuracy: 0.8157 - val_loss: 1.3102 - val_accuracy: 0.8070\n",
      "Epoch 831/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7318 - accuracy: 0.8220 - val_loss: 1.4439 - val_accuracy: 0.7678\n",
      "Epoch 832/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7283 - accuracy: 0.8188 - val_loss: 1.3588 - val_accuracy: 0.8043\n",
      "Epoch 833/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7400 - accuracy: 0.8132 - val_loss: 1.4032 - val_accuracy: 0.7787\n",
      "Epoch 834/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7510 - accuracy: 0.8161 - val_loss: 1.4117 - val_accuracy: 0.7779\n",
      "Epoch 835/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7441 - accuracy: 0.8160 - val_loss: 1.3010 - val_accuracy: 0.8070\n",
      "Epoch 836/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7278 - accuracy: 0.8235 - val_loss: 1.3168 - val_accuracy: 0.8062\n",
      "Epoch 837/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7369 - accuracy: 0.8124 - val_loss: 1.3303 - val_accuracy: 0.8112\n",
      "Epoch 838/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7328 - accuracy: 0.8189 - val_loss: 1.1456 - val_accuracy: 0.7880\n",
      "Epoch 839/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7219 - accuracy: 0.8192 - val_loss: 1.1517 - val_accuracy: 0.7919\n",
      "Epoch 840/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7363 - accuracy: 0.8160 - val_loss: 1.2070 - val_accuracy: 0.7740\n",
      "Epoch 841/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7423 - accuracy: 0.8133 - val_loss: 1.1966 - val_accuracy: 0.7926\n",
      "Epoch 842/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7356 - accuracy: 0.8178 - val_loss: 1.2022 - val_accuracy: 0.7922\n",
      "Epoch 843/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7328 - accuracy: 0.8171 - val_loss: 1.2091 - val_accuracy: 0.7992\n",
      "Epoch 844/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7445 - accuracy: 0.8127 - val_loss: 1.2082 - val_accuracy: 0.7934\n",
      "Epoch 845/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7446 - accuracy: 0.8125 - val_loss: 1.1959 - val_accuracy: 0.8178\n",
      "Epoch 846/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7321 - accuracy: 0.8178 - val_loss: 1.2061 - val_accuracy: 0.8097\n",
      "Epoch 847/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7278 - accuracy: 0.8200 - val_loss: 1.2562 - val_accuracy: 0.8000\n",
      "Epoch 848/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7308 - accuracy: 0.8182 - val_loss: 1.2444 - val_accuracy: 0.8124\n",
      "Epoch 849/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7279 - accuracy: 0.8199 - val_loss: 1.3116 - val_accuracy: 0.7895\n",
      "Epoch 850/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7354 - accuracy: 0.8165 - val_loss: 1.2744 - val_accuracy: 0.8043\n",
      "Epoch 851/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7339 - accuracy: 0.8147 - val_loss: 1.3133 - val_accuracy: 0.8004\n",
      "Epoch 852/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7419 - accuracy: 0.8144 - val_loss: 1.3028 - val_accuracy: 0.7961\n",
      "Epoch 853/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7301 - accuracy: 0.8185 - val_loss: 1.3178 - val_accuracy: 0.8225\n",
      "Epoch 854/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7251 - accuracy: 0.8184 - val_loss: 1.3363 - val_accuracy: 0.7969\n",
      "Epoch 855/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7201 - accuracy: 0.8206 - val_loss: 1.3403 - val_accuracy: 0.7953\n",
      "Epoch 856/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7357 - accuracy: 0.8170 - val_loss: 1.3443 - val_accuracy: 0.7868\n",
      "Epoch 857/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.8205 - val_loss: 1.3642 - val_accuracy: 0.7922\n",
      "Epoch 858/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7348 - accuracy: 0.8159 - val_loss: 1.3771 - val_accuracy: 0.7957\n",
      "Epoch 859/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7245 - accuracy: 0.8190 - val_loss: 1.4795 - val_accuracy: 0.7899\n",
      "Epoch 860/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7180 - accuracy: 0.8190 - val_loss: 1.4013 - val_accuracy: 0.7988\n",
      "Epoch 861/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7261 - accuracy: 0.8189 - val_loss: 1.5644 - val_accuracy: 0.7628\n",
      "Epoch 862/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.8058 - accuracy: 0.8149 - val_loss: 1.8425 - val_accuracy: 0.8093\n",
      "Epoch 863/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7123 - accuracy: 0.8276 - val_loss: 1.8708 - val_accuracy: 0.8174\n",
      "Epoch 864/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7080 - accuracy: 0.8261 - val_loss: 1.8298 - val_accuracy: 0.7957\n",
      "Epoch 865/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7229 - accuracy: 0.8219 - val_loss: 1.8611 - val_accuracy: 0.7922\n",
      "Epoch 866/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.8263 - val_loss: 1.7938 - val_accuracy: 0.8035\n",
      "Epoch 867/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7084 - accuracy: 0.8256 - val_loss: 1.8060 - val_accuracy: 0.7965\n",
      "Epoch 868/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7205 - accuracy: 0.8203 - val_loss: 1.7970 - val_accuracy: 0.8124\n",
      "Epoch 869/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7179 - accuracy: 0.8212 - val_loss: 1.7918 - val_accuracy: 0.8093\n",
      "Epoch 870/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7116 - accuracy: 0.8221 - val_loss: 1.8847 - val_accuracy: 0.7919\n",
      "Epoch 871/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7392 - accuracy: 0.8155 - val_loss: 1.8836 - val_accuracy: 0.8116\n",
      "Epoch 872/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7193 - accuracy: 0.8224 - val_loss: 1.9071 - val_accuracy: 0.8054\n",
      "Epoch 873/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7176 - accuracy: 0.8191 - val_loss: 2.1878 - val_accuracy: 0.7399\n",
      "Epoch 874/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7206 - accuracy: 0.8197 - val_loss: 1.9362 - val_accuracy: 0.8070\n",
      "Epoch 875/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.8187 - val_loss: 1.5494 - val_accuracy: 0.8116\n",
      "Epoch 876/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7197 - accuracy: 0.8216 - val_loss: 1.5421 - val_accuracy: 0.7981\n",
      "Epoch 877/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7293 - accuracy: 0.8189 - val_loss: 1.5784 - val_accuracy: 0.7969\n",
      "Epoch 878/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7261 - accuracy: 0.8189 - val_loss: 1.5800 - val_accuracy: 0.8008\n",
      "Epoch 879/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7209 - accuracy: 0.8202 - val_loss: 1.5734 - val_accuracy: 0.8019\n",
      "Epoch 880/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7255 - accuracy: 0.8196 - val_loss: 1.5993 - val_accuracy: 0.8116\n",
      "Epoch 881/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7252 - accuracy: 0.8177 - val_loss: 1.5538 - val_accuracy: 0.8155\n",
      "Epoch 882/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7202 - accuracy: 0.8211 - val_loss: 1.6262 - val_accuracy: 0.8054\n",
      "Epoch 883/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7245 - accuracy: 0.8193 - val_loss: 1.6422 - val_accuracy: 0.8167\n",
      "Epoch 884/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7212 - accuracy: 0.8208 - val_loss: 1.7344 - val_accuracy: 0.7872\n",
      "Epoch 885/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7105 - accuracy: 0.8232 - val_loss: 1.6704 - val_accuracy: 0.7950\n",
      "Epoch 886/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7133 - accuracy: 0.8227 - val_loss: 1.7941 - val_accuracy: 0.7605\n",
      "Epoch 887/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.8186 - val_loss: 1.6971 - val_accuracy: 0.7953\n",
      "Epoch 888/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7194 - accuracy: 0.8202 - val_loss: 1.7513 - val_accuracy: 0.7709\n",
      "Epoch 889/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7259 - accuracy: 0.8187 - val_loss: 1.7193 - val_accuracy: 0.8271\n",
      "Epoch 890/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7329 - accuracy: 0.8181 - val_loss: 1.7408 - val_accuracy: 0.8186\n",
      "Epoch 891/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.8230 - val_loss: 1.7862 - val_accuracy: 0.8101\n",
      "Epoch 892/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7336 - accuracy: 0.8178 - val_loss: 1.7776 - val_accuracy: 0.8105\n",
      "Epoch 893/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7121 - accuracy: 0.8219 - val_loss: 1.8273 - val_accuracy: 0.7876\n",
      "Epoch 894/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7217 - accuracy: 0.8196 - val_loss: 1.8590 - val_accuracy: 0.8043\n",
      "Epoch 895/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7081 - accuracy: 0.8238 - val_loss: 1.9394 - val_accuracy: 0.7752\n",
      "Epoch 896/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7146 - accuracy: 0.8216 - val_loss: 1.8205 - val_accuracy: 0.8132\n",
      "Epoch 897/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7235 - accuracy: 0.8182 - val_loss: 1.9307 - val_accuracy: 0.7849\n",
      "Epoch 898/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7192 - accuracy: 0.8205 - val_loss: 1.8253 - val_accuracy: 0.8078\n",
      "Epoch 899/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7196 - accuracy: 0.8226 - val_loss: 1.9017 - val_accuracy: 0.7891\n",
      "Epoch 900/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7096 - accuracy: 0.8229 - val_loss: 1.9209 - val_accuracy: 0.7841\n",
      "Epoch 901/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7140 - accuracy: 0.8214 - val_loss: 1.9141 - val_accuracy: 0.7841\n",
      "Epoch 902/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7110 - accuracy: 0.8239 - val_loss: 1.9493 - val_accuracy: 0.7798\n",
      "Epoch 903/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7136 - accuracy: 0.8226 - val_loss: 2.0025 - val_accuracy: 0.7798\n",
      "Epoch 904/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7200 - accuracy: 0.8234 - val_loss: 1.8849 - val_accuracy: 0.8116\n",
      "Epoch 905/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7127 - accuracy: 0.8220 - val_loss: 1.8918 - val_accuracy: 0.8136\n",
      "Epoch 906/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.8214 - val_loss: 1.3918 - val_accuracy: 0.7907\n",
      "Epoch 907/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7075 - accuracy: 0.8244 - val_loss: 1.3394 - val_accuracy: 0.8085\n",
      "Epoch 908/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7118 - accuracy: 0.8236 - val_loss: 1.3173 - val_accuracy: 0.8039\n",
      "Epoch 909/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7155 - accuracy: 0.8192 - val_loss: 1.4173 - val_accuracy: 0.8081\n",
      "Epoch 910/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7189 - accuracy: 0.8223 - val_loss: 1.3096 - val_accuracy: 0.8194\n",
      "Epoch 911/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7136 - accuracy: 0.8244 - val_loss: 1.3858 - val_accuracy: 0.7969\n",
      "Epoch 912/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7124 - accuracy: 0.8248 - val_loss: 1.3349 - val_accuracy: 0.8097\n",
      "Epoch 913/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7209 - accuracy: 0.8229 - val_loss: 1.3093 - val_accuracy: 0.8174\n",
      "Epoch 914/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7119 - accuracy: 0.8238 - val_loss: 1.3244 - val_accuracy: 0.8240\n",
      "Epoch 915/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7121 - accuracy: 0.8242 - val_loss: 1.3819 - val_accuracy: 0.7868\n",
      "Epoch 916/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7236 - accuracy: 0.8186 - val_loss: 1.4321 - val_accuracy: 0.7950\n",
      "Epoch 917/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7128 - accuracy: 0.8190 - val_loss: 1.4130 - val_accuracy: 0.7802\n",
      "Epoch 918/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7234 - accuracy: 0.8182 - val_loss: 1.4948 - val_accuracy: 0.7950\n",
      "Epoch 919/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7071 - accuracy: 0.8233 - val_loss: 1.4467 - val_accuracy: 0.8136\n",
      "Epoch 920/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7124 - accuracy: 0.8232 - val_loss: 1.4689 - val_accuracy: 0.8128\n",
      "Epoch 921/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.8263 - val_loss: 1.5826 - val_accuracy: 0.7872\n",
      "Epoch 922/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7115 - accuracy: 0.8190 - val_loss: 1.6079 - val_accuracy: 0.7736\n",
      "Epoch 923/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7175 - accuracy: 0.8233 - val_loss: 1.5864 - val_accuracy: 0.7609\n",
      "Epoch 924/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7439 - accuracy: 0.8209 - val_loss: 1.8738 - val_accuracy: 0.8151\n",
      "Epoch 925/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6968 - accuracy: 0.8332 - val_loss: 1.6439 - val_accuracy: 0.8171\n",
      "Epoch 926/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.8314 - val_loss: 1.6499 - val_accuracy: 0.8329\n",
      "Epoch 927/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7034 - accuracy: 0.8273 - val_loss: 1.7004 - val_accuracy: 0.8132\n",
      "Epoch 928/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.8311 - val_loss: 1.6921 - val_accuracy: 0.8182\n",
      "Epoch 929/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7076 - accuracy: 0.8239 - val_loss: 1.6984 - val_accuracy: 0.7876\n",
      "Epoch 930/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7458 - accuracy: 0.8212 - val_loss: 1.3662 - val_accuracy: 0.7915\n",
      "Epoch 931/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6972 - accuracy: 0.8278 - val_loss: 1.3578 - val_accuracy: 0.8124\n",
      "Epoch 932/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.8301 - val_loss: 1.3316 - val_accuracy: 0.8124\n",
      "Epoch 933/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7062 - accuracy: 0.8256 - val_loss: 1.3634 - val_accuracy: 0.8089\n",
      "Epoch 934/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7028 - accuracy: 0.8264 - val_loss: 1.4254 - val_accuracy: 0.7930\n",
      "Epoch 935/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7132 - accuracy: 0.8224 - val_loss: 1.4198 - val_accuracy: 0.8085\n",
      "Epoch 936/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7124 - accuracy: 0.8242 - val_loss: 1.4321 - val_accuracy: 0.8124\n",
      "Epoch 937/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6983 - accuracy: 0.8280 - val_loss: 1.3945 - val_accuracy: 0.7965\n",
      "Epoch 938/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7093 - accuracy: 0.8233 - val_loss: 1.5536 - val_accuracy: 0.7694\n",
      "Epoch 939/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7036 - accuracy: 0.8240 - val_loss: 1.3985 - val_accuracy: 0.8333\n",
      "Epoch 940/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7157 - accuracy: 0.8209 - val_loss: 1.4980 - val_accuracy: 0.7984\n",
      "Epoch 941/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7060 - accuracy: 0.8242 - val_loss: 1.4557 - val_accuracy: 0.7981\n",
      "Epoch 942/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.8221 - val_loss: 1.4251 - val_accuracy: 0.8233\n",
      "Epoch 943/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7075 - accuracy: 0.8225 - val_loss: 1.5009 - val_accuracy: 0.8112\n",
      "Epoch 944/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6969 - accuracy: 0.8266 - val_loss: 1.5053 - val_accuracy: 0.8019\n",
      "Epoch 945/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7023 - accuracy: 0.8236 - val_loss: 1.5911 - val_accuracy: 0.7795\n",
      "Epoch 946/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7092 - accuracy: 0.8222 - val_loss: 1.6481 - val_accuracy: 0.7636\n",
      "Epoch 947/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7056 - accuracy: 0.8229 - val_loss: 1.5475 - val_accuracy: 0.7857\n",
      "Epoch 948/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7102 - accuracy: 0.8234 - val_loss: 1.6258 - val_accuracy: 0.7775\n",
      "Epoch 949/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6942 - accuracy: 0.8273 - val_loss: 1.5016 - val_accuracy: 0.8190\n",
      "Epoch 950/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7030 - accuracy: 0.8251 - val_loss: 1.6324 - val_accuracy: 0.7818\n",
      "Epoch 951/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7015 - accuracy: 0.8261 - val_loss: 1.5610 - val_accuracy: 0.7934\n",
      "Epoch 952/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6971 - accuracy: 0.8252 - val_loss: 1.5907 - val_accuracy: 0.7984\n",
      "Epoch 953/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6998 - accuracy: 0.8252 - val_loss: 1.5819 - val_accuracy: 0.7919\n",
      "Epoch 954/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7140 - accuracy: 0.8217 - val_loss: 1.5456 - val_accuracy: 0.8116\n",
      "Epoch 955/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7107 - accuracy: 0.8225 - val_loss: 1.6031 - val_accuracy: 0.7942\n",
      "Epoch 956/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7077 - accuracy: 0.8209 - val_loss: 1.5137 - val_accuracy: 0.8205\n",
      "Epoch 957/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7014 - accuracy: 0.8264 - val_loss: 1.5455 - val_accuracy: 0.8089\n",
      "Epoch 958/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.8279 - val_loss: 1.5686 - val_accuracy: 0.8213\n",
      "Epoch 959/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7213 - accuracy: 0.8223 - val_loss: 1.6334 - val_accuracy: 0.7798\n",
      "Epoch 960/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7050 - accuracy: 0.8255 - val_loss: 1.6368 - val_accuracy: 0.7868\n",
      "Epoch 961/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.8278 - val_loss: 1.5519 - val_accuracy: 0.8019\n",
      "Epoch 962/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6997 - accuracy: 0.8233 - val_loss: 1.5821 - val_accuracy: 0.8155\n",
      "Epoch 963/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7040 - accuracy: 0.8248 - val_loss: 1.5900 - val_accuracy: 0.8078\n",
      "Epoch 964/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7062 - accuracy: 0.8243 - val_loss: 1.7156 - val_accuracy: 0.7934\n",
      "Epoch 965/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6924 - accuracy: 0.8270 - val_loss: 1.7318 - val_accuracy: 0.7802\n",
      "Epoch 966/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6980 - accuracy: 0.8243 - val_loss: 1.7022 - val_accuracy: 0.8140\n",
      "Epoch 967/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6998 - accuracy: 0.8266 - val_loss: 1.7573 - val_accuracy: 0.7915\n",
      "Epoch 968/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6971 - accuracy: 0.8270 - val_loss: 1.6729 - val_accuracy: 0.8074\n",
      "Epoch 969/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7088 - accuracy: 0.8233 - val_loss: 1.6452 - val_accuracy: 0.8213\n",
      "Epoch 970/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.8285 - val_loss: 1.7168 - val_accuracy: 0.7977\n",
      "Epoch 971/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6983 - accuracy: 0.8273 - val_loss: 1.7710 - val_accuracy: 0.7988\n",
      "Epoch 972/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6974 - accuracy: 0.8245 - val_loss: 1.7436 - val_accuracy: 0.7810\n",
      "Epoch 973/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.8281 - val_loss: 1.7288 - val_accuracy: 0.7922\n",
      "Epoch 974/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6950 - accuracy: 0.8276 - val_loss: 1.7248 - val_accuracy: 0.7950\n",
      "Epoch 975/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7099 - accuracy: 0.8229 - val_loss: 1.7497 - val_accuracy: 0.7988\n",
      "Epoch 976/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7022 - accuracy: 0.8237 - val_loss: 1.7148 - val_accuracy: 0.8089\n",
      "Epoch 977/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6968 - accuracy: 0.8239 - val_loss: 1.7086 - val_accuracy: 0.8062\n",
      "Epoch 978/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6970 - accuracy: 0.8244 - val_loss: 1.7437 - val_accuracy: 0.7884\n",
      "Epoch 979/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7169 - accuracy: 0.8225 - val_loss: 1.9163 - val_accuracy: 0.7791\n",
      "Epoch 980/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7054 - accuracy: 0.8233 - val_loss: 1.7599 - val_accuracy: 0.8058\n",
      "Epoch 981/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.8273 - val_loss: 1.7766 - val_accuracy: 0.8058\n",
      "Epoch 982/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.8280 - val_loss: 1.8218 - val_accuracy: 0.7957\n",
      "Epoch 983/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6986 - accuracy: 0.8240 - val_loss: 1.8894 - val_accuracy: 0.7826\n",
      "Epoch 984/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6980 - accuracy: 0.8270 - val_loss: 1.9538 - val_accuracy: 0.8163\n",
      "Epoch 985/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.7073 - accuracy: 0.8232 - val_loss: 1.9987 - val_accuracy: 0.8112\n",
      "Epoch 986/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6953 - accuracy: 0.8271 - val_loss: 2.0561 - val_accuracy: 0.7934\n",
      "Epoch 987/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6969 - accuracy: 0.8266 - val_loss: 1.8795 - val_accuracy: 0.8163\n",
      "Epoch 988/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.8280 - val_loss: 1.8760 - val_accuracy: 0.8178\n",
      "Epoch 989/1000\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.7560 - accuracy: 0.8262 - val_loss: 1.5123 - val_accuracy: 0.8000\n",
      "Epoch 990/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.8341 - val_loss: 1.3688 - val_accuracy: 0.8163\n",
      "Epoch 991/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6716 - accuracy: 0.8355 - val_loss: 1.3884 - val_accuracy: 0.7969\n",
      "Epoch 992/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6693 - accuracy: 0.8359 - val_loss: 1.4698 - val_accuracy: 0.7907\n",
      "Epoch 993/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6880 - accuracy: 0.8266 - val_loss: 1.5139 - val_accuracy: 0.7876\n",
      "Epoch 994/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6973 - accuracy: 0.8268 - val_loss: 1.4608 - val_accuracy: 0.8167\n",
      "Epoch 995/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.8307 - val_loss: 1.4436 - val_accuracy: 0.8070\n",
      "Epoch 996/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.8301 - val_loss: 1.5873 - val_accuracy: 0.8174\n",
      "Epoch 997/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6899 - accuracy: 0.8279 - val_loss: 1.6326 - val_accuracy: 0.7988\n",
      "Epoch 998/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6797 - accuracy: 0.8317 - val_loss: 1.5778 - val_accuracy: 0.8128\n",
      "Epoch 999/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6950 - accuracy: 0.8272 - val_loss: 1.6837 - val_accuracy: 0.7845\n",
      "Epoch 1000/1000\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 0.6925 - accuracy: 0.8267 - val_loss: 1.5931 - val_accuracy: 0.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sig_class\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 38s\n",
      "Wall time: 17min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'models/sig_class'\n",
    "if (os.path.exists(path)):\n",
    "    model = keras.models.load_model(path)\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(126)))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal())) #80\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(80, activation=tf.keras.layers.LeakyReLU(alpha=0.4), kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(keras.layers.Dense(129, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy']) #.0001\n",
    "    history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test)) #1000 epocas\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0092a047-87e7-4d41-92fe-442c1d497ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv('output/history_mlp_class_sig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804d5dca-da51-4c35-b5fd-3f6bf937b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc413ec-1d01-4036-8bab-e4309224cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 776us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3c63e-297b-428d-8528-da0aa58098c8",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345b8adc-5738-4839-82eb-69a6a1eb0741",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.38095   0.55172        21\n",
      "           1    0.92308   0.66667   0.77419        18\n",
      "           2    1.00000   0.78261   0.87805        23\n",
      "           3    0.90476   0.95000   0.92683        20\n",
      "           4    0.83333   0.86957   0.85106        23\n",
      "           5    0.29167   0.70000   0.41176        20\n",
      "           6    0.81818   0.78261   0.80000        23\n",
      "           7    1.00000   0.84000   0.91304        25\n",
      "           8    1.00000   0.80000   0.88889        25\n",
      "           9    0.68750   0.84615   0.75862        13\n",
      "          10    0.75000   0.39130   0.51429        23\n",
      "          11    0.93750   0.88235   0.90909        17\n",
      "          12    0.92857   0.81250   0.86667        16\n",
      "          13    0.83871   0.83871   0.83871        31\n",
      "          14    1.00000   0.70000   0.82353        30\n",
      "          15    1.00000   0.94737   0.97297        19\n",
      "          16    1.00000   0.84000   0.91304        25\n",
      "          17    0.77778   0.82353   0.80000        17\n",
      "          18    0.55556   0.75000   0.63830        20\n",
      "          19    1.00000   0.25000   0.40000        16\n",
      "          20    1.00000   0.78947   0.88235        19\n",
      "          21    1.00000   0.90476   0.95000        21\n",
      "          22    1.00000   0.77778   0.87500        18\n",
      "          23    1.00000   1.00000   1.00000        14\n",
      "          24    0.84211   0.76190   0.80000        21\n",
      "          25    1.00000   0.85714   0.92308        21\n",
      "          26    0.85714   0.92308   0.88889        13\n",
      "          27    1.00000   0.88000   0.93617        25\n",
      "          28    1.00000   0.81481   0.89796        27\n",
      "          29    1.00000   0.91667   0.95652        24\n",
      "          30    1.00000   0.85714   0.92308        21\n",
      "          31    1.00000   0.76190   0.86486        21\n",
      "          32    0.94118   0.88889   0.91429        18\n",
      "          33    1.00000   1.00000   1.00000        22\n",
      "          34    0.77778   0.38889   0.51852        18\n",
      "          35    0.88889   0.80000   0.84211        10\n",
      "          36    1.00000   0.92593   0.96154        27\n",
      "          37    1.00000   0.23810   0.38462        21\n",
      "          38    1.00000   0.85000   0.91892        20\n",
      "          39    0.87500   0.93333   0.90323        15\n",
      "          40    1.00000   0.89474   0.94444        19\n",
      "          41    1.00000   0.91667   0.95652        12\n",
      "          42    1.00000   0.90000   0.94737        30\n",
      "          43    0.40909   0.36000   0.38298        25\n",
      "          44    1.00000   0.72727   0.84211        22\n",
      "          45    1.00000   0.82609   0.90476        23\n",
      "          46    0.87500   1.00000   0.93333        14\n",
      "          47    1.00000   0.76471   0.86667        17\n",
      "          48    0.86364   0.95000   0.90476        20\n",
      "          49    1.00000   0.76190   0.86486        21\n",
      "          50    0.96000   0.96000   0.96000        25\n",
      "          51    1.00000   0.90909   0.95238        22\n",
      "          52    0.50000   0.61111   0.55000        18\n",
      "          53    0.80769   0.84000   0.82353        25\n",
      "          54    1.00000   0.86364   0.92683        22\n",
      "          55    1.00000   1.00000   1.00000        13\n",
      "          56    0.95455   1.00000   0.97674        21\n",
      "          57    1.00000   0.89286   0.94340        28\n",
      "          58    0.42424   1.00000   0.59574        14\n",
      "          59    0.80000   0.92308   0.85714        26\n",
      "          60    1.00000   0.70588   0.82759        17\n",
      "          61    0.77778   0.87500   0.82353        16\n",
      "          62    0.84211   0.94118   0.88889        17\n",
      "          63    1.00000   0.92000   0.95833        25\n",
      "          64    0.92857   1.00000   0.96296        13\n",
      "          65    0.93333   0.82353   0.87500        17\n",
      "          66    0.90476   0.95000   0.92683        20\n",
      "          67    0.92308   1.00000   0.96000        12\n",
      "          68    0.91304   1.00000   0.95455        21\n",
      "          69    1.00000   0.94444   0.97143        18\n",
      "          70    0.92857   0.92857   0.92857        14\n",
      "          71    0.93750   0.78947   0.85714        19\n",
      "          72    1.00000   1.00000   1.00000        11\n",
      "          73    0.86957   1.00000   0.93023        20\n",
      "          74    1.00000   0.73913   0.85000        23\n",
      "          75    0.80000   0.74074   0.76923        27\n",
      "          76    1.00000   0.95652   0.97778        23\n",
      "          77    0.45000   0.42857   0.43902        21\n",
      "          78    0.09302   1.00000   0.17021        20\n",
      "          79    1.00000   0.79167   0.88372        24\n",
      "          80    1.00000   0.84211   0.91429        19\n",
      "          81    1.00000   0.92857   0.96296        14\n",
      "          82    1.00000   0.70000   0.82353        20\n",
      "          83    1.00000   0.80000   0.88889        20\n",
      "          84    1.00000   0.86957   0.93023        23\n",
      "          85    1.00000   0.91304   0.95455        23\n",
      "          86    1.00000   0.42105   0.59259        19\n",
      "          87    1.00000   0.70000   0.82353        20\n",
      "          88    0.64000   0.84211   0.72727        19\n",
      "          89    1.00000   0.85000   0.91892        20\n",
      "          90    1.00000   0.72727   0.84211        22\n",
      "          91    0.81818   0.94737   0.87805        19\n",
      "          92    1.00000   0.83333   0.90909        12\n",
      "          93    1.00000   0.84211   0.91429        19\n",
      "          94    0.50000   0.60000   0.54545        25\n",
      "          95    0.80952   1.00000   0.89474        17\n",
      "          96    0.88889   0.57143   0.69565        28\n",
      "          97    0.70000   0.73684   0.71795        19\n",
      "          98    0.60000   0.85714   0.70588        21\n",
      "          99    0.58824   0.83333   0.68966        24\n",
      "         100    0.88889   0.53333   0.66667        15\n",
      "         101    1.00000   0.76471   0.86667        17\n",
      "         102    0.93333   0.56000   0.70000        25\n",
      "         103    1.00000   1.00000   1.00000        21\n",
      "         104    0.40000   0.75000   0.52174        16\n",
      "         105    0.57895   0.73333   0.64706        15\n",
      "         106    1.00000   0.93333   0.96552        15\n",
      "         107    1.00000   0.72222   0.83871        18\n",
      "         108    0.87500   0.63636   0.73684        22\n",
      "         109    0.87500   0.60870   0.71795        23\n",
      "         110    1.00000   0.92857   0.96296        28\n",
      "         111    0.62857   0.91667   0.74576        24\n",
      "         112    1.00000   0.47059   0.64000        17\n",
      "         113    1.00000   0.36842   0.53846        19\n",
      "         114    1.00000   0.85714   0.92308        14\n",
      "         115    0.20000   0.26316   0.22727        19\n",
      "         116    1.00000   0.76471   0.86667        17\n",
      "         117    0.75000   0.81818   0.78261        11\n",
      "         118    0.40000   0.35294   0.37500        17\n",
      "         119    0.93333   0.56000   0.70000        25\n",
      "         120    1.00000   0.72727   0.84211        22\n",
      "         121    0.55556   0.53571   0.54545        28\n",
      "         122    0.85714   0.85714   0.85714        14\n",
      "         123    1.00000   1.00000   1.00000        18\n",
      "         124    1.00000   0.79167   0.88372        24\n",
      "         125    1.00000   1.00000   1.00000        16\n",
      "         126    1.00000   0.94118   0.96970        17\n",
      "         127    1.00000   0.95455   0.97674        22\n",
      "         128    1.00000   0.95455   0.97674        22\n",
      "\n",
      "    accuracy                        0.79225      2580\n",
      "   macro avg    0.88174   0.79752   0.81911      2580\n",
      "weighted avg    0.88346   0.79225   0.81766      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3faff65-54f8-47d3-9a49-d28c736efb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ea22478172a15f4d285a38099e43e6726f3ab0af87c7dd16fc299baaec68f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
